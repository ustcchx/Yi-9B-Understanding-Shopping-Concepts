06/25/2024 02:01:43 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:43 - INFO - llmtuner.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, compute dtype: torch.float16
[INFO|tokenization_utils_base.py:2082] 2024-06-25 02:01:43,633 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2082] 2024-06-25 02:01:43,634 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2082] 2024-06-25 02:01:43,634 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2082] 2024-06-25 02:01:43,634 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2082] 2024-06-25 02:01:43,634 >> loading file tokenizer_config.json
06/25/2024 02:01:44 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:44 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
06/25/2024 02:01:44 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:44 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:44 - INFO - llmtuner.hparams.parser - Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, compute dtype: torch.float16
06/25/2024 02:01:44 - INFO - llmtuner.hparams.parser - Process rank: 5, device: cuda:5, n_gpu: 1, distributed training: True, compute dtype: torch.float16
06/25/2024 02:01:44 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:44 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:44 - INFO - llmtuner.hparams.parser - Process rank: 4, device: cuda:4, n_gpu: 1, distributed training: True, compute dtype: torch.float16
06/25/2024 02:01:44 - INFO - llmtuner.hparams.parser - Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, compute dtype: torch.float16
06/25/2024 02:01:44 - WARNING - llmtuner.hparams.parser - `ddp_find_unused_parameters` needs to be set as False for LoRA in DDP training.
06/25/2024 02:01:44 - INFO - llmtuner.hparams.parser - Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, compute dtype: torch.float16
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 8851 examples [00:00, 134268.09 examples/s]
Converting format of dataset (num_proc=6):   0%|          | 0/8851 [00:00<?, ? examples/s]Converting format of dataset (num_proc=6):  17%|█▋        | 1476/8851 [00:00<00:01, 6159.21 examples/s]Converting format of dataset (num_proc=6): 100%|██████████| 8851/8851 [00:00<00:00, 24519.01 examples/s]
06/25/2024 02:01:56 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:56 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
06/25/2024 02:01:56 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:56 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:56 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
06/25/2024 02:01:56 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:56 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
06/25/2024 02:01:56 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
06/25/2024 02:01:56 - INFO - llmtuner.data.loader - Loading dataset SFT-shopping-data.json...
06/25/2024 02:01:56 - WARNING - llmtuner.data.utils - Checksum failed: missing SHA-1 hash value in dataset_info.json.
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
Running tokenizer on dataset (num_proc=6):   0%|          | 0/8851 [00:00<?, ? examples/s]The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
Running tokenizer on dataset (num_proc=6):  11%|█▏        | 1000/8851 [00:02<00:16, 467.14 examples/s]Running tokenizer on dataset (num_proc=6):  23%|██▎       | 2000/8851 [00:02<00:06, 1013.70 examples/s]Running tokenizer on dataset (num_proc=6):  68%|██████▊   | 6000/8851 [00:02<00:00, 3881.75 examples/s]Running tokenizer on dataset (num_proc=6):  84%|████████▍ | 7426/8851 [00:02<00:00, 3532.87 examples/s]Running tokenizer on dataset (num_proc=6): 100%|██████████| 8851/8851 [00:03<00:00, 4191.83 examples/s]Running tokenizer on dataset (num_proc=6): 100%|██████████| 8851/8851 [00:03<00:00, 2727.12 examples/s]
input_ids:
[45752, 59601, 26965, 1879, 567, 1156, 3674, 14863, 5314, 594, 567, 1926, 1774, 6451, 631, 562, 11293, 59601, 144, 59592, 1263, 57258, 59840, 11293, 28538, 562, 5735, 15315, 97, 21596, 1715, 97, 597, 562, 14132, 3996, 631, 663, 53469, 6138, 2157, 98, 59592, 144, 13669, 59601, 59568, 144, 8377, 13611, 59601, 59568, 10971, 1262, 15315, 2]
inputs:
Human: Identify the most positive attribute mentioned in the following product description for a laptop:
"The XYZ laptop boasts a powerful processor, lightweight design, and a stunning display for an immersive visual experience."
Output: 
Assistant: powerful processor<|endoftext|>
label_ids:
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 10971, 1262, 15315, 2]
labels:
powerful processor<|endoftext|>
[INFO|configuration_utils.py:724] 2024-06-25 02:02:06,845 >> loading configuration file Yi-9B-post-pt/config.json
[INFO|configuration_utils.py:789] 2024-06-25 02:02:06,847 >> Model config LlamaConfig {
  "_name_or_path": "Yi-9B-post-pt",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 48,
  "num_key_value_heads": 4,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 10000,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.39.0",
  "use_cache": true,
  "vocab_size": 64000
}

The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
[INFO|modeling_utils.py:3280] 2024-06-25 02:02:08,312 >> loading weights file Yi-9B-post-pt/model.safetensors.index.json
[INFO|modeling_utils.py:1417] 2024-06-25 02:02:08,330 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.
[INFO|configuration_utils.py:928] 2024-06-25 02:02:08,332 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:05, 21.87s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.69s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.70s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.66s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.71s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.71s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:36, 18.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.52s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.56s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:38<00:37, 18.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:58<00:19, 19.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.65s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:59<00:19, 19.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.28s/it]
06/25/2024 02:03:18 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:18 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:18 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
06/25/2024 02:03:18 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.95s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.39s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.40s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.39s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.40s/it]
06/25/2024 02:03:18 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:18 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:18 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 15.94s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:09<00:00, 17.39s/it]
[INFO|modeling_utils.py:4024] 2024-06-25 02:03:18,946 >> All model checkpoint weights were used when initializing LlamaForCausalLM.

[INFO|modeling_utils.py:4032] 2024-06-25 02:03:18,946 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at Yi-9B-post-pt.
If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.
[INFO|configuration_utils.py:881] 2024-06-25 02:03:18,950 >> loading configuration file Yi-9B-post-pt/generation_config.json
[INFO|configuration_utils.py:928] 2024-06-25 02:03:18,950 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "pad_token_id": 0
}

06/25/2024 02:03:19 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:19 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:19 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:19 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.checkpointing - Gradient checkpointing enabled.
06/25/2024 02:03:19 - INFO - llmtuner.model.utils.attention - Using torch SDPA for faster training and inference.
06/25/2024 02:03:19 - INFO - llmtuner.model.adapter - Fine-tuning method: LoRA
06/25/2024 02:03:19 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
06/25/2024 02:03:19 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
06/25/2024 02:03:19 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
06/25/2024 02:03:19 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
06/25/2024 02:03:19 - INFO - llmtuner.model.loader - trainable params: 2457600 || all params: 8831864832 || trainable%: 0.0278
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:607] 2024-06-25 02:03:19,138 >> Using auto half precision backend
[INFO|trainer.py:1969] 2024-06-25 02:03:21,317 >> ***** Running training *****
[INFO|trainer.py:1970] 2024-06-25 02:03:21,317 >>   Num examples = 8,408
[INFO|trainer.py:1971] 2024-06-25 02:03:21,317 >>   Num Epochs = 25
[INFO|trainer.py:1972] 2024-06-25 02:03:21,317 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1975] 2024-06-25 02:03:21,317 >>   Total train batch size (w. parallel, distributed & accumulation) = 12
[INFO|trainer.py:1976] 2024-06-25 02:03:21,317 >>   Gradient Accumulation steps = 2
[INFO|trainer.py:1977] 2024-06-25 02:03:21,317 >>   Total optimization steps = 17,525
[INFO|trainer.py:1978] 2024-06-25 02:03:21,319 >>   Number of trainable parameters = 2,457,600
  0%|          | 0/17525 [00:00<?, ?it/s]  0%|          | 1/17525 [00:04<23:48:29,  4.89s/it]  0%|          | 2/17525 [00:05<11:41:10,  2.40s/it]  0%|          | 3/17525 [00:06<7:43:32,  1.59s/it]   0%|          | 4/17525 [00:06<6:09:40,  1.27s/it]  0%|          | 5/17525 [00:07<4:59:38,  1.03s/it]  0%|          | 6/17525 [00:08<4:16:44,  1.14it/s]  0%|          | 7/17525 [00:08<4:01:25,  1.21it/s]  0%|          | 8/17525 [00:09<3:39:44,  1.33it/s]  0%|          | 9/17525 [00:10<3:26:14,  1.42it/s]  0%|          | 10/17525 [00:10<3:16:28,  1.49it/s]                                                    {'loss': 3.4719, 'grad_norm': 6.456544876098633, 'learning_rate': 7e-06, 'epoch': 0.01}
  0%|          | 10/17525 [00:10<3:16:28,  1.49it/s]  0%|          | 11/17525 [00:11<3:11:54,  1.52it/s]  0%|          | 12/17525 [00:11<3:07:27,  1.56it/s]  0%|          | 13/17525 [00:12<3:04:14,  1.58it/s]  0%|          | 14/17525 [00:13<3:02:07,  1.60it/s]  0%|          | 15/17525 [00:15<4:57:39,  1.02s/it]  0%|          | 16/17525 [00:15<4:20:52,  1.12it/s]  0%|          | 17/17525 [00:16<3:54:25,  1.24it/s]  0%|          | 18/17525 [00:16<3:36:38,  1.35it/s]  0%|          | 19/17525 [00:17<3:24:06,  1.43it/s]  0%|          | 20/17525 [00:18<3:14:49,  1.50it/s]                                                    {'loss': 3.7285, 'grad_norm': 8.432818412780762, 'learning_rate': 1.7e-05, 'epoch': 0.03}
  0%|          | 20/17525 [00:18<3:14:49,  1.50it/s]  0%|          | 21/17525 [00:18<3:08:57,  1.54it/s]  0%|          | 22/17525 [00:19<3:04:36,  1.58it/s]  0%|          | 23/17525 [00:19<3:01:12,  1.61it/s]  0%|          | 24/17525 [00:20<2:58:45,  1.63it/s]  0%|          | 25/17525 [00:21<2:57:08,  1.65it/s]  0%|          | 26/17525 [00:21<2:56:11,  1.66it/s]  0%|          | 27/17525 [00:22<3:08:24,  1.55it/s]  0%|          | 28/17525 [00:22<3:03:52,  1.59it/s]  0%|          | 29/17525 [00:23<3:00:58,  1.61it/s]  0%|          | 30/17525 [00:24<3:24:40,  1.42it/s]                                                    {'loss': 3.0281, 'grad_norm': 7.079733848571777, 'learning_rate': 1.9999994202403607e-05, 'epoch': 0.04}
  0%|          | 30/17525 [00:24<3:24:40,  1.42it/s]  0%|          | 31/17525 [00:25<3:15:33,  1.49it/s]  0%|          | 32/17525 [00:25<3:08:42,  1.54it/s]  0%|          | 33/17525 [00:26<3:03:25,  1.59it/s]  0%|          | 34/17525 [00:26<3:00:00,  1.62it/s]  0%|          | 35/17525 [00:27<2:57:47,  1.64it/s]  0%|          | 36/17525 [00:27<2:56:21,  1.65it/s]  0%|          | 37/17525 [00:28<2:54:57,  1.67it/s]  0%|          | 38/17525 [00:29<2:53:51,  1.68it/s]  0%|          | 39/17525 [00:29<2:53:33,  1.68it/s]  0%|          | 40/17525 [00:30<2:52:55,  1.69it/s]                                                    {'loss': 3.1756, 'grad_norm': 6.374765396118164, 'learning_rate': 1.9999958772672196e-05, 'epoch': 0.06}
  0%|          | 40/17525 [00:30<2:52:55,  1.69it/s]  0%|          | 41/17525 [00:30<2:53:00,  1.68it/s]  0%|          | 42/17525 [00:31<2:52:03,  1.69it/s]  0%|          | 43/17525 [00:32<2:52:04,  1.69it/s]  0%|          | 44/17525 [00:32<2:51:51,  1.70it/s]  0%|          | 45/17525 [00:33<2:51:35,  1.70it/s]  0%|          | 46/17525 [00:33<2:51:33,  1.70it/s]  0%|          | 47/17525 [00:35<3:57:34,  1.23it/s]  0%|          | 48/17525 [00:35<3:38:03,  1.34it/s]  0%|          | 49/17525 [00:36<3:24:06,  1.43it/s]  0%|          | 50/17525 [00:36<3:14:42,  1.50it/s]                                                    {'loss': 2.6799, 'grad_norm': 8.425003051757812, 'learning_rate': 1.9999891134210246e-05, 'epoch': 0.07}
  0%|          | 50/17525 [00:36<3:14:42,  1.50it/s]  0%|          | 51/17525 [00:37<3:07:54,  1.55it/s]  0%|          | 52/17525 [00:38<3:02:37,  1.59it/s]  0%|          | 53/17525 [00:38<2:59:42,  1.62it/s]  0%|          | 54/17525 [00:39<2:56:50,  1.65it/s]  0%|          | 55/17525 [00:39<2:54:37,  1.67it/s]  0%|          | 56/17525 [00:40<2:53:32,  1.68it/s]  0%|          | 57/17525 [00:41<2:52:25,  1.69it/s]  0%|          | 58/17525 [00:41<2:52:17,  1.69it/s]  0%|          | 59/17525 [00:42<2:51:53,  1.69it/s]  0%|          | 60/17525 [00:42<2:51:23,  1.70it/s]                                                    {'loss': 2.0943, 'grad_norm': 6.868257999420166, 'learning_rate': 1.9999791287235605e-05, 'epoch': 0.09}
  0%|          | 60/17525 [00:42<2:51:23,  1.70it/s]  0%|          | 61/17525 [00:43<2:52:02,  1.69it/s]  0%|          | 62/17525 [00:44<2:51:32,  1.70it/s]  0%|          | 63/17525 [00:44<2:51:15,  1.70it/s]  0%|          | 64/17525 [00:45<2:52:08,  1.69it/s]  0%|          | 65/17525 [00:45<2:51:59,  1.69it/s]  0%|          | 66/17525 [00:46<2:51:41,  1.69it/s]  0%|          | 67/17525 [00:46<2:51:29,  1.70it/s]  0%|          | 68/17525 [00:47<2:51:32,  1.70it/s]  0%|          | 69/17525 [00:48<2:51:11,  1.70it/s]  0%|          | 70/17525 [00:48<2:51:07,  1.70it/s]                                                    {'loss': 2.0003, 'grad_norm': 9.501016616821289, 'learning_rate': 1.999965923206987e-05, 'epoch': 0.1}
  0%|          | 70/17525 [00:48<2:51:07,  1.70it/s]  0%|          | 71/17525 [00:49<3:01:49,  1.60it/s]  0%|          | 72/17525 [00:50<2:58:50,  1.63it/s]  0%|          | 73/17525 [00:50<2:56:54,  1.64it/s]  0%|          | 74/17525 [00:51<3:31:02,  1.38it/s]  0%|          | 75/17525 [00:52<3:19:08,  1.46it/s]  0%|          | 76/17525 [00:52<3:10:48,  1.52it/s]  0%|          | 77/17525 [00:53<3:05:04,  1.57it/s]  0%|          | 78/17525 [00:54<3:01:06,  1.61it/s]  0%|          | 79/17525 [00:54<2:58:03,  1.63it/s]  0%|          | 80/17525 [00:55<2:56:11,  1.65it/s]                                                    {'loss': 1.5489, 'grad_norm': 6.109951496124268, 'learning_rate': 1.999949496913838e-05, 'epoch': 0.11}
  0%|          | 80/17525 [00:55<2:56:11,  1.65it/s]  0%|          | 81/17525 [00:55<2:55:19,  1.66it/s]  0%|          | 82/17525 [00:56<2:55:06,  1.66it/s]  0%|          | 83/17525 [00:56<2:53:52,  1.67it/s]  0%|          | 84/17525 [00:57<2:53:02,  1.68it/s]  0%|          | 85/17525 [00:58<2:52:25,  1.69it/s]  0%|          | 86/17525 [00:59<3:22:18,  1.44it/s]  0%|          | 87/17525 [00:59<3:13:10,  1.50it/s]  1%|          | 88/17525 [01:00<3:08:10,  1.54it/s]  1%|          | 89/17525 [01:00<3:05:12,  1.57it/s]  1%|          | 90/17525 [01:01<3:00:49,  1.61it/s]                                                    {'loss': 1.5431, 'grad_norm': 5.975345611572266, 'learning_rate': 1.9999298498970204e-05, 'epoch': 0.13}
  1%|          | 90/17525 [01:01<3:00:49,  1.61it/s]  1%|          | 91/17525 [01:02<2:58:15,  1.63it/s]  1%|          | 92/17525 [01:02<2:55:57,  1.65it/s]  1%|          | 93/17525 [01:03<2:55:04,  1.66it/s]  1%|          | 94/17525 [01:03<2:54:12,  1.67it/s]  1%|          | 95/17525 [01:04<2:53:16,  1.68it/s]  1%|          | 96/17525 [01:05<2:52:31,  1.68it/s]  1%|          | 97/17525 [01:05<2:51:42,  1.69it/s]  1%|          | 98/17525 [01:06<2:51:30,  1.69it/s]  1%|          | 99/17525 [01:06<2:51:20,  1.70it/s]  1%|          | 100/17525 [01:07<2:51:41,  1.69it/s]                                                     {'loss': 1.0174, 'grad_norm': 7.176097869873047, 'learning_rate': 1.9999069822198146e-05, 'epoch': 0.14}
  1%|          | 100/17525 [01:07<2:51:41,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:04:28,787 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:04:28,787 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:04:28,787 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.88it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.08it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.43it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.67it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.91it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.36it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.62it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.72it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.76it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.86it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.92it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.07it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.18it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.23it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.62it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.03it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.78it/s][A                                                     
                                               [A{'eval_loss': 1.2390289306640625, 'eval_runtime': 4.616, 'eval_samples_per_second': 95.97, 'eval_steps_per_second': 4.116, 'epoch': 0.14}
  1%|          | 100/17525 [01:12<2:51:41,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.78it/s][A
                                               [A  1%|          | 101/17525 [01:12<9:34:13,  1.98s/it]  1%|          | 102/17525 [01:13<7:33:15,  1.56s/it]  1%|          | 103/17525 [01:13<6:08:23,  1.27s/it]  1%|          | 104/17525 [01:14<5:08:53,  1.06s/it]  1%|          | 105/17525 [01:14<4:27:11,  1.09it/s]  1%|          | 106/17525 [01:15<3:58:06,  1.22it/s]  1%|          | 107/17525 [01:16<3:37:43,  1.33it/s]  1%|          | 108/17525 [01:16<3:23:28,  1.43it/s]  1%|          | 109/17525 [01:17<3:13:19,  1.50it/s]  1%|          | 110/17525 [01:17<3:06:09,  1.56it/s]                                                     {'loss': 1.1697, 'grad_norm': 2.6476800441741943, 'learning_rate': 1.9998808939558755e-05, 'epoch': 0.16}
  1%|          | 110/17525 [01:17<3:06:09,  1.56it/s]  1%|          | 111/17525 [01:18<3:01:30,  1.60it/s]  1%|          | 112/17525 [01:19<2:58:01,  1.63it/s]  1%|          | 113/17525 [01:19<2:55:39,  1.65it/s]  1%|          | 114/17525 [01:20<2:54:40,  1.66it/s]  1%|          | 115/17525 [01:20<2:53:45,  1.67it/s]  1%|          | 116/17525 [01:21<2:52:40,  1.68it/s]  1%|          | 117/17525 [01:21<2:52:08,  1.69it/s]  1%|          | 118/17525 [01:22<2:51:48,  1.69it/s]  1%|          | 119/17525 [01:23<2:51:10,  1.69it/s]  1%|          | 120/17525 [01:23<2:50:54,  1.70it/s]                                                     {'loss': 1.0533, 'grad_norm': 4.9202752113342285, 'learning_rate': 1.99985158518923e-05, 'epoch': 0.17}
  1%|          | 120/17525 [01:23<2:50:54,  1.70it/s]  1%|          | 121/17525 [01:24<2:51:30,  1.69it/s]  1%|          | 122/17525 [01:24<2:51:06,  1.70it/s]  1%|          | 123/17525 [01:25<3:02:09,  1.59it/s]  1%|          | 124/17525 [01:26<2:59:45,  1.61it/s]  1%|          | 125/17525 [01:26<2:57:16,  1.64it/s]  1%|          | 126/17525 [01:27<2:55:01,  1.66it/s]  1%|          | 127/17525 [01:28<2:53:50,  1.67it/s]  1%|          | 128/17525 [01:28<2:53:16,  1.67it/s]  1%|          | 129/17525 [01:29<2:52:53,  1.68it/s]  1%|          | 130/17525 [01:29<2:52:23,  1.68it/s]                                                     {'loss': 1.1796, 'grad_norm': 2.5650596618652344, 'learning_rate': 1.9998190560142787e-05, 'epoch': 0.19}
  1%|          | 130/17525 [01:29<2:52:23,  1.68it/s]  1%|          | 131/17525 [01:30<2:52:57,  1.68it/s]  1%|          | 132/17525 [01:30<2:52:45,  1.68it/s]  1%|          | 133/17525 [01:31<2:52:34,  1.68it/s]  1%|          | 134/17525 [01:32<2:52:32,  1.68it/s]  1%|          | 135/17525 [01:32<2:52:40,  1.68it/s]  1%|          | 136/17525 [01:33<2:52:51,  1.68it/s]  1%|          | 137/17525 [01:33<2:52:08,  1.68it/s]  1%|          | 138/17525 [01:34<2:54:40,  1.66it/s]  1%|          | 139/17525 [01:35<2:53:40,  1.67it/s]  1%|          | 140/17525 [01:35<2:53:11,  1.67it/s]                                                     {'loss': 1.1106, 'grad_norm': 4.1062331199646, 'learning_rate': 1.9997833065357937e-05, 'epoch': 0.2}
  1%|          | 140/17525 [01:35<2:53:11,  1.67it/s]  1%|          | 141/17525 [01:36<2:53:38,  1.67it/s]  1%|          | 142/17525 [01:36<2:52:51,  1.68it/s]  1%|          | 143/17525 [01:37<2:52:14,  1.68it/s]  1%|          | 144/17525 [01:38<2:52:05,  1.68it/s]  1%|          | 145/17525 [01:38<2:52:03,  1.68it/s]  1%|          | 146/17525 [01:39<2:53:29,  1.67it/s]  1%|          | 147/17525 [01:39<2:53:12,  1.67it/s]  1%|          | 148/17525 [01:40<2:52:25,  1.68it/s]  1%|          | 149/17525 [01:41<2:51:34,  1.69it/s]  1%|          | 150/17525 [01:41<2:50:39,  1.70it/s]                                                     {'loss': 0.8956, 'grad_norm': 3.1632912158966064, 'learning_rate': 1.9997443368689207e-05, 'epoch': 0.21}
  1%|          | 150/17525 [01:41<2:50:39,  1.70it/s][INFO|trainer.py:3203] 2024-06-25 02:05:03,325 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b283d94da50>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 811abc40-c250-4efa-bdf4-6ee8e9b37c8e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:05:13,465 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:05:13,469 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  1%|          | 151/17525 [01:52<18:07:19,  3.76s/it]  1%|          | 152/17525 [01:53<13:44:08,  2.85s/it]  1%|          | 153/17525 [01:54<10:27:49,  2.17s/it]  1%|          | 154/17525 [01:54<8:10:37,  1.69s/it]   1%|          | 155/17525 [01:55<6:34:38,  1.36s/it]  1%|          | 156/17525 [01:56<5:57:42,  1.24s/it]  1%|          | 157/17525 [01:56<5:01:10,  1.04s/it]  1%|          | 158/17525 [01:57<4:22:08,  1.10it/s]  1%|          | 159/17525 [01:58<3:54:22,  1.23it/s]  1%|          | 160/17525 [01:58<3:35:03,  1.35it/s]                                                     {'loss': 1.105, 'grad_norm': 5.885013103485107, 'learning_rate': 1.999702147139176e-05, 'epoch': 0.23}
  1%|          | 160/17525 [01:58<3:35:03,  1.35it/s]  1%|          | 161/17525 [01:59<3:22:55,  1.43it/s]  1%|          | 162/17525 [01:59<3:13:19,  1.50it/s]  1%|          | 163/17525 [02:00<3:08:00,  1.54it/s]  1%|          | 164/17525 [02:01<3:03:15,  1.58it/s]  1%|          | 165/17525 [02:01<2:59:24,  1.61it/s]  1%|          | 166/17525 [02:02<2:56:29,  1.64it/s]  1%|          | 167/17525 [02:02<2:54:35,  1.66it/s]  1%|          | 168/17525 [02:03<2:52:54,  1.67it/s]  1%|          | 169/17525 [02:03<2:51:57,  1.68it/s]  1%|          | 170/17525 [02:04<2:51:32,  1.69it/s]                                                     {'loss': 1.0093, 'grad_norm': 4.933262825012207, 'learning_rate': 1.999656737482449e-05, 'epoch': 0.24}
  1%|          | 170/17525 [02:04<2:51:32,  1.69it/s]  1%|          | 171/17525 [02:05<2:51:27,  1.69it/s]  1%|          | 172/17525 [02:05<2:50:57,  1.69it/s]  1%|          | 173/17525 [02:06<2:50:45,  1.69it/s]  1%|          | 174/17525 [02:06<2:50:52,  1.69it/s]  1%|          | 175/17525 [02:07<2:50:35,  1.70it/s]  1%|          | 176/17525 [02:08<2:51:01,  1.69it/s]  1%|          | 177/17525 [02:08<2:50:46,  1.69it/s]  1%|          | 178/17525 [02:09<2:50:22,  1.70it/s]  1%|          | 179/17525 [02:09<2:50:08,  1.70it/s]  1%|          | 180/17525 [02:10<2:49:42,  1.70it/s]                                                     {'loss': 0.9853, 'grad_norm': 5.110368251800537, 'learning_rate': 1.9996081080449974e-05, 'epoch': 0.26}
  1%|          | 180/17525 [02:10<2:49:42,  1.70it/s]  1%|          | 181/17525 [02:11<2:50:10,  1.70it/s]  1%|          | 182/17525 [02:11<2:49:56,  1.70it/s]  1%|          | 183/17525 [02:12<2:49:47,  1.70it/s]  1%|          | 184/17525 [02:12<2:49:35,  1.70it/s]  1%|          | 185/17525 [02:13<2:49:43,  1.70it/s]  1%|          | 186/17525 [02:13<2:49:30,  1.70it/s]  1%|          | 187/17525 [02:14<2:49:27,  1.71it/s]  1%|          | 188/17525 [02:15<2:50:04,  1.70it/s]  1%|          | 189/17525 [02:15<2:49:36,  1.70it/s]  1%|          | 190/17525 [02:16<2:51:11,  1.69it/s]                                                     {'loss': 0.9188, 'grad_norm': 3.146162271499634, 'learning_rate': 1.999556258983452e-05, 'epoch': 0.27}
  1%|          | 190/17525 [02:16<2:51:11,  1.69it/s]  1%|          | 191/17525 [02:16<2:51:04,  1.69it/s]  1%|          | 192/17525 [02:17<2:50:37,  1.69it/s]  1%|          | 193/17525 [02:18<2:50:18,  1.70it/s]  1%|          | 194/17525 [02:18<2:50:12,  1.70it/s]  1%|          | 195/17525 [02:19<2:49:42,  1.70it/s]  1%|          | 196/17525 [02:19<2:49:30,  1.70it/s]  1%|          | 197/17525 [02:20<2:49:31,  1.70it/s]  1%|          | 198/17525 [02:21<2:49:54,  1.70it/s]  1%|          | 199/17525 [02:21<2:49:55,  1.70it/s]  1%|          | 200/17525 [02:22<2:50:32,  1.69it/s]                                                     {'loss': 0.9745, 'grad_norm': 4.080647945404053, 'learning_rate': 1.9995011904648133e-05, 'epoch': 0.29}
  1%|          | 200/17525 [02:22<2:50:32,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:05:43,621 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:05:43,621 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:05:43,621 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 1.08811616897583, 'eval_runtime': 4.5982, 'eval_samples_per_second': 96.342, 'eval_steps_per_second': 4.132, 'epoch': 0.29}
  1%|          | 200/17525 [02:26<2:50:32,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  1%|          | 201/17525 [02:27<9:29:51,  1.97s/it]  1%|          | 202/17525 [02:28<7:29:32,  1.56s/it]  1%|          | 203/17525 [02:28<6:05:36,  1.27s/it]  1%|          | 204/17525 [02:29<5:06:29,  1.06s/it]  1%|          | 205/17525 [02:30<4:56:25,  1.03s/it]  1%|          | 206/17525 [02:30<4:18:04,  1.12it/s]  1%|          | 207/17525 [02:31<3:51:19,  1.25it/s]  1%|          | 208/17525 [02:31<3:32:26,  1.36it/s]  1%|          | 209/17525 [02:32<3:19:22,  1.45it/s]  1%|          | 210/17525 [02:33<3:10:27,  1.52it/s]                                                     {'loss': 0.8739, 'grad_norm': 9.584779739379883, 'learning_rate': 1.9994429026664498e-05, 'epoch': 0.3}
  1%|          | 210/17525 [02:33<3:10:27,  1.52it/s]  1%|          | 211/17525 [02:33<3:04:07,  1.57it/s]  1%|          | 212/17525 [02:34<2:59:26,  1.61it/s]  1%|          | 213/17525 [02:34<2:56:13,  1.64it/s]  1%|          | 214/17525 [02:35<2:53:52,  1.66it/s]  1%|          | 215/17525 [02:35<2:52:35,  1.67it/s]  1%|          | 216/17525 [02:36<2:51:47,  1.68it/s]  1%|          | 217/17525 [02:37<2:50:56,  1.69it/s]  1%|          | 218/17525 [02:37<2:50:22,  1.69it/s]  1%|          | 219/17525 [02:38<2:51:34,  1.68it/s]  1%|▏         | 220/17525 [02:38<2:50:36,  1.69it/s]                                                     {'loss': 0.9814, 'grad_norm': 8.148241996765137, 'learning_rate': 1.9993813957761e-05, 'epoch': 0.31}
  1%|▏         | 220/17525 [02:38<2:50:36,  1.69it/s]  1%|▏         | 221/17525 [02:39<2:50:12,  1.69it/s]  1%|▏         | 222/17525 [02:40<2:49:36,  1.70it/s]  1%|▏         | 223/17525 [02:40<2:49:21,  1.70it/s]  1%|▏         | 224/17525 [02:41<2:49:17,  1.70it/s]  1%|▏         | 225/17525 [02:41<2:49:01,  1.71it/s]  1%|▏         | 226/17525 [02:42<2:48:45,  1.71it/s]  1%|▏         | 227/17525 [02:43<2:48:34,  1.71it/s]  1%|▏         | 228/17525 [02:43<2:48:53,  1.71it/s]  1%|▏         | 229/17525 [02:44<2:48:23,  1.71it/s]  1%|▏         | 230/17525 [02:44<2:48:25,  1.71it/s]                                                     {'loss': 0.9311, 'grad_norm': 3.2149710655212402, 'learning_rate': 1.9993166699918714e-05, 'epoch': 0.33}
  1%|▏         | 230/17525 [02:44<2:48:25,  1.71it/s]  1%|▏         | 231/17525 [02:45<2:48:44,  1.71it/s]  1%|▏         | 232/17525 [02:45<2:48:43,  1.71it/s]  1%|▏         | 233/17525 [02:46<3:25:27,  1.40it/s]  1%|▏         | 234/17525 [02:47<3:15:01,  1.48it/s]  1%|▏         | 235/17525 [02:48<3:07:20,  1.54it/s]  1%|▏         | 236/17525 [02:48<3:01:52,  1.58it/s]  1%|▏         | 237/17525 [02:49<3:37:41,  1.32it/s]  1%|▏         | 238/17525 [02:50<3:23:18,  1.42it/s]  1%|▏         | 239/17525 [02:50<3:13:22,  1.49it/s]  1%|▏         | 240/17525 [02:51<3:06:24,  1.55it/s]                                                     {'loss': 0.7776, 'grad_norm': 5.085140228271484, 'learning_rate': 1.9992487255222374e-05, 'epoch': 0.34}
  1%|▏         | 240/17525 [02:51<3:06:24,  1.55it/s]  1%|▏         | 241/17525 [02:52<3:01:27,  1.59it/s]  1%|▏         | 242/17525 [02:52<2:57:50,  1.62it/s]  1%|▏         | 243/17525 [02:53<2:55:37,  1.64it/s]  1%|▏         | 244/17525 [02:53<2:53:30,  1.66it/s]  1%|▏         | 245/17525 [02:54<2:52:24,  1.67it/s]  1%|▏         | 246/17525 [02:55<2:51:29,  1.68it/s]  1%|▏         | 247/17525 [02:55<2:51:04,  1.68it/s]  1%|▏         | 248/17525 [02:56<2:51:09,  1.68it/s]  1%|▏         | 249/17525 [02:56<2:50:59,  1.68it/s]  1%|▏         | 250/17525 [02:57<2:50:35,  1.69it/s]                                                     {'loss': 0.8999, 'grad_norm': 2.8530538082122803, 'learning_rate': 1.9991775625860395e-05, 'epoch': 0.36}
  1%|▏         | 250/17525 [02:57<2:50:35,  1.69it/s]  1%|▏         | 251/17525 [02:58<2:50:12,  1.69it/s]  1%|▏         | 252/17525 [02:58<2:49:55,  1.69it/s]  1%|▏         | 253/17525 [02:59<2:49:51,  1.69it/s]  1%|▏         | 254/17525 [02:59<2:49:26,  1.70it/s]  1%|▏         | 255/17525 [03:00<2:49:05,  1.70it/s]  1%|▏         | 256/17525 [03:00<2:49:11,  1.70it/s]  1%|▏         | 257/17525 [03:01<2:48:47,  1.71it/s]  1%|▏         | 258/17525 [03:02<2:48:48,  1.70it/s]  1%|▏         | 259/17525 [03:02<2:48:54,  1.70it/s]  1%|▏         | 260/17525 [03:03<2:48:28,  1.71it/s]                                                     {'loss': 0.857, 'grad_norm': 3.6204874515533447, 'learning_rate': 1.999103181412486e-05, 'epoch': 0.37}
  1%|▏         | 260/17525 [03:03<2:48:28,  1.71it/s]  1%|▏         | 261/17525 [03:03<2:48:37,  1.71it/s]  1%|▏         | 262/17525 [03:04<2:59:23,  1.60it/s]  2%|▏         | 263/17525 [03:05<2:56:31,  1.63it/s]  2%|▏         | 264/17525 [03:05<2:54:32,  1.65it/s]  2%|▏         | 265/17525 [03:06<2:53:12,  1.66it/s]  2%|▏         | 266/17525 [03:06<2:52:21,  1.67it/s]  2%|▏         | 267/17525 [03:07<2:51:47,  1.67it/s]  2%|▏         | 268/17525 [03:08<2:51:18,  1.68it/s]  2%|▏         | 269/17525 [03:08<2:51:05,  1.68it/s]  2%|▏         | 270/17525 [03:09<2:50:58,  1.68it/s]                                                     {'loss': 0.8891, 'grad_norm': 3.897031784057617, 'learning_rate': 1.99902558224115e-05, 'epoch': 0.39}
  2%|▏         | 270/17525 [03:09<2:50:58,  1.68it/s]  2%|▏         | 271/17525 [03:09<2:51:11,  1.68it/s]  2%|▏         | 272/17525 [03:10<2:51:05,  1.68it/s]  2%|▏         | 273/17525 [03:11<2:51:04,  1.68it/s]  2%|▏         | 274/17525 [03:11<2:50:52,  1.68it/s]  2%|▏         | 275/17525 [03:12<2:50:46,  1.68it/s]  2%|▏         | 276/17525 [03:12<2:50:59,  1.68it/s]  2%|▏         | 277/17525 [03:13<2:50:56,  1.68it/s]  2%|▏         | 278/17525 [03:14<2:50:38,  1.68it/s]  2%|▏         | 279/17525 [03:14<2:50:16,  1.69it/s]  2%|▏         | 280/17525 [03:15<2:50:29,  1.69it/s]                                                     {'loss': 0.777, 'grad_norm': 8.871711730957031, 'learning_rate': 1.9989447653219694e-05, 'epoch': 0.4}
  2%|▏         | 280/17525 [03:15<2:50:29,  1.69it/s]  2%|▏         | 281/17525 [03:15<2:50:57,  1.68it/s]  2%|▏         | 282/17525 [03:16<2:50:52,  1.68it/s]  2%|▏         | 283/17525 [03:17<3:17:17,  1.46it/s]  2%|▏         | 284/17525 [03:17<3:09:28,  1.52it/s]  2%|▏         | 285/17525 [03:18<3:03:43,  1.56it/s]  2%|▏         | 286/17525 [03:19<2:59:24,  1.60it/s]  2%|▏         | 287/17525 [03:19<2:57:15,  1.62it/s]  2%|▏         | 288/17525 [03:20<2:55:16,  1.64it/s]  2%|▏         | 289/17525 [03:20<2:55:00,  1.64it/s]  2%|▏         | 290/17525 [03:21<2:53:29,  1.66it/s]                                                     {'loss': 0.8428, 'grad_norm': 3.8167014122009277, 'learning_rate': 1.9988607309152466e-05, 'epoch': 0.41}
  2%|▏         | 290/17525 [03:21<2:53:29,  1.66it/s]  2%|▏         | 291/17525 [03:22<2:52:23,  1.67it/s]  2%|▏         | 292/17525 [03:22<2:51:33,  1.67it/s]  2%|▏         | 293/17525 [03:23<2:51:22,  1.68it/s]  2%|▏         | 294/17525 [03:23<2:50:47,  1.68it/s]  2%|▏         | 295/17525 [03:24<2:50:30,  1.68it/s]  2%|▏         | 296/17525 [03:25<2:49:57,  1.69it/s]  2%|▏         | 297/17525 [03:25<2:50:09,  1.69it/s]  2%|▏         | 298/17525 [03:26<2:50:22,  1.69it/s]  2%|▏         | 299/17525 [03:26<2:49:58,  1.69it/s]  2%|▏         | 300/17525 [03:27<2:49:47,  1.69it/s]                                                     {'loss': 0.9435, 'grad_norm': 7.834965229034424, 'learning_rate': 1.9987734792916468e-05, 'epoch': 0.43}
  2%|▏         | 300/17525 [03:27<2:49:47,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:06:48,861 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:06:48,861 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:06:48,861 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 1.0405068397521973, 'eval_runtime': 4.5993, 'eval_samples_per_second': 96.319, 'eval_steps_per_second': 4.131, 'epoch': 0.43}
  2%|▏         | 300/17525 [03:32<2:49:47,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:06:53,464 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f2e0d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 1a36d662-1346-40e1-8f1d-eeb7bc1c45ef)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:07:03,520 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:07:03,523 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  2%|▏         | 301/17525 [03:42<24:03:05,  5.03s/it]  2%|▏         | 302/17525 [03:43<17:41:15,  3.70s/it]  2%|▏         | 303/17525 [03:44<13:13:54,  2.77s/it]  2%|▏         | 304/17525 [03:44<10:07:00,  2.11s/it]  2%|▏         | 305/17525 [03:45<7:55:42,  1.66s/it]   2%|▏         | 306/17525 [03:45<6:23:59,  1.34s/it]  2%|▏         | 307/17525 [03:46<5:50:20,  1.22s/it]  2%|▏         | 308/17525 [03:47<4:56:31,  1.03s/it]  2%|▏         | 309/17525 [03:48<4:29:05,  1.07it/s]  2%|▏         | 310/17525 [03:48<3:58:57,  1.20it/s]                                                     {'loss': 0.9446, 'grad_norm': 6.077687740325928, 'learning_rate': 1.9986830107321973e-05, 'epoch': 0.44}
  2%|▏         | 310/17525 [03:48<3:58:57,  1.20it/s]  2%|▏         | 311/17525 [03:49<3:38:02,  1.32it/s]  2%|▏         | 312/17525 [03:49<3:23:35,  1.41it/s]  2%|▏         | 313/17525 [03:50<3:13:32,  1.48it/s]  2%|▏         | 314/17525 [03:51<3:06:54,  1.53it/s]  2%|▏         | 315/17525 [03:51<3:01:30,  1.58it/s]  2%|▏         | 316/17525 [03:52<3:28:01,  1.38it/s]  2%|▏         | 317/17525 [03:53<3:33:34,  1.34it/s]  2%|▏         | 318/17525 [03:53<3:21:32,  1.42it/s]  2%|▏         | 319/17525 [03:54<3:12:04,  1.49it/s]  2%|▏         | 320/17525 [03:55<3:05:51,  1.54it/s]                                                     {'loss': 0.8536, 'grad_norm': 5.742436408996582, 'learning_rate': 1.998589325528287e-05, 'epoch': 0.46}
  2%|▏         | 320/17525 [03:55<3:05:51,  1.54it/s]  2%|▏         | 321/17525 [03:55<3:01:34,  1.58it/s]  2%|▏         | 322/17525 [03:56<2:58:09,  1.61it/s]  2%|▏         | 323/17525 [03:56<2:55:22,  1.63it/s]  2%|▏         | 324/17525 [03:57<2:54:24,  1.64it/s]  2%|▏         | 325/17525 [03:58<2:52:47,  1.66it/s]  2%|▏         | 326/17525 [03:58<2:51:40,  1.67it/s]  2%|▏         | 327/17525 [03:59<3:27:30,  1.38it/s]  2%|▏         | 328/17525 [04:00<3:16:09,  1.46it/s]  2%|▏         | 329/17525 [04:00<3:08:22,  1.52it/s]  2%|▏         | 330/17525 [04:01<3:02:50,  1.57it/s]                                                     {'loss': 0.8361, 'grad_norm': 7.199343681335449, 'learning_rate': 1.9984924239816662e-05, 'epoch': 0.47}
  2%|▏         | 330/17525 [04:01<3:02:50,  1.57it/s]  2%|▏         | 331/17525 [04:02<2:59:12,  1.60it/s]  2%|▏         | 332/17525 [04:02<2:56:49,  1.62it/s]  2%|▏         | 333/17525 [04:03<2:54:47,  1.64it/s]  2%|▏         | 334/17525 [04:04<3:07:26,  1.53it/s]  2%|▏         | 335/17525 [04:04<3:02:07,  1.57it/s]  2%|▏         | 336/17525 [04:05<2:58:20,  1.61it/s]  2%|▏         | 337/17525 [04:05<2:55:48,  1.63it/s]  2%|▏         | 338/17525 [04:06<2:54:19,  1.64it/s]  2%|▏         | 339/17525 [04:07<2:52:53,  1.66it/s]  2%|▏         | 340/17525 [04:07<2:51:45,  1.67it/s]                                                     {'loss': 0.9758, 'grad_norm': 3.2355334758758545, 'learning_rate': 1.998392306404443e-05, 'epoch': 0.49}
  2%|▏         | 340/17525 [04:07<2:51:45,  1.67it/s]  2%|▏         | 341/17525 [04:08<2:51:37,  1.67it/s]  2%|▏         | 342/17525 [04:08<2:51:05,  1.67it/s]  2%|▏         | 343/17525 [04:09<2:50:33,  1.68it/s]  2%|▏         | 344/17525 [04:09<2:50:19,  1.68it/s]  2%|▏         | 345/17525 [04:10<2:50:14,  1.68it/s]  2%|▏         | 346/17525 [04:11<2:49:54,  1.69it/s]  2%|▏         | 347/17525 [04:11<2:49:55,  1.68it/s]  2%|▏         | 348/17525 [04:12<2:49:38,  1.69it/s]  2%|▏         | 349/17525 [04:12<2:49:25,  1.69it/s]  2%|▏         | 350/17525 [04:13<2:49:17,  1.69it/s]                                                     {'loss': 0.8697, 'grad_norm': 4.512752532958984, 'learning_rate': 1.9982889731190842e-05, 'epoch': 0.5}
  2%|▏         | 350/17525 [04:13<2:49:17,  1.69it/s]  2%|▏         | 351/17525 [04:14<2:49:42,  1.69it/s]  2%|▏         | 352/17525 [04:14<2:49:46,  1.69it/s]  2%|▏         | 353/17525 [04:15<2:49:45,  1.69it/s]  2%|▏         | 354/17525 [04:15<2:49:17,  1.69it/s]  2%|▏         | 355/17525 [04:16<2:49:35,  1.69it/s]  2%|▏         | 356/17525 [04:17<2:49:21,  1.69it/s]  2%|▏         | 357/17525 [04:17<2:49:06,  1.69it/s]  2%|▏         | 358/17525 [04:18<2:48:55,  1.69it/s]  2%|▏         | 359/17525 [04:18<2:48:32,  1.70it/s]  2%|▏         | 360/17525 [04:19<2:48:24,  1.70it/s]                                                     {'loss': 0.9455, 'grad_norm': 4.560360431671143, 'learning_rate': 1.9981824244584156e-05, 'epoch': 0.51}
  2%|▏         | 360/17525 [04:19<2:48:24,  1.70it/s]  2%|▏         | 361/17525 [04:20<2:48:26,  1.70it/s]  2%|▏         | 362/17525 [04:20<2:48:29,  1.70it/s]  2%|▏         | 363/17525 [04:21<2:48:56,  1.69it/s]  2%|▏         | 364/17525 [04:21<2:48:58,  1.69it/s]  2%|▏         | 365/17525 [04:22<2:48:38,  1.70it/s]  2%|▏         | 366/17525 [04:22<2:48:45,  1.69it/s]  2%|▏         | 367/17525 [04:23<2:48:51,  1.69it/s]  2%|▏         | 368/17525 [04:24<3:16:48,  1.45it/s]  2%|▏         | 369/17525 [04:25<3:37:54,  1.31it/s]  2%|▏         | 370/17525 [04:26<3:23:32,  1.40it/s]                                                     {'loss': 0.8333, 'grad_norm': 5.558557033538818, 'learning_rate': 1.998072660765618e-05, 'epoch': 0.53}
  2%|▏         | 370/17525 [04:26<3:23:32,  1.40it/s]  2%|▏         | 371/17525 [04:26<3:13:24,  1.48it/s]  2%|▏         | 372/17525 [04:27<3:06:16,  1.53it/s]  2%|▏         | 373/17525 [04:27<3:01:15,  1.58it/s]  2%|▏         | 374/17525 [04:28<2:59:10,  1.60it/s]  2%|▏         | 375/17525 [04:29<2:57:02,  1.61it/s]  2%|▏         | 376/17525 [04:29<2:54:35,  1.64it/s]  2%|▏         | 377/17525 [04:30<2:52:54,  1.65it/s]  2%|▏         | 378/17525 [04:30<2:52:00,  1.66it/s]  2%|▏         | 379/17525 [04:31<2:50:55,  1.67it/s]  2%|▏         | 380/17525 [04:31<2:50:26,  1.68it/s]                                                     {'loss': 0.968, 'grad_norm': 2.599428653717041, 'learning_rate': 1.9979596823942277e-05, 'epoch': 0.54}
  2%|▏         | 380/17525 [04:31<2:50:26,  1.68it/s]  2%|▏         | 381/17525 [04:32<2:50:22,  1.68it/s]  2%|▏         | 382/17525 [04:33<2:49:56,  1.68it/s]  2%|▏         | 383/17525 [04:33<2:49:52,  1.68it/s]  2%|▏         | 384/17525 [04:34<3:19:06,  1.43it/s]  2%|▏         | 385/17525 [04:35<3:10:20,  1.50it/s]  2%|▏         | 386/17525 [04:35<3:03:58,  1.55it/s]  2%|▏         | 387/17525 [04:36<2:59:50,  1.59it/s]  2%|▏         | 388/17525 [04:37<2:56:31,  1.62it/s]  2%|▏         | 389/17525 [04:37<2:54:21,  1.64it/s]  2%|▏         | 390/17525 [04:38<2:52:18,  1.66it/s]                                                     {'loss': 0.9233, 'grad_norm': 4.9356913566589355, 'learning_rate': 1.997843489708135e-05, 'epoch': 0.56}
  2%|▏         | 390/17525 [04:38<2:52:18,  1.66it/s]  2%|▏         | 391/17525 [04:38<2:51:30,  1.66it/s]  2%|▏         | 392/17525 [04:39<2:50:50,  1.67it/s]  2%|▏         | 393/17525 [04:40<2:50:11,  1.68it/s]  2%|▏         | 394/17525 [04:40<2:49:41,  1.68it/s]  2%|▏         | 395/17525 [04:41<2:49:38,  1.68it/s]  2%|▏         | 396/17525 [04:41<2:49:13,  1.69it/s]  2%|▏         | 397/17525 [04:42<2:48:48,  1.69it/s]  2%|▏         | 398/17525 [04:42<2:48:57,  1.69it/s]  2%|▏         | 399/17525 [04:43<2:49:15,  1.69it/s]  2%|▏         | 400/17525 [04:44<2:49:51,  1.68it/s]                                                     {'loss': 0.7129, 'grad_norm': 3.149655342102051, 'learning_rate': 1.9977240830815836e-05, 'epoch': 0.57}
  2%|▏         | 400/17525 [04:44<2:49:51,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 02:08:05,557 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:08:05,557 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:08:05,557 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 0.997581958770752, 'eval_runtime': 4.6029, 'eval_samples_per_second': 96.244, 'eval_steps_per_second': 4.128, 'epoch': 0.57}
  2%|▏         | 400/17525 [04:48<2:49:51,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  2%|▏         | 401/17525 [04:49<9:24:12,  1.98s/it]  2%|▏         | 402/17525 [04:49<7:25:48,  1.56s/it]  2%|▏         | 403/17525 [04:50<6:02:48,  1.27s/it]  2%|▏         | 404/17525 [04:51<5:04:49,  1.07s/it]  2%|▏         | 405/17525 [04:51<4:23:37,  1.08it/s]  2%|▏         | 406/17525 [04:52<3:55:15,  1.21it/s]  2%|▏         | 407/17525 [04:52<3:35:13,  1.33it/s]  2%|▏         | 408/17525 [04:53<3:21:55,  1.41it/s]  2%|▏         | 409/17525 [04:54<3:12:13,  1.48it/s]  2%|▏         | 410/17525 [04:54<3:05:52,  1.53it/s]                                                     {'loss': 0.9217, 'grad_norm': 2.956583023071289, 'learning_rate': 1.9976014628991686e-05, 'epoch': 0.58}
  2%|▏         | 410/17525 [04:54<3:05:52,  1.53it/s]  2%|▏         | 411/17525 [04:55<3:01:19,  1.57it/s]  2%|▏         | 412/17525 [04:55<2:58:21,  1.60it/s]  2%|▏         | 413/17525 [04:56<2:56:42,  1.61it/s]  2%|▏         | 414/17525 [04:57<2:54:34,  1.63it/s]  2%|▏         | 415/17525 [04:57<2:53:31,  1.64it/s]  2%|▏         | 416/17525 [04:58<2:52:27,  1.65it/s]  2%|▏         | 417/17525 [04:58<2:51:11,  1.67it/s]  2%|▏         | 418/17525 [04:59<2:50:18,  1.67it/s]  2%|▏         | 419/17525 [05:00<2:49:34,  1.68it/s]  2%|▏         | 420/17525 [05:00<2:49:18,  1.68it/s]                                                     {'loss': 0.7766, 'grad_norm': 5.777467727661133, 'learning_rate': 1.9974756295558357e-05, 'epoch': 0.6}
  2%|▏         | 420/17525 [05:00<2:49:18,  1.68it/s]  2%|▏         | 421/17525 [05:01<3:19:40,  1.43it/s]  2%|▏         | 422/17525 [05:02<3:10:27,  1.50it/s]  2%|▏         | 423/17525 [05:02<3:04:10,  1.55it/s]  2%|▏         | 424/17525 [05:03<2:58:47,  1.59it/s]  2%|▏         | 425/17525 [05:03<2:54:59,  1.63it/s]  2%|▏         | 426/17525 [05:04<2:52:21,  1.65it/s]  2%|▏         | 427/17525 [05:05<2:51:06,  1.67it/s]  2%|▏         | 428/17525 [05:05<2:49:52,  1.68it/s]  2%|▏         | 429/17525 [05:06<2:49:11,  1.68it/s]  2%|▏         | 430/17525 [05:06<2:48:36,  1.69it/s]                                                     {'loss': 0.8456, 'grad_norm': 3.5774106979370117, 'learning_rate': 1.99734658345688e-05, 'epoch': 0.61}
  2%|▏         | 430/17525 [05:06<2:48:36,  1.69it/s]  2%|▏         | 431/17525 [05:07<2:48:32,  1.69it/s]  2%|▏         | 432/17525 [05:08<2:47:42,  1.70it/s]  2%|▏         | 433/17525 [05:08<2:47:55,  1.70it/s]  2%|▏         | 434/17525 [05:09<2:47:37,  1.70it/s]  2%|▏         | 435/17525 [05:10<3:22:27,  1.41it/s]  2%|▏         | 436/17525 [05:10<3:12:13,  1.48it/s]  2%|▏         | 437/17525 [05:11<3:04:44,  1.54it/s]  2%|▏         | 438/17525 [05:12<3:01:06,  1.57it/s]  3%|▎         | 439/17525 [05:12<2:57:05,  1.61it/s]  3%|▎         | 440/17525 [05:13<2:55:07,  1.63it/s]                                                     {'loss': 0.9872, 'grad_norm': 3.9910545349121094, 'learning_rate': 1.997214325017944e-05, 'epoch': 0.63}
  3%|▎         | 440/17525 [05:13<2:55:07,  1.63it/s]  3%|▎         | 441/17525 [05:13<2:53:39,  1.64it/s]  3%|▎         | 442/17525 [05:14<2:51:51,  1.66it/s]  3%|▎         | 443/17525 [05:14<2:50:51,  1.67it/s]  3%|▎         | 444/17525 [05:15<2:50:27,  1.67it/s]  3%|▎         | 445/17525 [05:16<2:49:59,  1.67it/s]  3%|▎         | 446/17525 [05:16<2:49:11,  1.68it/s]  3%|▎         | 447/17525 [05:17<2:48:09,  1.69it/s]  3%|▎         | 448/17525 [05:18<3:03:35,  1.55it/s]  3%|▎         | 449/17525 [05:18<2:58:48,  1.59it/s]  3%|▎         | 450/17525 [05:19<2:58:37,  1.59it/s]                                                     {'loss': 0.7757, 'grad_norm': 2.4018359184265137, 'learning_rate': 1.9970788546650167e-05, 'epoch': 0.64}
  3%|▎         | 450/17525 [05:19<2:58:37,  1.59it/s][INFO|trainer.py:3203] 2024-06-25 02:08:40,745 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f045d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 25766ecd-3507-473d-bf4a-c8f1b4d60a36)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:08:50,804 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:08:50,806 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  3%|▎         | 451/17525 [05:30<17:26:30,  3.68s/it]  3%|▎         | 452/17525 [05:30<13:03:19,  2.75s/it]  3%|▎         | 453/17525 [05:31<9:59:45,  2.11s/it]   3%|▎         | 454/17525 [05:31<7:51:16,  1.66s/it]  3%|▎         | 455/17525 [05:32<6:21:05,  1.34s/it]  3%|▎         | 456/17525 [05:33<6:11:40,  1.31s/it]  3%|▎         | 457/17525 [05:34<5:11:38,  1.10s/it]  3%|▎         | 458/17525 [05:34<4:29:03,  1.06it/s]  3%|▎         | 459/17525 [05:35<4:00:10,  1.18it/s]  3%|▎         | 460/17525 [05:36<3:40:08,  1.29it/s]                                                     {'loss': 0.7364, 'grad_norm': 6.000966548919678, 'learning_rate': 1.9969401728344338e-05, 'epoch': 0.66}
  3%|▎         | 460/17525 [05:36<3:40:08,  1.29it/s]  3%|▎         | 461/17525 [05:36<3:25:00,  1.39it/s]  3%|▎         | 462/17525 [05:37<3:13:40,  1.47it/s]  3%|▎         | 463/17525 [05:37<3:06:14,  1.53it/s]  3%|▎         | 464/17525 [05:38<3:01:12,  1.57it/s]  3%|▎         | 465/17525 [05:39<2:58:10,  1.60it/s]  3%|▎         | 466/17525 [05:39<2:56:06,  1.61it/s]  3%|▎         | 467/17525 [05:40<2:54:17,  1.63it/s]  3%|▎         | 468/17525 [05:41<4:20:05,  1.09it/s]  3%|▎         | 469/17525 [05:42<3:52:25,  1.22it/s]  3%|▎         | 470/17525 [05:43<3:32:40,  1.34it/s]                                                     {'loss': 0.8995, 'grad_norm': 3.2711877822875977, 'learning_rate': 1.9967982799728725e-05, 'epoch': 0.67}
  3%|▎         | 470/17525 [05:43<3:32:40,  1.34it/s]  3%|▎         | 471/17525 [05:43<3:19:11,  1.43it/s]  3%|▎         | 472/17525 [05:44<3:08:56,  1.50it/s]  3%|▎         | 473/17525 [05:44<3:02:00,  1.56it/s]  3%|▎         | 474/17525 [05:45<2:56:58,  1.61it/s]  3%|▎         | 475/17525 [05:46<2:53:27,  1.64it/s]  3%|▎         | 476/17525 [05:46<2:51:22,  1.66it/s]  3%|▎         | 477/17525 [05:47<2:49:50,  1.67it/s]  3%|▎         | 478/17525 [05:47<2:48:55,  1.68it/s]  3%|▎         | 479/17525 [05:48<2:48:09,  1.69it/s]  3%|▎         | 480/17525 [05:49<2:47:24,  1.70it/s]                                                     {'loss': 0.9559, 'grad_norm': 5.165976524353027, 'learning_rate': 1.9966531765373548e-05, 'epoch': 0.68}
  3%|▎         | 480/17525 [05:49<2:47:24,  1.70it/s]  3%|▎         | 481/17525 [05:49<2:47:51,  1.69it/s]  3%|▎         | 482/17525 [05:50<2:47:26,  1.70it/s]  3%|▎         | 483/17525 [05:50<2:47:27,  1.70it/s]  3%|▎         | 484/17525 [05:51<2:47:33,  1.70it/s]  3%|▎         | 485/17525 [05:51<2:47:30,  1.70it/s]  3%|▎         | 486/17525 [05:52<2:47:20,  1.70it/s]  3%|▎         | 487/17525 [05:53<2:47:22,  1.70it/s]  3%|▎         | 488/17525 [05:53<2:47:19,  1.70it/s]  3%|▎         | 489/17525 [05:54<2:46:52,  1.70it/s]  3%|▎         | 490/17525 [05:54<2:47:12,  1.70it/s]                                                     {'loss': 0.7922, 'grad_norm': 2.8429789543151855, 'learning_rate': 1.9965048629952414e-05, 'epoch': 0.7}
  3%|▎         | 490/17525 [05:54<2:47:12,  1.70it/s]  3%|▎         | 491/17525 [05:55<2:46:59,  1.70it/s]  3%|▎         | 492/17525 [05:56<2:47:28,  1.70it/s]  3%|▎         | 493/17525 [05:56<2:47:06,  1.70it/s]  3%|▎         | 494/17525 [05:57<2:48:46,  1.68it/s]  3%|▎         | 495/17525 [05:57<2:47:53,  1.69it/s]  3%|▎         | 496/17525 [05:58<2:47:44,  1.69it/s]  3%|▎         | 497/17525 [05:59<2:47:15,  1.70it/s]  3%|▎         | 498/17525 [05:59<2:46:58,  1.70it/s]  3%|▎         | 499/17525 [06:00<2:46:45,  1.70it/s]  3%|▎         | 500/17525 [06:00<2:46:44,  1.70it/s]                                                     {'loss': 0.9014, 'grad_norm': 2.7416162490844727, 'learning_rate': 1.9963533398242342e-05, 'epoch': 0.71}
  3%|▎         | 500/17525 [06:00<2:46:44,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:09:22,193 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:09:22,193 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:09:22,193 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 0.9788879752159119, 'eval_runtime': 4.5962, 'eval_samples_per_second': 96.385, 'eval_steps_per_second': 4.134, 'epoch': 0.71}
  3%|▎         | 500/17525 [06:05<2:46:44,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  3%|▎         | 501/17525 [06:05<9:18:55,  1.97s/it]  3%|▎         | 502/17525 [06:06<7:22:05,  1.56s/it]  3%|▎         | 503/17525 [06:07<7:05:31,  1.50s/it]  3%|▎         | 504/17525 [06:08<5:47:55,  1.23s/it]  3%|▎         | 505/17525 [06:09<5:35:29,  1.18s/it]  3%|▎         | 506/17525 [06:10<4:44:35,  1.00s/it]  3%|▎         | 507/17525 [06:10<4:09:04,  1.14it/s]  3%|▎         | 508/17525 [06:11<3:44:27,  1.26it/s]  3%|▎         | 509/17525 [06:12<3:53:04,  1.22it/s]  3%|▎         | 510/17525 [06:12<3:32:59,  1.33it/s]                                                     {'loss': 0.978, 'grad_norm': 4.371282577514648, 'learning_rate': 1.996198607512371e-05, 'epoch': 0.73}
  3%|▎         | 510/17525 [06:12<3:32:59,  1.33it/s]  3%|▎         | 511/17525 [06:13<3:19:28,  1.42it/s]  3%|▎         | 512/17525 [06:14<3:09:19,  1.50it/s]  3%|▎         | 513/17525 [06:14<3:02:03,  1.56it/s]  3%|▎         | 514/17525 [06:15<2:58:46,  1.59it/s]  3%|▎         | 515/17525 [06:15<2:54:36,  1.62it/s]  3%|▎         | 516/17525 [06:16<3:07:55,  1.51it/s]  3%|▎         | 517/17525 [06:17<3:01:22,  1.56it/s]  3%|▎         | 518/17525 [06:17<2:56:51,  1.60it/s]  3%|▎         | 519/17525 [06:18<2:53:41,  1.63it/s]  3%|▎         | 520/17525 [06:18<2:50:46,  1.66it/s]                                                     {'loss': 0.7803, 'grad_norm': 6.082167148590088, 'learning_rate': 1.9960406665580278e-05, 'epoch': 0.74}
  3%|▎         | 520/17525 [06:18<2:50:46,  1.66it/s]  3%|▎         | 521/17525 [06:19<2:49:29,  1.67it/s]  3%|▎         | 522/17525 [06:20<3:18:56,  1.42it/s]  3%|▎         | 523/17525 [06:21<3:09:53,  1.49it/s]  3%|▎         | 524/17525 [06:21<3:03:25,  1.54it/s]  3%|▎         | 525/17525 [06:22<2:58:50,  1.58it/s]  3%|▎         | 526/17525 [06:22<2:55:34,  1.61it/s]  3%|▎         | 527/17525 [06:23<2:53:07,  1.64it/s]  3%|▎         | 528/17525 [06:24<2:51:09,  1.66it/s]  3%|▎         | 529/17525 [06:24<2:50:20,  1.66it/s]  3%|▎         | 530/17525 [06:25<2:49:34,  1.67it/s]                                                     {'loss': 0.7419, 'grad_norm': 3.4797301292419434, 'learning_rate': 1.9958795174699145e-05, 'epoch': 0.76}
  3%|▎         | 530/17525 [06:25<2:49:34,  1.67it/s]  3%|▎         | 531/17525 [06:25<2:48:57,  1.68it/s]  3%|▎         | 532/17525 [06:26<2:47:56,  1.69it/s]  3%|▎         | 533/17525 [06:26<2:46:54,  1.70it/s]  3%|▎         | 534/17525 [06:27<2:46:26,  1.70it/s]  3%|▎         | 535/17525 [06:28<2:46:17,  1.70it/s]  3%|▎         | 536/17525 [06:28<2:46:27,  1.70it/s]  3%|▎         | 537/17525 [06:29<2:46:16,  1.70it/s]  3%|▎         | 538/17525 [06:29<2:46:05,  1.70it/s]  3%|▎         | 539/17525 [06:30<2:45:40,  1.71it/s]  3%|▎         | 540/17525 [06:31<2:45:42,  1.71it/s]                                                     {'loss': 0.9728, 'grad_norm': 6.178449630737305, 'learning_rate': 1.995715160767074e-05, 'epoch': 0.77}
  3%|▎         | 540/17525 [06:31<2:45:42,  1.71it/s]  3%|▎         | 541/17525 [06:31<2:45:47,  1.71it/s]  3%|▎         | 542/17525 [06:32<2:45:38,  1.71it/s]  3%|▎         | 543/17525 [06:32<2:45:16,  1.71it/s]  3%|▎         | 544/17525 [06:33<2:45:20,  1.71it/s]  3%|▎         | 545/17525 [06:33<2:45:58,  1.71it/s]  3%|▎         | 546/17525 [06:34<2:45:46,  1.71it/s]  3%|▎         | 547/17525 [06:35<2:45:36,  1.71it/s]  3%|▎         | 548/17525 [06:35<2:45:20,  1.71it/s]  3%|▎         | 549/17525 [06:36<2:45:26,  1.71it/s]  3%|▎         | 550/17525 [06:36<2:45:28,  1.71it/s]                                                     {'loss': 0.7881, 'grad_norm': 3.436556816101074, 'learning_rate': 1.9955475969788795e-05, 'epoch': 0.78}
  3%|▎         | 550/17525 [06:36<2:45:28,  1.71it/s]  3%|▎         | 551/17525 [06:37<2:45:52,  1.71it/s]  3%|▎         | 552/17525 [06:38<2:45:56,  1.70it/s]  3%|▎         | 553/17525 [06:38<2:45:51,  1.71it/s]  3%|▎         | 554/17525 [06:39<2:45:42,  1.71it/s]  3%|▎         | 555/17525 [06:39<2:45:59,  1.70it/s]  3%|▎         | 556/17525 [06:40<2:45:48,  1.71it/s]  3%|▎         | 557/17525 [06:41<2:46:01,  1.70it/s]  3%|▎         | 558/17525 [06:41<2:46:21,  1.70it/s]  3%|▎         | 559/17525 [06:42<2:49:21,  1.67it/s]  3%|▎         | 560/17525 [06:42<2:48:05,  1.68it/s]                                                     {'loss': 0.8202, 'grad_norm': 5.509521961212158, 'learning_rate': 1.9953768266450362e-05, 'epoch': 0.8}
  3%|▎         | 560/17525 [06:42<2:48:05,  1.68it/s]  3%|▎         | 561/17525 [06:43<2:48:37,  1.68it/s]  3%|▎         | 562/17525 [06:43<2:47:25,  1.69it/s]  3%|▎         | 563/17525 [06:44<2:46:41,  1.70it/s]  3%|▎         | 564/17525 [06:45<2:46:27,  1.70it/s]  3%|▎         | 565/17525 [06:45<2:45:59,  1.70it/s]  3%|▎         | 566/17525 [06:46<2:45:56,  1.70it/s]  3%|▎         | 567/17525 [06:46<2:45:39,  1.71it/s]  3%|▎         | 568/17525 [06:47<2:45:12,  1.71it/s]  3%|▎         | 569/17525 [06:48<2:45:03,  1.71it/s]  3%|▎         | 570/17525 [06:48<2:44:59,  1.71it/s]                                                     {'loss': 0.8008, 'grad_norm': 3.793593406677246, 'learning_rate': 1.995202850315576e-05, 'epoch': 0.81}
  3%|▎         | 570/17525 [06:48<2:44:59,  1.71it/s]  3%|▎         | 571/17525 [06:49<2:45:22,  1.71it/s]  3%|▎         | 572/17525 [06:49<2:45:26,  1.71it/s]  3%|▎         | 573/17525 [06:50<2:45:17,  1.71it/s]  3%|▎         | 574/17525 [06:50<2:45:03,  1.71it/s]  3%|▎         | 575/17525 [06:51<2:46:11,  1.70it/s]  3%|▎         | 576/17525 [06:52<2:46:10,  1.70it/s]  3%|▎         | 577/17525 [06:52<2:46:04,  1.70it/s]  3%|▎         | 578/17525 [06:53<2:45:46,  1.70it/s]  3%|▎         | 579/17525 [06:53<2:45:23,  1.71it/s]  3%|▎         | 580/17525 [06:54<2:45:27,  1.71it/s]                                                     {'loss': 0.8582, 'grad_norm': 3.1134183406829834, 'learning_rate': 1.9950256685508556e-05, 'epoch': 0.83}
  3%|▎         | 580/17525 [06:54<2:45:27,  1.71it/s]  3%|▎         | 581/17525 [06:55<2:45:49,  1.70it/s]  3%|▎         | 582/17525 [06:55<2:45:53,  1.70it/s]  3%|▎         | 583/17525 [06:56<2:46:00,  1.70it/s]  3%|▎         | 584/17525 [06:56<2:45:28,  1.71it/s]  3%|▎         | 585/17525 [06:57<2:45:25,  1.71it/s]  3%|▎         | 586/17525 [06:58<2:45:34,  1.71it/s]  3%|▎         | 587/17525 [06:58<2:45:17,  1.71it/s]  3%|▎         | 588/17525 [06:59<2:44:41,  1.71it/s]  3%|▎         | 589/17525 [06:59<2:44:20,  1.72it/s]  3%|▎         | 590/17525 [07:00<2:43:55,  1.72it/s]                                                     {'loss': 0.7199, 'grad_norm': 7.101284980773926, 'learning_rate': 1.994845281921558e-05, 'epoch': 0.84}
  3%|▎         | 590/17525 [07:00<2:43:55,  1.72it/s]  3%|▎         | 591/17525 [07:00<2:43:57,  1.72it/s]  3%|▎         | 592/17525 [07:01<2:43:44,  1.72it/s]  3%|▎         | 593/17525 [07:02<2:43:27,  1.73it/s]  3%|▎         | 594/17525 [07:02<2:44:42,  1.71it/s]  3%|▎         | 595/17525 [07:03<2:44:27,  1.72it/s]  3%|▎         | 596/17525 [07:03<2:44:22,  1.72it/s]  3%|▎         | 597/17525 [07:04<2:43:58,  1.72it/s]  3%|▎         | 598/17525 [07:05<2:43:42,  1.72it/s]  3%|▎         | 599/17525 [07:05<2:43:33,  1.72it/s]  3%|▎         | 600/17525 [07:06<2:43:50,  1.72it/s]                                                     {'loss': 0.9883, 'grad_norm': 5.756633281707764, 'learning_rate': 1.9946616910086886e-05, 'epoch': 0.86}
  3%|▎         | 600/17525 [07:06<2:43:50,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:10:27,575 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:10:27,575 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:10:27,575 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 0.9737685322761536, 'eval_runtime': 4.602, 'eval_samples_per_second': 96.262, 'eval_steps_per_second': 4.129, 'epoch': 0.86}
  3%|▎         | 600/17525 [07:10<2:43:50,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:10:32,180 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f9b6d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: bdd13c07-5726-4ba8-8b19-08945b587868)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:10:42,238 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:10:42,241 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  3%|▎         | 601/17525 [07:21<23:35:45,  5.02s/it]  3%|▎         | 602/17525 [07:22<17:19:53,  3.69s/it]  3%|▎         | 603/17525 [07:22<12:56:52,  2.75s/it]  3%|▎         | 604/17525 [07:23<9:52:50,  2.10s/it]   3%|▎         | 605/17525 [07:23<7:43:56,  1.65s/it]  3%|▎         | 606/17525 [07:24<6:13:42,  1.33s/it]  3%|▎         | 607/17525 [07:25<5:10:43,  1.10s/it]  3%|▎         | 608/17525 [07:25<4:26:37,  1.06it/s]  3%|▎         | 609/17525 [07:26<3:55:39,  1.20it/s]  3%|▎         | 610/17525 [07:26<3:34:05,  1.32it/s]                                                     {'loss': 0.7282, 'grad_norm': 2.2151668071746826, 'learning_rate': 1.9944748964035723e-05, 'epoch': 0.87}
  3%|▎         | 610/17525 [07:26<3:34:05,  1.32it/s]  3%|▎         | 611/17525 [07:27<3:18:55,  1.42it/s]  3%|▎         | 612/17525 [07:27<3:07:56,  1.50it/s]  3%|▎         | 613/17525 [07:28<3:00:38,  1.56it/s]  4%|▎         | 614/17525 [07:29<2:55:56,  1.60it/s]  4%|▎         | 615/17525 [07:29<2:52:09,  1.64it/s]  4%|▎         | 616/17525 [07:30<2:49:36,  1.66it/s]  4%|▎         | 617/17525 [07:30<2:47:36,  1.68it/s]  4%|▎         | 618/17525 [07:31<2:46:27,  1.69it/s]  4%|▎         | 619/17525 [07:31<2:45:24,  1.70it/s]  4%|▎         | 620/17525 [07:32<2:44:46,  1.71it/s]                                                     {'loss': 0.905, 'grad_norm': 4.1088128089904785, 'learning_rate': 1.9942848987078535e-05, 'epoch': 0.88}
  4%|▎         | 620/17525 [07:32<2:44:46,  1.71it/s]  4%|▎         | 621/17525 [07:33<2:44:29,  1.71it/s]  4%|▎         | 622/17525 [07:33<2:44:16,  1.71it/s]  4%|▎         | 623/17525 [07:34<2:43:46,  1.72it/s]  4%|▎         | 624/17525 [07:34<2:43:43,  1.72it/s]  4%|▎         | 625/17525 [07:35<2:43:41,  1.72it/s]  4%|▎         | 626/17525 [07:36<2:43:31,  1.72it/s]  4%|▎         | 627/17525 [07:36<2:43:26,  1.72it/s]  4%|▎         | 628/17525 [07:37<2:43:20,  1.72it/s]  4%|▎         | 629/17525 [07:37<2:43:27,  1.72it/s]  4%|▎         | 630/17525 [07:38<2:43:23,  1.72it/s]                                                     {'loss': 0.843, 'grad_norm': 4.0367655754089355, 'learning_rate': 1.9940916985334926e-05, 'epoch': 0.9}
  4%|▎         | 630/17525 [07:38<2:43:23,  1.72it/s]  4%|▎         | 631/17525 [07:38<2:43:32,  1.72it/s]  4%|▎         | 632/17525 [07:39<2:43:29,  1.72it/s]  4%|▎         | 633/17525 [07:40<2:43:18,  1.72it/s]  4%|▎         | 634/17525 [07:40<2:43:07,  1.73it/s]  4%|▎         | 635/17525 [07:41<2:45:48,  1.70it/s]  4%|▎         | 636/17525 [07:42<2:57:50,  1.58it/s]  4%|▎         | 637/17525 [07:42<2:53:26,  1.62it/s]  4%|▎         | 638/17525 [07:43<2:50:14,  1.65it/s]  4%|▎         | 639/17525 [07:43<2:48:02,  1.67it/s]  4%|▎         | 640/17525 [07:44<2:46:45,  1.69it/s]                                                     {'loss': 0.8134, 'grad_norm': 2.6922667026519775, 'learning_rate': 1.993895296502766e-05, 'epoch': 0.91}
  4%|▎         | 640/17525 [07:44<2:46:45,  1.69it/s]  4%|▎         | 641/17525 [07:44<2:46:26,  1.69it/s]  4%|▎         | 642/17525 [07:45<2:45:32,  1.70it/s]  4%|▎         | 643/17525 [07:46<2:44:49,  1.71it/s]  4%|▎         | 644/17525 [07:47<3:51:24,  1.22it/s]  4%|▎         | 645/17525 [07:48<3:30:45,  1.33it/s]  4%|▎         | 646/17525 [07:48<3:16:28,  1.43it/s]  4%|▎         | 647/17525 [07:49<3:06:20,  1.51it/s]  4%|▎         | 648/17525 [07:49<2:59:21,  1.57it/s]  4%|▎         | 649/17525 [07:50<2:54:27,  1.61it/s]  4%|▎         | 650/17525 [07:50<2:51:13,  1.64it/s]                                                     {'loss': 0.8069, 'grad_norm': 4.93634557723999, 'learning_rate': 1.9936956932482626e-05, 'epoch': 0.93}
  4%|▎         | 650/17525 [07:50<2:51:13,  1.64it/s]  4%|▎         | 651/17525 [07:51<2:48:56,  1.66it/s]  4%|▎         | 652/17525 [07:52<2:47:12,  1.68it/s]  4%|▎         | 653/17525 [07:52<2:45:47,  1.70it/s]  4%|▎         | 654/17525 [07:53<2:44:41,  1.71it/s]  4%|▎         | 655/17525 [07:53<2:44:01,  1.71it/s]  4%|▎         | 656/17525 [07:54<2:43:24,  1.72it/s]  4%|▎         | 657/17525 [07:55<2:43:28,  1.72it/s]  4%|▍         | 658/17525 [07:55<2:43:25,  1.72it/s]  4%|▍         | 659/17525 [07:56<2:43:09,  1.72it/s]  4%|▍         | 660/17525 [07:56<2:43:08,  1.72it/s]                                                     {'loss': 0.7331, 'grad_norm': 4.073688983917236, 'learning_rate': 1.993492889412881e-05, 'epoch': 0.94}
  4%|▍         | 660/17525 [07:56<2:43:08,  1.72it/s]  4%|▍         | 661/17525 [07:57<2:43:41,  1.72it/s]  4%|▍         | 662/17525 [07:57<2:43:35,  1.72it/s]  4%|▍         | 663/17525 [07:58<2:43:24,  1.72it/s]  4%|▍         | 664/17525 [07:59<2:43:09,  1.72it/s]  4%|▍         | 665/17525 [07:59<2:42:44,  1.73it/s]  4%|▍         | 666/17525 [08:00<3:12:26,  1.46it/s]  4%|▍         | 667/17525 [08:01<3:03:20,  1.53it/s]  4%|▍         | 668/17525 [08:01<2:57:12,  1.59it/s]  4%|▍         | 669/17525 [08:02<3:08:40,  1.49it/s]  4%|▍         | 670/17525 [08:03<3:00:50,  1.55it/s]                                                     {'loss': 0.7707, 'grad_norm': 6.558278560638428, 'learning_rate': 1.99328688564983e-05, 'epoch': 0.96}
  4%|▍         | 670/17525 [08:03<3:00:50,  1.55it/s]  4%|▍         | 671/17525 [08:03<3:11:06,  1.47it/s]  4%|▍         | 672/17525 [08:05<3:55:07,  1.19it/s]  4%|▍         | 673/17525 [08:05<3:33:23,  1.32it/s]  4%|▍         | 674/17525 [08:06<3:18:20,  1.42it/s]  4%|▍         | 675/17525 [08:06<3:08:46,  1.49it/s]  4%|▍         | 676/17525 [08:07<3:02:52,  1.54it/s]  4%|▍         | 677/17525 [08:08<2:57:41,  1.58it/s]  4%|▍         | 678/17525 [08:09<3:58:56,  1.18it/s]  4%|▍         | 679/17525 [08:09<3:37:11,  1.29it/s]  4%|▍         | 680/17525 [08:10<3:21:21,  1.39it/s]                                                     {'loss': 0.8203, 'grad_norm': 2.9802751541137695, 'learning_rate': 1.9930776826226233e-05, 'epoch': 0.97}
  4%|▍         | 680/17525 [08:10<3:21:21,  1.39it/s]  4%|▍         | 681/17525 [08:11<3:10:47,  1.47it/s]  4%|▍         | 682/17525 [08:11<3:03:18,  1.53it/s]  4%|▍         | 683/17525 [08:12<2:58:29,  1.57it/s]  4%|▍         | 684/17525 [08:12<2:54:39,  1.61it/s]  4%|▍         | 685/17525 [08:13<2:52:09,  1.63it/s]  4%|▍         | 686/17525 [08:14<2:49:52,  1.65it/s]  4%|▍         | 687/17525 [08:14<2:48:36,  1.66it/s]  4%|▍         | 688/17525 [08:15<2:47:38,  1.67it/s]  4%|▍         | 689/17525 [08:15<2:47:09,  1.68it/s]  4%|▍         | 690/17525 [08:16<2:47:34,  1.67it/s]                                                     {'loss': 0.7558, 'grad_norm': 7.116620063781738, 'learning_rate': 1.992865281005081e-05, 'epoch': 0.98}
  4%|▍         | 690/17525 [08:16<2:47:34,  1.67it/s]  4%|▍         | 691/17525 [08:17<2:47:08,  1.68it/s]  4%|▍         | 692/17525 [08:17<2:46:47,  1.68it/s]  4%|▍         | 693/17525 [08:18<2:46:14,  1.69it/s]  4%|▍         | 694/17525 [08:18<2:46:10,  1.69it/s]  4%|▍         | 695/17525 [08:19<2:45:52,  1.69it/s]  4%|▍         | 696/17525 [08:20<2:45:40,  1.69it/s]  4%|▍         | 697/17525 [08:20<2:45:37,  1.69it/s]  4%|▍         | 698/17525 [08:21<2:45:49,  1.69it/s]  4%|▍         | 699/17525 [08:21<2:45:21,  1.70it/s]  4%|▍         | 700/17525 [08:22<2:45:26,  1.69it/s]                                                     {'loss': 0.8369, 'grad_norm': 4.617453098297119, 'learning_rate': 1.9926496814813246e-05, 'epoch': 1.0}
  4%|▍         | 700/17525 [08:22<2:45:26,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:11:43,759 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:11:43,759 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:11:43,759 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                     
                                               [A{'eval_loss': 0.952282726764679, 'eval_runtime': 4.6034, 'eval_samples_per_second': 96.233, 'eval_steps_per_second': 4.127, 'epoch': 1.0}
  4%|▍         | 700/17525 [08:26<2:45:26,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A  4%|▍         | 701/17525 [08:27<9:13:38,  1.97s/it]  4%|▍         | 702/17525 [08:28<7:17:01,  1.56s/it]  4%|▍         | 703/17525 [08:28<5:56:05,  1.27s/it]  4%|▍         | 704/17525 [08:29<4:58:51,  1.07s/it]  4%|▍         | 705/17525 [08:29<4:18:38,  1.08it/s]  4%|▍         | 706/17525 [08:30<3:50:33,  1.22it/s]  4%|▍         | 707/17525 [08:31<3:30:47,  1.33it/s]  4%|▍         | 708/17525 [08:31<3:16:53,  1.42it/s]  4%|▍         | 709/17525 [08:32<3:08:26,  1.49it/s]  4%|▍         | 710/17525 [08:32<3:01:39,  1.54it/s]                                                     {'loss': 0.8425, 'grad_norm': 5.691953659057617, 'learning_rate': 1.992430884745775e-05, 'epoch': 1.01}
  4%|▍         | 710/17525 [08:32<3:01:39,  1.54it/s]  4%|▍         | 711/17525 [08:33<2:57:12,  1.58it/s]  4%|▍         | 712/17525 [08:34<2:53:33,  1.61it/s]  4%|▍         | 713/17525 [08:35<3:56:40,  1.18it/s]  4%|▍         | 714/17525 [08:36<3:35:44,  1.30it/s]  4%|▍         | 715/17525 [08:36<3:20:20,  1.40it/s]  4%|▍         | 716/17525 [08:37<3:09:53,  1.48it/s]  4%|▍         | 717/17525 [08:37<3:02:30,  1.53it/s]  4%|▍         | 718/17525 [08:38<2:57:18,  1.58it/s]  4%|▍         | 719/17525 [08:38<2:53:56,  1.61it/s]  4%|▍         | 720/17525 [08:39<2:50:29,  1.64it/s]                                                     {'loss': 0.7981, 'grad_norm': 2.970207929611206, 'learning_rate': 1.9922088915031527e-05, 'epoch': 1.03}
  4%|▍         | 720/17525 [08:39<2:50:29,  1.64it/s]  4%|▍         | 721/17525 [08:40<2:48:23,  1.66it/s]  4%|▍         | 722/17525 [08:40<2:47:19,  1.67it/s]  4%|▍         | 723/17525 [08:41<2:45:53,  1.69it/s]  4%|▍         | 724/17525 [08:41<2:44:40,  1.70it/s]  4%|▍         | 725/17525 [08:42<2:43:46,  1.71it/s]  4%|▍         | 726/17525 [08:43<2:43:19,  1.71it/s]  4%|▍         | 727/17525 [08:43<2:43:39,  1.71it/s]  4%|▍         | 728/17525 [08:44<2:43:21,  1.71it/s]  4%|▍         | 729/17525 [08:44<2:43:18,  1.71it/s]  4%|▍         | 730/17525 [08:45<2:43:29,  1.71it/s]                                                     {'loss': 0.8428, 'grad_norm': 2.9460651874542236, 'learning_rate': 1.9919837024684715e-05, 'epoch': 1.04}
  4%|▍         | 730/17525 [08:45<2:43:29,  1.71it/s]  4%|▍         | 731/17525 [08:45<2:43:04,  1.72it/s]  4%|▍         | 732/17525 [08:46<2:42:45,  1.72it/s]  4%|▍         | 733/17525 [08:47<2:42:30,  1.72it/s]  4%|▍         | 734/17525 [08:48<3:09:17,  1.48it/s]  4%|▍         | 735/17525 [08:48<3:01:27,  1.54it/s]  4%|▍         | 736/17525 [08:49<2:55:58,  1.59it/s]  4%|▍         | 737/17525 [08:49<2:52:26,  1.62it/s]  4%|▍         | 738/17525 [08:50<2:49:57,  1.65it/s]  4%|▍         | 739/17525 [08:50<2:48:03,  1.66it/s]  4%|▍         | 740/17525 [08:51<2:46:38,  1.68it/s]                                                     {'loss': 0.7659, 'grad_norm': 2.738607406616211, 'learning_rate': 1.99175531836704e-05, 'epoch': 1.06}
  4%|▍         | 740/17525 [08:51<2:46:38,  1.68it/s]  4%|▍         | 741/17525 [08:52<2:45:30,  1.69it/s]  4%|▍         | 742/17525 [08:52<2:44:35,  1.70it/s]  4%|▍         | 743/17525 [08:53<2:44:11,  1.70it/s]  4%|▍         | 744/17525 [08:53<2:43:37,  1.71it/s]  4%|▍         | 745/17525 [08:54<2:43:16,  1.71it/s]  4%|▍         | 746/17525 [08:55<2:43:11,  1.71it/s]  4%|▍         | 747/17525 [08:55<2:44:39,  1.70it/s]  4%|▍         | 748/17525 [08:56<2:44:06,  1.70it/s]  4%|▍         | 749/17525 [08:56<2:43:32,  1.71it/s]  4%|▍         | 750/17525 [08:57<2:44:01,  1.70it/s]                                                     {'loss': 0.8008, 'grad_norm': 6.204690456390381, 'learning_rate': 1.991523739934458e-05, 'epoch': 1.07}
  4%|▍         | 750/17525 [08:57<2:44:01,  1.70it/s][INFO|trainer.py:3203] 2024-06-25 02:12:18,783 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a795da50>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5ec86545-99ea-4697-866f-2708a831d7bc)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:12:28,838 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:12:28,840 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  4%|▍         | 751/17525 [09:08<16:57:44,  3.64s/it]  4%|▍         | 752/17525 [09:08<12:41:20,  2.72s/it]  4%|▍         | 753/17525 [09:09<9:41:57,  2.08s/it]   4%|▍         | 754/17525 [09:09<7:36:35,  1.63s/it]  4%|▍         | 755/17525 [09:10<6:08:23,  1.32s/it]  4%|▍         | 756/17525 [09:11<5:06:44,  1.10s/it]  4%|▍         | 757/17525 [09:11<4:25:04,  1.05it/s]  4%|▍         | 758/17525 [09:12<3:54:30,  1.19it/s]  4%|▍         | 759/17525 [09:12<3:33:12,  1.31it/s]  4%|▍         | 760/17525 [09:13<3:18:19,  1.41it/s]                                                     {'loss': 0.8192, 'grad_norm': 3.5283703804016113, 'learning_rate': 1.9912889679166122e-05, 'epoch': 1.08}
  4%|▍         | 760/17525 [09:13<3:18:19,  1.41it/s]  4%|▍         | 761/17525 [09:14<3:07:42,  1.49it/s]  4%|▍         | 762/17525 [09:14<3:00:10,  1.55it/s]  4%|▍         | 763/17525 [09:15<2:54:43,  1.60it/s]  4%|▍         | 764/17525 [09:15<2:51:03,  1.63it/s]  4%|▍         | 765/17525 [09:16<2:48:31,  1.66it/s]  4%|▍         | 766/17525 [09:17<3:22:35,  1.38it/s]  4%|▍         | 767/17525 [09:17<3:10:16,  1.47it/s]  4%|▍         | 768/17525 [09:18<3:01:48,  1.54it/s]  4%|▍         | 769/17525 [09:19<2:56:03,  1.59it/s]  4%|▍         | 770/17525 [09:19<2:52:44,  1.62it/s]                                                     {'loss': 0.8133, 'grad_norm': 6.083454608917236, 'learning_rate': 1.9910510030696778e-05, 'epoch': 1.1}
  4%|▍         | 770/17525 [09:19<2:52:44,  1.62it/s]  4%|▍         | 771/17525 [09:20<2:49:56,  1.64it/s]  4%|▍         | 772/17525 [09:20<2:47:59,  1.66it/s]  4%|▍         | 773/17525 [09:21<2:47:01,  1.67it/s]  4%|▍         | 774/17525 [09:22<2:45:46,  1.68it/s]  4%|▍         | 775/17525 [09:22<2:44:50,  1.69it/s]  4%|▍         | 776/17525 [09:23<2:44:27,  1.70it/s]  4%|▍         | 777/17525 [09:23<2:43:55,  1.70it/s]  4%|▍         | 778/17525 [09:24<2:43:24,  1.71it/s]  4%|▍         | 779/17525 [09:24<2:43:40,  1.71it/s]  4%|▍         | 780/17525 [09:25<2:43:27,  1.71it/s]                                                     {'loss': 0.8101, 'grad_norm': 6.334158897399902, 'learning_rate': 1.990809846160112e-05, 'epoch': 1.11}
  4%|▍         | 780/17525 [09:25<2:43:27,  1.71it/s]  4%|▍         | 781/17525 [09:26<2:43:21,  1.71it/s]  4%|▍         | 782/17525 [09:26<2:43:12,  1.71it/s]  4%|▍         | 783/17525 [09:27<2:43:00,  1.71it/s]  4%|▍         | 784/17525 [09:27<2:42:55,  1.71it/s]  4%|▍         | 785/17525 [09:28<2:43:12,  1.71it/s]  4%|▍         | 786/17525 [09:29<2:43:28,  1.71it/s]  4%|▍         | 787/17525 [09:29<2:43:43,  1.70it/s]  4%|▍         | 788/17525 [09:30<2:55:17,  1.59it/s]  5%|▍         | 789/17525 [09:31<3:31:30,  1.32it/s]  5%|▍         | 790/17525 [09:31<3:16:44,  1.42it/s]                                                     {'loss': 0.8644, 'grad_norm': 4.3267951011657715, 'learning_rate': 1.990565497964654e-05, 'epoch': 1.13}
  5%|▍         | 790/17525 [09:32<3:16:44,  1.42it/s]  5%|▍         | 791/17525 [09:32<3:06:45,  1.49it/s]  5%|▍         | 792/17525 [09:33<2:59:45,  1.55it/s]  5%|▍         | 793/17525 [09:33<2:55:11,  1.59it/s]  5%|▍         | 794/17525 [09:34<2:51:30,  1.63it/s]  5%|▍         | 795/17525 [09:34<2:49:01,  1.65it/s]  5%|▍         | 796/17525 [09:35<2:46:59,  1.67it/s]  5%|▍         | 797/17525 [09:36<3:14:07,  1.44it/s]  5%|▍         | 798/17525 [09:37<3:04:46,  1.51it/s]  5%|▍         | 799/17525 [09:37<2:58:13,  1.56it/s]  5%|▍         | 800/17525 [09:38<2:53:21,  1.61it/s]                                                     {'loss': 0.8467, 'grad_norm': 4.559082984924316, 'learning_rate': 1.990317959270321e-05, 'epoch': 1.14}
  5%|▍         | 800/17525 [09:38<2:53:21,  1.61it/s][INFO|trainer.py:3512] 2024-06-25 02:12:59,582 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:12:59,582 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:12:59,582 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                     
                                               [A{'eval_loss': 0.939092218875885, 'eval_runtime': 4.5957, 'eval_samples_per_second': 96.395, 'eval_steps_per_second': 4.134, 'epoch': 1.14}
  5%|▍         | 800/17525 [09:42<2:53:21,  1.61it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A  5%|▍         | 801/17525 [09:43<9:15:12,  1.99s/it]  5%|▍         | 802/17525 [09:43<7:17:43,  1.57s/it]  5%|▍         | 803/17525 [09:44<5:55:20,  1.27s/it]  5%|▍         | 804/17525 [09:45<4:58:37,  1.07s/it]  5%|▍         | 805/17525 [09:45<4:17:48,  1.08it/s]  5%|▍         | 806/17525 [09:46<3:48:57,  1.22it/s]  5%|▍         | 807/17525 [09:46<3:28:49,  1.33it/s]  5%|▍         | 808/17525 [09:47<3:14:59,  1.43it/s]  5%|▍         | 809/17525 [09:48<3:31:54,  1.31it/s]  5%|▍         | 810/17525 [09:48<3:17:05,  1.41it/s]                                                     {'loss': 0.7311, 'grad_norm': 2.9703807830810547, 'learning_rate': 1.9900672308744076e-05, 'epoch': 1.16}
  5%|▍         | 810/17525 [09:48<3:17:05,  1.41it/s]  5%|▍         | 811/17525 [09:49<3:07:14,  1.49it/s]  5%|▍         | 812/17525 [09:50<3:00:01,  1.55it/s]  5%|▍         | 813/17525 [09:50<2:54:35,  1.60it/s]  5%|▍         | 814/17525 [09:51<2:51:08,  1.63it/s]  5%|▍         | 815/17525 [09:51<2:48:24,  1.65it/s]  5%|▍         | 816/17525 [09:52<2:46:24,  1.67it/s]  5%|▍         | 817/17525 [09:53<2:45:27,  1.68it/s]  5%|▍         | 818/17525 [09:53<2:44:31,  1.69it/s]  5%|▍         | 819/17525 [09:54<2:43:55,  1.70it/s]  5%|▍         | 820/17525 [09:54<2:43:17,  1.71it/s]                                                     {'loss': 0.7746, 'grad_norm': 3.0705301761627197, 'learning_rate': 1.9898133135844812e-05, 'epoch': 1.17}
  5%|▍         | 820/17525 [09:54<2:43:17,  1.71it/s]  5%|▍         | 821/17525 [09:55<2:42:59,  1.71it/s]  5%|▍         | 822/17525 [09:55<2:42:33,  1.71it/s]  5%|▍         | 823/17525 [09:56<2:42:09,  1.72it/s]  5%|▍         | 824/17525 [09:57<2:41:47,  1.72it/s]  5%|▍         | 825/17525 [09:57<2:41:43,  1.72it/s]  5%|▍         | 826/17525 [09:58<2:42:03,  1.72it/s]  5%|▍         | 827/17525 [09:58<2:41:36,  1.72it/s]  5%|▍         | 828/17525 [09:59<2:41:39,  1.72it/s]  5%|▍         | 829/17525 [10:00<2:41:41,  1.72it/s]  5%|▍         | 830/17525 [10:00<2:41:35,  1.72it/s]                                                     {'loss': 0.7553, 'grad_norm': 3.3944334983825684, 'learning_rate': 1.9895562082183804e-05, 'epoch': 1.18}
  5%|▍         | 830/17525 [10:00<2:41:35,  1.72it/s]  5%|▍         | 831/17525 [10:01<2:41:48,  1.72it/s]  5%|▍         | 832/17525 [10:01<2:41:43,  1.72it/s]  5%|▍         | 833/17525 [10:02<2:41:38,  1.72it/s]  5%|▍         | 834/17525 [10:02<2:41:54,  1.72it/s]  5%|▍         | 835/17525 [10:03<2:41:40,  1.72it/s]  5%|▍         | 836/17525 [10:04<2:41:22,  1.72it/s]  5%|▍         | 837/17525 [10:04<2:41:18,  1.72it/s]  5%|▍         | 838/17525 [10:05<2:41:35,  1.72it/s]  5%|▍         | 839/17525 [10:05<2:41:57,  1.72it/s]  5%|▍         | 840/17525 [10:06<2:41:48,  1.72it/s]                                                     {'loss': 0.9114, 'grad_norm': 5.5755486488342285, 'learning_rate': 1.9892959156042126e-05, 'epoch': 1.2}
  5%|▍         | 840/17525 [10:06<2:41:48,  1.72it/s]  5%|▍         | 841/17525 [10:07<2:41:48,  1.72it/s]  5%|▍         | 842/17525 [10:07<2:41:39,  1.72it/s]  5%|▍         | 843/17525 [10:08<2:41:48,  1.72it/s]  5%|▍         | 844/17525 [10:08<2:41:44,  1.72it/s]  5%|▍         | 845/17525 [10:09<2:56:07,  1.58it/s]  5%|▍         | 846/17525 [10:10<2:51:47,  1.62it/s]  5%|▍         | 847/17525 [10:10<2:48:50,  1.65it/s]  5%|▍         | 848/17525 [10:11<2:46:44,  1.67it/s]  5%|▍         | 849/17525 [10:11<2:45:37,  1.68it/s]  5%|▍         | 850/17525 [10:12<2:44:33,  1.69it/s]                                                     {'loss': 0.8278, 'grad_norm': 3.2455506324768066, 'learning_rate': 1.9890324365803505e-05, 'epoch': 1.21}
  5%|▍         | 850/17525 [10:12<2:44:33,  1.69it/s]  5%|▍         | 851/17525 [10:13<2:43:45,  1.70it/s]  5%|▍         | 852/17525 [10:13<2:43:33,  1.70it/s]  5%|▍         | 853/17525 [10:14<2:42:51,  1.71it/s]  5%|▍         | 854/17525 [10:14<2:42:24,  1.71it/s]  5%|▍         | 855/17525 [10:15<2:41:56,  1.72it/s]  5%|▍         | 856/17525 [10:15<2:41:45,  1.72it/s]  5%|▍         | 857/17525 [10:16<2:41:45,  1.72it/s]  5%|▍         | 858/17525 [10:17<2:41:43,  1.72it/s]  5%|▍         | 859/17525 [10:17<2:41:50,  1.72it/s]  5%|▍         | 860/17525 [10:18<2:41:37,  1.72it/s]                                                     {'loss': 0.7355, 'grad_norm': 6.193360328674316, 'learning_rate': 1.9887657719954307e-05, 'epoch': 1.23}
  5%|▍         | 860/17525 [10:18<2:41:37,  1.72it/s]  5%|▍         | 861/17525 [10:18<2:41:31,  1.72it/s]  5%|▍         | 862/17525 [10:19<2:41:42,  1.72it/s]  5%|▍         | 863/17525 [10:19<2:41:51,  1.72it/s]  5%|▍         | 864/17525 [10:20<2:41:52,  1.72it/s]  5%|▍         | 865/17525 [10:21<2:42:35,  1.71it/s]  5%|▍         | 866/17525 [10:21<2:42:09,  1.71it/s]  5%|▍         | 867/17525 [10:22<2:41:47,  1.72it/s]  5%|▍         | 868/17525 [10:22<2:41:43,  1.72it/s]  5%|▍         | 869/17525 [10:23<2:41:28,  1.72it/s]  5%|▍         | 870/17525 [10:24<2:53:17,  1.60it/s]                                                     {'loss': 0.791, 'grad_norm': 3.351740837097168, 'learning_rate': 1.9884959227083487e-05, 'epoch': 1.24}
  5%|▍         | 870/17525 [10:24<2:53:17,  1.60it/s]  5%|▍         | 871/17525 [10:24<3:01:49,  1.53it/s]  5%|▍         | 872/17525 [10:25<2:56:10,  1.58it/s]  5%|▍         | 873/17525 [10:26<2:51:59,  1.61it/s]  5%|▍         | 874/17525 [10:26<2:48:52,  1.64it/s]  5%|▍         | 875/17525 [10:27<2:46:44,  1.66it/s]  5%|▍         | 876/17525 [10:27<2:45:18,  1.68it/s]  5%|▌         | 877/17525 [10:28<2:44:25,  1.69it/s]  5%|▌         | 878/17525 [10:29<2:43:35,  1.70it/s]  5%|▌         | 879/17525 [10:29<2:43:02,  1.70it/s]  5%|▌         | 880/17525 [10:30<2:43:57,  1.69it/s]                                                     {'loss': 0.8634, 'grad_norm': 2.3735573291778564, 'learning_rate': 1.9882228895882588e-05, 'epoch': 1.26}
  5%|▌         | 880/17525 [10:30<2:43:57,  1.69it/s]  5%|▌         | 881/17525 [10:30<2:43:47,  1.69it/s]  5%|▌         | 882/17525 [10:31<2:44:13,  1.69it/s]  5%|▌         | 883/17525 [10:31<2:43:23,  1.70it/s]  5%|▌         | 884/17525 [10:32<2:42:38,  1.71it/s]  5%|▌         | 885/17525 [10:33<2:42:29,  1.71it/s]  5%|▌         | 886/17525 [10:33<2:42:52,  1.70it/s]  5%|▌         | 887/17525 [10:34<2:42:13,  1.71it/s]  5%|▌         | 888/17525 [10:34<2:42:32,  1.71it/s]  5%|▌         | 889/17525 [10:35<2:42:07,  1.71it/s]  5%|▌         | 890/17525 [10:36<2:42:40,  1.70it/s]                                                     {'loss': 0.7276, 'grad_norm': 4.345040321350098, 'learning_rate': 1.9879466735145697e-05, 'epoch': 1.27}
  5%|▌         | 890/17525 [10:36<2:42:40,  1.70it/s]  5%|▌         | 891/17525 [10:36<2:42:22,  1.71it/s]  5%|▌         | 892/17525 [10:37<2:42:04,  1.71it/s]  5%|▌         | 893/17525 [10:37<2:41:44,  1.71it/s]  5%|▌         | 894/17525 [10:38<2:41:16,  1.72it/s]  5%|▌         | 895/17525 [10:38<2:41:12,  1.72it/s]  5%|▌         | 896/17525 [10:39<2:40:59,  1.72it/s]  5%|▌         | 897/17525 [10:40<2:42:38,  1.70it/s]  5%|▌         | 898/17525 [10:40<2:41:56,  1.71it/s]  5%|▌         | 899/17525 [10:41<2:41:40,  1.71it/s]  5%|▌         | 900/17525 [10:41<2:41:18,  1.72it/s]                                                     {'loss': 0.7528, 'grad_norm': 6.932411193847656, 'learning_rate': 1.9876672753769415e-05, 'epoch': 1.28}
  5%|▌         | 900/17525 [10:41<2:41:18,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:14:03,289 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:14:03,289 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:14:03,289 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                     
                                               [A{'eval_loss': 0.9336985349655151, 'eval_runtime': 4.5998, 'eval_samples_per_second': 96.309, 'eval_steps_per_second': 4.131, 'epoch': 1.28}
  5%|▌         | 900/17525 [10:46<2:41:18,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:14:07,892 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b288b7760d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 8a5bb996-d915-45e2-a22c-cd32e6d3e16e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:14:18,008 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:14:18,010 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  5%|▌         | 901/17525 [10:57<23:15:10,  5.04s/it]  5%|▌         | 902/17525 [10:57<17:05:01,  3.70s/it]  5%|▌         | 903/17525 [10:58<12:48:53,  2.78s/it]  5%|▌         | 904/17525 [10:59<9:46:26,  2.12s/it]   5%|▌         | 905/17525 [10:59<7:38:50,  1.66s/it]  5%|▌         | 906/17525 [11:00<6:09:24,  1.33s/it]  5%|▌         | 907/17525 [11:00<5:06:51,  1.11s/it]  5%|▌         | 908/17525 [11:01<4:52:20,  1.06s/it]  5%|▌         | 909/17525 [11:02<4:12:54,  1.10it/s]  5%|▌         | 910/17525 [11:02<3:46:02,  1.23it/s]                                                     {'loss': 0.7098, 'grad_norm': 5.746902942657471, 'learning_rate': 1.9873846960752848e-05, 'epoch': 1.3}
  5%|▌         | 910/17525 [11:02<3:46:02,  1.23it/s]  5%|▌         | 911/17525 [11:03<3:26:45,  1.34it/s]  5%|▌         | 912/17525 [11:05<4:39:09,  1.01s/it]  5%|▌         | 913/17525 [11:05<4:03:41,  1.14it/s]  5%|▌         | 914/17525 [11:06<3:38:49,  1.27it/s]  5%|▌         | 915/17525 [11:06<3:21:13,  1.38it/s]  5%|▌         | 916/17525 [11:07<3:08:42,  1.47it/s]  5%|▌         | 917/17525 [11:08<3:00:09,  1.54it/s]  5%|▌         | 918/17525 [11:08<2:56:31,  1.57it/s]  5%|▌         | 919/17525 [11:09<2:52:10,  1.61it/s]  5%|▌         | 920/17525 [11:09<2:48:54,  1.64it/s]                                                     {'loss': 0.8476, 'grad_norm': 5.835756301879883, 'learning_rate': 1.9870989365197544e-05, 'epoch': 1.31}
  5%|▌         | 920/17525 [11:09<2:48:54,  1.64it/s]  5%|▌         | 921/17525 [11:10<2:46:37,  1.66it/s]  5%|▌         | 922/17525 [11:10<2:45:04,  1.68it/s]  5%|▌         | 923/17525 [11:11<2:43:49,  1.69it/s]  5%|▌         | 924/17525 [11:12<2:42:39,  1.70it/s]  5%|▌         | 925/17525 [11:12<2:41:49,  1.71it/s]  5%|▌         | 926/17525 [11:13<2:41:34,  1.71it/s]  5%|▌         | 927/17525 [11:13<2:41:44,  1.71it/s]  5%|▌         | 928/17525 [11:14<2:41:48,  1.71it/s]  5%|▌         | 929/17525 [11:15<2:41:30,  1.71it/s]  5%|▌         | 930/17525 [11:15<2:41:13,  1.72it/s]                                                     {'loss': 0.9475, 'grad_norm': 4.941715240478516, 'learning_rate': 1.9868099976307496e-05, 'epoch': 1.33}
  5%|▌         | 930/17525 [11:15<2:41:13,  1.72it/s]  5%|▌         | 931/17525 [11:16<2:41:08,  1.72it/s]  5%|▌         | 932/17525 [11:16<2:40:58,  1.72it/s]  5%|▌         | 933/17525 [11:17<3:09:07,  1.46it/s]  5%|▌         | 934/17525 [11:18<3:00:39,  1.53it/s]  5%|▌         | 935/17525 [11:18<2:54:17,  1.59it/s]  5%|▌         | 936/17525 [11:19<2:49:48,  1.63it/s]  5%|▌         | 937/17525 [11:20<2:47:17,  1.65it/s]  5%|▌         | 938/17525 [11:20<2:45:15,  1.67it/s]  5%|▌         | 939/17525 [11:21<2:43:57,  1.69it/s]  5%|▌         | 940/17525 [11:21<2:42:54,  1.70it/s]                                                     {'loss': 0.7856, 'grad_norm': 5.186848163604736, 'learning_rate': 1.98651788033891e-05, 'epoch': 1.34}
  5%|▌         | 940/17525 [11:21<2:42:54,  1.70it/s]  5%|▌         | 941/17525 [11:22<2:42:17,  1.70it/s]  5%|▌         | 942/17525 [11:22<2:42:51,  1.70it/s]  5%|▌         | 943/17525 [11:23<2:42:55,  1.70it/s]  5%|▌         | 944/17525 [11:24<2:42:10,  1.70it/s]  5%|▌         | 945/17525 [11:24<2:41:21,  1.71it/s]  5%|▌         | 946/17525 [11:25<2:41:21,  1.71it/s]  5%|▌         | 947/17525 [11:25<2:40:57,  1.72it/s]  5%|▌         | 948/17525 [11:26<2:40:32,  1.72it/s]  5%|▌         | 949/17525 [11:27<2:40:22,  1.72it/s]  5%|▌         | 950/17525 [11:27<2:40:34,  1.72it/s]                                                     {'loss': 0.7406, 'grad_norm': 2.6945555210113525, 'learning_rate': 1.9862225855851122e-05, 'epoch': 1.36}
  5%|▌         | 950/17525 [11:27<2:40:34,  1.72it/s]  5%|▌         | 951/17525 [11:28<2:40:58,  1.72it/s]  5%|▌         | 952/17525 [11:28<2:40:47,  1.72it/s]  5%|▌         | 953/17525 [11:29<2:40:45,  1.72it/s]  5%|▌         | 954/17525 [11:29<2:40:38,  1.72it/s]  5%|▌         | 955/17525 [11:30<2:40:50,  1.72it/s]  5%|▌         | 956/17525 [11:31<2:40:42,  1.72it/s]  5%|▌         | 957/17525 [11:31<2:43:01,  1.69it/s]  5%|▌         | 958/17525 [11:32<2:42:27,  1.70it/s]  5%|▌         | 959/17525 [11:32<2:41:37,  1.71it/s]  5%|▌         | 960/17525 [11:33<2:41:14,  1.71it/s]                                                     {'loss': 0.7927, 'grad_norm': 3.5621187686920166, 'learning_rate': 1.985924114320467e-05, 'epoch': 1.37}
  5%|▌         | 960/17525 [11:33<2:41:14,  1.71it/s]  5%|▌         | 961/17525 [11:34<2:40:53,  1.72it/s]  5%|▌         | 962/17525 [11:34<2:40:39,  1.72it/s]  5%|▌         | 963/17525 [11:35<2:40:33,  1.72it/s]  6%|▌         | 964/17525 [11:36<4:06:43,  1.12it/s]  6%|▌         | 965/17525 [11:37<3:42:16,  1.24it/s]  6%|▌         | 966/17525 [11:38<3:23:40,  1.36it/s]  6%|▌         | 967/17525 [11:38<3:10:57,  1.45it/s]  6%|▌         | 968/17525 [11:39<3:01:56,  1.52it/s]  6%|▌         | 969/17525 [11:39<2:55:23,  1.57it/s]  6%|▌         | 970/17525 [11:40<2:50:56,  1.61it/s]                                                     {'loss': 0.7941, 'grad_norm': 4.4595723152160645, 'learning_rate': 1.9856224675063162e-05, 'epoch': 1.38}
  6%|▌         | 970/17525 [11:40<2:50:56,  1.61it/s]  6%|▌         | 971/17525 [11:40<2:48:05,  1.64it/s]  6%|▌         | 972/17525 [11:41<2:45:57,  1.66it/s]  6%|▌         | 973/17525 [11:42<2:44:24,  1.68it/s]  6%|▌         | 974/17525 [11:42<2:42:59,  1.69it/s]  6%|▌         | 975/17525 [11:43<2:42:05,  1.70it/s]  6%|▌         | 976/17525 [11:43<2:41:42,  1.71it/s]  6%|▌         | 977/17525 [11:44<2:40:54,  1.71it/s]  6%|▌         | 978/17525 [11:44<2:40:42,  1.72it/s]  6%|▌         | 979/17525 [11:46<3:30:24,  1.31it/s]  6%|▌         | 980/17525 [11:46<3:15:21,  1.41it/s]                                                     {'loss': 0.7409, 'grad_norm': 10.830349922180176, 'learning_rate': 1.98531764611423e-05, 'epoch': 1.4}
  6%|▌         | 980/17525 [11:46<3:15:21,  1.41it/s]  6%|▌         | 981/17525 [11:47<3:05:07,  1.49it/s]  6%|▌         | 982/17525 [11:47<2:57:51,  1.55it/s]  6%|▌         | 983/17525 [11:48<2:52:48,  1.60it/s]  6%|▌         | 984/17525 [11:49<2:48:56,  1.63it/s]  6%|▌         | 985/17525 [11:49<2:46:21,  1.66it/s]  6%|▌         | 986/17525 [11:50<3:19:56,  1.38it/s]  6%|▌         | 987/17525 [11:51<3:08:18,  1.46it/s]  6%|▌         | 988/17525 [11:51<2:59:48,  1.53it/s]  6%|▌         | 989/17525 [11:52<2:53:57,  1.58it/s]  6%|▌         | 990/17525 [11:53<2:49:58,  1.62it/s]                                                     {'loss': 0.6264, 'grad_norm': 5.169059753417969, 'learning_rate': 1.9850096511260035e-05, 'epoch': 1.41}
  6%|▌         | 990/17525 [11:53<2:49:58,  1.62it/s]  6%|▌         | 991/17525 [11:53<2:47:07,  1.65it/s]  6%|▌         | 992/17525 [11:54<2:44:47,  1.67it/s]  6%|▌         | 993/17525 [11:54<2:43:04,  1.69it/s]  6%|▌         | 994/17525 [11:55<2:42:28,  1.70it/s]  6%|▌         | 995/17525 [11:55<2:41:37,  1.70it/s]  6%|▌         | 996/17525 [11:56<2:41:20,  1.71it/s]  6%|▌         | 997/17525 [11:57<2:40:47,  1.71it/s]  6%|▌         | 998/17525 [11:57<2:40:25,  1.72it/s]  6%|▌         | 999/17525 [11:58<2:39:58,  1.72it/s]  6%|▌         | 1000/17525 [11:58<2:39:37,  1.73it/s]                                                      {'loss': 0.6834, 'grad_norm': 4.765387058258057, 'learning_rate': 1.9846984835336535e-05, 'epoch': 1.43}
  6%|▌         | 1000/17525 [11:58<2:39:37,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 02:15:20,205 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:15:20,205 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:15:20,205 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9313746094703674, 'eval_runtime': 4.6034, 'eval_samples_per_second': 96.232, 'eval_steps_per_second': 4.127, 'epoch': 1.43}
  6%|▌         | 1000/17525 [12:03<2:39:37,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  6%|▌         | 1001/17525 [12:04<9:00:51,  1.96s/it]  6%|▌         | 1002/17525 [12:04<7:06:09,  1.55s/it]  6%|▌         | 1003/17525 [12:05<6:14:50,  1.36s/it]  6%|▌         | 1004/17525 [12:06<5:10:18,  1.13s/it]  6%|▌         | 1005/17525 [12:06<4:24:59,  1.04it/s]  6%|▌         | 1006/17525 [12:07<3:52:56,  1.18it/s]  6%|▌         | 1007/17525 [12:07<3:30:29,  1.31it/s]  6%|▌         | 1008/17525 [12:08<3:15:00,  1.41it/s]  6%|▌         | 1009/17525 [12:08<3:04:13,  1.49it/s]  6%|▌         | 1010/17525 [12:09<2:56:54,  1.56it/s]                                                      {'loss': 0.8311, 'grad_norm': 9.359355926513672, 'learning_rate': 1.984384144339415e-05, 'epoch': 1.44}
  6%|▌         | 1010/17525 [12:09<2:56:54,  1.56it/s]  6%|▌         | 1011/17525 [12:10<2:51:57,  1.60it/s]  6%|▌         | 1012/17525 [12:10<2:47:47,  1.64it/s]  6%|▌         | 1013/17525 [12:11<2:45:23,  1.66it/s]  6%|▌         | 1014/17525 [12:11<2:43:19,  1.68it/s]  6%|▌         | 1015/17525 [12:12<2:41:57,  1.70it/s]  6%|▌         | 1016/17525 [12:13<2:41:17,  1.71it/s]  6%|▌         | 1017/17525 [12:13<2:40:36,  1.71it/s]  6%|▌         | 1018/17525 [12:14<2:40:33,  1.71it/s]  6%|▌         | 1019/17525 [12:14<2:40:04,  1.72it/s]  6%|▌         | 1020/17525 [12:15<2:41:41,  1.70it/s]                                                      {'loss': 0.7744, 'grad_norm': 6.40288782119751, 'learning_rate': 1.98406663455574e-05, 'epoch': 1.46}
  6%|▌         | 1020/17525 [12:15<2:41:41,  1.70it/s]  6%|▌         | 1021/17525 [12:15<2:41:07,  1.71it/s]  6%|▌         | 1022/17525 [12:16<2:40:18,  1.72it/s]  6%|▌         | 1023/17525 [12:17<3:08:54,  1.46it/s]  6%|▌         | 1024/17525 [12:18<3:00:56,  1.52it/s]  6%|▌         | 1025/17525 [12:18<2:55:03,  1.57it/s]  6%|▌         | 1026/17525 [12:19<2:52:42,  1.59it/s]  6%|▌         | 1027/17525 [12:19<2:51:46,  1.60it/s]  6%|▌         | 1028/17525 [12:20<2:48:31,  1.63it/s]  6%|▌         | 1029/17525 [12:21<2:46:15,  1.65it/s]  6%|▌         | 1030/17525 [12:21<2:44:23,  1.67it/s]                                                      {'loss': 0.6975, 'grad_norm': 4.431643962860107, 'learning_rate': 1.9837459552052906e-05, 'epoch': 1.47}
  6%|▌         | 1030/17525 [12:21<2:44:23,  1.67it/s]  6%|▌         | 1031/17525 [12:22<2:43:16,  1.68it/s]  6%|▌         | 1032/17525 [12:22<2:42:20,  1.69it/s]  6%|▌         | 1033/17525 [12:23<2:42:18,  1.69it/s]  6%|▌         | 1034/17525 [12:23<2:41:28,  1.70it/s]  6%|▌         | 1035/17525 [12:24<2:40:54,  1.71it/s]  6%|▌         | 1036/17525 [12:25<2:40:42,  1.71it/s]  6%|▌         | 1037/17525 [12:25<2:40:31,  1.71it/s]  6%|▌         | 1038/17525 [12:26<2:40:06,  1.72it/s]  6%|▌         | 1039/17525 [12:27<3:09:51,  1.45it/s]  6%|▌         | 1040/17525 [12:27<3:00:34,  1.52it/s]                                                      {'loss': 0.7404, 'grad_norm': 3.2017428874969482, 'learning_rate': 1.9834221073209384e-05, 'epoch': 1.48}
  6%|▌         | 1040/17525 [12:27<3:00:34,  1.52it/s]  6%|▌         | 1041/17525 [12:28<2:54:51,  1.57it/s]  6%|▌         | 1042/17525 [12:28<2:50:35,  1.61it/s]  6%|▌         | 1043/17525 [12:29<2:47:21,  1.64it/s]  6%|▌         | 1044/17525 [12:30<2:45:15,  1.66it/s]  6%|▌         | 1045/17525 [12:31<3:13:56,  1.42it/s]  6%|▌         | 1046/17525 [12:31<3:03:37,  1.50it/s]  6%|▌         | 1047/17525 [12:32<2:56:09,  1.56it/s]  6%|▌         | 1048/17525 [12:32<2:52:30,  1.59it/s]  6%|▌         | 1049/17525 [12:33<2:48:40,  1.63it/s]  6%|▌         | 1050/17525 [12:33<2:45:49,  1.66it/s]                                                      {'loss': 0.8338, 'grad_norm': 6.250372409820557, 'learning_rate': 1.983095091945761e-05, 'epoch': 1.5}
  6%|▌         | 1050/17525 [12:33<2:45:49,  1.66it/s][INFO|trainer.py:3203] 2024-06-25 02:15:55,392 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f91f90>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 137be71c-2822-4777-8ba8-7f99b429ed82)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:16:05,470 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:16:05,473 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  6%|▌         | 1051/17525 [12:44<16:44:46,  3.66s/it]  6%|▌         | 1052/17525 [12:45<12:31:07,  2.74s/it]  6%|▌         | 1053/17525 [12:45<9:33:41,  2.09s/it]   6%|▌         | 1054/17525 [12:46<7:29:15,  1.64s/it]  6%|▌         | 1055/17525 [12:47<6:04:25,  1.33s/it]  6%|▌         | 1056/17525 [12:47<5:03:04,  1.10s/it]  6%|▌         | 1057/17525 [12:48<4:19:50,  1.06it/s]  6%|▌         | 1058/17525 [12:48<3:49:42,  1.19it/s]  6%|▌         | 1059/17525 [12:49<3:28:57,  1.31it/s]  6%|▌         | 1060/17525 [12:50<3:14:10,  1.41it/s]                                                      {'loss': 0.7063, 'grad_norm': 3.752580165863037, 'learning_rate': 1.9827649101330376e-05, 'epoch': 1.51}
  6%|▌         | 1060/17525 [12:50<3:14:10,  1.41it/s]  6%|▌         | 1061/17525 [12:50<3:04:03,  1.49it/s]  6%|▌         | 1062/17525 [12:51<2:56:45,  1.55it/s]  6%|▌         | 1063/17525 [12:51<2:51:44,  1.60it/s]  6%|▌         | 1064/17525 [12:52<3:03:25,  1.50it/s]  6%|▌         | 1065/17525 [12:53<2:56:42,  1.55it/s]  6%|▌         | 1066/17525 [12:53<2:51:58,  1.60it/s]  6%|▌         | 1067/17525 [12:54<2:47:56,  1.63it/s]  6%|▌         | 1068/17525 [12:54<2:45:47,  1.65it/s]  6%|▌         | 1069/17525 [12:55<2:43:50,  1.67it/s]  6%|▌         | 1070/17525 [12:56<2:42:34,  1.69it/s]                                                      {'loss': 0.8167, 'grad_norm': 3.4872725009918213, 'learning_rate': 1.9824315629462462e-05, 'epoch': 1.53}
  6%|▌         | 1070/17525 [12:56<2:42:34,  1.69it/s]  6%|▌         | 1071/17525 [12:56<2:42:25,  1.69it/s]  6%|▌         | 1072/17525 [12:57<2:41:53,  1.69it/s]  6%|▌         | 1073/17525 [12:57<2:41:31,  1.70it/s]  6%|▌         | 1074/17525 [12:58<2:41:09,  1.70it/s]  6%|▌         | 1075/17525 [12:59<2:43:04,  1.68it/s]  6%|▌         | 1076/17525 [12:59<2:42:22,  1.69it/s]  6%|▌         | 1077/17525 [13:00<2:41:49,  1.69it/s]  6%|▌         | 1078/17525 [13:00<2:55:08,  1.57it/s]  6%|▌         | 1079/17525 [13:01<2:50:53,  1.60it/s]  6%|▌         | 1080/17525 [13:02<2:48:17,  1.63it/s]                                                      {'loss': 0.6753, 'grad_norm': 5.48591423034668, 'learning_rate': 1.9820950514590603e-05, 'epoch': 1.54}
  6%|▌         | 1080/17525 [13:02<2:48:17,  1.63it/s]  6%|▌         | 1081/17525 [13:02<2:46:31,  1.65it/s]  6%|▌         | 1082/17525 [13:03<2:45:03,  1.66it/s]  6%|▌         | 1083/17525 [13:03<2:43:33,  1.68it/s]  6%|▌         | 1084/17525 [13:04<2:42:49,  1.68it/s]  6%|▌         | 1085/17525 [13:05<2:41:59,  1.69it/s]  6%|▌         | 1086/17525 [13:05<2:41:41,  1.69it/s]  6%|▌         | 1087/17525 [13:06<2:41:11,  1.70it/s]  6%|▌         | 1088/17525 [13:06<2:40:33,  1.71it/s]  6%|▌         | 1089/17525 [13:07<2:42:01,  1.69it/s]  6%|▌         | 1090/17525 [13:08<2:41:36,  1.69it/s]                                                      {'loss': 0.8789, 'grad_norm': 4.803267478942871, 'learning_rate': 1.9817553767553453e-05, 'epoch': 1.55}
  6%|▌         | 1090/17525 [13:08<2:41:36,  1.69it/s]  6%|▌         | 1091/17525 [13:08<2:41:05,  1.70it/s]  6%|▌         | 1092/17525 [13:09<2:40:38,  1.70it/s]  6%|▌         | 1093/17525 [13:09<2:40:35,  1.71it/s]  6%|▌         | 1094/17525 [13:10<2:56:23,  1.55it/s]  6%|▌         | 1095/17525 [13:11<2:53:55,  1.57it/s]  6%|▋         | 1096/17525 [13:11<2:49:18,  1.62it/s]  6%|▋         | 1097/17525 [13:12<2:46:21,  1.65it/s]  6%|▋         | 1098/17525 [13:12<2:44:48,  1.66it/s]  6%|▋         | 1099/17525 [13:13<2:44:47,  1.66it/s]  6%|▋         | 1100/17525 [13:14<2:42:59,  1.68it/s]                                                      {'loss': 0.7589, 'grad_norm': 5.239309787750244, 'learning_rate': 1.9814125399291547e-05, 'epoch': 1.57}
  6%|▋         | 1100/17525 [13:14<2:42:59,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 02:16:35,483 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:16:35,483 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:16:35,483 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9185393452644348, 'eval_runtime': 4.5973, 'eval_samples_per_second': 96.361, 'eval_steps_per_second': 4.133, 'epoch': 1.57}
  6%|▋         | 1100/17525 [13:18<2:42:59,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  6%|▋         | 1101/17525 [13:19<9:00:16,  1.97s/it]  6%|▋         | 1102/17525 [13:19<7:06:07,  1.56s/it]  6%|▋         | 1103/17525 [13:20<5:46:32,  1.27s/it]  6%|▋         | 1104/17525 [13:21<4:51:07,  1.06s/it]  6%|▋         | 1105/17525 [13:21<4:12:03,  1.09it/s]  6%|▋         | 1106/17525 [13:22<3:44:16,  1.22it/s]  6%|▋         | 1107/17525 [13:22<3:24:45,  1.34it/s]  6%|▋         | 1108/17525 [13:23<3:11:06,  1.43it/s]  6%|▋         | 1109/17525 [13:23<3:01:42,  1.51it/s]  6%|▋         | 1110/17525 [13:24<2:55:14,  1.56it/s]                                                      {'loss': 0.752, 'grad_norm': 7.277339935302734, 'learning_rate': 1.981066542084727e-05, 'epoch': 1.58}
  6%|▋         | 1110/17525 [13:24<2:55:14,  1.56it/s]  6%|▋         | 1111/17525 [13:25<2:50:50,  1.60it/s]  6%|▋         | 1112/17525 [13:25<2:49:16,  1.62it/s]  6%|▋         | 1113/17525 [13:26<2:46:16,  1.65it/s]  6%|▋         | 1114/17525 [13:26<2:43:55,  1.67it/s]  6%|▋         | 1115/17525 [13:28<3:46:36,  1.21it/s]  6%|▋         | 1116/17525 [13:28<3:26:41,  1.32it/s]  6%|▋         | 1117/17525 [13:29<3:12:50,  1.42it/s]  6%|▋         | 1118/17525 [13:30<3:02:48,  1.50it/s]  6%|▋         | 1119/17525 [13:30<2:58:20,  1.53it/s]  6%|▋         | 1120/17525 [13:31<2:52:38,  1.58it/s]                                                      {'loss': 0.7101, 'grad_norm': 6.097012996673584, 'learning_rate': 1.980717384336482e-05, 'epoch': 1.6}
  6%|▋         | 1120/17525 [13:31<2:52:38,  1.58it/s]  6%|▋         | 1121/17525 [13:32<3:18:28,  1.38it/s]  6%|▋         | 1122/17525 [13:32<3:07:00,  1.46it/s]  6%|▋         | 1123/17525 [13:33<2:58:28,  1.53it/s]  6%|▋         | 1124/17525 [13:33<2:52:48,  1.58it/s]  6%|▋         | 1125/17525 [13:34<2:48:45,  1.62it/s]  6%|▋         | 1126/17525 [13:35<2:45:36,  1.65it/s]  6%|▋         | 1127/17525 [13:35<2:43:39,  1.67it/s]  6%|▋         | 1128/17525 [13:36<2:42:42,  1.68it/s]  6%|▋         | 1129/17525 [13:36<2:41:43,  1.69it/s]  6%|▋         | 1130/17525 [13:37<2:41:51,  1.69it/s]                                                      {'loss': 0.8071, 'grad_norm': 6.2247114181518555, 'learning_rate': 1.9803650678090164e-05, 'epoch': 1.61}
  6%|▋         | 1130/17525 [13:37<2:41:51,  1.69it/s]  6%|▋         | 1131/17525 [13:38<2:41:18,  1.69it/s]  6%|▋         | 1132/17525 [13:38<2:40:31,  1.70it/s]  6%|▋         | 1133/17525 [13:39<2:40:15,  1.70it/s]  6%|▋         | 1134/17525 [13:39<2:40:02,  1.71it/s]  6%|▋         | 1135/17525 [13:40<2:40:12,  1.71it/s]  6%|▋         | 1136/17525 [13:40<2:40:10,  1.71it/s]  6%|▋         | 1137/17525 [13:41<2:39:37,  1.71it/s]  6%|▋         | 1138/17525 [13:42<2:39:22,  1.71it/s]  6%|▋         | 1139/17525 [13:42<2:38:51,  1.72it/s]  7%|▋         | 1140/17525 [13:43<2:39:13,  1.72it/s]                                                      {'loss': 0.7799, 'grad_norm': 3.9848036766052246, 'learning_rate': 1.9800095936371027e-05, 'epoch': 1.63}
  7%|▋         | 1140/17525 [13:43<2:39:13,  1.72it/s]  7%|▋         | 1141/17525 [13:43<2:39:10,  1.72it/s]  7%|▋         | 1142/17525 [13:44<2:38:55,  1.72it/s]  7%|▋         | 1143/17525 [13:45<3:08:45,  1.45it/s]  7%|▋         | 1144/17525 [13:45<2:59:41,  1.52it/s]  7%|▋         | 1145/17525 [13:46<2:53:22,  1.57it/s]  7%|▋         | 1146/17525 [13:47<2:48:54,  1.62it/s]  7%|▋         | 1147/17525 [13:47<2:45:52,  1.65it/s]  7%|▋         | 1148/17525 [13:48<2:43:32,  1.67it/s]  7%|▋         | 1149/17525 [13:48<2:41:51,  1.69it/s]  7%|▋         | 1150/17525 [13:49<2:42:58,  1.67it/s]                                                      {'loss': 0.7973, 'grad_norm': 2.729011058807373, 'learning_rate': 1.979650962965682e-05, 'epoch': 1.64}
  7%|▋         | 1150/17525 [13:49<2:42:58,  1.67it/s]  7%|▋         | 1151/17525 [13:50<2:41:49,  1.69it/s]  7%|▋         | 1152/17525 [13:50<2:40:38,  1.70it/s]  7%|▋         | 1153/17525 [13:51<2:40:11,  1.70it/s]  7%|▋         | 1154/17525 [13:51<2:39:51,  1.71it/s]  7%|▋         | 1155/17525 [13:52<2:39:27,  1.71it/s]  7%|▋         | 1156/17525 [13:52<2:39:13,  1.71it/s]  7%|▋         | 1157/17525 [13:53<2:38:59,  1.72it/s]  7%|▋         | 1158/17525 [13:54<2:38:40,  1.72it/s]  7%|▋         | 1159/17525 [13:55<3:42:06,  1.23it/s]  7%|▋         | 1160/17525 [13:56<3:22:48,  1.34it/s]                                                      {'loss': 0.7885, 'grad_norm': 5.224048614501953, 'learning_rate': 1.9792891769498635e-05, 'epoch': 1.65}
  7%|▋         | 1160/17525 [13:56<3:22:48,  1.34it/s]  7%|▋         | 1161/17525 [13:56<3:09:51,  1.44it/s]  7%|▋         | 1162/17525 [13:57<3:00:44,  1.51it/s]  7%|▋         | 1163/17525 [13:57<2:54:25,  1.56it/s]  7%|▋         | 1164/17525 [13:58<2:50:11,  1.60it/s]  7%|▋         | 1165/17525 [13:58<2:46:54,  1.63it/s]  7%|▋         | 1166/17525 [13:59<2:44:27,  1.66it/s]  7%|▋         | 1167/17525 [14:00<2:54:27,  1.56it/s]  7%|▋         | 1168/17525 [14:00<2:49:49,  1.61it/s]  7%|▋         | 1169/17525 [14:01<2:46:27,  1.64it/s]  7%|▋         | 1170/17525 [14:02<3:00:32,  1.51it/s]                                                      {'loss': 0.7874, 'grad_norm': 4.92510461807251, 'learning_rate': 1.9789242367549187e-05, 'epoch': 1.67}
  7%|▋         | 1170/17525 [14:02<3:00:32,  1.51it/s]  7%|▋         | 1171/17525 [14:02<2:53:42,  1.57it/s]  7%|▋         | 1172/17525 [14:03<2:48:55,  1.61it/s]  7%|▋         | 1173/17525 [14:03<2:45:34,  1.65it/s]  7%|▋         | 1174/17525 [14:04<2:43:13,  1.67it/s]  7%|▋         | 1175/17525 [14:05<2:41:54,  1.68it/s]  7%|▋         | 1176/17525 [14:05<2:40:56,  1.69it/s]  7%|▋         | 1177/17525 [14:06<2:40:32,  1.70it/s]  7%|▋         | 1178/17525 [14:06<2:39:58,  1.70it/s]  7%|▋         | 1179/17525 [14:07<2:39:29,  1.71it/s]  7%|▋         | 1180/17525 [14:08<2:39:03,  1.71it/s]                                                      {'loss': 0.8394, 'grad_norm': 4.575144290924072, 'learning_rate': 1.9785561435562782e-05, 'epoch': 1.68}
  7%|▋         | 1180/17525 [14:08<2:39:03,  1.71it/s]  7%|▋         | 1181/17525 [14:08<2:41:16,  1.69it/s]  7%|▋         | 1182/17525 [14:09<2:40:10,  1.70it/s]  7%|▋         | 1183/17525 [14:09<2:39:44,  1.71it/s]  7%|▋         | 1184/17525 [14:10<2:39:12,  1.71it/s]  7%|▋         | 1185/17525 [14:10<2:38:34,  1.72it/s]  7%|▋         | 1186/17525 [14:11<2:40:02,  1.70it/s]  7%|▋         | 1187/17525 [14:12<2:50:30,  1.60it/s]  7%|▋         | 1188/17525 [14:12<2:47:06,  1.63it/s]  7%|▋         | 1189/17525 [14:13<2:44:58,  1.65it/s]  7%|▋         | 1190/17525 [14:14<2:43:24,  1.67it/s]                                                      {'loss': 0.8221, 'grad_norm': 3.0165023803710938, 'learning_rate': 1.978184898539529e-05, 'epoch': 1.7}
  7%|▋         | 1190/17525 [14:14<2:43:24,  1.67it/s]  7%|▋         | 1191/17525 [14:14<2:41:56,  1.68it/s]  7%|▋         | 1192/17525 [14:15<2:40:51,  1.69it/s]  7%|▋         | 1193/17525 [14:15<2:39:47,  1.70it/s]  7%|▋         | 1194/17525 [14:16<2:38:53,  1.71it/s]  7%|▋         | 1195/17525 [14:16<2:38:39,  1.72it/s]  7%|▋         | 1196/17525 [14:17<2:38:34,  1.72it/s]  7%|▋         | 1197/17525 [14:18<2:38:14,  1.72it/s]  7%|▋         | 1198/17525 [14:18<2:37:58,  1.72it/s]  7%|▋         | 1199/17525 [14:19<2:37:45,  1.72it/s]  7%|▋         | 1200/17525 [14:19<2:38:52,  1.71it/s]                                                      {'loss': 0.7056, 'grad_norm': 3.280059814453125, 'learning_rate': 1.977810502900408e-05, 'epoch': 1.71}
  7%|▋         | 1200/17525 [14:19<2:38:52,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 02:17:41,247 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:17:41,248 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:17:41,248 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.12it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.18it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9173012375831604, 'eval_runtime': 4.6027, 'eval_samples_per_second': 96.247, 'eval_steps_per_second': 4.128, 'epoch': 1.71}
  7%|▋         | 1200/17525 [14:24<2:38:52,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:17:45,854 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28335d5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f52b2572-ab8a-4618-b6c5-b9ebf7def112)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:17:55,951 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:17:55,953 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  7%|▋         | 1201/17525 [14:35<22:49:15,  5.03s/it]  7%|▋         | 1202/17525 [14:35<16:45:46,  3.70s/it]  7%|▋         | 1203/17525 [14:36<12:31:28,  2.76s/it]  7%|▋         | 1204/17525 [14:37<9:33:25,  2.11s/it]   7%|▋         | 1205/17525 [14:37<7:28:47,  1.65s/it]  7%|▋         | 1206/17525 [14:38<6:01:31,  1.33s/it]  7%|▋         | 1207/17525 [14:38<5:00:04,  1.10s/it]  7%|▋         | 1208/17525 [14:39<4:17:13,  1.06it/s]  7%|▋         | 1209/17525 [14:40<4:15:28,  1.06it/s]  7%|▋         | 1210/17525 [14:40<3:46:21,  1.20it/s]                                                      {'loss': 0.7585, 'grad_norm': 8.376444816589355, 'learning_rate': 1.9774329578448023e-05, 'epoch': 1.73}
  7%|▋         | 1210/17525 [14:40<3:46:21,  1.20it/s]  7%|▋         | 1211/17525 [14:41<3:26:28,  1.32it/s]  7%|▋         | 1212/17525 [14:42<3:12:00,  1.42it/s]  7%|▋         | 1213/17525 [14:42<3:02:04,  1.49it/s]  7%|▋         | 1214/17525 [14:43<2:54:57,  1.55it/s]  7%|▋         | 1215/17525 [14:43<2:49:59,  1.60it/s]  7%|▋         | 1216/17525 [14:44<2:46:15,  1.63it/s]  7%|▋         | 1217/17525 [14:44<2:43:41,  1.66it/s]  7%|▋         | 1218/17525 [14:45<2:42:04,  1.68it/s]  7%|▋         | 1219/17525 [14:46<2:40:40,  1.69it/s]  7%|▋         | 1220/17525 [14:46<2:39:39,  1.70it/s]                                                      {'loss': 0.7679, 'grad_norm': 5.227290153503418, 'learning_rate': 1.9770522645887403e-05, 'epoch': 1.74}
  7%|▋         | 1220/17525 [14:46<2:39:39,  1.70it/s]  7%|▋         | 1221/17525 [14:47<2:39:17,  1.71it/s]  7%|▋         | 1222/17525 [14:47<2:50:22,  1.59it/s]  7%|▋         | 1223/17525 [14:48<2:46:43,  1.63it/s]  7%|▋         | 1224/17525 [14:49<2:43:59,  1.66it/s]  7%|▋         | 1225/17525 [14:49<2:44:07,  1.66it/s]  7%|▋         | 1226/17525 [14:50<2:42:15,  1.67it/s]  7%|▋         | 1227/17525 [14:50<2:41:10,  1.69it/s]  7%|▋         | 1228/17525 [14:51<2:40:25,  1.69it/s]  7%|▋         | 1229/17525 [14:52<2:39:22,  1.70it/s]  7%|▋         | 1230/17525 [14:52<2:38:53,  1.71it/s]                                                      {'loss': 0.7429, 'grad_norm': 5.623944282531738, 'learning_rate': 1.976668424358393e-05, 'epoch': 1.75}
  7%|▋         | 1230/17525 [14:52<2:38:53,  1.71it/s]  7%|▋         | 1231/17525 [14:53<2:39:10,  1.71it/s]  7%|▋         | 1232/17525 [14:53<2:39:03,  1.71it/s]  7%|▋         | 1233/17525 [14:54<2:38:41,  1.71it/s]  7%|▋         | 1234/17525 [14:54<2:38:37,  1.71it/s]  7%|▋         | 1235/17525 [14:55<2:38:18,  1.72it/s]  7%|▋         | 1236/17525 [14:56<2:38:09,  1.72it/s]  7%|▋         | 1237/17525 [14:56<2:38:01,  1.72it/s]  7%|▋         | 1238/17525 [14:57<2:37:51,  1.72it/s]  7%|▋         | 1239/17525 [14:57<2:37:48,  1.72it/s]  7%|▋         | 1240/17525 [14:58<2:52:32,  1.57it/s]                                                      {'loss': 0.6495, 'grad_norm': 4.305417537689209, 'learning_rate': 1.976281438390065e-05, 'epoch': 1.77}
  7%|▋         | 1240/17525 [14:58<2:52:32,  1.57it/s]  7%|▋         | 1241/17525 [14:59<2:48:23,  1.61it/s]  7%|▋         | 1242/17525 [14:59<2:45:23,  1.64it/s]  7%|▋         | 1243/17525 [15:00<2:43:24,  1.66it/s]  7%|▋         | 1244/17525 [15:00<2:41:39,  1.68it/s]  7%|▋         | 1245/17525 [15:01<2:40:43,  1.69it/s]  7%|▋         | 1246/17525 [15:02<2:39:55,  1.70it/s]  7%|▋         | 1247/17525 [15:02<2:39:29,  1.70it/s]  7%|▋         | 1248/17525 [15:03<2:38:48,  1.71it/s]  7%|▋         | 1249/17525 [15:03<2:38:25,  1.71it/s]  7%|▋         | 1250/17525 [15:04<2:38:07,  1.72it/s]                                                      {'loss': 0.8199, 'grad_norm': 7.796850681304932, 'learning_rate': 1.9758913079301952e-05, 'epoch': 1.78}
  7%|▋         | 1250/17525 [15:04<2:38:07,  1.72it/s]  7%|▋         | 1251/17525 [15:05<2:38:43,  1.71it/s]  7%|▋         | 1252/17525 [15:05<2:38:25,  1.71it/s]  7%|▋         | 1253/17525 [15:06<2:38:41,  1.71it/s]  7%|▋         | 1254/17525 [15:06<2:38:32,  1.71it/s]  7%|▋         | 1255/17525 [15:07<2:38:17,  1.71it/s]  7%|▋         | 1256/17525 [15:07<2:37:52,  1.72it/s]  7%|▋         | 1257/17525 [15:08<2:37:47,  1.72it/s]  7%|▋         | 1258/17525 [15:09<2:38:24,  1.71it/s]  7%|▋         | 1259/17525 [15:09<2:38:22,  1.71it/s]  7%|▋         | 1260/17525 [15:10<2:37:52,  1.72it/s]                                                      {'loss': 0.7499, 'grad_norm': 3.65990948677063, 'learning_rate': 1.9754980342353484e-05, 'epoch': 1.8}
  7%|▋         | 1260/17525 [15:10<2:37:52,  1.72it/s]  7%|▋         | 1261/17525 [15:10<2:38:04,  1.71it/s]  7%|▋         | 1262/17525 [15:11<2:37:44,  1.72it/s]  7%|▋         | 1263/17525 [15:12<2:37:32,  1.72it/s]  7%|▋         | 1264/17525 [15:12<2:37:26,  1.72it/s]  7%|▋         | 1265/17525 [15:13<2:37:46,  1.72it/s]  7%|▋         | 1266/17525 [15:13<2:37:48,  1.72it/s]  7%|▋         | 1267/17525 [15:14<2:38:53,  1.71it/s]  7%|▋         | 1268/17525 [15:14<2:38:28,  1.71it/s]  7%|▋         | 1269/17525 [15:15<2:38:03,  1.71it/s]  7%|▋         | 1270/17525 [15:16<2:37:42,  1.72it/s]                                                      {'loss': 0.8436, 'grad_norm': 6.252753734588623, 'learning_rate': 1.9751016185722153e-05, 'epoch': 1.81}
  7%|▋         | 1270/17525 [15:16<2:37:42,  1.72it/s]  7%|▋         | 1271/17525 [15:16<2:37:54,  1.72it/s]  7%|▋         | 1272/17525 [15:17<2:48:37,  1.61it/s]  7%|▋         | 1273/17525 [15:18<2:45:15,  1.64it/s]  7%|▋         | 1274/17525 [15:18<2:42:53,  1.66it/s]  7%|▋         | 1275/17525 [15:19<2:41:07,  1.68it/s]  7%|▋         | 1276/17525 [15:20<3:09:02,  1.43it/s]  7%|▋         | 1277/17525 [15:20<2:59:39,  1.51it/s]  7%|▋         | 1278/17525 [15:21<2:52:37,  1.57it/s]  7%|▋         | 1279/17525 [15:21<2:48:24,  1.61it/s]  7%|▋         | 1280/17525 [15:22<2:44:41,  1.64it/s]                                                      {'loss': 0.7662, 'grad_norm': 5.880133152008057, 'learning_rate': 1.974702062217605e-05, 'epoch': 1.83}
  7%|▋         | 1280/17525 [15:22<2:44:41,  1.64it/s]  7%|▋         | 1281/17525 [15:23<2:42:31,  1.67it/s]  7%|▋         | 1282/17525 [15:23<2:40:54,  1.68it/s]  7%|▋         | 1283/17525 [15:24<2:39:41,  1.70it/s]  7%|▋         | 1284/17525 [15:24<2:38:49,  1.70it/s]  7%|▋         | 1285/17525 [15:25<2:38:18,  1.71it/s]  7%|▋         | 1286/17525 [15:25<2:38:05,  1.71it/s]  7%|▋         | 1287/17525 [15:26<2:37:57,  1.71it/s]  7%|▋         | 1288/17525 [15:27<2:37:33,  1.72it/s]  7%|▋         | 1289/17525 [15:27<2:36:54,  1.72it/s]  7%|▋         | 1290/17525 [15:28<2:37:04,  1.72it/s]                                                      {'loss': 0.7623, 'grad_norm': 4.642055511474609, 'learning_rate': 1.974299366458444e-05, 'epoch': 1.84}
  7%|▋         | 1290/17525 [15:28<2:37:04,  1.72it/s]  7%|▋         | 1291/17525 [15:28<2:37:42,  1.72it/s]  7%|▋         | 1292/17525 [15:29<2:37:27,  1.72it/s]  7%|▋         | 1293/17525 [15:30<2:39:25,  1.70it/s]  7%|▋         | 1294/17525 [15:30<2:38:48,  1.70it/s]  7%|▋         | 1295/17525 [15:31<2:38:17,  1.71it/s]  7%|▋         | 1296/17525 [15:31<2:37:48,  1.71it/s]  7%|▋         | 1297/17525 [15:32<2:37:31,  1.72it/s]  7%|▋         | 1298/17525 [15:32<2:37:18,  1.72it/s]  7%|▋         | 1299/17525 [15:33<2:37:15,  1.72it/s]  7%|▋         | 1300/17525 [15:34<3:17:31,  1.37it/s]                                                      {'loss': 0.7408, 'grad_norm': 4.311429500579834, 'learning_rate': 1.9738935325917686e-05, 'epoch': 1.85}
  7%|▋         | 1300/17525 [15:34<3:17:31,  1.37it/s][INFO|trainer.py:3512] 2024-06-25 02:18:55,969 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:18:55,969 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:18:55,969 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9123651385307312, 'eval_runtime': 4.5983, 'eval_samples_per_second': 96.339, 'eval_steps_per_second': 4.132, 'epoch': 1.85}
  7%|▋         | 1300/17525 [15:39<3:17:31,  1.37it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  7%|▋         | 1301/17525 [15:39<9:22:01,  2.08s/it]  7%|▋         | 1302/17525 [15:40<7:20:24,  1.63s/it]  7%|▋         | 1303/17525 [15:40<5:55:10,  1.31s/it]  7%|▋         | 1304/17525 [15:41<4:55:53,  1.09s/it]  7%|▋         | 1305/17525 [15:42<4:14:08,  1.06it/s]  7%|▋         | 1306/17525 [15:42<3:45:03,  1.20it/s]  7%|▋         | 1307/17525 [15:43<3:25:40,  1.31it/s]  7%|▋         | 1308/17525 [15:43<3:11:34,  1.41it/s]  7%|▋         | 1309/17525 [15:44<3:01:18,  1.49it/s]  7%|▋         | 1310/17525 [15:45<3:22:41,  1.33it/s]                                                      {'loss': 0.7203, 'grad_norm': 7.022548675537109, 'learning_rate': 1.9734845619247244e-05, 'epoch': 1.87}
  7%|▋         | 1310/17525 [15:45<3:22:41,  1.33it/s]  7%|▋         | 1311/17525 [15:46<3:44:56,  1.20it/s]  7%|▋         | 1312/17525 [15:47<4:13:11,  1.07it/s]  7%|▋         | 1313/17525 [15:48<3:44:18,  1.20it/s]  7%|▋         | 1314/17525 [15:48<3:24:13,  1.32it/s]  8%|▊         | 1315/17525 [15:49<3:10:11,  1.42it/s]  8%|▊         | 1316/17525 [15:49<2:59:54,  1.50it/s]  8%|▊         | 1317/17525 [15:50<2:53:11,  1.56it/s]  8%|▊         | 1318/17525 [15:51<2:48:29,  1.60it/s]  8%|▊         | 1319/17525 [15:51<2:44:46,  1.64it/s]  8%|▊         | 1320/17525 [15:52<2:42:20,  1.66it/s]                                                      {'loss': 0.6591, 'grad_norm': 3.8406760692596436, 'learning_rate': 1.9730724557745585e-05, 'epoch': 1.88}
  8%|▊         | 1320/17525 [15:52<2:42:20,  1.66it/s]  8%|▊         | 1321/17525 [15:52<2:41:21,  1.67it/s]  8%|▊         | 1322/17525 [15:53<2:40:24,  1.68it/s]  8%|▊         | 1323/17525 [15:54<2:39:23,  1.69it/s]  8%|▊         | 1324/17525 [15:54<2:38:30,  1.70it/s]  8%|▊         | 1325/17525 [15:55<2:37:54,  1.71it/s]  8%|▊         | 1326/17525 [15:55<2:37:12,  1.72it/s]  8%|▊         | 1327/17525 [15:56<2:36:58,  1.72it/s]  8%|▊         | 1328/17525 [15:56<2:36:42,  1.72it/s]  8%|▊         | 1329/17525 [15:57<2:37:14,  1.72it/s]  8%|▊         | 1330/17525 [15:58<2:37:38,  1.71it/s]                                                      {'loss': 0.8101, 'grad_norm': 6.356865882873535, 'learning_rate': 1.972657215468619e-05, 'epoch': 1.9}
  8%|▊         | 1330/17525 [15:58<2:37:38,  1.71it/s]  8%|▊         | 1331/17525 [15:58<2:38:13,  1.71it/s]  8%|▊         | 1332/17525 [15:59<2:38:38,  1.70it/s]  8%|▊         | 1333/17525 [16:00<3:12:08,  1.40it/s]  8%|▊         | 1334/17525 [16:00<3:02:13,  1.48it/s]  8%|▊         | 1335/17525 [16:01<2:55:26,  1.54it/s]  8%|▊         | 1336/17525 [16:02<2:50:19,  1.58it/s]  8%|▊         | 1337/17525 [16:02<2:46:48,  1.62it/s]  8%|▊         | 1338/17525 [16:03<2:44:34,  1.64it/s]  8%|▊         | 1339/17525 [16:03<2:42:28,  1.66it/s]  8%|▊         | 1340/17525 [16:04<2:41:29,  1.67it/s]                                                      {'loss': 0.7301, 'grad_norm': 8.220074653625488, 'learning_rate': 1.972238842344347e-05, 'epoch': 1.91}
  8%|▊         | 1340/17525 [16:04<2:41:29,  1.67it/s]  8%|▊         | 1341/17525 [16:04<2:41:14,  1.67it/s]  8%|▊         | 1342/17525 [16:05<2:40:53,  1.68it/s]  8%|▊         | 1343/17525 [16:06<2:40:13,  1.68it/s]  8%|▊         | 1344/17525 [16:06<2:39:22,  1.69it/s]  8%|▊         | 1345/17525 [16:07<2:38:30,  1.70it/s]  8%|▊         | 1346/17525 [16:07<2:38:04,  1.71it/s]  8%|▊         | 1347/17525 [16:08<2:37:29,  1.71it/s]  8%|▊         | 1348/17525 [16:09<2:37:24,  1.71it/s]  8%|▊         | 1349/17525 [16:09<2:37:06,  1.72it/s]  8%|▊         | 1350/17525 [16:10<2:36:54,  1.72it/s]                                                      {'loss': 0.7839, 'grad_norm': 5.476638317108154, 'learning_rate': 1.971817337749275e-05, 'epoch': 1.93}
  8%|▊         | 1350/17525 [16:10<2:36:54,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 02:19:31,624 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28335d5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ad23ff78-82bb-4c77-baec-180d17dfadfe)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:19:41,714 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:19:41,716 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  8%|▊         | 1351/17525 [16:21<16:22:53,  3.65s/it]  8%|▊         | 1352/17525 [16:21<12:14:53,  2.73s/it]  8%|▊         | 1353/17525 [16:22<9:21:07,  2.08s/it]   8%|▊         | 1354/17525 [16:22<7:19:25,  1.63s/it]  8%|▊         | 1355/17525 [16:23<5:54:56,  1.32s/it]  8%|▊         | 1356/17525 [16:23<4:55:20,  1.10s/it]  8%|▊         | 1357/17525 [16:24<4:13:28,  1.06it/s]  8%|▊         | 1358/17525 [16:25<3:44:35,  1.20it/s]  8%|▊         | 1359/17525 [16:25<3:23:56,  1.32it/s]  8%|▊         | 1360/17525 [16:26<3:09:48,  1.42it/s]                                                      {'loss': 0.7967, 'grad_norm': 4.933831691741943, 'learning_rate': 1.9713927030410212e-05, 'epoch': 1.94}
  8%|▊         | 1360/17525 [16:26<3:09:48,  1.42it/s]  8%|▊         | 1361/17525 [16:26<2:59:49,  1.50it/s]  8%|▊         | 1362/17525 [16:27<2:52:29,  1.56it/s]  8%|▊         | 1363/17525 [16:27<2:47:19,  1.61it/s]  8%|▊         | 1364/17525 [16:28<2:44:38,  1.64it/s]  8%|▊         | 1365/17525 [16:29<2:42:16,  1.66it/s]  8%|▊         | 1366/17525 [16:29<2:40:37,  1.68it/s]  8%|▊         | 1367/17525 [16:30<2:39:34,  1.69it/s]  8%|▊         | 1368/17525 [16:30<2:38:39,  1.70it/s]  8%|▊         | 1369/17525 [16:31<2:37:59,  1.70it/s]  8%|▊         | 1370/17525 [16:32<2:37:24,  1.71it/s]                                                      {'loss': 0.6536, 'grad_norm': 5.811276435852051, 'learning_rate': 1.970964939587286e-05, 'epoch': 1.95}
  8%|▊         | 1370/17525 [16:32<2:37:24,  1.71it/s]  8%|▊         | 1371/17525 [16:32<2:37:44,  1.71it/s]  8%|▊         | 1372/17525 [16:33<2:37:06,  1.71it/s]  8%|▊         | 1373/17525 [16:33<2:36:53,  1.72it/s]  8%|▊         | 1374/17525 [16:34<2:36:47,  1.72it/s]  8%|▊         | 1375/17525 [16:34<2:36:36,  1.72it/s]  8%|▊         | 1376/17525 [16:35<2:36:50,  1.72it/s]  8%|▊         | 1377/17525 [16:36<2:36:34,  1.72it/s]  8%|▊         | 1378/17525 [16:36<2:51:38,  1.57it/s]  8%|▊         | 1379/17525 [16:37<2:47:15,  1.61it/s]  8%|▊         | 1380/17525 [16:38<2:43:43,  1.64it/s]                                                      {'loss': 0.7858, 'grad_norm': 4.1062703132629395, 'learning_rate': 1.970534048765847e-05, 'epoch': 1.97}
  8%|▊         | 1380/17525 [16:38<2:43:43,  1.64it/s]  8%|▊         | 1381/17525 [16:38<2:41:50,  1.66it/s]  8%|▊         | 1382/17525 [16:39<2:40:21,  1.68it/s]  8%|▊         | 1383/17525 [16:39<2:39:12,  1.69it/s]  8%|▊         | 1384/17525 [16:40<2:38:22,  1.70it/s]  8%|▊         | 1385/17525 [16:40<2:37:55,  1.70it/s]  8%|▊         | 1386/17525 [16:41<2:37:16,  1.71it/s]  8%|▊         | 1387/17525 [16:42<2:37:11,  1.71it/s]  8%|▊         | 1388/17525 [16:42<2:38:48,  1.69it/s]  8%|▊         | 1389/17525 [16:43<2:38:18,  1.70it/s]  8%|▊         | 1390/17525 [16:44<3:42:42,  1.21it/s]                                                      {'loss': 0.7744, 'grad_norm': 2.894726514816284, 'learning_rate': 1.970100031964554e-05, 'epoch': 1.98}
  8%|▊         | 1390/17525 [16:44<3:42:42,  1.21it/s]  8%|▊         | 1391/17525 [16:45<3:23:15,  1.32it/s]  8%|▊         | 1392/17525 [16:45<3:08:55,  1.42it/s]  8%|▊         | 1393/17525 [16:46<2:59:06,  1.50it/s]  8%|▊         | 1394/17525 [16:47<2:52:09,  1.56it/s]  8%|▊         | 1395/17525 [16:47<2:47:20,  1.61it/s]  8%|▊         | 1396/17525 [16:48<2:43:51,  1.64it/s]  8%|▊         | 1397/17525 [16:48<2:41:25,  1.67it/s]  8%|▊         | 1398/17525 [16:49<2:40:00,  1.68it/s]  8%|▊         | 1399/17525 [16:49<2:38:50,  1.69it/s]  8%|▊         | 1400/17525 [16:50<2:38:12,  1.70it/s]                                                      {'loss': 0.7493, 'grad_norm': 5.24916934967041, 'learning_rate': 1.9696628905813263e-05, 'epoch': 2.0}
  8%|▊         | 1400/17525 [16:50<2:38:12,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:20:11,929 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:20:11,929 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:20:11,929 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                      
                                               [A{'eval_loss': 0.9048264026641846, 'eval_runtime': 4.5948, 'eval_samples_per_second': 96.413, 'eval_steps_per_second': 4.135, 'epoch': 2.0}
  8%|▊         | 1400/17525 [16:55<2:38:12,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A  8%|▊         | 1401/17525 [16:55<8:48:34,  1.97s/it]  8%|▊         | 1402/17525 [16:56<6:56:44,  1.55s/it]  8%|▊         | 1403/17525 [16:56<5:38:54,  1.26s/it]  8%|▊         | 1404/17525 [16:57<4:44:22,  1.06s/it]  8%|▊         | 1405/17525 [16:58<4:06:03,  1.09it/s]  8%|▊         | 1406/17525 [16:58<3:39:17,  1.23it/s]  8%|▊         | 1407/17525 [17:00<4:42:46,  1.05s/it]  8%|▊         | 1408/17525 [17:00<4:04:56,  1.10it/s]  8%|▊         | 1409/17525 [17:01<3:38:21,  1.23it/s]  8%|▊         | 1410/17525 [17:02<3:21:23,  1.33it/s]                                                      {'loss': 0.6283, 'grad_norm': 3.0627498626708984, 'learning_rate': 1.9692226260241466e-05, 'epoch': 2.01}
  8%|▊         | 1410/17525 [17:02<3:21:23,  1.33it/s]  8%|▊         | 1411/17525 [17:02<3:07:45,  1.43it/s]  8%|▊         | 1412/17525 [17:03<2:58:13,  1.51it/s]  8%|▊         | 1413/17525 [17:03<2:51:46,  1.56it/s]  8%|▊         | 1414/17525 [17:04<2:46:58,  1.61it/s]  8%|▊         | 1415/17525 [17:04<2:43:13,  1.65it/s]  8%|▊         | 1416/17525 [17:05<2:41:23,  1.66it/s]  8%|▊         | 1417/17525 [17:06<2:50:17,  1.58it/s]  8%|▊         | 1418/17525 [17:06<2:46:02,  1.62it/s]  8%|▊         | 1419/17525 [17:07<2:43:05,  1.65it/s]  8%|▊         | 1420/17525 [17:08<3:19:38,  1.34it/s]                                                      {'loss': 0.8134, 'grad_norm': 5.129922389984131, 'learning_rate': 1.9687792397110567e-05, 'epoch': 2.03}
  8%|▊         | 1420/17525 [17:08<3:19:38,  1.34it/s]  8%|▊         | 1421/17525 [17:09<3:06:50,  1.44it/s]  8%|▊         | 1422/17525 [17:09<2:57:19,  1.51it/s]  8%|▊         | 1423/17525 [17:10<2:50:24,  1.57it/s]  8%|▊         | 1424/17525 [17:10<2:46:04,  1.62it/s]  8%|▊         | 1425/17525 [17:11<2:42:49,  1.65it/s]  8%|▊         | 1426/17525 [17:11<2:40:41,  1.67it/s]  8%|▊         | 1427/17525 [17:12<2:39:18,  1.68it/s]  8%|▊         | 1428/17525 [17:13<2:38:16,  1.69it/s]  8%|▊         | 1429/17525 [17:13<2:37:54,  1.70it/s]  8%|▊         | 1430/17525 [17:14<2:37:03,  1.71it/s]                                                      {'loss': 0.7166, 'grad_norm': 9.088287353515625, 'learning_rate': 1.9683327330701533e-05, 'epoch': 2.04}
  8%|▊         | 1430/17525 [17:14<2:37:03,  1.71it/s]  8%|▊         | 1431/17525 [17:14<2:36:39,  1.71it/s]  8%|▊         | 1432/17525 [17:15<2:36:05,  1.72it/s]  8%|▊         | 1433/17525 [17:15<2:35:51,  1.72it/s]  8%|▊         | 1434/17525 [17:16<2:35:36,  1.72it/s]  8%|▊         | 1435/17525 [17:17<2:35:20,  1.73it/s]  8%|▊         | 1436/17525 [17:17<2:34:58,  1.73it/s]  8%|▊         | 1437/17525 [17:18<3:04:11,  1.46it/s]  8%|▊         | 1438/17525 [17:19<2:55:33,  1.53it/s]  8%|▊         | 1439/17525 [17:19<2:49:39,  1.58it/s]  8%|▊         | 1440/17525 [17:20<2:45:29,  1.62it/s]                                                      {'loss': 0.7159, 'grad_norm': 3.552171468734741, 'learning_rate': 1.9678831075395843e-05, 'epoch': 2.05}
  8%|▊         | 1440/17525 [17:20<2:45:29,  1.62it/s]  8%|▊         | 1441/17525 [17:20<2:42:53,  1.65it/s]  8%|▊         | 1442/17525 [17:21<2:41:03,  1.66it/s]  8%|▊         | 1443/17525 [17:22<2:39:18,  1.68it/s]  8%|▊         | 1444/17525 [17:22<2:38:17,  1.69it/s]  8%|▊         | 1445/17525 [17:23<2:37:35,  1.70it/s]  8%|▊         | 1446/17525 [17:23<2:36:37,  1.71it/s]  8%|▊         | 1447/17525 [17:24<2:36:34,  1.71it/s]  8%|▊         | 1448/17525 [17:25<2:51:35,  1.56it/s]  8%|▊         | 1449/17525 [17:25<2:47:00,  1.60it/s]  8%|▊         | 1450/17525 [17:26<2:58:09,  1.50it/s]                                                      {'loss': 0.8672, 'grad_norm': 6.430697441101074, 'learning_rate': 1.967430364567542e-05, 'epoch': 2.07}
  8%|▊         | 1450/17525 [17:26<2:58:09,  1.50it/s]  8%|▊         | 1451/17525 [17:27<2:53:07,  1.55it/s]  8%|▊         | 1452/17525 [17:27<2:47:51,  1.60it/s]  8%|▊         | 1453/17525 [17:28<2:44:12,  1.63it/s]  8%|▊         | 1454/17525 [17:28<2:41:29,  1.66it/s]  8%|▊         | 1455/17525 [17:29<2:39:43,  1.68it/s]  8%|▊         | 1456/17525 [17:30<2:38:33,  1.69it/s]  8%|▊         | 1457/17525 [17:30<2:37:43,  1.70it/s]  8%|▊         | 1458/17525 [17:31<2:36:54,  1.71it/s]  8%|▊         | 1459/17525 [17:31<2:36:16,  1.71it/s]  8%|▊         | 1460/17525 [17:32<2:38:18,  1.69it/s]                                                      {'loss': 0.7536, 'grad_norm': 3.2429327964782715, 'learning_rate': 1.96697450561226e-05, 'epoch': 2.08}
  8%|▊         | 1460/17525 [17:32<2:38:18,  1.69it/s]  8%|▊         | 1461/17525 [17:33<2:38:57,  1.68it/s]  8%|▊         | 1462/17525 [17:33<2:37:47,  1.70it/s]  8%|▊         | 1463/17525 [17:34<2:37:05,  1.70it/s]  8%|▊         | 1464/17525 [17:34<2:36:23,  1.71it/s]  8%|▊         | 1465/17525 [17:35<2:36:07,  1.71it/s]  8%|▊         | 1466/17525 [17:35<2:35:39,  1.72it/s]  8%|▊         | 1467/17525 [17:36<2:35:23,  1.72it/s]  8%|▊         | 1468/17525 [17:37<2:35:09,  1.72it/s]  8%|▊         | 1469/17525 [17:37<2:34:51,  1.73it/s]  8%|▊         | 1470/17525 [17:38<2:34:41,  1.73it/s]                                                      {'loss': 0.7547, 'grad_norm': 7.685490131378174, 'learning_rate': 1.966515532142008e-05, 'epoch': 2.1}
  8%|▊         | 1470/17525 [17:38<2:34:41,  1.73it/s]  8%|▊         | 1471/17525 [17:38<2:34:41,  1.73it/s]  8%|▊         | 1472/17525 [17:39<2:34:45,  1.73it/s]  8%|▊         | 1473/17525 [17:39<2:34:45,  1.73it/s]  8%|▊         | 1474/17525 [17:40<2:34:43,  1.73it/s]  8%|▊         | 1475/17525 [17:41<2:34:31,  1.73it/s]  8%|▊         | 1476/17525 [17:41<2:34:32,  1.73it/s]  8%|▊         | 1477/17525 [17:42<2:46:12,  1.61it/s]  8%|▊         | 1478/17525 [17:43<2:42:33,  1.65it/s]  8%|▊         | 1479/17525 [17:43<2:40:12,  1.67it/s]  8%|▊         | 1480/17525 [17:44<2:39:35,  1.68it/s]                                                      {'loss': 0.7945, 'grad_norm': 5.211631774902344, 'learning_rate': 1.9660534456350878e-05, 'epoch': 2.11}
  8%|▊         | 1480/17525 [17:44<2:39:35,  1.68it/s]  8%|▊         | 1481/17525 [17:44<2:38:16,  1.69it/s]  8%|▊         | 1482/17525 [17:45<2:37:18,  1.70it/s]  8%|▊         | 1483/17525 [17:45<2:36:13,  1.71it/s]  8%|▊         | 1484/17525 [17:46<2:35:50,  1.72it/s]  8%|▊         | 1485/17525 [17:47<2:35:32,  1.72it/s]  8%|▊         | 1486/17525 [17:47<2:35:26,  1.72it/s]  8%|▊         | 1487/17525 [17:48<2:35:06,  1.72it/s]  8%|▊         | 1488/17525 [17:48<2:35:07,  1.72it/s]  8%|▊         | 1489/17525 [17:49<2:35:11,  1.72it/s]  9%|▊         | 1490/17525 [17:49<2:35:01,  1.72it/s]                                                      {'loss': 0.8722, 'grad_norm': 3.4677064418792725, 'learning_rate': 1.9655882475798275e-05, 'epoch': 2.13}
  9%|▊         | 1490/17525 [17:49<2:35:01,  1.72it/s]  9%|▊         | 1491/17525 [17:50<2:35:05,  1.72it/s]  9%|▊         | 1492/17525 [17:51<3:38:02,  1.23it/s]  9%|▊         | 1493/17525 [17:52<3:19:30,  1.34it/s]  9%|▊         | 1494/17525 [17:53<3:06:46,  1.43it/s]  9%|▊         | 1495/17525 [17:53<2:57:42,  1.50it/s]  9%|▊         | 1496/17525 [17:54<2:51:03,  1.56it/s]  9%|▊         | 1497/17525 [17:54<2:45:59,  1.61it/s]  9%|▊         | 1498/17525 [17:55<2:42:38,  1.64it/s]  9%|▊         | 1499/17525 [17:55<2:40:15,  1.67it/s]  9%|▊         | 1500/17525 [17:56<2:38:21,  1.69it/s]                                                      {'loss': 0.7584, 'grad_norm': 5.925901889801025, 'learning_rate': 1.9651199394745766e-05, 'epoch': 2.14}
  9%|▊         | 1500/17525 [17:56<2:38:21,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:21:17,963 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:21:17,963 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:21:17,963 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9097425937652588, 'eval_runtime': 4.605, 'eval_samples_per_second': 96.199, 'eval_steps_per_second': 4.126, 'epoch': 2.14}
  9%|▊         | 1500/17525 [18:01<2:38:21,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:21:22,574 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b288b775990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4d1fb0eb-96b0-4fef-8ea3-be9ae632d123)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:21:32,641 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:21:32,643 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  9%|▊         | 1501/17525 [18:12<22:28:45,  5.05s/it]  9%|▊         | 1502/17525 [18:12<16:30:28,  3.71s/it]  9%|▊         | 1503/17525 [18:13<12:19:59,  2.77s/it]  9%|▊         | 1504/17525 [18:13<9:24:30,  2.11s/it]   9%|▊         | 1505/17525 [18:14<7:21:38,  1.65s/it]  9%|▊         | 1506/17525 [18:14<5:55:15,  1.33s/it]  9%|▊         | 1507/17525 [18:15<4:54:52,  1.10s/it]  9%|▊         | 1508/17525 [18:16<4:12:30,  1.06it/s]  9%|▊         | 1509/17525 [18:16<3:43:03,  1.20it/s]  9%|▊         | 1510/17525 [18:17<3:22:38,  1.32it/s]                                                      {'loss': 0.723, 'grad_norm': 5.062584400177002, 'learning_rate': 1.9646485228277027e-05, 'epoch': 2.15}
  9%|▊         | 1510/17525 [18:17<3:22:38,  1.32it/s]  9%|▊         | 1511/17525 [18:17<3:08:21,  1.42it/s]  9%|▊         | 1512/17525 [18:18<2:58:19,  1.50it/s]  9%|▊         | 1513/17525 [18:18<2:50:59,  1.56it/s]  9%|▊         | 1514/17525 [18:19<2:46:07,  1.61it/s]  9%|▊         | 1515/17525 [18:20<2:42:36,  1.64it/s]  9%|▊         | 1516/17525 [18:20<2:40:11,  1.67it/s]  9%|▊         | 1517/17525 [18:21<2:38:44,  1.68it/s]  9%|▊         | 1518/17525 [18:21<2:37:41,  1.69it/s]  9%|▊         | 1519/17525 [18:22<2:37:01,  1.70it/s]  9%|▊         | 1520/17525 [18:23<2:36:14,  1.71it/s]                                                      {'loss': 0.7495, 'grad_norm': 4.922976016998291, 'learning_rate': 1.9641739991575856e-05, 'epoch': 2.17}
  9%|▊         | 1520/17525 [18:23<2:36:14,  1.71it/s]  9%|▊         | 1521/17525 [18:23<2:36:16,  1.71it/s]  9%|▊         | 1522/17525 [18:24<2:35:52,  1.71it/s]  9%|▊         | 1523/17525 [18:24<2:35:50,  1.71it/s]  9%|▊         | 1524/17525 [18:25<2:35:39,  1.71it/s]  9%|▊         | 1525/17525 [18:26<2:46:06,  1.61it/s]  9%|▊         | 1526/17525 [18:26<2:42:45,  1.64it/s]  9%|▊         | 1527/17525 [18:27<2:40:22,  1.66it/s]  9%|▊         | 1528/17525 [18:27<2:38:39,  1.68it/s]  9%|▊         | 1529/17525 [18:28<2:37:41,  1.69it/s]  9%|▊         | 1530/17525 [18:28<2:36:44,  1.70it/s]                                                      {'loss': 0.7044, 'grad_norm': 6.127582550048828, 'learning_rate': 1.963696369992611e-05, 'epoch': 2.18}
  9%|▊         | 1530/17525 [18:28<2:36:44,  1.70it/s]  9%|▊         | 1531/17525 [18:29<2:36:15,  1.71it/s]  9%|▊         | 1532/17525 [18:30<2:36:00,  1.71it/s]  9%|▊         | 1533/17525 [18:30<2:35:25,  1.71it/s]  9%|▉         | 1534/17525 [18:31<2:35:25,  1.71it/s]  9%|▉         | 1535/17525 [18:31<2:35:39,  1.71it/s]  9%|▉         | 1536/17525 [18:32<2:35:21,  1.72it/s]  9%|▉         | 1537/17525 [18:33<2:35:15,  1.72it/s]  9%|▉         | 1538/17525 [18:33<2:35:30,  1.71it/s]  9%|▉         | 1539/17525 [18:34<2:35:02,  1.72it/s]  9%|▉         | 1540/17525 [18:34<2:35:00,  1.72it/s]                                                      {'loss': 0.7518, 'grad_norm': 5.525087356567383, 'learning_rate': 1.963215636871169e-05, 'epoch': 2.2}
  9%|▉         | 1540/17525 [18:34<2:35:00,  1.72it/s]  9%|▉         | 1541/17525 [18:35<2:34:54,  1.72it/s]  9%|▉         | 1542/17525 [18:35<2:35:00,  1.72it/s]  9%|▉         | 1543/17525 [18:36<2:36:13,  1.71it/s]  9%|▉         | 1544/17525 [18:37<2:35:40,  1.71it/s]  9%|▉         | 1545/17525 [18:37<2:35:16,  1.72it/s]  9%|▉         | 1546/17525 [18:38<2:35:08,  1.72it/s]  9%|▉         | 1547/17525 [18:38<2:34:55,  1.72it/s]  9%|▉         | 1548/17525 [18:39<2:34:31,  1.72it/s]  9%|▉         | 1549/17525 [18:40<2:34:28,  1.72it/s]  9%|▉         | 1550/17525 [18:40<2:34:20,  1.72it/s]                                                      {'loss': 0.6018, 'grad_norm': 2.977419853210449, 'learning_rate': 1.9627318013416467e-05, 'epoch': 2.21}
  9%|▉         | 1550/17525 [18:40<2:34:20,  1.72it/s]  9%|▉         | 1551/17525 [18:41<2:34:19,  1.73it/s]  9%|▉         | 1552/17525 [18:41<2:34:32,  1.72it/s]  9%|▉         | 1553/17525 [18:42<2:34:45,  1.72it/s]  9%|▉         | 1554/17525 [18:42<2:34:28,  1.72it/s]  9%|▉         | 1555/17525 [18:43<2:34:22,  1.72it/s]  9%|▉         | 1556/17525 [18:44<2:34:35,  1.72it/s]  9%|▉         | 1557/17525 [18:44<2:34:41,  1.72it/s]  9%|▉         | 1558/17525 [18:45<2:34:48,  1.72it/s]  9%|▉         | 1559/17525 [18:45<2:35:02,  1.72it/s]  9%|▉         | 1560/17525 [18:46<2:34:46,  1.72it/s]                                                      {'loss': 0.7661, 'grad_norm': 6.859838962554932, 'learning_rate': 1.9622448649624226e-05, 'epoch': 2.23}
  9%|▉         | 1560/17525 [18:46<2:34:46,  1.72it/s]  9%|▉         | 1561/17525 [18:47<2:34:59,  1.72it/s]  9%|▉         | 1562/17525 [18:47<2:35:05,  1.72it/s]  9%|▉         | 1563/17525 [18:48<2:35:19,  1.71it/s]  9%|▉         | 1564/17525 [18:48<2:35:14,  1.71it/s]  9%|▉         | 1565/17525 [18:49<2:35:00,  1.72it/s]  9%|▉         | 1566/17525 [18:50<3:00:46,  1.47it/s]  9%|▉         | 1567/17525 [18:50<2:53:05,  1.54it/s]  9%|▉         | 1568/17525 [18:51<2:47:36,  1.59it/s]  9%|▉         | 1569/17525 [18:52<2:43:38,  1.63it/s]  9%|▉         | 1570/17525 [18:52<2:40:54,  1.65it/s]                                                      {'loss': 0.7056, 'grad_norm': 5.1504034996032715, 'learning_rate': 1.961754829301864e-05, 'epoch': 2.24}
  9%|▉         | 1570/17525 [18:52<2:40:54,  1.65it/s]  9%|▉         | 1571/17525 [18:53<2:39:20,  1.67it/s]  9%|▉         | 1572/17525 [18:53<2:40:20,  1.66it/s]  9%|▉         | 1573/17525 [18:54<2:38:28,  1.68it/s]  9%|▉         | 1574/17525 [18:54<2:37:28,  1.69it/s]  9%|▉         | 1575/17525 [18:55<2:36:29,  1.70it/s]  9%|▉         | 1576/17525 [18:56<2:35:52,  1.71it/s]  9%|▉         | 1577/17525 [18:56<2:35:24,  1.71it/s]  9%|▉         | 1578/17525 [18:57<2:37:32,  1.69it/s]  9%|▉         | 1579/17525 [18:58<3:10:31,  1.39it/s]  9%|▉         | 1580/17525 [18:58<2:59:54,  1.48it/s]                                                      {'loss': 0.791, 'grad_norm': 5.054824352264404, 'learning_rate': 1.961261695938319e-05, 'epoch': 2.25}
  9%|▉         | 1580/17525 [18:58<2:59:54,  1.48it/s]  9%|▉         | 1581/17525 [18:59<2:54:00,  1.53it/s]  9%|▉         | 1582/17525 [19:00<2:48:06,  1.58it/s]  9%|▉         | 1583/17525 [19:00<2:44:01,  1.62it/s]  9%|▉         | 1584/17525 [19:01<2:41:08,  1.65it/s]  9%|▉         | 1585/17525 [19:01<2:38:57,  1.67it/s]  9%|▉         | 1586/17525 [19:02<2:37:31,  1.69it/s]  9%|▉         | 1587/17525 [19:02<2:36:37,  1.70it/s]  9%|▉         | 1588/17525 [19:03<2:37:07,  1.69it/s]  9%|▉         | 1589/17525 [19:04<2:36:13,  1.70it/s]  9%|▉         | 1590/17525 [19:04<2:35:28,  1.71it/s]                                                      {'loss': 0.6822, 'grad_norm': 6.979025840759277, 'learning_rate': 1.9607654664601152e-05, 'epoch': 2.27}
  9%|▉         | 1590/17525 [19:04<2:35:28,  1.71it/s]  9%|▉         | 1591/17525 [19:05<2:35:29,  1.71it/s]  9%|▉         | 1592/17525 [19:05<2:35:04,  1.71it/s]  9%|▉         | 1593/17525 [19:06<2:34:58,  1.71it/s]  9%|▉         | 1594/17525 [19:07<2:34:12,  1.72it/s]  9%|▉         | 1595/17525 [19:07<2:33:48,  1.73it/s]  9%|▉         | 1596/17525 [19:08<2:33:40,  1.73it/s]  9%|▉         | 1597/17525 [19:08<2:33:28,  1.73it/s]  9%|▉         | 1598/17525 [19:09<2:33:33,  1.73it/s]  9%|▉         | 1599/17525 [19:09<2:33:28,  1.73it/s]  9%|▉         | 1600/17525 [19:10<2:33:26,  1.73it/s]                                                      {'loss': 0.7729, 'grad_norm': 9.534884452819824, 'learning_rate': 1.960266142465551e-05, 'epoch': 2.28}
  9%|▉         | 1600/17525 [19:10<2:33:26,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 02:22:31,921 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:22:31,921 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:22:31,921 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9049099087715149, 'eval_runtime': 4.604, 'eval_samples_per_second': 96.22, 'eval_steps_per_second': 4.127, 'epoch': 2.28}
  9%|▉         | 1600/17525 [19:15<2:33:26,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A  9%|▉         | 1601/17525 [19:15<8:41:33,  1.97s/it]  9%|▉         | 1602/17525 [19:16<6:51:11,  1.55s/it]  9%|▉         | 1603/17525 [19:16<5:34:09,  1.26s/it]  9%|▉         | 1604/17525 [19:17<4:40:35,  1.06s/it]  9%|▉         | 1605/17525 [19:18<4:02:29,  1.09it/s]  9%|▉         | 1606/17525 [19:18<3:36:08,  1.23it/s]  9%|▉         | 1607/17525 [19:19<3:17:50,  1.34it/s]  9%|▉         | 1608/17525 [19:19<3:05:02,  1.43it/s]  9%|▉         | 1609/17525 [19:20<2:55:59,  1.51it/s]  9%|▉         | 1610/17525 [19:20<2:49:41,  1.56it/s]                                                      {'loss': 0.7666, 'grad_norm': 6.074899673461914, 'learning_rate': 1.9597637255628924e-05, 'epoch': 2.3}
  9%|▉         | 1610/17525 [19:20<2:49:41,  1.56it/s]  9%|▉         | 1611/17525 [19:22<3:48:21,  1.16it/s]  9%|▉         | 1612/17525 [19:22<3:26:19,  1.29it/s]  9%|▉         | 1613/17525 [19:23<3:10:43,  1.39it/s]  9%|▉         | 1614/17525 [19:24<2:59:47,  1.47it/s]  9%|▉         | 1615/17525 [19:24<2:52:09,  1.54it/s]  9%|▉         | 1616/17525 [19:25<2:46:52,  1.59it/s]  9%|▉         | 1617/17525 [19:25<2:43:06,  1.63it/s]  9%|▉         | 1618/17525 [19:26<2:40:27,  1.65it/s]  9%|▉         | 1619/17525 [19:27<2:38:22,  1.67it/s]  9%|▉         | 1620/17525 [19:27<2:36:43,  1.69it/s]                                                      {'loss': 0.7517, 'grad_norm': 6.382460594177246, 'learning_rate': 1.9592582173703666e-05, 'epoch': 2.31}
  9%|▉         | 1620/17525 [19:27<2:36:43,  1.69it/s]  9%|▉         | 1621/17525 [19:28<2:36:35,  1.69it/s]  9%|▉         | 1622/17525 [19:29<3:01:12,  1.46it/s]  9%|▉         | 1623/17525 [19:29<2:53:15,  1.53it/s]  9%|▉         | 1624/17525 [19:30<2:47:37,  1.58it/s]  9%|▉         | 1625/17525 [19:30<2:43:44,  1.62it/s]  9%|▉         | 1626/17525 [19:31<2:56:31,  1.50it/s]  9%|▉         | 1627/17525 [19:32<2:50:00,  1.56it/s]  9%|▉         | 1628/17525 [19:32<2:45:33,  1.60it/s]  9%|▉         | 1629/17525 [19:33<2:42:37,  1.63it/s]  9%|▉         | 1630/17525 [19:33<2:40:29,  1.65it/s]                                                      {'loss': 0.8613, 'grad_norm': 5.172187328338623, 'learning_rate': 1.9587496195161582e-05, 'epoch': 2.33}
  9%|▉         | 1630/17525 [19:33<2:40:29,  1.65it/s]  9%|▉         | 1631/17525 [19:34<2:39:21,  1.66it/s]  9%|▉         | 1632/17525 [19:35<2:38:15,  1.67it/s]  9%|▉         | 1633/17525 [19:35<2:37:13,  1.68it/s]  9%|▉         | 1634/17525 [19:36<2:36:21,  1.69it/s]  9%|▉         | 1635/17525 [19:36<2:35:30,  1.70it/s]  9%|▉         | 1636/17525 [19:37<2:34:59,  1.71it/s]  9%|▉         | 1637/17525 [19:38<2:34:34,  1.71it/s]  9%|▉         | 1638/17525 [19:38<2:34:01,  1.72it/s]  9%|▉         | 1639/17525 [19:39<2:33:41,  1.72it/s]  9%|▉         | 1640/17525 [19:39<2:34:41,  1.71it/s]                                                      {'loss': 0.6972, 'grad_norm': 4.447597980499268, 'learning_rate': 1.9582379336384037e-05, 'epoch': 2.34}
  9%|▉         | 1640/17525 [19:39<2:34:41,  1.71it/s]  9%|▉         | 1641/17525 [19:40<2:35:51,  1.70it/s]  9%|▉         | 1642/17525 [19:40<2:35:06,  1.71it/s]  9%|▉         | 1643/17525 [19:41<2:34:40,  1.71it/s]  9%|▉         | 1644/17525 [19:42<2:34:09,  1.72it/s]  9%|▉         | 1645/17525 [19:42<2:33:56,  1.72it/s]  9%|▉         | 1646/17525 [19:43<2:33:54,  1.72it/s]  9%|▉         | 1647/17525 [19:43<2:33:29,  1.72it/s]  9%|▉         | 1648/17525 [19:44<2:33:15,  1.73it/s]  9%|▉         | 1649/17525 [19:45<2:33:00,  1.73it/s]  9%|▉         | 1650/17525 [19:45<2:33:03,  1.73it/s]                                                      {'loss': 0.7389, 'grad_norm': 4.355895042419434, 'learning_rate': 1.9577231613851846e-05, 'epoch': 2.35}
  9%|▉         | 1650/17525 [19:45<2:33:03,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 02:23:06,989 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897ed4ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 322c2fbf-7104-4bb0-acf6-f8db55fad16c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:23:17,044 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:23:17,047 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
  9%|▉         | 1651/17525 [19:56<16:01:16,  3.63s/it]  9%|▉         | 1652/17525 [19:56<11:59:02,  2.72s/it]  9%|▉         | 1653/17525 [19:57<9:37:24,  2.18s/it]   9%|▉         | 1654/17525 [19:58<7:30:49,  1.70s/it]  9%|▉         | 1655/17525 [19:59<6:01:39,  1.37s/it]  9%|▉         | 1656/17525 [19:59<5:13:31,  1.19s/it]  9%|▉         | 1657/17525 [20:00<4:27:02,  1.01s/it]  9%|▉         | 1658/17525 [20:00<3:53:11,  1.13it/s]  9%|▉         | 1659/17525 [20:01<3:29:28,  1.26it/s]  9%|▉         | 1660/17525 [20:02<3:12:54,  1.37it/s]                                                      {'loss': 0.7013, 'grad_norm': 6.394806861877441, 'learning_rate': 1.9572053044145236e-05, 'epoch': 2.37}
  9%|▉         | 1660/17525 [20:02<3:12:54,  1.37it/s]  9%|▉         | 1661/17525 [20:02<3:01:15,  1.46it/s]  9%|▉         | 1662/17525 [20:03<2:52:58,  1.53it/s]  9%|▉         | 1663/17525 [20:03<2:47:18,  1.58it/s]  9%|▉         | 1664/17525 [20:04<2:43:07,  1.62it/s] 10%|▉         | 1665/17525 [20:05<2:43:27,  1.62it/s] 10%|▉         | 1666/17525 [20:05<2:40:51,  1.64it/s] 10%|▉         | 1667/17525 [20:06<2:38:47,  1.66it/s] 10%|▉         | 1668/17525 [20:06<2:37:08,  1.68it/s] 10%|▉         | 1669/17525 [20:07<2:36:30,  1.69it/s] 10%|▉         | 1670/17525 [20:08<2:35:37,  1.70it/s]                                                      {'loss': 0.8115, 'grad_norm': 4.7993998527526855, 'learning_rate': 1.95668436439438e-05, 'epoch': 2.38}
 10%|▉         | 1670/17525 [20:08<2:35:37,  1.70it/s] 10%|▉         | 1671/17525 [20:08<2:35:12,  1.70it/s] 10%|▉         | 1672/17525 [20:09<2:34:48,  1.71it/s] 10%|▉         | 1673/17525 [20:09<2:34:36,  1.71it/s] 10%|▉         | 1674/17525 [20:10<2:48:45,  1.57it/s] 10%|▉         | 1675/17525 [20:11<2:44:32,  1.61it/s] 10%|▉         | 1676/17525 [20:11<2:41:01,  1.64it/s] 10%|▉         | 1677/17525 [20:12<2:40:45,  1.64it/s] 10%|▉         | 1678/17525 [20:12<2:38:44,  1.66it/s] 10%|▉         | 1679/17525 [20:13<2:37:19,  1.68it/s] 10%|▉         | 1680/17525 [20:14<2:36:06,  1.69it/s]                                                      {'loss': 0.6628, 'grad_norm': 7.406335353851318, 'learning_rate': 1.9561603430026414e-05, 'epoch': 2.4}
 10%|▉         | 1680/17525 [20:14<2:36:06,  1.69it/s] 10%|▉         | 1681/17525 [20:14<2:35:16,  1.70it/s] 10%|▉         | 1682/17525 [20:15<2:34:30,  1.71it/s] 10%|▉         | 1683/17525 [20:15<2:36:32,  1.69it/s] 10%|▉         | 1684/17525 [20:16<2:35:35,  1.70it/s] 10%|▉         | 1685/17525 [20:16<2:34:50,  1.70it/s] 10%|▉         | 1686/17525 [20:17<2:34:27,  1.71it/s] 10%|▉         | 1687/17525 [20:18<2:34:13,  1.71it/s] 10%|▉         | 1688/17525 [20:18<2:33:43,  1.72it/s] 10%|▉         | 1689/17525 [20:19<2:33:35,  1.72it/s] 10%|▉         | 1690/17525 [20:19<2:33:33,  1.72it/s]                                                      {'loss': 0.7653, 'grad_norm': 5.345989227294922, 'learning_rate': 1.9556332419271218e-05, 'epoch': 2.41}
 10%|▉         | 1690/17525 [20:19<2:33:33,  1.72it/s] 10%|▉         | 1691/17525 [20:20<2:33:31,  1.72it/s] 10%|▉         | 1692/17525 [20:21<2:33:46,  1.72it/s] 10%|▉         | 1693/17525 [20:21<2:33:45,  1.72it/s] 10%|▉         | 1694/17525 [20:22<2:33:28,  1.72it/s] 10%|▉         | 1695/17525 [20:22<2:33:06,  1.72it/s] 10%|▉         | 1696/17525 [20:23<2:33:02,  1.72it/s] 10%|▉         | 1697/17525 [20:23<2:33:18,  1.72it/s] 10%|▉         | 1698/17525 [20:24<2:33:23,  1.72it/s] 10%|▉         | 1699/17525 [20:25<2:33:21,  1.72it/s] 10%|▉         | 1700/17525 [20:25<2:33:27,  1.72it/s]                                                      {'loss': 0.7722, 'grad_norm': 3.032991886138916, 'learning_rate': 1.9551030628655536e-05, 'epoch': 2.43}
 10%|▉         | 1700/17525 [20:25<2:33:27,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:23:47,093 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:23:47,093 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:23:47,093 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.9068970680236816, 'eval_runtime': 4.5983, 'eval_samples_per_second': 96.34, 'eval_steps_per_second': 4.132, 'epoch': 2.43}
 10%|▉         | 1700/17525 [20:30<2:33:27,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 10%|▉         | 1701/17525 [20:30<8:38:02,  1.96s/it] 10%|▉         | 1702/17525 [20:31<6:48:34,  1.55s/it] 10%|▉         | 1703/17525 [20:32<5:31:55,  1.26s/it] 10%|▉         | 1704/17525 [20:32<4:49:53,  1.10s/it] 10%|▉         | 1705/17525 [20:33<4:09:04,  1.06it/s] 10%|▉         | 1706/17525 [20:33<3:40:18,  1.20it/s] 10%|▉         | 1707/17525 [20:34<3:20:08,  1.32it/s] 10%|▉         | 1708/17525 [20:35<3:06:24,  1.41it/s] 10%|▉         | 1709/17525 [20:35<2:56:28,  1.49it/s] 10%|▉         | 1710/17525 [20:36<2:51:37,  1.54it/s]                                                      {'loss': 0.7037, 'grad_norm': 6.459873676300049, 'learning_rate': 1.954569807525583e-05, 'epoch': 2.44}
 10%|▉         | 1710/17525 [20:36<2:51:37,  1.54it/s] 10%|▉         | 1711/17525 [20:36<2:46:11,  1.59it/s] 10%|▉         | 1712/17525 [20:37<2:42:10,  1.63it/s] 10%|▉         | 1713/17525 [20:38<2:39:43,  1.65it/s] 10%|▉         | 1714/17525 [20:38<2:37:50,  1.67it/s] 10%|▉         | 1715/17525 [20:39<2:36:09,  1.69it/s] 10%|▉         | 1716/17525 [20:39<2:35:17,  1.70it/s] 10%|▉         | 1717/17525 [20:40<2:34:37,  1.70it/s] 10%|▉         | 1718/17525 [20:40<2:34:02,  1.71it/s] 10%|▉         | 1719/17525 [20:41<2:33:57,  1.71it/s] 10%|▉         | 1720/17525 [20:42<3:07:25,  1.41it/s]                                                      {'loss': 0.7373, 'grad_norm': 4.193446636199951, 'learning_rate': 1.9540334776247657e-05, 'epoch': 2.45}
 10%|▉         | 1720/17525 [20:42<3:07:25,  1.41it/s] 10%|▉         | 1721/17525 [20:43<3:32:16,  1.24it/s] 10%|▉         | 1722/17525 [20:44<3:15:00,  1.35it/s] 10%|▉         | 1723/17525 [20:44<3:02:23,  1.44it/s] 10%|▉         | 1724/17525 [20:45<2:53:25,  1.52it/s] 10%|▉         | 1725/17525 [20:45<2:47:26,  1.57it/s] 10%|▉         | 1726/17525 [20:46<2:43:35,  1.61it/s] 10%|▉         | 1727/17525 [20:47<2:42:09,  1.62it/s] 10%|▉         | 1728/17525 [20:47<2:39:35,  1.65it/s] 10%|▉         | 1729/17525 [20:48<2:38:07,  1.67it/s] 10%|▉         | 1730/17525 [20:48<2:36:47,  1.68it/s]                                                      {'loss': 0.7051, 'grad_norm': 5.185254096984863, 'learning_rate': 1.9534940748905587e-05, 'epoch': 2.47}
 10%|▉         | 1730/17525 [20:48<2:36:47,  1.68it/s] 10%|▉         | 1731/17525 [20:49<2:37:14,  1.67it/s] 10%|▉         | 1732/17525 [20:50<2:35:46,  1.69it/s] 10%|▉         | 1733/17525 [20:50<2:34:48,  1.70it/s] 10%|▉         | 1734/17525 [20:51<2:34:19,  1.71it/s] 10%|▉         | 1735/17525 [20:51<2:33:44,  1.71it/s] 10%|▉         | 1736/17525 [20:52<2:33:19,  1.72it/s] 10%|▉         | 1737/17525 [20:52<2:33:04,  1.72it/s] 10%|▉         | 1738/17525 [20:53<2:33:13,  1.72it/s] 10%|▉         | 1739/17525 [20:54<2:33:04,  1.72it/s] 10%|▉         | 1740/17525 [20:54<2:32:52,  1.72it/s]                                                      {'loss': 0.6322, 'grad_norm': 9.957931518554688, 'learning_rate': 1.952951601060317e-05, 'epoch': 2.48}
 10%|▉         | 1740/17525 [20:54<2:32:52,  1.72it/s] 10%|▉         | 1741/17525 [20:55<2:33:02,  1.72it/s] 10%|▉         | 1742/17525 [20:55<2:32:49,  1.72it/s] 10%|▉         | 1743/17525 [20:56<2:32:50,  1.72it/s] 10%|▉         | 1744/17525 [20:56<2:33:15,  1.72it/s] 10%|▉         | 1745/17525 [20:57<2:32:43,  1.72it/s] 10%|▉         | 1746/17525 [20:58<2:32:47,  1.72it/s] 10%|▉         | 1747/17525 [20:58<2:34:21,  1.70it/s] 10%|▉         | 1748/17525 [20:59<2:33:53,  1.71it/s] 10%|▉         | 1749/17525 [20:59<2:33:34,  1.71it/s] 10%|▉         | 1750/17525 [21:00<2:33:26,  1.71it/s]                                                      {'loss': 0.7041, 'grad_norm': 4.61060905456543, 'learning_rate': 1.952406057881287e-05, 'epoch': 2.5}
 10%|▉         | 1750/17525 [21:00<2:33:26,  1.71it/s] 10%|▉         | 1751/17525 [21:01<2:33:14,  1.72it/s] 10%|▉         | 1752/17525 [21:01<2:33:14,  1.72it/s] 10%|█         | 1753/17525 [21:02<2:33:08,  1.72it/s] 10%|█         | 1754/17525 [21:02<2:33:05,  1.72it/s] 10%|█         | 1755/17525 [21:03<2:33:05,  1.72it/s] 10%|█         | 1756/17525 [21:03<2:32:59,  1.72it/s] 10%|█         | 1757/17525 [21:04<2:32:59,  1.72it/s] 10%|█         | 1758/17525 [21:05<2:32:47,  1.72it/s] 10%|█         | 1759/17525 [21:05<2:32:45,  1.72it/s] 10%|█         | 1760/17525 [21:06<2:32:50,  1.72it/s]                                                      {'loss': 0.6663, 'grad_norm': 4.608870506286621, 'learning_rate': 1.9518574471106012e-05, 'epoch': 2.51}
 10%|█         | 1760/17525 [21:06<2:32:50,  1.72it/s] 10%|█         | 1761/17525 [21:06<2:32:57,  1.72it/s] 10%|█         | 1762/17525 [21:08<3:35:41,  1.22it/s] 10%|█         | 1763/17525 [21:08<3:16:58,  1.33it/s] 10%|█         | 1764/17525 [21:09<3:04:07,  1.43it/s] 10%|█         | 1765/17525 [21:10<2:54:58,  1.50it/s] 10%|█         | 1766/17525 [21:10<2:48:44,  1.56it/s] 10%|█         | 1767/17525 [21:11<2:44:05,  1.60it/s] 10%|█         | 1768/17525 [21:11<2:40:49,  1.63it/s] 10%|█         | 1769/17525 [21:12<2:38:18,  1.66it/s] 10%|█         | 1770/17525 [21:12<2:36:29,  1.68it/s]                                                      {'loss': 0.7288, 'grad_norm': 3.8253865242004395, 'learning_rate': 1.951305770515273e-05, 'epoch': 2.52}
 10%|█         | 1770/17525 [21:12<2:36:29,  1.68it/s] 10%|█         | 1771/17525 [21:13<2:35:40,  1.69it/s] 10%|█         | 1772/17525 [21:14<2:34:44,  1.70it/s] 10%|█         | 1773/17525 [21:14<2:34:02,  1.70it/s] 10%|█         | 1774/17525 [21:15<2:33:17,  1.71it/s] 10%|█         | 1775/17525 [21:15<2:33:16,  1.71it/s] 10%|█         | 1776/17525 [21:16<2:33:07,  1.71it/s] 10%|█         | 1777/17525 [21:17<2:34:32,  1.70it/s] 10%|█         | 1778/17525 [21:17<2:35:35,  1.69it/s] 10%|█         | 1779/17525 [21:18<2:34:43,  1.70it/s] 10%|█         | 1780/17525 [21:18<2:34:11,  1.70it/s]                                                      {'loss': 0.6162, 'grad_norm': 4.030210971832275, 'learning_rate': 1.95075102987219e-05, 'epoch': 2.54}
 10%|█         | 1780/17525 [21:18<2:34:11,  1.70it/s] 10%|█         | 1781/17525 [21:19<2:33:45,  1.71it/s] 10%|█         | 1782/17525 [21:19<2:32:57,  1.72it/s] 10%|█         | 1783/17525 [21:20<2:32:34,  1.72it/s] 10%|█         | 1784/17525 [21:21<2:32:08,  1.72it/s] 10%|█         | 1785/17525 [21:21<2:31:55,  1.73it/s] 10%|█         | 1786/17525 [21:22<2:32:03,  1.73it/s] 10%|█         | 1787/17525 [21:22<2:31:57,  1.73it/s] 10%|█         | 1788/17525 [21:23<2:31:45,  1.73it/s] 10%|█         | 1789/17525 [21:24<2:32:03,  1.72it/s] 10%|█         | 1790/17525 [21:24<2:33:46,  1.71it/s]                                                      {'loss': 0.734, 'grad_norm': 6.619640827178955, 'learning_rate': 1.9501932269681082e-05, 'epoch': 2.55}
 10%|█         | 1790/17525 [21:24<2:33:46,  1.71it/s] 10%|█         | 1791/17525 [21:25<2:33:12,  1.71it/s] 10%|█         | 1792/17525 [21:25<2:32:48,  1.72it/s] 10%|█         | 1793/17525 [21:26<2:32:39,  1.72it/s] 10%|█         | 1794/17525 [21:26<2:32:23,  1.72it/s] 10%|█         | 1795/17525 [21:27<2:32:22,  1.72it/s] 10%|█         | 1796/17525 [21:28<2:32:17,  1.72it/s] 10%|█         | 1797/17525 [21:28<2:32:00,  1.72it/s] 10%|█         | 1798/17525 [21:29<2:32:01,  1.72it/s] 10%|█         | 1799/17525 [21:30<3:00:38,  1.45it/s] 10%|█         | 1800/17525 [21:30<2:52:05,  1.52it/s]                                                      {'loss': 0.717, 'grad_norm': 4.1802659034729, 'learning_rate': 1.949632363599648e-05, 'epoch': 2.57}
 10%|█         | 1800/17525 [21:30<2:52:05,  1.52it/s][INFO|trainer.py:3512] 2024-06-25 02:24:52,176 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:24:52,176 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:24:52,176 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.74it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.83it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8992795348167419, 'eval_runtime': 4.6085, 'eval_samples_per_second': 96.127, 'eval_steps_per_second': 4.123, 'epoch': 2.57}
 10%|█         | 1800/17525 [21:35<2:52:05,  1.52it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:24:56,788 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f2cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7f0b8e6c-a9da-4739-af63-1aef7f702799)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:25:06,844 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:25:06,846 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 10%|█         | 1801/17525 [21:46<22:12:13,  5.08s/it] 10%|█         | 1802/17525 [21:46<16:18:07,  3.73s/it] 10%|█         | 1803/17525 [21:47<12:09:57,  2.79s/it] 10%|█         | 1804/17525 [21:47<9:16:24,  2.12s/it]  10%|█         | 1805/17525 [21:48<7:14:46,  1.66s/it] 10%|█         | 1806/17525 [21:49<5:49:39,  1.33s/it] 10%|█         | 1807/17525 [21:49<4:50:00,  1.11s/it] 10%|█         | 1808/17525 [21:50<4:08:43,  1.05it/s] 10%|█         | 1809/17525 [21:50<3:39:59,  1.19it/s] 10%|█         | 1810/17525 [21:51<3:19:46,  1.31it/s]                                                      {'loss': 0.6269, 'grad_norm': 4.330286979675293, 'learning_rate': 1.949068441573286e-05, 'epoch': 2.58}
 10%|█         | 1810/17525 [21:51<3:19:46,  1.31it/s] 10%|█         | 1811/17525 [21:51<3:05:44,  1.41it/s] 10%|█         | 1812/17525 [21:52<3:23:16,  1.29it/s] 10%|█         | 1813/17525 [21:53<3:07:48,  1.39it/s] 10%|█         | 1814/17525 [21:54<2:56:57,  1.48it/s] 10%|█         | 1815/17525 [21:54<2:49:19,  1.55it/s] 10%|█         | 1816/17525 [21:55<2:43:49,  1.60it/s] 10%|█         | 1817/17525 [21:55<2:39:53,  1.64it/s] 10%|█         | 1818/17525 [21:56<2:37:41,  1.66it/s] 10%|█         | 1819/17525 [21:56<2:35:38,  1.68it/s] 10%|█         | 1820/17525 [21:57<2:34:24,  1.70it/s]                                                      {'loss': 0.7883, 'grad_norm': 3.801408290863037, 'learning_rate': 1.9485014627053513e-05, 'epoch': 2.6}
 10%|█         | 1820/17525 [21:57<2:34:24,  1.70it/s] 10%|█         | 1821/17525 [21:58<2:33:58,  1.70it/s] 10%|█         | 1822/17525 [21:58<2:33:16,  1.71it/s] 10%|█         | 1823/17525 [21:59<2:32:39,  1.71it/s] 10%|█         | 1824/17525 [21:59<2:32:23,  1.72it/s] 10%|█         | 1825/17525 [22:00<2:32:15,  1.72it/s] 10%|█         | 1826/17525 [22:01<2:31:57,  1.72it/s] 10%|█         | 1827/17525 [22:01<2:31:55,  1.72it/s] 10%|█         | 1828/17525 [22:02<2:31:35,  1.73it/s] 10%|█         | 1829/17525 [22:02<2:31:31,  1.73it/s] 10%|█         | 1830/17525 [22:03<2:31:38,  1.72it/s]                                                      {'loss': 0.595, 'grad_norm': 5.7961249351501465, 'learning_rate': 1.9479314288220182e-05, 'epoch': 2.61}
 10%|█         | 1830/17525 [22:03<2:31:38,  1.72it/s] 10%|█         | 1831/17525 [22:03<2:31:48,  1.72it/s] 10%|█         | 1832/17525 [22:04<2:31:33,  1.73it/s] 10%|█         | 1833/17525 [22:05<2:31:22,  1.73it/s] 10%|█         | 1834/17525 [22:05<2:31:15,  1.73it/s] 10%|█         | 1835/17525 [22:06<2:31:51,  1.72it/s] 10%|█         | 1836/17525 [22:06<2:31:45,  1.72it/s] 10%|█         | 1837/17525 [22:07<2:31:27,  1.73it/s] 10%|█         | 1838/17525 [22:07<2:31:32,  1.73it/s] 10%|█         | 1839/17525 [22:08<2:31:25,  1.73it/s] 10%|█         | 1840/17525 [22:09<2:31:37,  1.72it/s]                                                      {'loss': 0.7186, 'grad_norm': 5.491518497467041, 'learning_rate': 1.947358341759301e-05, 'epoch': 2.62}
 10%|█         | 1840/17525 [22:09<2:31:37,  1.72it/s] 11%|█         | 1841/17525 [22:09<2:31:38,  1.72it/s] 11%|█         | 1842/17525 [22:10<2:31:31,  1.73it/s] 11%|█         | 1843/17525 [22:10<2:31:14,  1.73it/s] 11%|█         | 1844/17525 [22:11<2:31:22,  1.73it/s] 11%|█         | 1845/17525 [22:12<2:31:22,  1.73it/s] 11%|█         | 1846/17525 [22:12<2:31:24,  1.73it/s] 11%|█         | 1847/17525 [22:13<2:31:18,  1.73it/s] 11%|█         | 1848/17525 [22:13<2:31:32,  1.72it/s] 11%|█         | 1849/17525 [22:14<2:31:25,  1.73it/s] 11%|█         | 1850/17525 [22:14<2:31:12,  1.73it/s]                                                      {'loss': 0.638, 'grad_norm': 6.312572956085205, 'learning_rate': 1.946782203363048e-05, 'epoch': 2.64}
 11%|█         | 1850/17525 [22:14<2:31:12,  1.73it/s] 11%|█         | 1851/17525 [22:15<2:31:22,  1.73it/s] 11%|█         | 1852/17525 [22:16<2:31:23,  1.73it/s] 11%|█         | 1853/17525 [22:16<2:31:21,  1.73it/s] 11%|█         | 1854/17525 [22:17<2:31:19,  1.73it/s] 11%|█         | 1855/17525 [22:17<2:31:11,  1.73it/s] 11%|█         | 1856/17525 [22:18<2:30:50,  1.73it/s] 11%|█         | 1857/17525 [22:18<2:30:42,  1.73it/s] 11%|█         | 1858/17525 [22:19<2:31:09,  1.73it/s] 11%|█         | 1859/17525 [22:20<2:31:14,  1.73it/s] 11%|█         | 1860/17525 [22:20<2:31:09,  1.73it/s]                                                      {'loss': 0.77, 'grad_norm': 8.720131874084473, 'learning_rate': 1.9462030154889356e-05, 'epoch': 2.65}
 11%|█         | 1860/17525 [22:20<2:31:09,  1.73it/s] 11%|█         | 1861/17525 [22:21<2:31:31,  1.72it/s] 11%|█         | 1862/17525 [22:21<2:31:25,  1.72it/s] 11%|█         | 1863/17525 [22:22<2:31:22,  1.72it/s] 11%|█         | 1864/17525 [22:23<3:08:55,  1.38it/s] 11%|█         | 1865/17525 [22:24<2:58:00,  1.47it/s] 11%|█         | 1866/17525 [22:24<2:50:01,  1.53it/s] 11%|█         | 1867/17525 [22:25<2:45:36,  1.58it/s] 11%|█         | 1868/17525 [22:25<2:40:58,  1.62it/s] 11%|█         | 1869/17525 [22:26<2:38:13,  1.65it/s] 11%|█         | 1870/17525 [22:27<2:47:08,  1.56it/s]                                                      {'loss': 0.6889, 'grad_norm': 8.529890060424805, 'learning_rate': 1.9456207800024622e-05, 'epoch': 2.67}
 11%|█         | 1870/17525 [22:27<2:47:08,  1.56it/s] 11%|█         | 1871/17525 [22:27<2:43:43,  1.59it/s] 11%|█         | 1872/17525 [22:28<2:39:56,  1.63it/s] 11%|█         | 1873/17525 [22:28<2:37:02,  1.66it/s] 11%|█         | 1874/17525 [22:29<2:35:28,  1.68it/s] 11%|█         | 1875/17525 [22:30<2:34:06,  1.69it/s] 11%|█         | 1876/17525 [22:30<2:33:20,  1.70it/s] 11%|█         | 1877/17525 [22:31<2:34:19,  1.69it/s] 11%|█         | 1878/17525 [22:31<2:33:25,  1.70it/s] 11%|█         | 1879/17525 [22:32<2:32:36,  1.71it/s] 11%|█         | 1880/17525 [22:33<2:32:25,  1.71it/s]                                                      {'loss': 0.685, 'grad_norm': 4.973337650299072, 'learning_rate': 1.945035498778942e-05, 'epoch': 2.68}
 11%|█         | 1880/17525 [22:33<2:32:25,  1.71it/s] 11%|█         | 1881/17525 [22:33<2:31:59,  1.72it/s] 11%|█         | 1882/17525 [22:34<2:31:44,  1.72it/s] 11%|█         | 1883/17525 [22:34<2:31:23,  1.72it/s] 11%|█         | 1884/17525 [22:35<2:31:07,  1.73it/s] 11%|█         | 1885/17525 [22:35<2:31:17,  1.72it/s] 11%|█         | 1886/17525 [22:36<2:31:13,  1.72it/s] 11%|█         | 1887/17525 [22:37<2:31:25,  1.72it/s] 11%|█         | 1888/17525 [22:37<2:31:17,  1.72it/s] 11%|█         | 1889/17525 [22:38<2:31:00,  1.73it/s] 11%|█         | 1890/17525 [22:38<2:31:00,  1.73it/s]                                                      {'loss': 0.7023, 'grad_norm': 5.35148286819458, 'learning_rate': 1.9444471737034996e-05, 'epoch': 2.7}
 11%|█         | 1890/17525 [22:38<2:31:00,  1.73it/s] 11%|█         | 1891/17525 [22:39<2:31:21,  1.72it/s] 11%|█         | 1892/17525 [22:39<2:31:22,  1.72it/s] 11%|█         | 1893/17525 [22:40<2:31:07,  1.72it/s] 11%|█         | 1894/17525 [22:41<2:30:48,  1.73it/s] 11%|█         | 1895/17525 [22:41<2:30:52,  1.73it/s] 11%|█         | 1896/17525 [22:42<2:30:45,  1.73it/s] 11%|█         | 1897/17525 [22:42<2:30:37,  1.73it/s] 11%|█         | 1898/17525 [22:43<2:30:48,  1.73it/s] 11%|█         | 1899/17525 [22:44<2:30:43,  1.73it/s] 11%|█         | 1900/17525 [22:44<2:30:52,  1.73it/s]                                                      {'loss': 0.703, 'grad_norm': 7.955843925476074, 'learning_rate': 1.9438558066710627e-05, 'epoch': 2.71}
 11%|█         | 1900/17525 [22:44<2:30:52,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 02:26:05,988 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:26:05,988 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:26:05,988 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8991110324859619, 'eval_runtime': 4.5973, 'eval_samples_per_second': 96.361, 'eval_steps_per_second': 4.133, 'epoch': 2.71}
 11%|█         | 1900/17525 [22:49<2:30:52,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 11%|█         | 1901/17525 [22:50<8:58:38,  2.07s/it] 11%|█         | 1902/17525 [22:50<7:02:27,  1.62s/it] 11%|█         | 1903/17525 [22:51<5:41:04,  1.31s/it] 11%|█         | 1904/17525 [22:51<4:44:12,  1.09s/it] 11%|█         | 1905/17525 [22:52<4:04:31,  1.06it/s] 11%|█         | 1906/17525 [22:53<3:36:28,  1.20it/s] 11%|█         | 1907/17525 [22:53<3:16:43,  1.32it/s] 11%|█         | 1908/17525 [22:54<3:02:36,  1.43it/s] 11%|█         | 1909/17525 [22:54<2:52:59,  1.50it/s] 11%|█         | 1910/17525 [22:55<2:46:21,  1.56it/s]                                                      {'loss': 0.8954, 'grad_norm': 4.626853942871094, 'learning_rate': 1.9432613995863575e-05, 'epoch': 2.72}
 11%|█         | 1910/17525 [22:55<2:46:21,  1.56it/s] 11%|█         | 1911/17525 [22:55<2:41:43,  1.61it/s] 11%|█         | 1912/17525 [22:56<2:38:29,  1.64it/s] 11%|█         | 1913/17525 [22:57<2:36:04,  1.67it/s] 11%|█         | 1914/17525 [22:57<2:34:26,  1.68it/s] 11%|█         | 1915/17525 [22:58<2:33:17,  1.70it/s] 11%|█         | 1916/17525 [22:58<2:32:23,  1.71it/s] 11%|█         | 1917/17525 [22:59<2:32:09,  1.71it/s] 11%|█         | 1918/17525 [22:59<2:31:36,  1.72it/s] 11%|█         | 1919/17525 [23:00<2:31:00,  1.72it/s] 11%|█         | 1920/17525 [23:01<2:30:52,  1.72it/s]                                                      {'loss': 0.675, 'grad_norm': 6.863593101501465, 'learning_rate': 1.9426639543639015e-05, 'epoch': 2.74}
 11%|█         | 1920/17525 [23:01<2:30:52,  1.72it/s] 11%|█         | 1921/17525 [23:01<2:31:01,  1.72it/s] 11%|█         | 1922/17525 [23:02<2:30:47,  1.72it/s] 11%|█         | 1923/17525 [23:02<2:30:33,  1.73it/s] 11%|█         | 1924/17525 [23:03<2:30:36,  1.73it/s] 11%|█         | 1925/17525 [23:04<2:30:25,  1.73it/s] 11%|█         | 1926/17525 [23:04<2:30:31,  1.73it/s] 11%|█         | 1927/17525 [23:05<2:30:26,  1.73it/s] 11%|█         | 1928/17525 [23:05<2:30:22,  1.73it/s] 11%|█         | 1929/17525 [23:06<2:30:20,  1.73it/s] 11%|█         | 1930/17525 [23:06<2:30:30,  1.73it/s]                                                      {'loss': 0.7599, 'grad_norm': 4.56238317489624, 'learning_rate': 1.942063472927998e-05, 'epoch': 2.75}
 11%|█         | 1930/17525 [23:06<2:30:30,  1.73it/s] 11%|█         | 1931/17525 [23:07<2:31:01,  1.72it/s] 11%|█         | 1932/17525 [23:08<2:56:15,  1.47it/s] 11%|█         | 1933/17525 [23:09<2:48:36,  1.54it/s] 11%|█         | 1934/17525 [23:09<2:43:16,  1.59it/s] 11%|█         | 1935/17525 [23:10<2:39:28,  1.63it/s] 11%|█         | 1936/17525 [23:10<2:36:16,  1.66it/s] 11%|█         | 1937/17525 [23:11<2:34:35,  1.68it/s] 11%|█         | 1938/17525 [23:12<3:53:07,  1.11it/s] 11%|█         | 1939/17525 [23:13<3:28:46,  1.24it/s] 11%|█         | 1940/17525 [23:14<3:11:06,  1.36it/s]                                                      {'loss': 0.6921, 'grad_norm': 4.197783946990967, 'learning_rate': 1.9414599572127296e-05, 'epoch': 2.77}
 11%|█         | 1940/17525 [23:14<3:11:06,  1.36it/s] 11%|█         | 1941/17525 [23:14<2:58:53,  1.45it/s] 11%|█         | 1942/17525 [23:15<2:50:13,  1.53it/s] 11%|█         | 1943/17525 [23:15<2:44:20,  1.58it/s] 11%|█         | 1944/17525 [23:16<2:42:12,  1.60it/s] 11%|█         | 1945/17525 [23:17<2:38:34,  1.64it/s] 11%|█         | 1946/17525 [23:17<2:36:12,  1.66it/s] 11%|█         | 1947/17525 [23:18<2:34:30,  1.68it/s] 11%|█         | 1948/17525 [23:18<2:33:23,  1.69it/s] 11%|█         | 1949/17525 [23:19<2:32:27,  1.70it/s] 11%|█         | 1950/17525 [23:19<2:32:05,  1.71it/s]                                                      {'loss': 0.7776, 'grad_norm': 7.599947929382324, 'learning_rate': 1.9408534091619517e-05, 'epoch': 2.78}
 11%|█         | 1950/17525 [23:19<2:32:05,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 02:26:41,302 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f2cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d799d35e-dd7e-4218-aa7e-babbf6cf495a)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:26:51,359 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:26:51,361 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-1950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 11%|█         | 1951/17525 [23:30<15:50:29,  3.66s/it] 11%|█         | 1952/17525 [23:31<11:50:19,  2.74s/it] 11%|█         | 1953/17525 [23:31<9:02:11,  2.09s/it]  11%|█         | 1954/17525 [23:32<7:04:45,  1.64s/it] 11%|█         | 1955/17525 [23:33<5:42:39,  1.32s/it] 11%|█         | 1956/17525 [23:33<4:45:00,  1.10s/it] 11%|█         | 1957/17525 [23:34<4:04:28,  1.06it/s] 11%|█         | 1958/17525 [23:34<3:36:10,  1.20it/s] 11%|█         | 1959/17525 [23:35<3:16:37,  1.32it/s] 11%|█         | 1960/17525 [23:35<3:02:36,  1.42it/s]                                                      {'loss': 0.7162, 'grad_norm': 6.976758003234863, 'learning_rate': 1.9402438307292867e-05, 'epoch': 2.8}
 11%|█         | 1960/17525 [23:35<3:02:36,  1.42it/s] 11%|█         | 1961/17525 [23:36<2:52:58,  1.50it/s] 11%|█         | 1962/17525 [23:37<2:47:01,  1.55it/s] 11%|█         | 1963/17525 [23:37<2:42:12,  1.60it/s] 11%|█         | 1964/17525 [23:38<2:38:30,  1.64it/s] 11%|█         | 1965/17525 [23:38<2:35:56,  1.66it/s] 11%|█         | 1966/17525 [23:39<2:34:00,  1.68it/s] 11%|█         | 1967/17525 [23:40<2:46:54,  1.55it/s] 11%|█         | 1968/17525 [23:40<2:41:52,  1.60it/s] 11%|█         | 1969/17525 [23:41<2:38:22,  1.64it/s] 11%|█         | 1970/17525 [23:41<2:35:47,  1.66it/s]                                                      {'loss': 0.7182, 'grad_norm': 5.197422981262207, 'learning_rate': 1.939631223878117e-05, 'epoch': 2.81}
 11%|█         | 1970/17525 [23:41<2:35:47,  1.66it/s] 11%|█         | 1971/17525 [23:42<2:34:14,  1.68it/s] 11%|█▏        | 1972/17525 [23:43<2:33:31,  1.69it/s] 11%|█▏        | 1973/17525 [23:43<2:32:42,  1.70it/s] 11%|█▏        | 1974/17525 [23:44<2:31:50,  1.71it/s] 11%|█▏        | 1975/17525 [23:44<2:31:18,  1.71it/s] 11%|█▏        | 1976/17525 [23:45<2:31:02,  1.72it/s] 11%|█▏        | 1977/17525 [23:46<2:30:49,  1.72it/s] 11%|█▏        | 1978/17525 [23:46<2:30:55,  1.72it/s] 11%|█▏        | 1979/17525 [23:47<2:30:55,  1.72it/s] 11%|█▏        | 1980/17525 [23:47<2:30:47,  1.72it/s]                                                      {'loss': 0.6642, 'grad_norm': 5.3686676025390625, 'learning_rate': 1.93901559058158e-05, 'epoch': 2.82}
 11%|█▏        | 1980/17525 [23:47<2:30:47,  1.72it/s] 11%|█▏        | 1981/17525 [23:48<2:30:59,  1.72it/s] 11%|█▏        | 1982/17525 [23:48<2:30:58,  1.72it/s] 11%|█▏        | 1983/17525 [23:49<2:30:59,  1.72it/s] 11%|█▏        | 1984/17525 [23:50<2:30:36,  1.72it/s] 11%|█▏        | 1985/17525 [23:51<2:58:00,  1.46it/s] 11%|█▏        | 1986/17525 [23:52<3:23:56,  1.27it/s] 11%|█▏        | 1987/17525 [23:53<3:57:28,  1.09it/s] 11%|█▏        | 1988/17525 [23:53<3:31:18,  1.23it/s] 11%|█▏        | 1989/17525 [23:54<3:12:47,  1.34it/s] 11%|█▏        | 1990/17525 [23:54<2:59:42,  1.44it/s]                                                      {'loss': 0.711, 'grad_norm': 4.775778293609619, 'learning_rate': 1.9383969328225607e-05, 'epoch': 2.84}
 11%|█▏        | 1990/17525 [23:54<2:59:42,  1.44it/s] 11%|█▏        | 1991/17525 [23:55<3:17:44,  1.31it/s] 11%|█▏        | 1992/17525 [23:56<3:03:28,  1.41it/s] 11%|█▏        | 1993/17525 [23:57<2:53:20,  1.49it/s] 11%|█▏        | 1994/17525 [23:57<2:46:23,  1.56it/s] 11%|█▏        | 1995/17525 [23:58<2:41:37,  1.60it/s] 11%|█▏        | 1996/17525 [23:58<2:38:13,  1.64it/s] 11%|█▏        | 1997/17525 [23:59<2:35:46,  1.66it/s] 11%|█▏        | 1998/17525 [23:59<2:34:07,  1.68it/s] 11%|█▏        | 1999/17525 [24:00<2:32:39,  1.69it/s] 11%|█▏        | 2000/17525 [24:01<2:32:02,  1.70it/s]                                                      {'loss': 0.7396, 'grad_norm': 3.3998305797576904, 'learning_rate': 1.9377752525936853e-05, 'epoch': 2.85}
 11%|█▏        | 2000/17525 [24:01<2:32:02,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:27:22,539 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:27:22,540 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:27:22,540 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                      
                                               [A{'eval_loss': 0.8905491828918457, 'eval_runtime': 4.5936, 'eval_samples_per_second': 96.438, 'eval_steps_per_second': 4.136, 'epoch': 2.85}
 11%|█▏        | 2000/17525 [24:05<2:32:02,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 11%|█▏        | 2001/17525 [24:06<8:28:58,  1.97s/it] 11%|█▏        | 2002/17525 [24:06<6:41:16,  1.55s/it] 11%|█▏        | 2003/17525 [24:07<5:25:58,  1.26s/it] 11%|█▏        | 2004/17525 [24:08<4:33:22,  1.06s/it] 11%|█▏        | 2005/17525 [24:08<3:56:18,  1.09it/s] 11%|█▏        | 2006/17525 [24:09<3:58:27,  1.08it/s] 11%|█▏        | 2007/17525 [24:10<3:31:52,  1.22it/s] 11%|█▏        | 2008/17525 [24:10<3:13:05,  1.34it/s] 11%|█▏        | 2009/17525 [24:11<3:00:05,  1.44it/s] 11%|█▏        | 2010/17525 [24:11<2:50:55,  1.51it/s]                                                      {'loss': 0.7142, 'grad_norm': 11.957464218139648, 'learning_rate': 1.937150551897315e-05, 'epoch': 2.87}
 11%|█▏        | 2010/17525 [24:11<2:50:55,  1.51it/s] 11%|█▏        | 2011/17525 [24:12<2:45:00,  1.57it/s] 11%|█▏        | 2012/17525 [24:13<2:40:20,  1.61it/s] 11%|█▏        | 2013/17525 [24:13<2:37:23,  1.64it/s] 11%|█▏        | 2014/17525 [24:14<2:36:49,  1.65it/s] 11%|█▏        | 2015/17525 [24:14<2:34:53,  1.67it/s] 12%|█▏        | 2016/17525 [24:15<2:33:15,  1.69it/s] 12%|█▏        | 2017/17525 [24:15<2:32:04,  1.70it/s] 12%|█▏        | 2018/17525 [24:16<2:31:24,  1.71it/s] 12%|█▏        | 2019/17525 [24:17<2:31:06,  1.71it/s] 12%|█▏        | 2020/17525 [24:17<2:30:48,  1.71it/s]                                                      {'loss': 0.7256, 'grad_norm': 4.06635856628418, 'learning_rate': 1.9365228327455398e-05, 'epoch': 2.88}
 12%|█▏        | 2020/17525 [24:17<2:30:48,  1.71it/s] 12%|█▏        | 2021/17525 [24:18<2:30:40,  1.71it/s] 12%|█▏        | 2022/17525 [24:18<2:31:48,  1.70it/s] 12%|█▏        | 2023/17525 [24:19<2:34:34,  1.67it/s] 12%|█▏        | 2024/17525 [24:20<2:33:04,  1.69it/s] 12%|█▏        | 2025/17525 [24:20<2:31:55,  1.70it/s] 12%|█▏        | 2026/17525 [24:21<2:31:12,  1.71it/s] 12%|█▏        | 2027/17525 [24:21<2:30:58,  1.71it/s] 12%|█▏        | 2028/17525 [24:22<2:30:40,  1.71it/s] 12%|█▏        | 2029/17525 [24:23<2:30:18,  1.72it/s] 12%|█▏        | 2030/17525 [24:23<2:29:59,  1.72it/s]                                                      {'loss': 0.7169, 'grad_norm': 7.159647464752197, 'learning_rate': 1.935892097160172e-05, 'epoch': 2.9}
 12%|█▏        | 2030/17525 [24:23<2:29:59,  1.72it/s] 12%|█▏        | 2031/17525 [24:24<2:30:05,  1.72it/s] 12%|█▏        | 2032/17525 [24:24<2:29:52,  1.72it/s] 12%|█▏        | 2033/17525 [24:25<2:29:43,  1.72it/s] 12%|█▏        | 2034/17525 [24:25<2:29:42,  1.72it/s] 12%|█▏        | 2035/17525 [24:26<2:29:50,  1.72it/s] 12%|█▏        | 2036/17525 [24:27<2:29:52,  1.72it/s] 12%|█▏        | 2037/17525 [24:27<2:40:54,  1.60it/s] 12%|█▏        | 2038/17525 [24:28<2:37:45,  1.64it/s] 12%|█▏        | 2039/17525 [24:28<2:35:29,  1.66it/s] 12%|█▏        | 2040/17525 [24:29<2:33:52,  1.68it/s]                                                      {'loss': 0.7177, 'grad_norm': 5.28741979598999, 'learning_rate': 1.935258347172739e-05, 'epoch': 2.91}
 12%|█▏        | 2040/17525 [24:29<2:33:52,  1.68it/s] 12%|█▏        | 2041/17525 [24:30<2:32:40,  1.69it/s] 12%|█▏        | 2042/17525 [24:30<2:31:45,  1.70it/s] 12%|█▏        | 2043/17525 [24:31<2:30:54,  1.71it/s] 12%|█▏        | 2044/17525 [24:31<2:30:26,  1.72it/s] 12%|█▏        | 2045/17525 [24:32<2:30:11,  1.72it/s] 12%|█▏        | 2046/17525 [24:33<2:30:08,  1.72it/s] 12%|█▏        | 2047/17525 [24:33<2:29:51,  1.72it/s] 12%|█▏        | 2048/17525 [24:34<2:29:55,  1.72it/s] 12%|█▏        | 2049/17525 [24:34<2:29:35,  1.72it/s] 12%|█▏        | 2050/17525 [24:35<2:29:43,  1.72it/s]                                                      {'loss': 0.7292, 'grad_norm': 5.418210983276367, 'learning_rate': 1.9346215848244772e-05, 'epoch': 2.92}
 12%|█▏        | 2050/17525 [24:35<2:29:43,  1.72it/s] 12%|█▏        | 2051/17525 [24:35<2:29:51,  1.72it/s] 12%|█▏        | 2052/17525 [24:36<2:29:47,  1.72it/s] 12%|█▏        | 2053/17525 [24:37<2:30:06,  1.72it/s] 12%|█▏        | 2054/17525 [24:37<2:29:47,  1.72it/s] 12%|█▏        | 2055/17525 [24:38<2:29:48,  1.72it/s] 12%|█▏        | 2056/17525 [24:38<2:29:40,  1.72it/s] 12%|█▏        | 2057/17525 [24:39<2:29:34,  1.72it/s] 12%|█▏        | 2058/17525 [24:40<2:31:25,  1.70it/s] 12%|█▏        | 2059/17525 [24:40<2:30:43,  1.71it/s] 12%|█▏        | 2060/17525 [24:41<2:45:20,  1.56it/s]                                                      {'loss': 0.6479, 'grad_norm': 4.690081596374512, 'learning_rate': 1.9339818121663266e-05, 'epoch': 2.94}
 12%|█▏        | 2060/17525 [24:41<2:45:20,  1.56it/s] 12%|█▏        | 2061/17525 [24:41<2:41:06,  1.60it/s] 12%|█▏        | 2062/17525 [24:42<2:37:47,  1.63it/s] 12%|█▏        | 2063/17525 [24:43<2:35:14,  1.66it/s] 12%|█▏        | 2064/17525 [24:43<2:33:37,  1.68it/s] 12%|█▏        | 2065/17525 [24:44<2:32:17,  1.69it/s] 12%|█▏        | 2066/17525 [24:44<2:32:51,  1.69it/s] 12%|█▏        | 2067/17525 [24:45<2:31:46,  1.70it/s] 12%|█▏        | 2068/17525 [24:46<2:30:48,  1.71it/s] 12%|█▏        | 2069/17525 [24:46<2:30:15,  1.71it/s] 12%|█▏        | 2070/17525 [24:47<2:30:02,  1.72it/s]                                                      {'loss': 0.8185, 'grad_norm': 5.136175632476807, 'learning_rate': 1.933339031258921e-05, 'epoch': 2.95}
 12%|█▏        | 2070/17525 [24:47<2:30:02,  1.72it/s] 12%|█▏        | 2071/17525 [24:47<2:31:50,  1.70it/s] 12%|█▏        | 2072/17525 [24:48<2:30:51,  1.71it/s] 12%|█▏        | 2073/17525 [24:48<2:30:44,  1.71it/s] 12%|█▏        | 2074/17525 [24:49<2:30:23,  1.71it/s] 12%|█▏        | 2075/17525 [24:50<2:30:01,  1.72it/s] 12%|█▏        | 2076/17525 [24:51<2:57:39,  1.45it/s] 12%|█▏        | 2077/17525 [24:51<2:50:50,  1.51it/s] 12%|█▏        | 2078/17525 [24:52<2:44:23,  1.57it/s] 12%|█▏        | 2079/17525 [24:52<2:39:48,  1.61it/s] 12%|█▏        | 2080/17525 [24:53<2:36:52,  1.64it/s]                                                      {'loss': 0.7537, 'grad_norm': 5.264343738555908, 'learning_rate': 1.932693244172586e-05, 'epoch': 2.97}
 12%|█▏        | 2080/17525 [24:53<2:36:52,  1.64it/s] 12%|█▏        | 2081/17525 [24:54<3:03:03,  1.41it/s] 12%|█▏        | 2082/17525 [24:55<3:55:21,  1.09it/s] 12%|█▏        | 2083/17525 [24:56<3:29:51,  1.23it/s] 12%|█▏        | 2084/17525 [24:57<4:01:08,  1.07it/s] 12%|█▏        | 2085/17525 [24:58<3:34:19,  1.20it/s] 12%|█▏        | 2086/17525 [24:58<3:14:40,  1.32it/s] 12%|█▏        | 2087/17525 [24:59<3:00:56,  1.42it/s] 12%|█▏        | 2088/17525 [24:59<2:51:24,  1.50it/s] 12%|█▏        | 2089/17525 [25:00<2:44:43,  1.56it/s] 12%|█▏        | 2090/17525 [25:01<2:40:05,  1.61it/s]                                                      {'loss': 0.642, 'grad_norm': 3.94673228263855, 'learning_rate': 1.932044452987327e-05, 'epoch': 2.98}
 12%|█▏        | 2090/17525 [25:01<2:40:05,  1.61it/s] 12%|█▏        | 2091/17525 [25:01<2:36:53,  1.64it/s] 12%|█▏        | 2092/17525 [25:02<2:34:52,  1.66it/s] 12%|█▏        | 2093/17525 [25:02<2:33:14,  1.68it/s] 12%|█▏        | 2094/17525 [25:03<2:31:59,  1.69it/s] 12%|█▏        | 2095/17525 [25:03<2:30:51,  1.70it/s] 12%|█▏        | 2096/17525 [25:04<2:30:23,  1.71it/s] 12%|█▏        | 2097/17525 [25:05<2:29:33,  1.72it/s] 12%|█▏        | 2098/17525 [25:05<2:29:26,  1.72it/s] 12%|█▏        | 2099/17525 [25:06<2:31:20,  1.70it/s] 12%|█▏        | 2100/17525 [25:06<2:30:42,  1.71it/s]                                                      {'loss': 0.6602, 'grad_norm': 15.67177963256836, 'learning_rate': 1.931392659792828e-05, 'epoch': 3.0}
 12%|█▏        | 2100/17525 [25:06<2:30:42,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 02:28:28,252 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:28:28,252 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:28:28,252 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8937795758247375, 'eval_runtime': 4.6035, 'eval_samples_per_second': 96.231, 'eval_steps_per_second': 4.127, 'epoch': 3.0}
 12%|█▏        | 2100/17525 [25:11<2:30:42,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:28:32,859 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28335d5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7f8e3511-2a6f-46cc-81f5-6464995a6023)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:28:42,916 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:28:42,918 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 12%|█▏        | 2101/17525 [25:22<21:31:00,  5.02s/it] 12%|█▏        | 2102/17525 [25:22<15:48:17,  3.69s/it] 12%|█▏        | 2103/17525 [25:23<11:48:07,  2.75s/it] 12%|█▏        | 2104/17525 [25:23<9:00:22,  2.10s/it]  12%|█▏        | 2105/17525 [25:24<7:03:06,  1.65s/it] 12%|█▏        | 2106/17525 [25:25<5:41:09,  1.33s/it] 12%|█▏        | 2107/17525 [25:25<4:53:35,  1.14s/it] 12%|█▏        | 2108/17525 [25:26<4:10:27,  1.03it/s] 12%|█▏        | 2109/17525 [25:27<3:40:07,  1.17it/s] 12%|█▏        | 2110/17525 [25:27<3:18:50,  1.29it/s]                                                      {'loss': 0.7234, 'grad_norm': 3.451650381088257, 'learning_rate': 1.9307378666884395e-05, 'epoch': 3.01}
 12%|█▏        | 2110/17525 [25:27<3:18:50,  1.29it/s] 12%|█▏        | 2111/17525 [25:28<3:04:19,  1.39it/s] 12%|█▏        | 2112/17525 [25:28<2:53:53,  1.48it/s] 12%|█▏        | 2113/17525 [25:29<2:46:19,  1.54it/s] 12%|█▏        | 2114/17525 [25:29<2:40:57,  1.60it/s] 12%|█▏        | 2115/17525 [25:30<3:04:16,  1.39it/s] 12%|█▏        | 2116/17525 [25:31<3:08:10,  1.36it/s] 12%|█▏        | 2117/17525 [25:32<2:55:55,  1.46it/s] 12%|█▏        | 2118/17525 [25:33<3:49:25,  1.12it/s] 12%|█▏        | 2119/17525 [25:34<3:25:14,  1.25it/s] 12%|█▏        | 2120/17525 [25:34<3:08:24,  1.36it/s]                                                      {'loss': 0.6404, 'grad_norm': 4.746321201324463, 'learning_rate': 1.9300800757831765e-05, 'epoch': 3.02}
 12%|█▏        | 2120/17525 [25:34<3:08:24,  1.36it/s] 12%|█▏        | 2121/17525 [25:35<2:56:49,  1.45it/s] 12%|█▏        | 2122/17525 [25:35<2:48:31,  1.52it/s] 12%|█▏        | 2123/17525 [25:36<2:42:28,  1.58it/s] 12%|█▏        | 2124/17525 [25:37<2:38:27,  1.62it/s] 12%|█▏        | 2125/17525 [25:37<2:35:29,  1.65it/s] 12%|█▏        | 2126/17525 [25:38<2:33:30,  1.67it/s] 12%|█▏        | 2127/17525 [25:38<2:32:06,  1.69it/s] 12%|█▏        | 2128/17525 [25:39<2:31:01,  1.70it/s] 12%|█▏        | 2129/17525 [25:39<2:30:18,  1.71it/s] 12%|█▏        | 2130/17525 [25:40<2:30:09,  1.71it/s]                                                      {'loss': 0.75, 'grad_norm': 6.27472448348999, 'learning_rate': 1.9294192891957085e-05, 'epoch': 3.04}
 12%|█▏        | 2130/17525 [25:40<2:30:09,  1.71it/s] 12%|█▏        | 2131/17525 [25:41<2:29:44,  1.71it/s] 12%|█▏        | 2132/17525 [25:41<2:29:36,  1.71it/s] 12%|█▏        | 2133/17525 [25:42<2:29:21,  1.72it/s] 12%|█▏        | 2134/17525 [25:42<2:29:14,  1.72it/s] 12%|█▏        | 2135/17525 [25:43<2:29:16,  1.72it/s] 12%|█▏        | 2136/17525 [25:44<2:29:08,  1.72it/s] 12%|█▏        | 2137/17525 [25:44<2:29:07,  1.72it/s] 12%|█▏        | 2138/17525 [25:45<2:29:08,  1.72it/s] 12%|█▏        | 2139/17525 [25:45<2:44:26,  1.56it/s] 12%|█▏        | 2140/17525 [25:46<2:39:40,  1.61it/s]                                                      {'loss': 0.6537, 'grad_norm': 6.506287097930908, 'learning_rate': 1.9287555090543545e-05, 'epoch': 3.05}
 12%|█▏        | 2140/17525 [25:46<2:39:40,  1.61it/s] 12%|█▏        | 2141/17525 [25:47<2:36:40,  1.64it/s] 12%|█▏        | 2142/17525 [25:47<2:34:11,  1.66it/s] 12%|█▏        | 2143/17525 [25:48<2:32:28,  1.68it/s] 12%|█▏        | 2144/17525 [25:48<2:31:17,  1.69it/s] 12%|█▏        | 2145/17525 [25:49<2:30:35,  1.70it/s] 12%|█▏        | 2146/17525 [25:50<2:30:30,  1.70it/s] 12%|█▏        | 2147/17525 [25:50<2:29:54,  1.71it/s] 12%|█▏        | 2148/17525 [25:51<2:29:26,  1.71it/s] 12%|█▏        | 2149/17525 [25:51<2:29:15,  1.72it/s] 12%|█▏        | 2150/17525 [25:52<2:53:50,  1.47it/s]                                                      {'loss': 0.6193, 'grad_norm': 2.786849021911621, 'learning_rate': 1.928088737497074e-05, 'epoch': 3.07}
 12%|█▏        | 2150/17525 [25:52<2:53:50,  1.47it/s] 12%|█▏        | 2151/17525 [25:53<2:46:32,  1.54it/s] 12%|█▏        | 2152/17525 [25:53<2:41:01,  1.59it/s] 12%|█▏        | 2153/17525 [25:54<2:37:14,  1.63it/s] 12%|█▏        | 2154/17525 [25:54<2:34:38,  1.66it/s] 12%|█▏        | 2155/17525 [25:55<2:32:35,  1.68it/s] 12%|█▏        | 2156/17525 [25:56<2:31:06,  1.70it/s] 12%|█▏        | 2157/17525 [25:56<2:30:36,  1.70it/s] 12%|█▏        | 2158/17525 [25:57<2:31:29,  1.69it/s] 12%|█▏        | 2159/17525 [25:57<2:30:29,  1.70it/s] 12%|█▏        | 2160/17525 [25:58<2:30:15,  1.70it/s]                                                      {'loss': 0.7382, 'grad_norm': 8.211319923400879, 'learning_rate': 1.927418976671463e-05, 'epoch': 3.08}
 12%|█▏        | 2160/17525 [25:58<2:30:15,  1.70it/s] 12%|█▏        | 2161/17525 [25:59<2:29:31,  1.71it/s] 12%|█▏        | 2162/17525 [25:59<2:29:07,  1.72it/s] 12%|█▏        | 2163/17525 [26:00<2:28:59,  1.72it/s] 12%|█▏        | 2164/17525 [26:00<2:28:49,  1.72it/s] 12%|█▏        | 2165/17525 [26:01<2:42:36,  1.57it/s] 12%|█▏        | 2166/17525 [26:02<2:38:23,  1.62it/s] 12%|█▏        | 2167/17525 [26:02<2:35:23,  1.65it/s] 12%|█▏        | 2168/17525 [26:03<2:33:22,  1.67it/s] 12%|█▏        | 2169/17525 [26:03<2:31:53,  1.69it/s] 12%|█▏        | 2170/17525 [26:04<2:30:35,  1.70it/s]                                                      {'loss': 0.626, 'grad_norm': 6.4073076248168945, 'learning_rate': 1.9267462287347444e-05, 'epoch': 3.1}
 12%|█▏        | 2170/17525 [26:04<2:30:35,  1.70it/s] 12%|█▏        | 2171/17525 [26:05<2:30:11,  1.70it/s] 12%|█▏        | 2172/17525 [26:05<2:29:38,  1.71it/s] 12%|█▏        | 2173/17525 [26:06<2:29:06,  1.72it/s] 12%|█▏        | 2174/17525 [26:06<2:28:47,  1.72it/s] 12%|█▏        | 2175/17525 [26:07<2:28:25,  1.72it/s] 12%|█▏        | 2176/17525 [26:07<2:28:26,  1.72it/s] 12%|█▏        | 2177/17525 [26:08<3:01:58,  1.41it/s] 12%|█▏        | 2178/17525 [26:09<2:52:07,  1.49it/s] 12%|█▏        | 2179/17525 [26:10<2:44:46,  1.55it/s] 12%|█▏        | 2180/17525 [26:10<2:39:49,  1.60it/s]                                                      {'loss': 0.6931, 'grad_norm': 5.451793193817139, 'learning_rate': 1.9260704958537636e-05, 'epoch': 3.11}
 12%|█▏        | 2180/17525 [26:10<2:39:49,  1.60it/s] 12%|█▏        | 2181/17525 [26:11<2:36:22,  1.64it/s] 12%|█▏        | 2182/17525 [26:11<2:34:01,  1.66it/s] 12%|█▏        | 2183/17525 [26:12<2:32:16,  1.68it/s] 12%|█▏        | 2184/17525 [26:13<2:30:44,  1.70it/s] 12%|█▏        | 2185/17525 [26:13<2:30:09,  1.70it/s] 12%|█▏        | 2186/17525 [26:14<2:29:19,  1.71it/s] 12%|█▏        | 2187/17525 [26:14<2:29:03,  1.71it/s] 12%|█▏        | 2188/17525 [26:15<2:28:48,  1.72it/s] 12%|█▏        | 2189/17525 [26:15<2:28:33,  1.72it/s] 12%|█▏        | 2190/17525 [26:16<2:28:31,  1.72it/s]                                                      {'loss': 0.6515, 'grad_norm': 5.584385871887207, 'learning_rate': 1.9253917802049787e-05, 'epoch': 3.12}
 12%|█▏        | 2190/17525 [26:16<2:28:31,  1.72it/s] 13%|█▎        | 2191/17525 [26:17<2:28:22,  1.72it/s] 13%|█▎        | 2192/17525 [26:17<2:43:00,  1.57it/s] 13%|█▎        | 2193/17525 [26:18<2:40:27,  1.59it/s] 13%|█▎        | 2194/17525 [26:19<2:36:38,  1.63it/s] 13%|█▎        | 2195/17525 [26:19<2:34:05,  1.66it/s] 13%|█▎        | 2196/17525 [26:20<2:32:17,  1.68it/s] 13%|█▎        | 2197/17525 [26:20<2:31:13,  1.69it/s] 13%|█▎        | 2198/17525 [26:21<2:30:30,  1.70it/s] 13%|█▎        | 2199/17525 [26:21<2:29:52,  1.70it/s] 13%|█▎        | 2200/17525 [26:22<2:29:12,  1.71it/s]                                                      {'loss': 0.7151, 'grad_norm': 6.135488986968994, 'learning_rate': 1.9247100839744565e-05, 'epoch': 3.14}
 13%|█▎        | 2200/17525 [26:22<2:29:12,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 02:29:43,908 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:29:43,908 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:29:43,908 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8905813694000244, 'eval_runtime': 4.5981, 'eval_samples_per_second': 96.344, 'eval_steps_per_second': 4.132, 'epoch': 3.14}
 13%|█▎        | 2200/17525 [26:27<2:29:12,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 13%|█▎        | 2201/17525 [26:27<8:22:45,  1.97s/it] 13%|█▎        | 2202/17525 [26:28<6:36:27,  1.55s/it] 13%|█▎        | 2203/17525 [26:28<5:21:56,  1.26s/it] 13%|█▎        | 2204/17525 [26:29<4:29:58,  1.06s/it] 13%|█▎        | 2205/17525 [26:30<3:55:14,  1.09it/s] 13%|█▎        | 2206/17525 [26:30<3:29:05,  1.22it/s] 13%|█▎        | 2207/17525 [26:31<3:10:35,  1.34it/s] 13%|█▎        | 2208/17525 [26:31<2:57:41,  1.44it/s] 13%|█▎        | 2209/17525 [26:32<3:15:38,  1.30it/s] 13%|█▎        | 2210/17525 [26:33<3:01:35,  1.41it/s]                                                      {'loss': 0.677, 'grad_norm': 9.843199729919434, 'learning_rate': 1.924025409357862e-05, 'epoch': 3.15}
 13%|█▎        | 2210/17525 [26:33<3:01:35,  1.41it/s] 13%|█▎        | 2211/17525 [26:33<2:51:46,  1.49it/s] 13%|█▎        | 2212/17525 [26:34<2:44:37,  1.55it/s] 13%|█▎        | 2213/17525 [26:35<2:39:37,  1.60it/s] 13%|█▎        | 2214/17525 [26:35<2:35:51,  1.64it/s] 13%|█▎        | 2215/17525 [26:36<2:33:32,  1.66it/s] 13%|█▎        | 2216/17525 [26:36<2:31:39,  1.68it/s] 13%|█▎        | 2217/17525 [26:37<2:30:36,  1.69it/s] 13%|█▎        | 2218/17525 [26:37<2:29:57,  1.70it/s] 13%|█▎        | 2219/17525 [26:38<2:29:07,  1.71it/s] 13%|█▎        | 2220/17525 [26:39<2:28:53,  1.71it/s]                                                      {'loss': 0.6435, 'grad_norm': 8.056146621704102, 'learning_rate': 1.9233377585604554e-05, 'epoch': 3.17}
 13%|█▎        | 2220/17525 [26:39<2:28:53,  1.71it/s] 13%|█▎        | 2221/17525 [26:39<2:28:59,  1.71it/s] 13%|█▎        | 2222/17525 [26:40<2:28:35,  1.72it/s] 13%|█▎        | 2223/17525 [26:40<2:28:26,  1.72it/s] 13%|█▎        | 2224/17525 [26:41<2:28:09,  1.72it/s] 13%|█▎        | 2225/17525 [26:42<2:29:14,  1.71it/s] 13%|█▎        | 2226/17525 [26:42<2:28:55,  1.71it/s] 13%|█▎        | 2227/17525 [26:43<2:28:43,  1.71it/s] 13%|█▎        | 2228/17525 [26:43<2:31:00,  1.69it/s] 13%|█▎        | 2229/17525 [26:44<2:30:04,  1.70it/s] 13%|█▎        | 2230/17525 [26:44<2:29:20,  1.71it/s]                                                      {'loss': 0.6077, 'grad_norm': 7.286020278930664, 'learning_rate': 1.9226471337970812e-05, 'epoch': 3.18}
 13%|█▎        | 2230/17525 [26:44<2:29:20,  1.71it/s] 13%|█▎        | 2231/17525 [26:45<2:29:17,  1.71it/s] 13%|█▎        | 2232/17525 [26:46<2:28:48,  1.71it/s] 13%|█▎        | 2233/17525 [26:46<2:28:24,  1.72it/s] 13%|█▎        | 2234/17525 [26:47<2:28:05,  1.72it/s] 13%|█▎        | 2235/17525 [26:47<2:27:59,  1.72it/s] 13%|█▎        | 2236/17525 [26:48<2:27:41,  1.73it/s] 13%|█▎        | 2237/17525 [26:49<2:27:43,  1.72it/s] 13%|█▎        | 2238/17525 [26:49<2:27:43,  1.72it/s] 13%|█▎        | 2239/17525 [26:50<2:27:46,  1.72it/s] 13%|█▎        | 2240/17525 [26:50<2:27:51,  1.72it/s]                                                      {'loss': 0.6271, 'grad_norm': 4.706252574920654, 'learning_rate': 1.921953537292163e-05, 'epoch': 3.2}
 13%|█▎        | 2240/17525 [26:50<2:27:51,  1.72it/s] 13%|█▎        | 2241/17525 [26:51<2:28:10,  1.72it/s] 13%|█▎        | 2242/17525 [26:51<2:28:21,  1.72it/s] 13%|█▎        | 2243/17525 [26:52<2:28:14,  1.72it/s] 13%|█▎        | 2244/17525 [26:53<2:28:11,  1.72it/s] 13%|█▎        | 2245/17525 [26:53<2:28:04,  1.72it/s] 13%|█▎        | 2246/17525 [26:54<2:28:00,  1.72it/s] 13%|█▎        | 2247/17525 [26:54<2:28:00,  1.72it/s] 13%|█▎        | 2248/17525 [26:55<2:27:53,  1.72it/s] 13%|█▎        | 2249/17525 [26:55<2:28:03,  1.72it/s] 13%|█▎        | 2250/17525 [26:56<2:27:50,  1.72it/s]                                                      {'loss': 0.7023, 'grad_norm': 12.67782211303711, 'learning_rate': 1.921256971279697e-05, 'epoch': 3.21}
 13%|█▎        | 2250/17525 [26:56<2:27:50,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 02:30:17,973 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a795d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 047aa1d8-c1d6-49cc-a45d-25038a0b851e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:30:28,028 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:30:28,030 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 13%|█▎        | 2251/17525 [27:07<15:25:03,  3.63s/it] 13%|█▎        | 2252/17525 [27:07<11:31:28,  2.72s/it] 13%|█▎        | 2253/17525 [27:08<8:47:50,  2.07s/it]  13%|█▎        | 2254/17525 [27:09<7:31:27,  1.77s/it] 13%|█▎        | 2255/17525 [27:10<6:00:07,  1.42s/it] 13%|█▎        | 2256/17525 [27:11<5:24:11,  1.27s/it] 13%|█▎        | 2257/17525 [27:11<4:31:02,  1.07s/it] 13%|█▎        | 2258/17525 [27:12<3:54:03,  1.09it/s] 13%|█▎        | 2259/17525 [27:12<3:28:07,  1.22it/s] 13%|█▎        | 2260/17525 [27:13<3:10:00,  1.34it/s]                                                      {'loss': 0.7338, 'grad_norm': 5.818084239959717, 'learning_rate': 1.9205574380032425e-05, 'epoch': 3.22}
 13%|█▎        | 2260/17525 [27:13<3:10:00,  1.34it/s] 13%|█▎        | 2261/17525 [27:13<2:57:13,  1.44it/s] 13%|█▎        | 2262/17525 [27:14<2:48:03,  1.51it/s] 13%|█▎        | 2263/17525 [27:15<2:41:47,  1.57it/s] 13%|█▎        | 2264/17525 [27:15<2:37:35,  1.61it/s] 13%|█▎        | 2265/17525 [27:16<2:34:30,  1.65it/s] 13%|█▎        | 2266/17525 [27:16<2:32:32,  1.67it/s] 13%|█▎        | 2267/17525 [27:17<2:31:11,  1.68it/s] 13%|█▎        | 2268/17525 [27:18<2:29:49,  1.70it/s] 13%|█▎        | 2269/17525 [27:18<2:28:57,  1.71it/s] 13%|█▎        | 2270/17525 [27:19<2:28:46,  1.71it/s]                                                      {'loss': 0.6435, 'grad_norm': 6.541399955749512, 'learning_rate': 1.9198549397159166e-05, 'epoch': 3.24}
 13%|█▎        | 2270/17525 [27:19<2:28:46,  1.71it/s] 13%|█▎        | 2271/17525 [27:19<2:28:20,  1.71it/s] 13%|█▎        | 2272/17525 [27:20<2:27:57,  1.72it/s] 13%|█▎        | 2273/17525 [27:20<2:27:49,  1.72it/s] 13%|█▎        | 2274/17525 [27:21<2:27:45,  1.72it/s] 13%|█▎        | 2275/17525 [27:22<2:27:34,  1.72it/s] 13%|█▎        | 2276/17525 [27:22<2:27:18,  1.73it/s] 13%|█▎        | 2277/17525 [27:23<2:27:22,  1.72it/s] 13%|█▎        | 2278/17525 [27:23<2:27:19,  1.72it/s] 13%|█▎        | 2279/17525 [27:24<2:27:13,  1.73it/s] 13%|█▎        | 2280/17525 [27:24<2:27:21,  1.72it/s]                                                      {'loss': 0.7217, 'grad_norm': 10.713027954101562, 'learning_rate': 1.9191494786803874e-05, 'epoch': 3.25}
 13%|█▎        | 2280/17525 [27:24<2:27:21,  1.72it/s] 13%|█▎        | 2281/17525 [27:25<2:27:26,  1.72it/s] 13%|█▎        | 2282/17525 [27:26<2:27:26,  1.72it/s] 13%|█▎        | 2283/17525 [27:26<2:27:20,  1.72it/s] 13%|█▎        | 2284/17525 [27:27<2:27:06,  1.73it/s] 13%|█▎        | 2285/17525 [27:27<2:27:08,  1.73it/s] 13%|█▎        | 2286/17525 [27:28<2:27:02,  1.73it/s] 13%|█▎        | 2287/17525 [27:29<2:26:51,  1.73it/s] 13%|█▎        | 2288/17525 [27:29<2:26:28,  1.73it/s] 13%|█▎        | 2289/17525 [27:30<2:26:37,  1.73it/s] 13%|█▎        | 2290/17525 [27:31<2:54:00,  1.46it/s]                                                      {'loss': 0.7644, 'grad_norm': 9.109288215637207, 'learning_rate': 1.9184410571688638e-05, 'epoch': 3.27}
 13%|█▎        | 2290/17525 [27:31<2:54:00,  1.46it/s] 13%|█▎        | 2291/17525 [27:31<2:49:14,  1.50it/s] 13%|█▎        | 2292/17525 [27:32<2:42:23,  1.56it/s] 13%|█▎        | 2293/17525 [27:32<2:37:28,  1.61it/s] 13%|█▎        | 2294/17525 [27:33<2:34:28,  1.64it/s] 13%|█▎        | 2295/17525 [27:34<2:32:12,  1.67it/s] 13%|█▎        | 2296/17525 [27:34<2:30:56,  1.68it/s] 13%|█▎        | 2297/17525 [27:35<2:29:28,  1.70it/s] 13%|█▎        | 2298/17525 [27:35<2:28:40,  1.71it/s] 13%|█▎        | 2299/17525 [27:36<2:27:57,  1.72it/s] 13%|█▎        | 2300/17525 [27:36<2:27:16,  1.72it/s]                                                      {'loss': 0.6107, 'grad_norm': 3.93571400642395, 'learning_rate': 1.917729677463091e-05, 'epoch': 3.28}
 13%|█▎        | 2300/17525 [27:36<2:27:16,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:30:58,355 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:30:58,355 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:30:58,355 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.86it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8926582336425781, 'eval_runtime': 4.5981, 'eval_samples_per_second': 96.343, 'eval_steps_per_second': 4.132, 'epoch': 3.28}
 13%|█▎        | 2300/17525 [27:41<2:27:16,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 13%|█▎        | 2301/17525 [27:42<8:17:31,  1.96s/it] 13%|█▎        | 2302/17525 [27:42<6:34:42,  1.56s/it] 13%|█▎        | 2303/17525 [27:43<5:20:30,  1.26s/it] 13%|█▎        | 2304/17525 [27:43<4:28:07,  1.06s/it] 13%|█▎        | 2305/17525 [27:44<3:51:25,  1.10it/s] 13%|█▎        | 2306/17525 [27:45<3:28:02,  1.22it/s] 13%|█▎        | 2307/17525 [27:45<3:09:34,  1.34it/s] 13%|█▎        | 2308/17525 [27:46<2:56:22,  1.44it/s] 13%|█▎        | 2309/17525 [27:46<2:47:24,  1.51it/s] 13%|█▎        | 2310/17525 [27:47<2:41:09,  1.57it/s]                                                      {'loss': 0.7493, 'grad_norm': 5.754220962524414, 'learning_rate': 1.9170153418543428e-05, 'epoch': 3.3}
 13%|█▎        | 2310/17525 [27:47<2:41:09,  1.57it/s] 13%|█▎        | 2311/17525 [27:47<2:37:09,  1.61it/s] 13%|█▎        | 2312/17525 [27:48<2:35:22,  1.63it/s] 13%|█▎        | 2313/17525 [27:49<2:32:39,  1.66it/s] 13%|█▎        | 2314/17525 [27:49<2:30:54,  1.68it/s] 13%|█▎        | 2315/17525 [27:50<2:29:53,  1.69it/s] 13%|█▎        | 2316/17525 [27:50<2:28:51,  1.70it/s] 13%|█▎        | 2317/17525 [27:51<2:28:09,  1.71it/s] 13%|█▎        | 2318/17525 [27:52<2:27:47,  1.71it/s] 13%|█▎        | 2319/17525 [27:52<2:27:51,  1.71it/s] 13%|█▎        | 2320/17525 [27:53<2:27:35,  1.72it/s]                                                      {'loss': 0.8225, 'grad_norm': 4.8759074211120605, 'learning_rate': 1.9162980526434122e-05, 'epoch': 3.31}
 13%|█▎        | 2320/17525 [27:53<2:27:35,  1.72it/s] 13%|█▎        | 2321/17525 [27:53<2:27:37,  1.72it/s] 13%|█▎        | 2322/17525 [27:54<2:27:23,  1.72it/s] 13%|█▎        | 2323/17525 [27:54<2:27:33,  1.72it/s] 13%|█▎        | 2324/17525 [27:55<2:54:18,  1.45it/s] 13%|█▎        | 2325/17525 [27:56<2:46:04,  1.53it/s] 13%|█▎        | 2326/17525 [27:57<2:40:14,  1.58it/s] 13%|█▎        | 2327/17525 [27:57<2:36:00,  1.62it/s] 13%|█▎        | 2328/17525 [27:58<2:33:14,  1.65it/s] 13%|█▎        | 2329/17525 [27:58<2:31:20,  1.67it/s] 13%|█▎        | 2330/17525 [27:59<2:29:54,  1.69it/s]                                                      {'loss': 0.69, 'grad_norm': 3.8561110496520996, 'learning_rate': 1.915577812140607e-05, 'epoch': 3.32}
 13%|█▎        | 2330/17525 [27:59<2:29:54,  1.69it/s] 13%|█▎        | 2331/17525 [27:59<2:29:11,  1.70it/s] 13%|█▎        | 2332/17525 [28:00<2:28:26,  1.71it/s] 13%|█▎        | 2333/17525 [28:01<2:27:53,  1.71it/s] 13%|█▎        | 2334/17525 [28:01<2:27:37,  1.71it/s] 13%|█▎        | 2335/17525 [28:02<2:38:41,  1.60it/s] 13%|█▎        | 2336/17525 [28:02<2:35:02,  1.63it/s] 13%|█▎        | 2337/17525 [28:03<2:32:33,  1.66it/s] 13%|█▎        | 2338/17525 [28:04<2:30:59,  1.68it/s] 13%|█▎        | 2339/17525 [28:04<2:29:39,  1.69it/s] 13%|█▎        | 2340/17525 [28:05<2:28:47,  1.70it/s]                                                      {'loss': 0.6612, 'grad_norm': 9.518461227416992, 'learning_rate': 1.914854622665739e-05, 'epoch': 3.34}
 13%|█▎        | 2340/17525 [28:05<2:28:47,  1.70it/s] 13%|█▎        | 2341/17525 [28:05<2:28:23,  1.71it/s] 13%|█▎        | 2342/17525 [28:06<2:27:59,  1.71it/s] 13%|█▎        | 2343/17525 [28:07<2:27:27,  1.72it/s] 13%|█▎        | 2344/17525 [28:07<2:26:58,  1.72it/s] 13%|█▎        | 2345/17525 [28:09<3:26:33,  1.22it/s] 13%|█▎        | 2346/17525 [28:09<3:08:27,  1.34it/s] 13%|█▎        | 2347/17525 [28:10<3:10:06,  1.33it/s] 13%|█▎        | 2348/17525 [28:10<2:56:53,  1.43it/s] 13%|█▎        | 2349/17525 [28:11<2:47:47,  1.51it/s] 13%|█▎        | 2350/17525 [28:12<2:41:13,  1.57it/s]                                                      {'loss': 0.7296, 'grad_norm': 3.3302974700927734, 'learning_rate': 1.9141284865481205e-05, 'epoch': 3.35}
 13%|█▎        | 2350/17525 [28:12<2:41:13,  1.57it/s] 13%|█▎        | 2351/17525 [28:12<2:38:27,  1.60it/s] 13%|█▎        | 2352/17525 [28:13<2:34:59,  1.63it/s] 13%|█▎        | 2353/17525 [28:13<2:31:53,  1.66it/s] 13%|█▎        | 2354/17525 [28:14<2:30:08,  1.68it/s] 13%|█▎        | 2355/17525 [28:14<2:28:55,  1.70it/s] 13%|█▎        | 2356/17525 [28:15<2:27:57,  1.71it/s] 13%|█▎        | 2357/17525 [28:16<2:27:41,  1.71it/s] 13%|█▎        | 2358/17525 [28:16<2:27:20,  1.72it/s] 13%|█▎        | 2359/17525 [28:17<2:27:24,  1.71it/s] 13%|█▎        | 2360/17525 [28:17<2:26:58,  1.72it/s]                                                      {'loss': 0.685, 'grad_norm': 4.457328796386719, 'learning_rate': 1.9133994061265528e-05, 'epoch': 3.37}
 13%|█▎        | 2360/17525 [28:17<2:26:58,  1.72it/s] 13%|█▎        | 2361/17525 [28:18<2:26:48,  1.72it/s] 13%|█▎        | 2362/17525 [28:19<2:26:34,  1.72it/s] 13%|█▎        | 2363/17525 [28:19<2:26:26,  1.73it/s] 13%|█▎        | 2364/17525 [28:20<2:26:35,  1.72it/s] 13%|█▎        | 2365/17525 [28:20<2:26:22,  1.73it/s] 14%|█▎        | 2366/17525 [28:21<2:26:36,  1.72it/s] 14%|█▎        | 2367/17525 [28:21<2:26:27,  1.72it/s] 14%|█▎        | 2368/17525 [28:23<3:25:22,  1.23it/s] 14%|█▎        | 2369/17525 [28:23<3:07:43,  1.35it/s] 14%|█▎        | 2370/17525 [28:24<2:55:17,  1.44it/s]                                                      {'loss': 0.642, 'grad_norm': 4.487933158874512, 'learning_rate': 1.912667383749321e-05, 'epoch': 3.38}
 14%|█▎        | 2370/17525 [28:24<2:55:17,  1.44it/s] 14%|█▎        | 2371/17525 [28:25<2:48:26,  1.50it/s] 14%|█▎        | 2372/17525 [28:25<2:41:47,  1.56it/s] 14%|█▎        | 2373/17525 [28:26<2:36:52,  1.61it/s] 14%|█▎        | 2374/17525 [28:26<2:33:43,  1.64it/s] 14%|█▎        | 2375/17525 [28:27<2:32:48,  1.65it/s] 14%|█▎        | 2376/17525 [28:27<2:30:39,  1.68it/s] 14%|█▎        | 2377/17525 [28:28<2:29:19,  1.69it/s] 14%|█▎        | 2378/17525 [28:29<2:28:22,  1.70it/s] 14%|█▎        | 2379/17525 [28:29<2:27:34,  1.71it/s] 14%|█▎        | 2380/17525 [28:30<2:27:08,  1.72it/s]                                                      {'loss': 0.6693, 'grad_norm': 5.6816840171813965, 'learning_rate': 1.9119324217741858e-05, 'epoch': 3.4}
 14%|█▎        | 2380/17525 [28:30<2:27:08,  1.72it/s] 14%|█▎        | 2381/17525 [28:30<2:26:48,  1.72it/s] 14%|█▎        | 2382/17525 [28:31<2:26:26,  1.72it/s] 14%|█▎        | 2383/17525 [28:32<2:26:37,  1.72it/s] 14%|█▎        | 2384/17525 [28:32<2:26:16,  1.73it/s] 14%|█▎        | 2385/17525 [28:33<2:26:12,  1.73it/s] 14%|█▎        | 2386/17525 [28:33<2:26:14,  1.73it/s] 14%|█▎        | 2387/17525 [28:34<2:25:45,  1.73it/s] 14%|█▎        | 2388/17525 [28:34<2:25:40,  1.73it/s] 14%|█▎        | 2389/17525 [28:35<2:25:37,  1.73it/s] 14%|█▎        | 2390/17525 [28:36<2:27:27,  1.71it/s]                                                      {'loss': 0.7495, 'grad_norm': 4.955872535705566, 'learning_rate': 1.9111945225683762e-05, 'epoch': 3.41}
 14%|█▎        | 2390/17525 [28:36<2:27:27,  1.71it/s] 14%|█▎        | 2391/17525 [28:36<2:27:11,  1.71it/s] 14%|█▎        | 2392/17525 [28:37<2:26:28,  1.72it/s] 14%|█▎        | 2393/17525 [28:38<3:14:44,  1.30it/s] 14%|█▎        | 2394/17525 [28:39<3:00:15,  1.40it/s] 14%|█▎        | 2395/17525 [28:39<2:49:57,  1.48it/s] 14%|█▎        | 2396/17525 [28:40<2:42:39,  1.55it/s] 14%|█▎        | 2397/17525 [28:40<2:37:37,  1.60it/s] 14%|█▎        | 2398/17525 [28:41<3:01:01,  1.39it/s] 14%|█▎        | 2399/17525 [28:42<3:14:07,  1.30it/s] 14%|█▎        | 2400/17525 [28:43<2:59:44,  1.40it/s]                                                      {'loss': 0.7226, 'grad_norm': 5.4805684089660645, 'learning_rate': 1.9104536885085826e-05, 'epoch': 3.42}
 14%|█▎        | 2400/17525 [28:43<2:59:44,  1.40it/s][INFO|trainer.py:3512] 2024-06-25 02:32:04,588 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:32:04,588 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:32:04,588 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8841623067855835, 'eval_runtime': 4.6011, 'eval_samples_per_second': 96.281, 'eval_steps_per_second': 4.129, 'epoch': 3.42}
 14%|█▎        | 2400/17525 [28:47<2:59:44,  1.40it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:32:09,192 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7964ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 47d35d4b-68d2-4c05-a721-ba956cc8c565)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:32:19,249 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:32:19,251 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 14%|█▎        | 2401/17525 [28:58<21:27:49,  5.11s/it] 14%|█▎        | 2402/17525 [29:00<17:03:41,  4.06s/it] 14%|█▎        | 2403/17525 [29:00<12:40:17,  3.02s/it] 14%|█▎        | 2404/17525 [29:01<9:35:57,  2.29s/it]  14%|█▎        | 2405/17525 [29:01<7:26:41,  1.77s/it] 14%|█▎        | 2406/17525 [29:02<5:56:30,  1.41s/it] 14%|█▎        | 2407/17525 [29:03<4:53:26,  1.16s/it] 14%|█▎        | 2408/17525 [29:03<4:08:58,  1.01it/s] 14%|█▎        | 2409/17525 [29:04<3:37:50,  1.16it/s] 14%|█▍        | 2410/17525 [29:04<3:16:16,  1.28it/s]                                                      {'loss': 0.6959, 'grad_norm': 5.420713901519775, 'learning_rate': 1.9097099219809462e-05, 'epoch': 3.44}
 14%|█▍        | 2410/17525 [29:04<3:16:16,  1.28it/s] 14%|█▍        | 2411/17525 [29:05<3:01:13,  1.39it/s] 14%|█▍        | 2412/17525 [29:05<2:50:36,  1.48it/s] 14%|█▍        | 2413/17525 [29:06<2:43:02,  1.54it/s] 14%|█▍        | 2414/17525 [29:08<3:55:42,  1.07it/s] 14%|█▍        | 2415/17525 [29:08<3:29:06,  1.20it/s] 14%|█▍        | 2416/17525 [29:09<3:11:32,  1.31it/s] 14%|█▍        | 2417/17525 [29:09<2:58:02,  1.41it/s] 14%|█▍        | 2418/17525 [29:10<2:49:30,  1.49it/s] 14%|█▍        | 2419/17525 [29:11<2:43:18,  1.54it/s] 14%|█▍        | 2420/17525 [29:12<3:38:12,  1.15it/s]                                                      {'loss': 0.5965, 'grad_norm': 4.919134140014648, 'learning_rate': 1.9089632253810548e-05, 'epoch': 3.45}
 14%|█▍        | 2420/17525 [29:12<3:38:12,  1.15it/s] 14%|█▍        | 2421/17525 [29:13<3:17:37,  1.27it/s] 14%|█▍        | 2422/17525 [29:13<3:02:54,  1.38it/s] 14%|█▍        | 2423/17525 [29:14<2:53:05,  1.45it/s] 14%|█▍        | 2424/17525 [29:14<2:45:34,  1.52it/s] 14%|█▍        | 2425/17525 [29:15<2:40:41,  1.57it/s] 14%|█▍        | 2426/17525 [29:16<2:37:37,  1.60it/s] 14%|█▍        | 2427/17525 [29:16<2:35:30,  1.62it/s] 14%|█▍        | 2428/17525 [29:17<2:34:27,  1.63it/s] 14%|█▍        | 2429/17525 [29:17<2:33:55,  1.63it/s] 14%|█▍        | 2430/17525 [29:18<2:34:23,  1.63it/s]                                                      {'loss': 0.629, 'grad_norm': 8.143654823303223, 'learning_rate': 1.9082136011139334e-05, 'epoch': 3.47}
 14%|█▍        | 2430/17525 [29:18<2:34:23,  1.63it/s] 14%|█▍        | 2431/17525 [29:19<2:32:58,  1.64it/s] 14%|█▍        | 2432/17525 [29:19<2:32:20,  1.65it/s] 14%|█▍        | 2433/17525 [29:20<2:31:20,  1.66it/s] 14%|█▍        | 2434/17525 [29:20<2:31:42,  1.66it/s] 14%|█▍        | 2435/17525 [29:21<2:31:14,  1.66it/s] 14%|█▍        | 2436/17525 [29:22<2:31:00,  1.67it/s] 14%|█▍        | 2437/17525 [29:22<2:30:13,  1.67it/s] 14%|█▍        | 2438/17525 [29:23<2:29:33,  1.68it/s] 14%|█▍        | 2439/17525 [29:23<2:28:58,  1.69it/s] 14%|█▍        | 2440/17525 [29:24<2:28:44,  1.69it/s]                                                      {'loss': 0.708, 'grad_norm': 8.266788482666016, 'learning_rate': 1.9074610515940365e-05, 'epoch': 3.48}
 14%|█▍        | 2440/17525 [29:24<2:28:44,  1.69it/s] 14%|█▍        | 2441/17525 [29:24<2:28:16,  1.70it/s] 14%|█▍        | 2442/17525 [29:25<2:28:07,  1.70it/s] 14%|█▍        | 2443/17525 [29:26<2:28:01,  1.70it/s] 14%|█▍        | 2444/17525 [29:26<2:28:17,  1.69it/s] 14%|█▍        | 2445/17525 [29:27<2:28:50,  1.69it/s] 14%|█▍        | 2446/17525 [29:27<2:30:37,  1.67it/s] 14%|█▍        | 2447/17525 [29:28<2:30:34,  1.67it/s] 14%|█▍        | 2448/17525 [29:29<2:29:43,  1.68it/s] 14%|█▍        | 2449/17525 [29:29<2:28:42,  1.69it/s] 14%|█▍        | 2450/17525 [29:30<2:28:50,  1.69it/s]                                                      {'loss': 0.7332, 'grad_norm': 8.121418952941895, 'learning_rate': 1.9067055792452403e-05, 'epoch': 3.5}
 14%|█▍        | 2450/17525 [29:30<2:28:50,  1.69it/s] 14%|█▍        | 2451/17525 [29:30<2:29:47,  1.68it/s] 14%|█▍        | 2452/17525 [29:31<2:28:53,  1.69it/s] 14%|█▍        | 2453/17525 [29:32<2:59:17,  1.40it/s] 14%|█▍        | 2454/17525 [29:33<2:50:00,  1.48it/s] 14%|█▍        | 2455/17525 [29:33<2:44:03,  1.53it/s] 14%|█▍        | 2456/17525 [29:34<2:39:13,  1.58it/s] 14%|█▍        | 2457/17525 [29:34<2:36:04,  1.61it/s] 14%|█▍        | 2458/17525 [29:35<2:33:14,  1.64it/s] 14%|█▍        | 2459/17525 [29:36<2:31:43,  1.65it/s] 14%|█▍        | 2460/17525 [29:36<2:30:31,  1.67it/s]                                                      {'loss': 0.69, 'grad_norm': 7.2944231033325195, 'learning_rate': 1.9059471865008355e-05, 'epoch': 3.51}
 14%|█▍        | 2460/17525 [29:36<2:30:31,  1.67it/s] 14%|█▍        | 2461/17525 [29:37<2:29:24,  1.68it/s] 14%|█▍        | 2462/17525 [29:37<2:28:16,  1.69it/s] 14%|█▍        | 2463/17525 [29:38<2:27:36,  1.70it/s] 14%|█▍        | 2464/17525 [29:38<2:27:12,  1.71it/s] 14%|█▍        | 2465/17525 [29:39<2:27:22,  1.70it/s] 14%|█▍        | 2466/17525 [29:40<2:27:07,  1.71it/s] 14%|█▍        | 2467/17525 [29:40<2:26:53,  1.71it/s] 14%|█▍        | 2468/17525 [29:41<2:26:17,  1.72it/s] 14%|█▍        | 2469/17525 [29:41<2:26:38,  1.71it/s] 14%|█▍        | 2470/17525 [29:42<2:26:29,  1.71it/s]                                                      {'loss': 0.6198, 'grad_norm': 5.185541152954102, 'learning_rate': 1.9051858758035197e-05, 'epoch': 3.52}
 14%|█▍        | 2470/17525 [29:42<2:26:29,  1.71it/s] 14%|█▍        | 2471/17525 [29:43<2:26:40,  1.71it/s] 14%|█▍        | 2472/17525 [29:43<2:37:03,  1.60it/s] 14%|█▍        | 2473/17525 [29:44<2:34:39,  1.62it/s] 14%|█▍        | 2474/17525 [29:44<2:31:37,  1.65it/s] 14%|█▍        | 2475/17525 [29:45<2:29:53,  1.67it/s] 14%|█▍        | 2476/17525 [29:46<2:28:42,  1.69it/s] 14%|█▍        | 2477/17525 [29:46<2:28:18,  1.69it/s] 14%|█▍        | 2478/17525 [29:47<2:27:33,  1.70it/s] 14%|█▍        | 2479/17525 [29:47<2:26:44,  1.71it/s] 14%|█▍        | 2480/17525 [29:48<2:26:27,  1.71it/s]                                                      {'loss': 0.718, 'grad_norm': 3.9832675457000732, 'learning_rate': 1.9044216496053868e-05, 'epoch': 3.54}
 14%|█▍        | 2480/17525 [29:48<2:26:27,  1.71it/s] 14%|█▍        | 2481/17525 [29:49<2:53:53,  1.44it/s] 14%|█▍        | 2482/17525 [29:49<2:45:36,  1.51it/s] 14%|█▍        | 2483/17525 [29:50<2:40:13,  1.56it/s] 14%|█▍        | 2484/17525 [29:51<2:37:27,  1.59it/s] 14%|█▍        | 2485/17525 [29:51<2:33:45,  1.63it/s] 14%|█▍        | 2486/17525 [29:52<2:31:05,  1.66it/s] 14%|█▍        | 2487/17525 [29:52<2:29:31,  1.68it/s] 14%|█▍        | 2488/17525 [29:53<2:28:20,  1.69it/s] 14%|█▍        | 2489/17525 [29:54<2:27:21,  1.70it/s] 14%|█▍        | 2490/17525 [29:54<2:27:29,  1.70it/s]                                                      {'loss': 0.6011, 'grad_norm': 6.808416366577148, 'learning_rate': 1.903654510367923e-05, 'epoch': 3.55}
 14%|█▍        | 2490/17525 [29:54<2:27:29,  1.70it/s] 14%|█▍        | 2491/17525 [29:55<2:26:44,  1.71it/s] 14%|█▍        | 2492/17525 [29:55<2:26:27,  1.71it/s] 14%|█▍        | 2493/17525 [29:56<2:26:38,  1.71it/s] 14%|█▍        | 2494/17525 [29:57<2:26:13,  1.71it/s] 14%|█▍        | 2495/17525 [29:57<2:26:33,  1.71it/s] 14%|█▍        | 2496/17525 [29:58<2:26:35,  1.71it/s] 14%|█▍        | 2497/17525 [29:58<2:26:16,  1.71it/s] 14%|█▍        | 2498/17525 [29:59<2:25:49,  1.72it/s] 14%|█▍        | 2499/17525 [29:59<2:25:42,  1.72it/s] 14%|█▍        | 2500/17525 [30:00<2:25:35,  1.72it/s]                                                      {'loss': 0.6901, 'grad_norm': 12.326281547546387, 'learning_rate': 1.9028844605619975e-05, 'epoch': 3.57}
 14%|█▍        | 2500/17525 [30:00<2:25:35,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:33:21,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:33:21,895 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:33:21,895 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8796443343162537, 'eval_runtime': 4.6019, 'eval_samples_per_second': 96.264, 'eval_steps_per_second': 4.129, 'epoch': 3.57}
 14%|█▍        | 2500/17525 [30:05<2:25:35,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 14%|█▍        | 2501/17525 [30:05<8:11:59,  1.96s/it] 14%|█▍        | 2502/17525 [30:06<6:27:57,  1.55s/it] 14%|█▍        | 2503/17525 [30:06<5:15:16,  1.26s/it] 14%|█▍        | 2504/17525 [30:07<4:24:19,  1.06s/it] 14%|█▍        | 2505/17525 [30:08<3:50:07,  1.09it/s] 14%|█▍        | 2506/17525 [30:08<3:24:22,  1.22it/s] 14%|█▍        | 2507/17525 [30:09<3:06:52,  1.34it/s] 14%|█▍        | 2508/17525 [30:09<2:54:14,  1.44it/s] 14%|█▍        | 2509/17525 [30:10<2:45:33,  1.51it/s] 14%|█▍        | 2510/17525 [30:10<2:39:29,  1.57it/s]                                                      {'loss': 0.7358, 'grad_norm': 4.2510881423950195, 'learning_rate': 1.902111502667852e-05, 'epoch': 3.58}
 14%|█▍        | 2510/17525 [30:10<2:39:29,  1.57it/s] 14%|█▍        | 2511/17525 [30:11<2:35:16,  1.61it/s] 14%|█▍        | 2512/17525 [30:12<2:32:43,  1.64it/s] 14%|█▍        | 2513/17525 [30:12<2:30:18,  1.66it/s] 14%|█▍        | 2514/17525 [30:13<2:28:55,  1.68it/s] 14%|█▍        | 2515/17525 [30:13<2:27:48,  1.69it/s] 14%|█▍        | 2516/17525 [30:14<2:28:28,  1.68it/s] 14%|█▍        | 2517/17525 [30:15<2:27:16,  1.70it/s] 14%|█▍        | 2518/17525 [30:15<2:26:28,  1.71it/s] 14%|█▍        | 2519/17525 [30:16<2:25:47,  1.72it/s] 14%|█▍        | 2520/17525 [30:16<2:25:21,  1.72it/s]                                                      {'loss': 0.6728, 'grad_norm': 4.4255170822143555, 'learning_rate': 1.9013356391750962e-05, 'epoch': 3.59}
 14%|█▍        | 2520/17525 [30:16<2:25:21,  1.72it/s] 14%|█▍        | 2521/17525 [30:17<2:39:04,  1.57it/s] 14%|█▍        | 2522/17525 [30:18<2:34:59,  1.61it/s] 14%|█▍        | 2523/17525 [30:18<2:32:08,  1.64it/s] 14%|█▍        | 2524/17525 [30:19<2:29:37,  1.67it/s] 14%|█▍        | 2525/17525 [30:19<2:28:17,  1.69it/s] 14%|█▍        | 2526/17525 [30:20<2:27:09,  1.70it/s] 14%|█▍        | 2527/17525 [30:20<2:26:37,  1.70it/s] 14%|█▍        | 2528/17525 [30:21<2:25:56,  1.71it/s] 14%|█▍        | 2529/17525 [30:22<2:25:22,  1.72it/s] 14%|█▍        | 2530/17525 [30:22<2:25:10,  1.72it/s]                                                      {'loss': 0.6637, 'grad_norm': 11.552473068237305, 'learning_rate': 1.9005568725826987e-05, 'epoch': 3.61}
 14%|█▍        | 2530/17525 [30:22<2:25:10,  1.72it/s] 14%|█▍        | 2531/17525 [30:23<2:26:58,  1.70it/s] 14%|█▍        | 2532/17525 [30:23<2:26:11,  1.71it/s] 14%|█▍        | 2533/17525 [30:24<2:25:35,  1.72it/s] 14%|█▍        | 2534/17525 [30:25<2:25:17,  1.72it/s] 14%|█▍        | 2535/17525 [30:25<2:24:57,  1.72it/s] 14%|█▍        | 2536/17525 [30:26<2:24:48,  1.73it/s] 14%|█▍        | 2537/17525 [30:26<2:25:24,  1.72it/s] 14%|█▍        | 2538/17525 [30:27<2:25:58,  1.71it/s] 14%|█▍        | 2539/17525 [30:27<2:26:48,  1.70it/s] 14%|█▍        | 2540/17525 [30:28<2:26:16,  1.71it/s]                                                      {'loss': 0.6318, 'grad_norm': 7.605648517608643, 'learning_rate': 1.899775205398978e-05, 'epoch': 3.62}
 14%|█▍        | 2540/17525 [30:28<2:26:16,  1.71it/s] 14%|█▍        | 2541/17525 [30:29<2:52:25,  1.45it/s] 15%|█▍        | 2542/17525 [30:30<2:44:25,  1.52it/s] 15%|█▍        | 2543/17525 [30:30<2:38:50,  1.57it/s] 15%|█▍        | 2544/17525 [30:31<2:34:42,  1.61it/s] 15%|█▍        | 2545/17525 [30:31<2:31:43,  1.65it/s] 15%|█▍        | 2546/17525 [30:32<2:29:44,  1.67it/s] 15%|█▍        | 2547/17525 [30:33<2:28:11,  1.68it/s] 15%|█▍        | 2548/17525 [30:33<2:27:34,  1.69it/s] 15%|█▍        | 2549/17525 [30:34<2:36:42,  1.59it/s] 15%|█▍        | 2550/17525 [30:34<2:33:23,  1.63it/s]                                                      {'loss': 0.6517, 'grad_norm': 8.627143859863281, 'learning_rate': 1.8989906401415953e-05, 'epoch': 3.64}
 15%|█▍        | 2550/17525 [30:34<2:33:23,  1.63it/s][INFO|trainer.py:3203] 2024-06-25 02:33:56,282 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2550
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79cd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e16ac8a0-5242-4ca1-9d8c-3b5ae19e7910)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:34:06,344 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:34:06,346 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2550/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 15%|█▍        | 2551/17525 [30:45<15:14:52,  3.67s/it] 15%|█▍        | 2552/17525 [30:46<11:23:57,  2.74s/it] 15%|█▍        | 2553/17525 [30:46<8:42:01,  2.09s/it]  15%|█▍        | 2554/17525 [30:47<6:48:49,  1.64s/it] 15%|█▍        | 2555/17525 [30:47<5:29:43,  1.32s/it] 15%|█▍        | 2556/17525 [30:48<4:34:00,  1.10s/it] 15%|█▍        | 2557/17525 [30:49<4:42:43,  1.13s/it] 15%|█▍        | 2558/17525 [30:50<4:01:39,  1.03it/s] 15%|█▍        | 2559/17525 [30:50<3:32:41,  1.17it/s] 15%|█▍        | 2560/17525 [30:51<3:12:26,  1.30it/s]                                                      {'loss': 0.6949, 'grad_norm': 9.236418724060059, 'learning_rate': 1.898203179337546e-05, 'epoch': 3.65}
 15%|█▍        | 2560/17525 [30:51<3:12:26,  1.30it/s] 15%|█▍        | 2561/17525 [30:52<2:58:25,  1.40it/s] 15%|█▍        | 2562/17525 [30:52<2:48:39,  1.48it/s] 15%|█▍        | 2563/17525 [30:53<2:41:25,  1.54it/s] 15%|█▍        | 2564/17525 [30:53<2:36:27,  1.59it/s] 15%|█▍        | 2565/17525 [30:54<2:32:55,  1.63it/s] 15%|█▍        | 2566/17525 [30:55<2:30:34,  1.66it/s] 15%|█▍        | 2567/17525 [30:55<2:28:38,  1.68it/s] 15%|█▍        | 2568/17525 [30:56<2:27:20,  1.69it/s] 15%|█▍        | 2569/17525 [30:56<2:26:45,  1.70it/s] 15%|█▍        | 2570/17525 [30:57<2:26:15,  1.70it/s]                                                      {'loss': 0.8408, 'grad_norm': 8.660894393920898, 'learning_rate': 1.8974128255231513e-05, 'epoch': 3.67}
 15%|█▍        | 2570/17525 [30:57<2:26:15,  1.70it/s] 15%|█▍        | 2571/17525 [30:57<2:26:07,  1.71it/s] 15%|█▍        | 2572/17525 [30:58<2:25:45,  1.71it/s] 15%|█▍        | 2573/17525 [30:59<2:25:10,  1.72it/s] 15%|█▍        | 2574/17525 [30:59<2:24:53,  1.72it/s] 15%|█▍        | 2575/17525 [31:00<2:24:51,  1.72it/s] 15%|█▍        | 2576/17525 [31:00<2:24:45,  1.72it/s] 15%|█▍        | 2577/17525 [31:01<2:24:38,  1.72it/s] 15%|█▍        | 2578/17525 [31:01<2:24:45,  1.72it/s] 15%|█▍        | 2579/17525 [31:02<2:24:34,  1.72it/s] 15%|█▍        | 2580/17525 [31:03<2:24:27,  1.72it/s]                                                      {'loss': 0.6807, 'grad_norm': 6.40501070022583, 'learning_rate': 1.8966195812440523e-05, 'epoch': 3.68}
 15%|█▍        | 2580/17525 [31:03<2:24:27,  1.72it/s] 15%|█▍        | 2581/17525 [31:03<2:24:36,  1.72it/s] 15%|█▍        | 2582/17525 [31:04<2:24:35,  1.72it/s] 15%|█▍        | 2583/17525 [31:04<2:24:36,  1.72it/s] 15%|█▍        | 2584/17525 [31:05<2:24:23,  1.72it/s] 15%|█▍        | 2585/17525 [31:06<2:24:39,  1.72it/s] 15%|█▍        | 2586/17525 [31:06<2:24:34,  1.72it/s] 15%|█▍        | 2587/17525 [31:07<2:24:32,  1.72it/s] 15%|█▍        | 2588/17525 [31:07<2:24:35,  1.72it/s] 15%|█▍        | 2589/17525 [31:08<2:25:20,  1.71it/s] 15%|█▍        | 2590/17525 [31:08<2:25:47,  1.71it/s]                                                      {'loss': 0.6652, 'grad_norm': 8.691232681274414, 'learning_rate': 1.8958234490551976e-05, 'epoch': 3.69}
 15%|█▍        | 2590/17525 [31:08<2:25:47,  1.71it/s] 15%|█▍        | 2591/17525 [31:09<2:26:33,  1.70it/s] 15%|█▍        | 2592/17525 [31:10<2:28:20,  1.68it/s] 15%|█▍        | 2593/17525 [31:10<2:28:00,  1.68it/s] 15%|█▍        | 2594/17525 [31:11<2:27:54,  1.68it/s] 15%|█▍        | 2595/17525 [31:11<2:27:38,  1.69it/s] 15%|█▍        | 2596/17525 [31:12<2:27:04,  1.69it/s] 15%|█▍        | 2597/17525 [31:13<2:27:19,  1.69it/s] 15%|█▍        | 2598/17525 [31:13<2:26:57,  1.69it/s] 15%|█▍        | 2599/17525 [31:14<2:27:08,  1.69it/s] 15%|█▍        | 2600/17525 [31:14<2:26:59,  1.69it/s]                                                      {'loss': 0.7084, 'grad_norm': 8.392406463623047, 'learning_rate': 1.8950244315208387e-05, 'epoch': 3.71}
 15%|█▍        | 2600/17525 [31:14<2:26:59,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:34:36,315 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:34:36,315 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:34:36,315 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8829488754272461, 'eval_runtime': 4.5977, 'eval_samples_per_second': 96.353, 'eval_steps_per_second': 4.133, 'epoch': 3.71}
 15%|█▍        | 2600/17525 [31:19<2:26:59,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 15%|█▍        | 2601/17525 [31:20<8:11:01,  1.97s/it] 15%|█▍        | 2602/17525 [31:20<6:27:51,  1.56s/it] 15%|█▍        | 2603/17525 [31:21<5:15:28,  1.27s/it] 15%|█▍        | 2604/17525 [31:21<4:25:10,  1.07s/it] 15%|█▍        | 2605/17525 [31:22<3:50:45,  1.08it/s] 15%|█▍        | 2606/17525 [31:23<3:25:44,  1.21it/s] 15%|█▍        | 2607/17525 [31:23<3:07:56,  1.32it/s] 15%|█▍        | 2608/17525 [31:24<2:55:28,  1.42it/s] 15%|█▍        | 2609/17525 [31:24<2:46:57,  1.49it/s] 15%|█▍        | 2610/17525 [31:25<2:40:49,  1.55it/s]                                                      {'loss': 0.7065, 'grad_norm': 11.18270492553711, 'learning_rate': 1.8942225312145205e-05, 'epoch': 3.72}
 15%|█▍        | 2610/17525 [31:25<2:40:49,  1.55it/s] 15%|█▍        | 2611/17525 [31:26<2:36:39,  1.59it/s] 15%|█▍        | 2612/17525 [31:26<2:35:43,  1.60it/s] 15%|█▍        | 2613/17525 [31:27<2:33:06,  1.62it/s] 15%|█▍        | 2614/17525 [31:27<2:31:15,  1.64it/s] 15%|█▍        | 2615/17525 [31:28<2:30:04,  1.66it/s] 15%|█▍        | 2616/17525 [31:29<2:28:54,  1.67it/s] 15%|█▍        | 2617/17525 [31:29<2:28:05,  1.68it/s] 15%|█▍        | 2618/17525 [31:30<2:27:31,  1.68it/s] 15%|█▍        | 2619/17525 [31:30<2:27:02,  1.69it/s] 15%|█▍        | 2620/17525 [31:31<2:26:50,  1.69it/s]                                                      {'loss': 0.6325, 'grad_norm': 8.918546676635742, 'learning_rate': 1.8934177507190724e-05, 'epoch': 3.74}
 15%|█▍        | 2620/17525 [31:31<2:26:50,  1.69it/s] 15%|█▍        | 2621/17525 [31:31<2:27:00,  1.69it/s] 15%|█▍        | 2622/17525 [31:32<2:27:05,  1.69it/s] 15%|█▍        | 2623/17525 [31:33<2:26:55,  1.69it/s] 15%|█▍        | 2624/17525 [31:33<2:26:54,  1.69it/s] 15%|█▍        | 2625/17525 [31:34<2:26:44,  1.69it/s] 15%|█▍        | 2626/17525 [31:34<2:26:27,  1.70it/s] 15%|█▍        | 2627/17525 [31:35<2:26:45,  1.69it/s] 15%|█▍        | 2628/17525 [31:36<2:27:14,  1.69it/s] 15%|█▌        | 2629/17525 [31:36<2:26:30,  1.69it/s] 15%|█▌        | 2630/17525 [31:37<2:26:33,  1.69it/s]                                                      {'loss': 0.7451, 'grad_norm': 5.07221794128418, 'learning_rate': 1.892610092626601e-05, 'epoch': 3.75}
 15%|█▌        | 2630/17525 [31:37<2:26:33,  1.69it/s] 15%|█▌        | 2631/17525 [31:37<2:26:26,  1.70it/s] 15%|█▌        | 2632/17525 [31:38<2:26:40,  1.69it/s] 15%|█▌        | 2633/17525 [31:39<2:26:33,  1.69it/s] 15%|█▌        | 2634/17525 [31:39<2:26:32,  1.69it/s] 15%|█▌        | 2635/17525 [31:40<2:26:34,  1.69it/s] 15%|█▌        | 2636/17525 [31:40<2:26:12,  1.70it/s] 15%|█▌        | 2637/17525 [31:41<2:28:19,  1.67it/s] 15%|█▌        | 2638/17525 [31:42<2:27:40,  1.68it/s] 15%|█▌        | 2639/17525 [31:42<2:27:21,  1.68it/s] 15%|█▌        | 2640/17525 [31:43<2:52:54,  1.43it/s]                                                      {'loss': 0.6258, 'grad_norm': 6.412656784057617, 'learning_rate': 1.8917995595384816e-05, 'epoch': 3.77}
 15%|█▌        | 2640/17525 [31:43<2:52:54,  1.43it/s] 15%|█▌        | 2641/17525 [31:44<2:45:10,  1.50it/s] 15%|█▌        | 2642/17525 [31:44<2:39:13,  1.56it/s] 15%|█▌        | 2643/17525 [31:45<2:35:17,  1.60it/s] 15%|█▌        | 2644/17525 [31:45<2:32:52,  1.62it/s] 15%|█▌        | 2645/17525 [31:46<2:31:07,  1.64it/s] 15%|█▌        | 2646/17525 [31:47<2:29:28,  1.66it/s] 15%|█▌        | 2647/17525 [31:47<2:28:39,  1.67it/s] 15%|█▌        | 2648/17525 [31:48<2:27:50,  1.68it/s] 15%|█▌        | 2649/17525 [31:48<2:27:41,  1.68it/s] 15%|█▌        | 2650/17525 [31:49<2:28:56,  1.66it/s]                                                      {'loss': 0.7491, 'grad_norm': 4.728060722351074, 'learning_rate': 1.890986154065349e-05, 'epoch': 3.78}
 15%|█▌        | 2650/17525 [31:49<2:28:56,  1.66it/s] 15%|█▌        | 2651/17525 [31:50<2:28:17,  1.67it/s] 15%|█▌        | 2652/17525 [31:50<2:37:40,  1.57it/s] 15%|█▌        | 2653/17525 [31:51<2:34:22,  1.61it/s] 15%|█▌        | 2654/17525 [31:52<2:57:53,  1.39it/s] 15%|█▌        | 2655/17525 [31:52<2:48:25,  1.47it/s] 15%|█▌        | 2656/17525 [31:53<2:41:34,  1.53it/s] 15%|█▌        | 2657/17525 [31:54<2:37:51,  1.57it/s] 15%|█▌        | 2658/17525 [31:54<2:34:24,  1.60it/s] 15%|█▌        | 2659/17525 [31:55<2:32:01,  1.63it/s] 15%|█▌        | 2660/17525 [31:55<2:30:13,  1.65it/s]                                                      {'loss': 0.7369, 'grad_norm': 7.917919635772705, 'learning_rate': 1.8901698788270894e-05, 'epoch': 3.79}
 15%|█▌        | 2660/17525 [31:55<2:30:13,  1.65it/s] 15%|█▌        | 2661/17525 [31:56<2:29:19,  1.66it/s] 15%|█▌        | 2662/17525 [31:57<2:28:01,  1.67it/s] 15%|█▌        | 2663/17525 [31:57<2:27:08,  1.68it/s] 15%|█▌        | 2664/17525 [31:58<2:26:57,  1.69it/s] 15%|█▌        | 2665/17525 [31:58<2:26:40,  1.69it/s] 15%|█▌        | 2666/17525 [31:59<2:26:17,  1.69it/s] 15%|█▌        | 2667/17525 [32:00<2:26:23,  1.69it/s] 15%|█▌        | 2668/17525 [32:00<2:26:14,  1.69it/s] 15%|█▌        | 2669/17525 [32:01<2:26:04,  1.69it/s] 15%|█▌        | 2670/17525 [32:01<2:26:02,  1.70it/s]                                                      {'loss': 0.641, 'grad_norm': 3.483731508255005, 'learning_rate': 1.8893507364528324e-05, 'epoch': 3.81}
 15%|█▌        | 2670/17525 [32:01<2:26:02,  1.70it/s] 15%|█▌        | 2671/17525 [32:02<2:26:07,  1.69it/s] 15%|█▌        | 2672/17525 [32:02<2:26:11,  1.69it/s] 15%|█▌        | 2673/17525 [32:03<2:26:09,  1.69it/s] 15%|█▌        | 2674/17525 [32:04<2:26:06,  1.69it/s] 15%|█▌        | 2675/17525 [32:04<2:26:03,  1.69it/s] 15%|█▌        | 2676/17525 [32:05<2:26:16,  1.69it/s] 15%|█▌        | 2677/17525 [32:05<2:27:00,  1.68it/s] 15%|█▌        | 2678/17525 [32:06<2:26:35,  1.69it/s] 15%|█▌        | 2679/17525 [32:07<2:26:06,  1.69it/s] 15%|█▌        | 2680/17525 [32:07<2:25:56,  1.70it/s]                                                      {'loss': 0.7289, 'grad_norm': 9.227301597595215, 'learning_rate': 1.8885287295809433e-05, 'epoch': 3.82}
 15%|█▌        | 2680/17525 [32:07<2:25:56,  1.70it/s] 15%|█▌        | 2681/17525 [32:08<2:26:04,  1.69it/s] 15%|█▌        | 2682/17525 [32:08<2:26:15,  1.69it/s] 15%|█▌        | 2683/17525 [32:09<2:26:11,  1.69it/s] 15%|█▌        | 2684/17525 [32:10<2:25:54,  1.70it/s] 15%|█▌        | 2685/17525 [32:10<2:26:09,  1.69it/s] 15%|█▌        | 2686/17525 [32:11<2:26:13,  1.69it/s] 15%|█▌        | 2687/17525 [32:11<2:26:10,  1.69it/s] 15%|█▌        | 2688/17525 [32:12<2:42:04,  1.53it/s] 15%|█▌        | 2689/17525 [32:13<2:37:29,  1.57it/s] 15%|█▌        | 2690/17525 [32:13<2:33:52,  1.61it/s]                                                      {'loss': 0.6064, 'grad_norm': 3.832489252090454, 'learning_rate': 1.8877038608590123e-05, 'epoch': 3.84}
 15%|█▌        | 2690/17525 [32:13<2:33:52,  1.61it/s] 15%|█▌        | 2691/17525 [32:14<2:31:22,  1.63it/s] 15%|█▌        | 2692/17525 [32:14<2:29:21,  1.66it/s] 15%|█▌        | 2693/17525 [32:15<2:27:31,  1.68it/s] 15%|█▌        | 2694/17525 [32:16<2:26:40,  1.69it/s] 15%|█▌        | 2695/17525 [32:16<2:25:40,  1.70it/s] 15%|█▌        | 2696/17525 [32:17<2:25:13,  1.70it/s] 15%|█▌        | 2697/17525 [32:18<2:56:25,  1.40it/s] 15%|█▌        | 2698/17525 [32:18<2:46:48,  1.48it/s] 15%|█▌        | 2699/17525 [32:19<2:40:09,  1.54it/s] 15%|█▌        | 2700/17525 [32:20<2:35:22,  1.59it/s]                                                      {'loss': 0.7204, 'grad_norm': 6.597891330718994, 'learning_rate': 1.8868761329438477e-05, 'epoch': 3.85}
 15%|█▌        | 2700/17525 [32:20<2:35:22,  1.59it/s][INFO|trainer.py:3512] 2024-06-25 02:35:41,485 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:35:41,485 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:35:41,486 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                      
                                               [A{'eval_loss': 0.8776292204856873, 'eval_runtime': 4.5977, 'eval_samples_per_second': 96.353, 'eval_steps_per_second': 4.133, 'epoch': 3.85}
 15%|█▌        | 2700/17525 [32:24<2:35:22,  1.59it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:35:46,087 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2700
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897ed5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 011e0180-83a5-4a78-aef5-b88a2b186f4e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:35:56,148 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:35:56,150 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2700/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 15%|█▌        | 2701/17525 [32:35<20:48:44,  5.05s/it] 15%|█▌        | 2702/17525 [32:36<15:17:32,  3.71s/it] 15%|█▌        | 2703/17525 [32:36<11:25:17,  2.77s/it] 15%|█▌        | 2704/17525 [32:37<8:42:44,  2.12s/it]  15%|█▌        | 2705/17525 [32:37<6:48:54,  1.66s/it] 15%|█▌        | 2706/17525 [32:38<5:29:28,  1.33s/it] 15%|█▌        | 2707/17525 [32:38<4:33:57,  1.11s/it] 15%|█▌        | 2708/17525 [32:39<3:54:58,  1.05it/s] 15%|█▌        | 2709/17525 [32:40<3:27:51,  1.19it/s] 15%|█▌        | 2710/17525 [32:40<3:08:32,  1.31it/s]                                                      {'loss': 0.7085, 'grad_norm': 4.146684646606445, 'learning_rate': 1.8860455485014674e-05, 'epoch': 3.87}
 15%|█▌        | 2710/17525 [32:40<3:08:32,  1.31it/s] 15%|█▌        | 2711/17525 [32:41<2:55:26,  1.41it/s] 15%|█▌        | 2712/17525 [32:41<2:46:11,  1.49it/s] 15%|█▌        | 2713/17525 [32:42<2:39:36,  1.55it/s] 15%|█▌        | 2714/17525 [32:43<2:35:13,  1.59it/s] 15%|█▌        | 2715/17525 [32:43<2:32:02,  1.62it/s] 15%|█▌        | 2716/17525 [32:44<2:40:03,  1.54it/s] 16%|█▌        | 2717/17525 [32:44<2:35:31,  1.59it/s] 16%|█▌        | 2718/17525 [32:45<2:32:32,  1.62it/s] 16%|█▌        | 2719/17525 [32:46<2:30:14,  1.64it/s] 16%|█▌        | 2720/17525 [32:46<2:28:43,  1.66it/s]                                                      {'loss': 0.7037, 'grad_norm': 5.346276760101318, 'learning_rate': 1.885212110207089e-05, 'epoch': 3.88}
 16%|█▌        | 2720/17525 [32:46<2:28:43,  1.66it/s] 16%|█▌        | 2721/17525 [32:47<2:27:37,  1.67it/s] 16%|█▌        | 2722/17525 [32:47<2:26:41,  1.68it/s] 16%|█▌        | 2723/17525 [32:48<2:26:00,  1.69it/s] 16%|█▌        | 2724/17525 [32:49<2:25:32,  1.69it/s] 16%|█▌        | 2725/17525 [32:49<2:25:09,  1.70it/s] 16%|█▌        | 2726/17525 [32:50<3:00:35,  1.37it/s] 16%|█▌        | 2727/17525 [32:51<2:49:50,  1.45it/s] 16%|█▌        | 2728/17525 [32:51<2:41:54,  1.52it/s] 16%|█▌        | 2729/17525 [32:52<2:36:32,  1.58it/s] 16%|█▌        | 2730/17525 [32:53<2:33:07,  1.61it/s]                                                      {'loss': 0.7339, 'grad_norm': 10.199246406555176, 'learning_rate': 1.884375820745123e-05, 'epoch': 3.89}
 16%|█▌        | 2730/17525 [32:53<2:33:07,  1.61it/s] 16%|█▌        | 2731/17525 [32:53<2:30:21,  1.64it/s] 16%|█▌        | 2732/17525 [32:54<2:28:34,  1.66it/s] 16%|█▌        | 2733/17525 [32:54<2:27:27,  1.67it/s] 16%|█▌        | 2734/17525 [32:55<2:26:32,  1.68it/s] 16%|█▌        | 2735/17525 [32:55<2:26:07,  1.69it/s] 16%|█▌        | 2736/17525 [32:56<2:27:08,  1.68it/s] 16%|█▌        | 2737/17525 [32:57<2:26:09,  1.69it/s] 16%|█▌        | 2738/17525 [32:57<2:25:50,  1.69it/s] 16%|█▌        | 2739/17525 [32:58<2:25:14,  1.70it/s] 16%|█▌        | 2740/17525 [32:58<2:25:24,  1.69it/s]                                                      {'loss': 0.7512, 'grad_norm': 8.108353614807129, 'learning_rate': 1.8835366828091623e-05, 'epoch': 3.91}
 16%|█▌        | 2740/17525 [32:58<2:25:24,  1.69it/s] 16%|█▌        | 2741/17525 [32:59<2:25:24,  1.69it/s] 16%|█▌        | 2742/17525 [33:00<2:25:03,  1.70it/s] 16%|█▌        | 2743/17525 [33:00<2:24:43,  1.70it/s] 16%|█▌        | 2744/17525 [33:01<2:24:31,  1.70it/s] 16%|█▌        | 2745/17525 [33:01<2:24:15,  1.71it/s] 16%|█▌        | 2746/17525 [33:02<2:24:13,  1.71it/s] 16%|█▌        | 2747/17525 [33:03<2:26:02,  1.69it/s] 16%|█▌        | 2748/17525 [33:03<2:25:38,  1.69it/s] 16%|█▌        | 2749/17525 [33:04<2:25:31,  1.69it/s] 16%|█▌        | 2750/17525 [33:04<2:25:30,  1.69it/s]                                                      {'loss': 0.6455, 'grad_norm': 4.062922477722168, 'learning_rate': 1.882694699101975e-05, 'epoch': 3.92}
 16%|█▌        | 2750/17525 [33:04<2:25:30,  1.69it/s] 16%|█▌        | 2751/17525 [33:05<2:25:20,  1.69it/s] 16%|█▌        | 2752/17525 [33:06<2:24:56,  1.70it/s] 16%|█▌        | 2753/17525 [33:06<2:24:52,  1.70it/s] 16%|█▌        | 2754/17525 [33:07<2:49:46,  1.45it/s] 16%|█▌        | 2755/17525 [33:08<2:41:51,  1.52it/s] 16%|█▌        | 2756/17525 [33:08<2:36:42,  1.57it/s] 16%|█▌        | 2757/17525 [33:09<2:32:57,  1.61it/s] 16%|█▌        | 2758/17525 [33:09<2:30:15,  1.64it/s] 16%|█▌        | 2759/17525 [33:10<2:59:24,  1.37it/s] 16%|█▌        | 2760/17525 [33:11<2:48:55,  1.46it/s]                                                      {'loss': 0.6596, 'grad_norm': 9.664213180541992, 'learning_rate': 1.881849872335495e-05, 'epoch': 3.94}
 16%|█▌        | 2760/17525 [33:11<2:48:55,  1.46it/s] 16%|█▌        | 2761/17525 [33:12<2:41:52,  1.52it/s] 16%|█▌        | 2762/17525 [33:12<2:36:37,  1.57it/s] 16%|█▌        | 2763/17525 [33:13<2:33:28,  1.60it/s] 16%|█▌        | 2764/17525 [33:13<2:30:38,  1.63it/s] 16%|█▌        | 2765/17525 [33:14<2:28:54,  1.65it/s] 16%|█▌        | 2766/17525 [33:14<2:27:13,  1.67it/s] 16%|█▌        | 2767/17525 [33:15<2:26:33,  1.68it/s] 16%|█▌        | 2768/17525 [33:16<2:26:07,  1.68it/s] 16%|█▌        | 2769/17525 [33:16<2:25:46,  1.69it/s] 16%|█▌        | 2770/17525 [33:17<2:25:02,  1.70it/s]                                                      {'loss': 0.6589, 'grad_norm': 9.88304328918457, 'learning_rate': 1.881002205230813e-05, 'epoch': 3.95}
 16%|█▌        | 2770/17525 [33:17<2:25:02,  1.70it/s] 16%|█▌        | 2771/17525 [33:17<2:25:00,  1.70it/s] 16%|█▌        | 2772/17525 [33:18<2:47:56,  1.46it/s] 16%|█▌        | 2773/17525 [33:19<2:40:40,  1.53it/s] 16%|█▌        | 2774/17525 [33:20<2:35:41,  1.58it/s] 16%|█▌        | 2775/17525 [33:20<2:32:29,  1.61it/s] 16%|█▌        | 2776/17525 [33:21<2:30:07,  1.64it/s] 16%|█▌        | 2777/17525 [33:21<2:28:37,  1.65it/s] 16%|█▌        | 2778/17525 [33:22<2:27:18,  1.67it/s] 16%|█▌        | 2779/17525 [33:22<2:26:36,  1.68it/s] 16%|█▌        | 2780/17525 [33:23<2:25:45,  1.69it/s]                                                      {'loss': 0.6783, 'grad_norm': 9.235940933227539, 'learning_rate': 1.8801517005181686e-05, 'epoch': 3.97}
 16%|█▌        | 2780/17525 [33:23<2:25:45,  1.69it/s] 16%|█▌        | 2781/17525 [33:24<2:25:37,  1.69it/s] 16%|█▌        | 2782/17525 [33:24<2:25:21,  1.69it/s] 16%|█▌        | 2783/17525 [33:25<2:35:15,  1.58it/s] 16%|█▌        | 2784/17525 [33:26<2:31:52,  1.62it/s] 16%|█▌        | 2785/17525 [33:26<2:29:37,  1.64it/s] 16%|█▌        | 2786/17525 [33:27<2:28:00,  1.66it/s] 16%|█▌        | 2787/17525 [33:27<2:26:55,  1.67it/s] 16%|█▌        | 2788/17525 [33:28<2:26:18,  1.68it/s] 16%|█▌        | 2789/17525 [33:28<2:25:33,  1.69it/s] 16%|█▌        | 2790/17525 [33:29<2:25:02,  1.69it/s]                                                      {'loss': 0.6323, 'grad_norm': 4.933924674987793, 'learning_rate': 1.879298360936941e-05, 'epoch': 3.98}
 16%|█▌        | 2790/17525 [33:29<2:25:02,  1.69it/s] 16%|█▌        | 2791/17525 [33:30<2:27:32,  1.66it/s] 16%|█▌        | 2792/17525 [33:30<2:26:36,  1.67it/s] 16%|█▌        | 2793/17525 [33:31<2:25:55,  1.68it/s] 16%|█▌        | 2794/17525 [33:31<2:24:57,  1.69it/s] 16%|█▌        | 2795/17525 [33:32<2:24:32,  1.70it/s] 16%|█▌        | 2796/17525 [33:33<2:24:06,  1.70it/s] 16%|█▌        | 2797/17525 [33:33<2:23:32,  1.71it/s] 16%|█▌        | 2798/17525 [33:34<2:25:36,  1.69it/s] 16%|█▌        | 2799/17525 [33:34<2:24:53,  1.69it/s] 16%|█▌        | 2800/17525 [33:35<2:24:06,  1.70it/s]                                                      {'loss': 0.7285, 'grad_norm': 10.449732780456543, 'learning_rate': 1.8784421892356396e-05, 'epoch': 3.99}
 16%|█▌        | 2800/17525 [33:35<2:24:06,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:36:56,858 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:36:56,858 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:36:56,858 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8795331120491028, 'eval_runtime': 4.602, 'eval_samples_per_second': 96.263, 'eval_steps_per_second': 4.129, 'epoch': 3.99}
 16%|█▌        | 2800/17525 [33:40<2:24:06,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 16%|█▌        | 2801/17525 [33:40<8:03:36,  1.97s/it] 16%|█▌        | 2802/17525 [33:41<6:21:22,  1.55s/it] 16%|█▌        | 2803/17525 [33:41<5:10:03,  1.26s/it] 16%|█▌        | 2804/17525 [33:42<4:20:10,  1.06s/it] 16%|█▌        | 2805/17525 [33:42<3:44:53,  1.09it/s] 16%|█▌        | 2806/17525 [33:43<3:20:31,  1.22it/s] 16%|█▌        | 2807/17525 [33:44<3:03:10,  1.34it/s] 16%|█▌        | 2808/17525 [33:44<2:50:52,  1.44it/s] 16%|█▌        | 2809/17525 [33:45<3:07:48,  1.31it/s] 16%|█▌        | 2810/17525 [33:46<2:54:08,  1.41it/s]                                                      {'loss': 0.7333, 'grad_norm': 8.112680435180664, 'learning_rate': 1.8775831881718966e-05, 'epoch': 4.01}
 16%|█▌        | 2810/17525 [33:46<2:54:08,  1.41it/s] 16%|█▌        | 2811/17525 [33:46<2:45:00,  1.49it/s] 16%|█▌        | 2812/17525 [33:47<2:38:41,  1.55it/s] 16%|█▌        | 2813/17525 [33:48<2:34:09,  1.59it/s] 16%|█▌        | 2814/17525 [33:48<2:30:46,  1.63it/s] 16%|█▌        | 2815/17525 [33:49<2:28:38,  1.65it/s] 16%|█▌        | 2816/17525 [33:49<2:27:09,  1.67it/s] 16%|█▌        | 2817/17525 [33:50<2:25:39,  1.68it/s] 16%|█▌        | 2818/17525 [33:50<2:24:48,  1.69it/s] 16%|█▌        | 2819/17525 [33:51<2:24:17,  1.70it/s] 16%|█▌        | 2820/17525 [33:52<2:23:51,  1.70it/s]                                                      {'loss': 0.6317, 'grad_norm': 8.977546691894531, 'learning_rate': 1.876721360512456e-05, 'epoch': 4.02}
 16%|█▌        | 2820/17525 [33:52<2:23:51,  1.70it/s] 16%|█▌        | 2821/17525 [33:52<2:23:41,  1.71it/s] 16%|█▌        | 2822/17525 [33:53<2:23:18,  1.71it/s] 16%|█▌        | 2823/17525 [33:53<2:22:59,  1.71it/s] 16%|█▌        | 2824/17525 [33:54<2:23:01,  1.71it/s] 16%|█▌        | 2825/17525 [33:55<2:23:06,  1.71it/s] 16%|█▌        | 2826/17525 [33:55<2:23:12,  1.71it/s] 16%|█▌        | 2827/17525 [33:56<2:23:05,  1.71it/s] 16%|█▌        | 2828/17525 [33:56<2:23:22,  1.71it/s] 16%|█▌        | 2829/17525 [33:57<2:24:57,  1.69it/s] 16%|█▌        | 2830/17525 [33:57<2:24:27,  1.70it/s]                                                      {'loss': 0.6223, 'grad_norm': 6.40812349319458, 'learning_rate': 1.8758567090331673e-05, 'epoch': 4.04}
 16%|█▌        | 2830/17525 [33:57<2:24:27,  1.70it/s] 16%|█▌        | 2831/17525 [33:58<2:24:17,  1.70it/s] 16%|█▌        | 2832/17525 [33:59<2:23:56,  1.70it/s] 16%|█▌        | 2833/17525 [33:59<2:23:43,  1.70it/s] 16%|█▌        | 2834/17525 [34:00<2:23:43,  1.70it/s] 16%|█▌        | 2835/17525 [34:00<2:23:36,  1.70it/s] 16%|█▌        | 2836/17525 [34:01<2:33:59,  1.59it/s] 16%|█▌        | 2837/17525 [34:02<2:30:46,  1.62it/s] 16%|█▌        | 2838/17525 [34:02<2:28:24,  1.65it/s] 16%|█▌        | 2839/17525 [34:03<2:49:25,  1.44it/s] 16%|█▌        | 2840/17525 [34:04<2:41:25,  1.52it/s]                                                      {'loss': 0.7676, 'grad_norm': 11.295364379882812, 'learning_rate': 1.8749892365189747e-05, 'epoch': 4.05}
 16%|█▌        | 2840/17525 [34:04<2:41:25,  1.52it/s] 16%|█▌        | 2841/17525 [34:04<2:35:55,  1.57it/s] 16%|█▌        | 2842/17525 [34:05<2:32:10,  1.61it/s] 16%|█▌        | 2843/17525 [34:06<2:29:29,  1.64it/s] 16%|█▌        | 2844/17525 [34:06<2:27:31,  1.66it/s] 16%|█▌        | 2845/17525 [34:07<2:26:00,  1.68it/s] 16%|█▌        | 2846/17525 [34:07<2:24:58,  1.69it/s] 16%|█▌        | 2847/17525 [34:08<2:24:28,  1.69it/s] 16%|█▋        | 2848/17525 [34:08<2:23:59,  1.70it/s] 16%|█▋        | 2849/17525 [34:09<2:23:20,  1.71it/s] 16%|█▋        | 2850/17525 [34:10<2:23:14,  1.71it/s]                                                      {'loss': 0.6727, 'grad_norm': 9.181163787841797, 'learning_rate': 1.8741189457639083e-05, 'epoch': 4.07}
 16%|█▋        | 2850/17525 [34:10<2:23:14,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 02:37:31,498 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2850
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b288b77d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ba0146de-2046-4a39-8add-e8334ae4b5e1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:37:41,559 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:37:41,561 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-2850/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 16%|█▋        | 2851/17525 [34:20<14:51:04,  3.64s/it] 16%|█▋        | 2852/17525 [34:21<11:06:12,  2.72s/it] 16%|█▋        | 2853/17525 [34:22<8:29:01,  2.08s/it]  16%|█▋        | 2854/17525 [34:22<6:39:10,  1.63s/it] 16%|█▋        | 2855/17525 [34:23<5:22:07,  1.32s/it] 16%|█▋        | 2856/17525 [34:23<4:28:19,  1.10s/it] 16%|█▋        | 2857/17525 [34:24<4:16:27,  1.05s/it] 16%|█▋        | 2858/17525 [34:25<3:42:23,  1.10it/s] 16%|█▋        | 2859/17525 [34:25<3:18:25,  1.23it/s] 16%|█▋        | 2860/17525 [34:26<3:01:52,  1.34it/s]                                                      {'loss': 0.6784, 'grad_norm': 4.179086685180664, 'learning_rate': 1.8732458395710763e-05, 'epoch': 4.08}
 16%|█▋        | 2860/17525 [34:26<3:01:52,  1.34it/s] 16%|█▋        | 2861/17525 [34:27<2:50:31,  1.43it/s] 16%|█▋        | 2862/17525 [34:27<2:42:21,  1.51it/s] 16%|█▋        | 2863/17525 [34:28<2:36:47,  1.56it/s] 16%|█▋        | 2864/17525 [34:28<2:32:32,  1.60it/s] 16%|█▋        | 2865/17525 [34:29<2:29:36,  1.63it/s] 16%|█▋        | 2866/17525 [34:29<2:27:20,  1.66it/s] 16%|█▋        | 2867/17525 [34:30<2:26:01,  1.67it/s] 16%|█▋        | 2868/17525 [34:31<2:24:50,  1.69it/s] 16%|█▋        | 2869/17525 [34:31<2:24:06,  1.70it/s] 16%|█▋        | 2870/17525 [34:32<2:23:34,  1.70it/s]                                                      {'loss': 0.6384, 'grad_norm': 7.837072372436523, 'learning_rate': 1.8723699207526534e-05, 'epoch': 4.09}
 16%|█▋        | 2870/17525 [34:32<2:23:34,  1.70it/s] 16%|█▋        | 2871/17525 [34:32<2:23:30,  1.70it/s] 16%|█▋        | 2872/17525 [34:33<2:23:05,  1.71it/s] 16%|█▋        | 2873/17525 [34:34<2:22:47,  1.71it/s] 16%|█▋        | 2874/17525 [34:34<2:22:56,  1.71it/s] 16%|█▋        | 2875/17525 [34:35<2:48:27,  1.45it/s] 16%|█▋        | 2876/17525 [34:36<2:40:41,  1.52it/s] 16%|█▋        | 2877/17525 [34:37<3:51:58,  1.05it/s] 16%|█▋        | 2878/17525 [34:38<3:24:57,  1.19it/s] 16%|█▋        | 2879/17525 [34:38<3:06:12,  1.31it/s] 16%|█▋        | 2880/17525 [34:39<2:52:58,  1.41it/s]                                                      {'loss': 0.7282, 'grad_norm': 8.375194549560547, 'learning_rate': 1.8714911921298756e-05, 'epoch': 4.11}
 16%|█▋        | 2880/17525 [34:39<2:52:58,  1.41it/s] 16%|█▋        | 2881/17525 [34:40<2:43:49,  1.49it/s] 16%|█▋        | 2882/17525 [34:40<2:37:29,  1.55it/s] 16%|█▋        | 2883/17525 [34:41<2:34:27,  1.58it/s] 16%|█▋        | 2884/17525 [34:42<3:27:07,  1.18it/s] 16%|█▋        | 2885/17525 [34:43<3:07:45,  1.30it/s] 16%|█▋        | 2886/17525 [34:43<2:53:53,  1.40it/s] 16%|█▋        | 2887/17525 [34:44<2:44:16,  1.49it/s] 16%|█▋        | 2888/17525 [34:45<2:37:38,  1.55it/s] 16%|█▋        | 2889/17525 [34:45<2:33:14,  1.59it/s] 16%|█▋        | 2890/17525 [34:46<2:29:59,  1.63it/s]                                                      {'loss': 0.6012, 'grad_norm': 4.852752208709717, 'learning_rate': 1.8706096565330273e-05, 'epoch': 4.12}
 16%|█▋        | 2890/17525 [34:46<2:29:59,  1.63it/s] 16%|█▋        | 2891/17525 [34:46<2:27:42,  1.65it/s] 17%|█▋        | 2892/17525 [34:47<2:25:58,  1.67it/s] 17%|█▋        | 2893/17525 [34:47<2:24:50,  1.68it/s] 17%|█▋        | 2894/17525 [34:48<2:24:12,  1.69it/s] 17%|█▋        | 2895/17525 [34:49<2:23:41,  1.70it/s] 17%|█▋        | 2896/17525 [34:49<2:23:20,  1.70it/s] 17%|█▋        | 2897/17525 [34:50<2:22:48,  1.71it/s] 17%|█▋        | 2898/17525 [34:50<2:22:33,  1.71it/s] 17%|█▋        | 2899/17525 [34:51<2:22:29,  1.71it/s] 17%|█▋        | 2900/17525 [34:52<2:22:29,  1.71it/s]                                                      {'loss': 0.5597, 'grad_norm': 4.179206371307373, 'learning_rate': 1.8697253168014345e-05, 'epoch': 4.14}
 17%|█▋        | 2900/17525 [34:52<2:22:29,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 02:38:13,423 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:38:13,423 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:38:13,423 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.84it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8777949810028076, 'eval_runtime': 4.5945, 'eval_samples_per_second': 96.419, 'eval_steps_per_second': 4.135, 'epoch': 4.14}
 17%|█▋        | 2900/17525 [34:56<2:22:29,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 17%|█▋        | 2901/17525 [34:57<7:58:54,  1.96s/it] 17%|█▋        | 2902/17525 [34:57<6:17:50,  1.55s/it] 17%|█▋        | 2903/17525 [34:58<5:07:16,  1.26s/it] 17%|█▋        | 2904/17525 [34:58<4:17:49,  1.06s/it] 17%|█▋        | 2905/17525 [34:59<3:57:02,  1.03it/s] 17%|█▋        | 2906/17525 [35:00<3:28:48,  1.17it/s] 17%|█▋        | 2907/17525 [35:00<3:08:34,  1.29it/s] 17%|█▋        | 2908/17525 [35:01<2:55:09,  1.39it/s] 17%|█▋        | 2909/17525 [35:02<2:45:06,  1.48it/s] 17%|█▋        | 2910/17525 [35:02<2:38:12,  1.54it/s]                                                      {'loss': 0.6119, 'grad_norm': 9.071855545043945, 'learning_rate': 1.8688381757834554e-05, 'epoch': 4.15}
 17%|█▋        | 2910/17525 [35:02<2:38:12,  1.54it/s] 17%|█▋        | 2911/17525 [35:03<2:33:23,  1.59it/s] 17%|█▋        | 2912/17525 [35:03<2:30:09,  1.62it/s] 17%|█▋        | 2913/17525 [35:04<2:27:57,  1.65it/s] 17%|█▋        | 2914/17525 [35:05<2:26:23,  1.66it/s] 17%|█▋        | 2915/17525 [35:05<2:24:54,  1.68it/s] 17%|█▋        | 2916/17525 [35:06<2:24:01,  1.69it/s] 17%|█▋        | 2917/17525 [35:06<2:23:21,  1.70it/s] 17%|█▋        | 2918/17525 [35:07<2:49:19,  1.44it/s] 17%|█▋        | 2919/17525 [35:08<2:42:42,  1.50it/s] 17%|█▋        | 2920/17525 [35:08<2:36:37,  1.55it/s]                                                      {'loss': 0.6236, 'grad_norm': 4.749208927154541, 'learning_rate': 1.8679482363364697e-05, 'epoch': 4.17}
 17%|█▋        | 2920/17525 [35:08<2:36:37,  1.55it/s] 17%|█▋        | 2921/17525 [35:09<2:32:42,  1.59it/s] 17%|█▋        | 2922/17525 [35:10<2:29:23,  1.63it/s] 17%|█▋        | 2923/17525 [35:10<2:27:12,  1.65it/s] 17%|█▋        | 2924/17525 [35:11<2:56:53,  1.38it/s] 17%|█▋        | 2925/17525 [35:12<2:46:23,  1.46it/s] 17%|█▋        | 2926/17525 [35:12<2:38:53,  1.53it/s] 17%|█▋        | 2927/17525 [35:13<2:33:50,  1.58it/s] 17%|█▋        | 2928/17525 [35:13<2:30:00,  1.62it/s] 17%|█▋        | 2929/17525 [35:14<2:27:05,  1.65it/s] 17%|█▋        | 2930/17525 [35:15<2:25:25,  1.67it/s]                                                      {'loss': 0.6623, 'grad_norm': 7.157829284667969, 'learning_rate': 1.8670555013268718e-05, 'epoch': 4.18}
 17%|█▋        | 2930/17525 [35:15<2:25:25,  1.67it/s] 17%|█▋        | 2931/17525 [35:15<2:24:20,  1.69it/s] 17%|█▋        | 2932/17525 [35:16<2:23:22,  1.70it/s] 17%|█▋        | 2933/17525 [35:16<2:22:32,  1.71it/s] 17%|█▋        | 2934/17525 [35:17<2:21:49,  1.71it/s] 17%|█▋        | 2935/17525 [35:18<2:21:35,  1.72it/s] 17%|█▋        | 2936/17525 [35:18<2:46:49,  1.46it/s] 17%|█▋        | 2937/17525 [35:19<2:38:58,  1.53it/s] 17%|█▋        | 2938/17525 [35:20<2:56:43,  1.38it/s] 17%|█▋        | 2939/17525 [35:21<2:46:37,  1.46it/s] 17%|█▋        | 2940/17525 [35:21<2:39:06,  1.53it/s]                                                      {'loss': 0.607, 'grad_norm': 6.638284206390381, 'learning_rate': 1.8661599736300596e-05, 'epoch': 4.19}
 17%|█▋        | 2940/17525 [35:21<2:39:06,  1.53it/s] 17%|█▋        | 2941/17525 [35:22<2:35:28,  1.56it/s] 17%|█▋        | 2942/17525 [35:22<2:31:13,  1.61it/s] 17%|█▋        | 2943/17525 [35:23<2:28:31,  1.64it/s] 17%|█▋        | 2944/17525 [35:23<2:26:19,  1.66it/s] 17%|█▋        | 2945/17525 [35:24<2:25:51,  1.67it/s] 17%|█▋        | 2946/17525 [35:25<2:25:08,  1.67it/s] 17%|█▋        | 2947/17525 [35:25<2:24:08,  1.69it/s] 17%|█▋        | 2948/17525 [35:26<2:23:28,  1.69it/s] 17%|█▋        | 2949/17525 [35:26<2:22:58,  1.70it/s] 17%|█▋        | 2950/17525 [35:27<2:22:36,  1.70it/s]                                                      {'loss': 0.6902, 'grad_norm': 4.847146511077881, 'learning_rate': 1.8652616561304257e-05, 'epoch': 4.21}
 17%|█▋        | 2950/17525 [35:27<2:22:36,  1.70it/s] 17%|█▋        | 2951/17525 [35:28<2:22:47,  1.70it/s] 17%|█▋        | 2952/17525 [35:28<2:22:29,  1.70it/s] 17%|█▋        | 2953/17525 [35:29<2:22:08,  1.71it/s] 17%|█▋        | 2954/17525 [35:29<2:22:01,  1.71it/s] 17%|█▋        | 2955/17525 [35:30<2:22:07,  1.71it/s] 17%|█▋        | 2956/17525 [35:30<2:21:53,  1.71it/s] 17%|█▋        | 2957/17525 [35:31<2:21:40,  1.71it/s] 17%|█▋        | 2958/17525 [35:32<2:21:50,  1.71it/s] 17%|█▋        | 2959/17525 [35:32<2:22:01,  1.71it/s] 17%|█▋        | 2960/17525 [35:33<2:21:49,  1.71it/s]                                                      {'loss': 0.6518, 'grad_norm': 4.687063694000244, 'learning_rate': 1.864360551721349e-05, 'epoch': 4.22}
 17%|█▋        | 2960/17525 [35:33<2:21:49,  1.71it/s] 17%|█▋        | 2961/17525 [35:33<2:21:47,  1.71it/s] 17%|█▋        | 2962/17525 [35:34<2:21:49,  1.71it/s] 17%|█▋        | 2963/17525 [35:35<2:21:36,  1.71it/s] 17%|█▋        | 2964/17525 [35:35<2:21:34,  1.71it/s] 17%|█▋        | 2965/17525 [35:36<2:21:49,  1.71it/s] 17%|█▋        | 2966/17525 [35:36<2:31:57,  1.60it/s] 17%|█▋        | 2967/17525 [35:37<2:29:11,  1.63it/s] 17%|█▋        | 2968/17525 [35:38<2:26:37,  1.65it/s] 17%|█▋        | 2969/17525 [35:38<2:25:17,  1.67it/s] 17%|█▋        | 2970/17525 [35:39<2:24:07,  1.68it/s]                                                      {'loss': 0.694, 'grad_norm': 6.889383316040039, 'learning_rate': 1.863456663305184e-05, 'epoch': 4.24}
 17%|█▋        | 2970/17525 [35:39<2:24:07,  1.68it/s] 17%|█▋        | 2971/17525 [35:39<2:27:00,  1.65it/s] 17%|█▋        | 2972/17525 [35:40<2:25:16,  1.67it/s] 17%|█▋        | 2973/17525 [35:41<2:25:35,  1.67it/s] 17%|█▋        | 2974/17525 [35:41<2:24:24,  1.68it/s] 17%|█▋        | 2975/17525 [35:42<2:23:28,  1.69it/s] 17%|█▋        | 2976/17525 [35:42<2:23:00,  1.70it/s] 17%|█▋        | 2977/17525 [35:43<2:22:43,  1.70it/s] 17%|█▋        | 2978/17525 [35:44<2:22:09,  1.71it/s] 17%|█▋        | 2979/17525 [35:44<2:21:44,  1.71it/s] 17%|█▋        | 2980/17525 [35:45<2:21:31,  1.71it/s]                                                      {'loss': 0.752, 'grad_norm': 8.434741020202637, 'learning_rate': 1.862549993793253e-05, 'epoch': 4.25}
 17%|█▋        | 2980/17525 [35:45<2:21:31,  1.71it/s] 17%|█▋        | 2981/17525 [35:45<2:21:54,  1.71it/s] 17%|█▋        | 2982/17525 [35:46<2:21:38,  1.71it/s] 17%|█▋        | 2983/17525 [35:46<2:21:39,  1.71it/s] 17%|█▋        | 2984/17525 [35:47<2:21:26,  1.71it/s] 17%|█▋        | 2985/17525 [35:48<2:21:10,  1.72it/s] 17%|█▋        | 2986/17525 [35:48<2:21:09,  1.72it/s] 17%|█▋        | 2987/17525 [35:49<2:21:21,  1.71it/s] 17%|█▋        | 2988/17525 [35:49<2:21:21,  1.71it/s] 17%|█▋        | 2989/17525 [35:50<2:21:22,  1.71it/s] 17%|█▋        | 2990/17525 [35:51<2:21:30,  1.71it/s]                                                      {'loss': 0.7828, 'grad_norm': 7.0544939041137695, 'learning_rate': 1.861640546105835e-05, 'epoch': 4.27}
 17%|█▋        | 2990/17525 [35:51<2:21:30,  1.71it/s] 17%|█▋        | 2991/17525 [35:51<2:21:36,  1.71it/s] 17%|█▋        | 2992/17525 [35:52<2:21:28,  1.71it/s] 17%|█▋        | 2993/17525 [35:52<2:21:39,  1.71it/s] 17%|█▋        | 2994/17525 [35:53<2:21:17,  1.71it/s] 17%|█▋        | 2995/17525 [35:53<2:21:07,  1.72it/s] 17%|█▋        | 2996/17525 [35:54<2:21:22,  1.71it/s] 17%|█▋        | 2997/17525 [35:55<2:21:20,  1.71it/s] 17%|█▋        | 2998/17525 [35:55<2:21:13,  1.71it/s] 17%|█▋        | 2999/17525 [35:56<2:21:11,  1.71it/s] 17%|█▋        | 3000/17525 [35:56<2:20:59,  1.72it/s]                                                      {'loss': 0.6233, 'grad_norm': 5.01940393447876, 'learning_rate': 1.8607283231721578e-05, 'epoch': 4.28}
 17%|█▋        | 3000/17525 [35:56<2:20:59,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:39:18,283 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:39:18,284 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:39:18,284 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8764382004737854, 'eval_runtime': 4.6004, 'eval_samples_per_second': 96.296, 'eval_steps_per_second': 4.13, 'epoch': 4.28}
 17%|█▋        | 3000/17525 [36:01<2:20:59,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:39:22,888 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3000
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b2897f2cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6dd97558-e02d-4cf7-a31d-52c15dedc222)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:39:32,949 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:39:32,952 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3000/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 17%|█▋        | 3001/17525 [36:12<20:20:44,  5.04s/it] 17%|█▋        | 3002/17525 [36:12<14:57:38,  3.71s/it] 17%|█▋        | 3003/17525 [36:13<11:10:35,  2.77s/it] 17%|█▋        | 3004/17525 [36:14<8:31:21,  2.11s/it]  17%|█▋        | 3005/17525 [36:14<6:40:02,  1.65s/it] 17%|█▋        | 3006/17525 [36:15<6:07:08,  1.52s/it] 17%|█▋        | 3007/17525 [36:16<4:59:09,  1.24s/it] 17%|█▋        | 3008/17525 [36:17<4:11:22,  1.04s/it] 17%|█▋        | 3009/17525 [36:17<3:37:59,  1.11it/s] 17%|█▋        | 3010/17525 [36:18<3:45:03,  1.07it/s]                                                      {'loss': 0.6536, 'grad_norm': 6.02886962890625, 'learning_rate': 1.8598133279303877e-05, 'epoch': 4.29}
 17%|█▋        | 3010/17525 [36:18<3:45:03,  1.07it/s] 17%|█▋        | 3011/17525 [36:19<3:20:00,  1.21it/s] 17%|█▋        | 3012/17525 [36:19<3:01:59,  1.33it/s] 17%|█▋        | 3013/17525 [36:20<3:02:16,  1.33it/s] 17%|█▋        | 3014/17525 [36:21<2:49:58,  1.42it/s] 17%|█▋        | 3015/17525 [36:21<2:40:57,  1.50it/s] 17%|█▋        | 3016/17525 [36:22<2:34:22,  1.57it/s] 17%|█▋        | 3017/17525 [36:22<2:30:19,  1.61it/s] 17%|█▋        | 3018/17525 [36:23<2:27:23,  1.64it/s] 17%|█▋        | 3019/17525 [36:24<2:25:14,  1.66it/s] 17%|█▋        | 3020/17525 [36:24<2:23:46,  1.68it/s]                                                      {'loss': 0.551, 'grad_norm': 8.087098121643066, 'learning_rate': 1.858895563327621e-05, 'epoch': 4.31}
 17%|█▋        | 3020/17525 [36:24<2:23:46,  1.68it/s] 17%|█▋        | 3021/17525 [36:25<2:22:56,  1.69it/s] 17%|█▋        | 3022/17525 [36:25<2:22:06,  1.70it/s] 17%|█▋        | 3023/17525 [36:26<2:21:25,  1.71it/s] 17%|█▋        | 3024/17525 [36:26<2:21:05,  1.71it/s] 17%|█▋        | 3025/17525 [36:27<2:20:53,  1.72it/s] 17%|█▋        | 3026/17525 [36:28<2:20:48,  1.72it/s] 17%|█▋        | 3027/17525 [36:28<2:20:54,  1.71it/s] 17%|█▋        | 3028/17525 [36:29<2:20:36,  1.72it/s] 17%|█▋        | 3029/17525 [36:29<2:20:24,  1.72it/s] 17%|█▋        | 3030/17525 [36:30<2:20:16,  1.72it/s]                                                      {'loss': 0.7103, 'grad_norm': 7.873466491699219, 'learning_rate': 1.8579750323198724e-05, 'epoch': 4.32}
 17%|█▋        | 3030/17525 [36:30<2:20:16,  1.72it/s] 17%|█▋        | 3031/17525 [36:30<2:20:23,  1.72it/s] 17%|█▋        | 3032/17525 [36:31<2:20:10,  1.72it/s] 17%|█▋        | 3033/17525 [36:32<2:20:25,  1.72it/s] 17%|█▋        | 3034/17525 [36:32<2:20:22,  1.72it/s] 17%|█▋        | 3035/17525 [36:33<2:30:56,  1.60it/s] 17%|█▋        | 3036/17525 [36:34<2:27:31,  1.64it/s] 17%|█▋        | 3037/17525 [36:34<2:25:20,  1.66it/s] 17%|█▋        | 3038/17525 [36:35<2:23:35,  1.68it/s] 17%|█▋        | 3039/17525 [36:36<2:46:00,  1.45it/s] 17%|█▋        | 3040/17525 [36:36<2:38:08,  1.53it/s]                                                      {'loss': 0.5669, 'grad_norm': 8.738883972167969, 'learning_rate': 1.857051737872068e-05, 'epoch': 4.34}
 17%|█▋        | 3040/17525 [36:36<2:38:08,  1.53it/s] 17%|█▋        | 3041/17525 [36:37<2:32:50,  1.58it/s] 17%|█▋        | 3042/17525 [36:37<2:29:01,  1.62it/s] 17%|█▋        | 3043/17525 [36:38<2:26:23,  1.65it/s] 17%|█▋        | 3044/17525 [36:38<2:24:18,  1.67it/s] 17%|█▋        | 3045/17525 [36:39<2:23:04,  1.69it/s] 17%|█▋        | 3046/17525 [36:40<2:21:59,  1.70it/s] 17%|█▋        | 3047/17525 [36:40<2:21:15,  1.71it/s] 17%|█▋        | 3048/17525 [36:41<2:20:51,  1.71it/s] 17%|█▋        | 3049/17525 [36:42<2:29:34,  1.61it/s] 17%|█▋        | 3050/17525 [36:42<2:26:47,  1.64it/s]                                                      {'loss': 0.7461, 'grad_norm': 6.321151256561279, 'learning_rate': 1.856125682958034e-05, 'epoch': 4.35}
 17%|█▋        | 3050/17525 [36:42<2:26:47,  1.64it/s] 17%|█▋        | 3051/17525 [36:43<2:25:12,  1.66it/s] 17%|█▋        | 3052/17525 [36:43<2:23:38,  1.68it/s] 17%|█▋        | 3053/17525 [36:44<2:22:40,  1.69it/s] 17%|█▋        | 3054/17525 [36:44<2:21:55,  1.70it/s] 17%|█▋        | 3055/17525 [36:45<2:21:31,  1.70it/s] 17%|█▋        | 3056/17525 [36:46<2:21:10,  1.71it/s] 17%|█▋        | 3057/17525 [36:46<2:20:35,  1.72it/s] 17%|█▋        | 3058/17525 [36:47<2:20:31,  1.72it/s] 17%|█▋        | 3059/17525 [36:48<3:18:06,  1.22it/s] 17%|█▋        | 3060/17525 [36:49<3:00:49,  1.33it/s]                                                      {'loss': 0.6594, 'grad_norm': 7.800105571746826, 'learning_rate': 1.8551968705604883e-05, 'epoch': 4.37}
 17%|█▋        | 3060/17525 [36:49<3:00:49,  1.33it/s] 17%|█▋        | 3061/17525 [36:49<2:48:34,  1.43it/s] 17%|█▋        | 3062/17525 [36:50<2:39:44,  1.51it/s] 17%|█▋        | 3063/17525 [36:50<2:33:58,  1.57it/s] 17%|█▋        | 3064/17525 [36:51<2:29:28,  1.61it/s] 17%|█▋        | 3065/17525 [36:52<2:26:34,  1.64it/s] 17%|█▋        | 3066/17525 [36:52<2:24:27,  1.67it/s] 18%|█▊        | 3067/17525 [36:53<2:24:27,  1.67it/s] 18%|█▊        | 3068/17525 [36:53<2:23:02,  1.68it/s] 18%|█▊        | 3069/17525 [36:54<2:22:09,  1.69it/s] 18%|█▊        | 3070/17525 [36:55<2:21:28,  1.70it/s]                                                      {'loss': 0.5926, 'grad_norm': 8.128488540649414, 'learning_rate': 1.8542653036710295e-05, 'epoch': 4.38}
 18%|█▊        | 3070/17525 [36:55<2:21:28,  1.70it/s] 18%|█▊        | 3071/17525 [36:55<2:20:54,  1.71it/s] 18%|█▊        | 3072/17525 [36:56<2:20:37,  1.71it/s] 18%|█▊        | 3073/17525 [36:56<2:20:33,  1.71it/s] 18%|█▊        | 3074/17525 [36:57<2:20:15,  1.72it/s] 18%|█▊        | 3075/17525 [36:57<2:20:02,  1.72it/s] 18%|█▊        | 3076/17525 [36:58<2:19:58,  1.72it/s] 18%|█▊        | 3077/17525 [36:59<2:20:41,  1.71it/s] 18%|█▊        | 3078/17525 [36:59<2:20:24,  1.71it/s] 18%|█▊        | 3079/17525 [37:00<2:20:06,  1.72it/s] 18%|█▊        | 3080/17525 [37:00<2:19:43,  1.72it/s]                                                      {'loss': 0.6773, 'grad_norm': 10.98373794555664, 'learning_rate': 1.8533309852901292e-05, 'epoch': 4.39}
 18%|█▊        | 3080/17525 [37:00<2:19:43,  1.72it/s] 18%|█▊        | 3081/17525 [37:01<2:19:52,  1.72it/s] 18%|█▊        | 3082/17525 [37:02<2:19:28,  1.73it/s] 18%|█▊        | 3083/17525 [37:02<2:19:21,  1.73it/s] 18%|█▊        | 3084/17525 [37:03<2:19:15,  1.73it/s] 18%|█▊        | 3085/17525 [37:03<2:19:16,  1.73it/s] 18%|█▊        | 3086/17525 [37:04<2:19:17,  1.73it/s] 18%|█▊        | 3087/17525 [37:04<2:19:14,  1.73it/s] 18%|█▊        | 3088/17525 [37:05<2:19:10,  1.73it/s] 18%|█▊        | 3089/17525 [37:06<2:19:22,  1.73it/s] 18%|█▊        | 3090/17525 [37:06<2:33:11,  1.57it/s]                                                      {'loss': 0.6639, 'grad_norm': 6.475991249084473, 'learning_rate': 1.8523939184271212e-05, 'epoch': 4.41}
 18%|█▊        | 3090/17525 [37:06<2:33:11,  1.57it/s] 18%|█▊        | 3091/17525 [37:07<2:29:00,  1.61it/s] 18%|█▊        | 3092/17525 [37:08<2:38:58,  1.51it/s] 18%|█▊        | 3093/17525 [37:08<2:33:19,  1.57it/s] 18%|█▊        | 3094/17525 [37:09<2:29:03,  1.61it/s] 18%|█▊        | 3095/17525 [37:09<2:26:06,  1.65it/s] 18%|█▊        | 3096/17525 [37:10<2:24:14,  1.67it/s] 18%|█▊        | 3097/17525 [37:11<2:22:49,  1.68it/s] 18%|█▊        | 3098/17525 [37:12<2:47:43,  1.43it/s] 18%|█▊        | 3099/17525 [37:12<2:39:11,  1.51it/s] 18%|█▊        | 3100/17525 [37:13<2:33:27,  1.57it/s]                                                      {'loss': 0.5749, 'grad_norm': 9.491329193115234, 'learning_rate': 1.8514541061001906e-05, 'epoch': 4.42}
 18%|█▊        | 3100/17525 [37:13<2:33:27,  1.57it/s][INFO|trainer.py:3512] 2024-06-25 02:40:34,565 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:40:34,566 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:40:34,566 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8759788870811462, 'eval_runtime': 4.6005, 'eval_samples_per_second': 96.293, 'eval_steps_per_second': 4.13, 'epoch': 4.42}
 18%|█▊        | 3100/17525 [37:17<2:33:27,  1.57it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 18%|█▊        | 3101/17525 [37:18<8:01:56,  2.00s/it] 18%|█▊        | 3102/17525 [37:18<6:18:55,  1.58s/it] 18%|█▊        | 3103/17525 [37:19<5:07:14,  1.28s/it] 18%|█▊        | 3104/17525 [37:20<4:16:55,  1.07s/it] 18%|█▊        | 3105/17525 [37:21<4:57:07,  1.24s/it] 18%|█▊        | 3106/17525 [37:22<4:10:07,  1.04s/it] 18%|█▊        | 3107/17525 [37:22<3:36:44,  1.11it/s] 18%|█▊        | 3108/17525 [37:23<3:13:24,  1.24it/s] 18%|█▊        | 3109/17525 [37:24<2:57:11,  1.36it/s] 18%|█▊        | 3110/17525 [37:24<2:45:53,  1.45it/s]                                                      {'loss': 0.5948, 'grad_norm': 4.4615559577941895, 'learning_rate': 1.8505115513363658e-05, 'epoch': 4.44}
 18%|█▊        | 3110/17525 [37:24<2:45:53,  1.45it/s] 18%|█▊        | 3111/17525 [37:25<2:38:00,  1.52it/s] 18%|█▊        | 3112/17525 [37:25<2:32:11,  1.58it/s] 18%|█▊        | 3113/17525 [37:26<2:28:21,  1.62it/s] 18%|█▊        | 3114/17525 [37:26<2:25:43,  1.65it/s] 18%|█▊        | 3115/17525 [37:27<2:23:41,  1.67it/s] 18%|█▊        | 3116/17525 [37:28<2:22:34,  1.68it/s] 18%|█▊        | 3117/17525 [37:28<2:21:32,  1.70it/s] 18%|█▊        | 3118/17525 [37:29<2:20:55,  1.70it/s] 18%|█▊        | 3119/17525 [37:29<2:20:24,  1.71it/s] 18%|█▊        | 3120/17525 [37:30<2:19:55,  1.72it/s]                                                      {'loss': 0.6305, 'grad_norm': 6.734975337982178, 'learning_rate': 1.8495662571715095e-05, 'epoch': 4.45}
 18%|█▊        | 3120/17525 [37:30<2:19:55,  1.72it/s] 18%|█▊        | 3121/17525 [37:31<2:19:50,  1.72it/s] 18%|█▊        | 3122/17525 [37:31<2:19:57,  1.72it/s] 18%|█▊        | 3123/17525 [37:32<2:19:43,  1.72it/s] 18%|█▊        | 3124/17525 [37:32<2:19:40,  1.72it/s] 18%|█▊        | 3125/17525 [37:33<2:50:24,  1.41it/s] 18%|█▊        | 3126/17525 [37:34<2:40:54,  1.49it/s] 18%|█▊        | 3127/17525 [37:34<2:34:16,  1.56it/s] 18%|█▊        | 3128/17525 [37:35<2:29:38,  1.60it/s] 18%|█▊        | 3129/17525 [37:36<2:51:47,  1.40it/s] 18%|█▊        | 3130/17525 [37:37<2:42:12,  1.48it/s]                                                      {'loss': 0.6878, 'grad_norm': 5.825077533721924, 'learning_rate': 1.848618226650306e-05, 'epoch': 4.47}
 18%|█▊        | 3130/17525 [37:37<2:42:12,  1.48it/s] 18%|█▊        | 3131/17525 [37:37<2:35:22,  1.54it/s] 18%|█▊        | 3132/17525 [37:38<2:30:29,  1.59it/s] 18%|█▊        | 3133/17525 [37:38<2:27:13,  1.63it/s] 18%|█▊        | 3134/17525 [37:39<2:24:57,  1.65it/s] 18%|█▊        | 3135/17525 [37:39<2:23:18,  1.67it/s] 18%|█▊        | 3136/17525 [37:40<2:21:57,  1.69it/s] 18%|█▊        | 3137/17525 [37:41<2:20:59,  1.70it/s] 18%|█▊        | 3138/17525 [37:41<2:21:44,  1.69it/s] 18%|█▊        | 3139/17525 [37:42<2:21:01,  1.70it/s] 18%|█▊        | 3140/17525 [37:42<2:20:16,  1.71it/s]                                                      {'loss': 0.6168, 'grad_norm': 7.20577335357666, 'learning_rate': 1.847667462826254e-05, 'epoch': 4.48}
 18%|█▊        | 3140/17525 [37:42<2:20:16,  1.71it/s] 18%|█▊        | 3141/17525 [37:43<2:20:20,  1.71it/s] 18%|█▊        | 3142/17525 [37:44<2:20:00,  1.71it/s] 18%|█▊        | 3143/17525 [37:44<2:19:41,  1.72it/s] 18%|█▊        | 3144/17525 [37:45<2:19:38,  1.72it/s] 18%|█▊        | 3145/17525 [37:45<2:19:25,  1.72it/s] 18%|█▊        | 3146/17525 [37:46<2:19:12,  1.72it/s] 18%|█▊        | 3147/17525 [37:46<2:19:14,  1.72it/s] 18%|█▊        | 3148/17525 [37:47<2:19:03,  1.72it/s] 18%|█▊        | 3149/17525 [37:48<2:18:53,  1.73it/s] 18%|█▊        | 3150/17525 [37:48<2:19:00,  1.72it/s]                                                      {'loss': 0.7158, 'grad_norm': 11.246978759765625, 'learning_rate': 1.8467139687616557e-05, 'epoch': 4.49}
 18%|█▊        | 3150/17525 [37:48<2:19:00,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 02:41:10,044 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79a5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 21acf8ff-ca4c-4a47-8620-04546d161f43)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:41:20,156 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:41:20,158 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 18%|█▊        | 3151/17525 [37:59<14:39:48,  3.67s/it] 18%|█▊        | 3152/17525 [38:00<10:57:15,  2.74s/it] 18%|█▊        | 3153/17525 [38:00<8:21:33,  2.09s/it]  18%|█▊        | 3154/17525 [38:01<6:32:47,  1.64s/it] 18%|█▊        | 3155/17525 [38:01<5:16:24,  1.32s/it] 18%|█▊        | 3156/17525 [38:02<4:23:02,  1.10s/it] 18%|█▊        | 3157/17525 [38:03<3:45:34,  1.06it/s] 18%|█▊        | 3158/17525 [38:03<3:19:13,  1.20it/s] 18%|█▊        | 3159/17525 [38:04<3:01:11,  1.32it/s] 18%|█▊        | 3160/17525 [38:04<2:48:31,  1.42it/s]                                                      {'loss': 0.6335, 'grad_norm': 8.688811302185059, 'learning_rate': 1.8457577475276073e-05, 'epoch': 4.51}
 18%|█▊        | 3160/17525 [38:04<2:48:31,  1.42it/s] 18%|█▊        | 3161/17525 [38:05<2:39:30,  1.50it/s] 18%|█▊        | 3162/17525 [38:05<2:33:23,  1.56it/s] 18%|█▊        | 3163/17525 [38:06<2:28:55,  1.61it/s] 18%|█▊        | 3164/17525 [38:07<2:25:57,  1.64it/s] 18%|█▊        | 3165/17525 [38:07<2:23:35,  1.67it/s] 18%|█▊        | 3166/17525 [38:08<2:22:16,  1.68it/s] 18%|█▊        | 3167/17525 [38:08<2:21:14,  1.69it/s] 18%|█▊        | 3168/17525 [38:09<2:20:19,  1.71it/s] 18%|█▊        | 3169/17525 [38:09<2:19:56,  1.71it/s] 18%|█▊        | 3170/17525 [38:10<2:33:49,  1.56it/s]                                                      {'loss': 0.6667, 'grad_norm': 8.583375930786133, 'learning_rate': 1.8447988022039886e-05, 'epoch': 4.52}
 18%|█▊        | 3170/17525 [38:10<2:33:49,  1.56it/s] 18%|█▊        | 3171/17525 [38:11<2:29:19,  1.60it/s] 18%|█▊        | 3172/17525 [38:11<2:26:16,  1.64it/s] 18%|█▊        | 3173/17525 [38:12<2:25:26,  1.64it/s] 18%|█▊        | 3174/17525 [38:13<2:23:35,  1.67it/s] 18%|█▊        | 3175/17525 [38:13<2:22:18,  1.68it/s] 18%|█▊        | 3176/17525 [38:14<2:21:14,  1.69it/s] 18%|█▊        | 3177/17525 [38:14<2:20:07,  1.71it/s] 18%|█▊        | 3178/17525 [38:15<2:19:42,  1.71it/s] 18%|█▊        | 3179/17525 [38:15<2:19:10,  1.72it/s] 18%|█▊        | 3180/17525 [38:16<2:19:04,  1.72it/s]                                                      {'loss': 0.6835, 'grad_norm': 7.633630752563477, 'learning_rate': 1.8438371358794537e-05, 'epoch': 4.54}
 18%|█▊        | 3180/17525 [38:16<2:19:04,  1.72it/s] 18%|█▊        | 3181/17525 [38:17<2:18:43,  1.72it/s] 18%|█▊        | 3182/17525 [38:17<2:18:48,  1.72it/s] 18%|█▊        | 3183/17525 [38:18<2:18:40,  1.72it/s] 18%|█▊        | 3184/17525 [38:18<2:18:40,  1.72it/s] 18%|█▊        | 3185/17525 [38:19<2:45:20,  1.45it/s] 18%|█▊        | 3186/17525 [38:20<2:37:25,  1.52it/s] 18%|█▊        | 3187/17525 [38:20<2:31:57,  1.57it/s] 18%|█▊        | 3188/17525 [38:21<2:28:01,  1.61it/s] 18%|█▊        | 3189/17525 [38:22<2:25:23,  1.64it/s] 18%|█▊        | 3190/17525 [38:22<2:23:31,  1.66it/s]                                                      {'loss': 0.6229, 'grad_norm': 6.84039831161499, 'learning_rate': 1.8428727516514202e-05, 'epoch': 4.55}
 18%|█▊        | 3190/17525 [38:22<2:23:31,  1.66it/s] 18%|█▊        | 3191/17525 [38:23<2:22:04,  1.68it/s] 18%|█▊        | 3192/17525 [38:23<2:21:06,  1.69it/s] 18%|█▊        | 3193/17525 [38:24<2:20:29,  1.70it/s] 18%|█▊        | 3194/17525 [38:25<2:19:53,  1.71it/s] 18%|█▊        | 3195/17525 [38:25<2:19:38,  1.71it/s] 18%|█▊        | 3196/17525 [38:26<2:19:30,  1.71it/s] 18%|█▊        | 3197/17525 [38:26<2:19:20,  1.71it/s] 18%|█▊        | 3198/17525 [38:27<2:18:56,  1.72it/s] 18%|█▊        | 3199/17525 [38:27<2:18:46,  1.72it/s] 18%|█▊        | 3200/17525 [38:28<2:18:46,  1.72it/s]                                                      {'loss': 0.6587, 'grad_norm': 4.467879295349121, 'learning_rate': 1.8419056526260602e-05, 'epoch': 4.56}
 18%|█▊        | 3200/17525 [38:28<2:18:46,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:41:49,945 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:41:49,945 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:41:49,945 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8732197880744934, 'eval_runtime': 4.597, 'eval_samples_per_second': 96.367, 'eval_steps_per_second': 4.133, 'epoch': 4.56}
 18%|█▊        | 3200/17525 [38:33<2:18:46,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 18%|█▊        | 3201/17525 [38:33<7:48:39,  1.96s/it] 18%|█▊        | 3202/17525 [38:34<6:09:31,  1.55s/it] 18%|█▊        | 3203/17525 [38:34<5:00:16,  1.26s/it] 18%|█▊        | 3204/17525 [38:35<4:11:36,  1.05s/it] 18%|█▊        | 3205/17525 [38:36<3:37:40,  1.10it/s] 18%|█▊        | 3206/17525 [38:36<3:13:43,  1.23it/s] 18%|█▊        | 3207/17525 [38:37<2:57:15,  1.35it/s] 18%|█▊        | 3208/17525 [38:37<2:46:00,  1.44it/s] 18%|█▊        | 3209/17525 [38:38<2:37:51,  1.51it/s] 18%|█▊        | 3210/17525 [38:38<2:33:51,  1.55it/s]                                                      {'loss': 0.6764, 'grad_norm': 5.623814582824707, 'learning_rate': 1.84093584191829e-05, 'epoch': 4.58}
 18%|█▊        | 3210/17525 [38:38<2:33:51,  1.55it/s] 18%|█▊        | 3211/17525 [38:39<2:29:27,  1.60it/s] 18%|█▊        | 3212/17525 [38:40<2:26:17,  1.63it/s] 18%|█▊        | 3213/17525 [38:40<2:26:28,  1.63it/s] 18%|█▊        | 3214/17525 [38:41<2:24:09,  1.65it/s] 18%|█▊        | 3215/17525 [38:41<2:22:23,  1.67it/s] 18%|█▊        | 3216/17525 [38:42<2:21:05,  1.69it/s] 18%|█▊        | 3217/17525 [38:43<2:21:54,  1.68it/s] 18%|█▊        | 3218/17525 [38:43<2:20:48,  1.69it/s] 18%|█▊        | 3219/17525 [38:44<2:20:15,  1.70it/s] 18%|█▊        | 3220/17525 [38:44<2:19:34,  1.71it/s]                                                      {'loss': 0.6371, 'grad_norm': 6.891300201416016, 'learning_rate': 1.839963322651759e-05, 'epoch': 4.59}
 18%|█▊        | 3220/17525 [38:44<2:19:34,  1.71it/s] 18%|█▊        | 3221/17525 [38:45<2:19:21,  1.71it/s] 18%|█▊        | 3222/17525 [38:46<2:19:57,  1.70it/s] 18%|█▊        | 3223/17525 [38:46<2:19:26,  1.71it/s] 18%|█▊        | 3224/17525 [38:47<2:19:10,  1.71it/s] 18%|█▊        | 3225/17525 [38:47<2:18:46,  1.72it/s] 18%|█▊        | 3226/17525 [38:48<2:18:47,  1.72it/s] 18%|█▊        | 3227/17525 [38:48<2:18:37,  1.72it/s] 18%|█▊        | 3228/17525 [38:49<2:18:33,  1.72it/s] 18%|█▊        | 3229/17525 [38:50<2:18:27,  1.72it/s] 18%|█▊        | 3230/17525 [38:50<2:18:43,  1.72it/s]                                                      {'loss': 0.6079, 'grad_norm': 7.054752826690674, 'learning_rate': 1.8389880979588416e-05, 'epoch': 4.61}
 18%|█▊        | 3230/17525 [38:50<2:18:43,  1.72it/s] 18%|█▊        | 3231/17525 [38:51<2:18:59,  1.71it/s] 18%|█▊        | 3232/17525 [38:51<2:18:51,  1.72it/s] 18%|█▊        | 3233/17525 [38:52<2:18:43,  1.72it/s] 18%|█▊        | 3234/17525 [38:53<2:18:44,  1.72it/s] 18%|█▊        | 3235/17525 [38:53<2:18:43,  1.72it/s] 18%|█▊        | 3236/17525 [38:54<2:49:20,  1.41it/s] 18%|█▊        | 3237/17525 [38:55<2:40:11,  1.49it/s] 18%|█▊        | 3238/17525 [38:55<2:33:38,  1.55it/s] 18%|█▊        | 3239/17525 [38:56<2:29:28,  1.59it/s] 18%|█▊        | 3240/17525 [38:56<2:26:14,  1.63it/s]                                                      {'loss': 0.7002, 'grad_norm': 6.681221961975098, 'learning_rate': 1.838010170980626e-05, 'epoch': 4.62}
 18%|█▊        | 3240/17525 [38:56<2:26:14,  1.63it/s] 18%|█▊        | 3241/17525 [38:57<2:24:11,  1.65it/s] 18%|█▊        | 3242/17525 [38:58<2:22:37,  1.67it/s] 19%|█▊        | 3243/17525 [38:58<2:21:17,  1.68it/s] 19%|█▊        | 3244/17525 [38:59<2:20:33,  1.69it/s] 19%|█▊        | 3245/17525 [38:59<2:21:17,  1.68it/s] 19%|█▊        | 3246/17525 [39:00<2:20:21,  1.70it/s] 19%|█▊        | 3247/17525 [39:01<2:19:42,  1.70it/s] 19%|█▊        | 3248/17525 [39:01<2:19:01,  1.71it/s] 19%|█▊        | 3249/17525 [39:02<2:18:59,  1.71it/s] 19%|█▊        | 3250/17525 [39:02<2:18:42,  1.72it/s]                                                      {'loss': 0.6188, 'grad_norm': 5.188226699829102, 'learning_rate': 1.8370295448669035e-05, 'epoch': 4.64}
 19%|█▊        | 3250/17525 [39:02<2:18:42,  1.72it/s] 19%|█▊        | 3251/17525 [39:03<2:18:50,  1.71it/s] 19%|█▊        | 3252/17525 [39:03<2:18:37,  1.72it/s] 19%|█▊        | 3253/17525 [39:04<2:18:35,  1.72it/s] 19%|█▊        | 3254/17525 [39:05<2:18:31,  1.72it/s] 19%|█▊        | 3255/17525 [39:05<2:18:54,  1.71it/s] 19%|█▊        | 3256/17525 [39:06<2:18:41,  1.71it/s] 19%|█▊        | 3257/17525 [39:06<2:20:15,  1.70it/s] 19%|█▊        | 3258/17525 [39:07<2:19:46,  1.70it/s] 19%|█▊        | 3259/17525 [39:08<2:19:18,  1.71it/s] 19%|█▊        | 3260/17525 [39:08<2:19:00,  1.71it/s]                                                      {'loss': 0.6612, 'grad_norm': 4.677147388458252, 'learning_rate': 1.836046222776159e-05, 'epoch': 4.65}
 19%|█▊        | 3260/17525 [39:08<2:19:00,  1.71it/s] 19%|█▊        | 3261/17525 [39:09<2:18:59,  1.71it/s] 19%|█▊        | 3262/17525 [39:09<2:18:31,  1.72it/s] 19%|█▊        | 3263/17525 [39:10<2:18:24,  1.72it/s] 19%|█▊        | 3264/17525 [39:10<2:18:22,  1.72it/s] 19%|█▊        | 3265/17525 [39:11<2:18:19,  1.72it/s] 19%|█▊        | 3266/17525 [39:12<2:17:57,  1.72it/s] 19%|█▊        | 3267/17525 [39:12<2:18:01,  1.72it/s] 19%|█▊        | 3268/17525 [39:13<2:18:15,  1.72it/s] 19%|█▊        | 3269/17525 [39:13<2:18:18,  1.72it/s] 19%|█▊        | 3270/17525 [39:14<2:18:26,  1.72it/s]                                                      {'loss': 0.7096, 'grad_norm': 5.2844038009643555, 'learning_rate': 1.8350602078755618e-05, 'epoch': 4.66}
 19%|█▊        | 3270/17525 [39:14<2:18:26,  1.72it/s] 19%|█▊        | 3271/17525 [39:15<2:18:37,  1.71it/s] 19%|█▊        | 3272/17525 [39:15<2:18:34,  1.71it/s] 19%|█▊        | 3273/17525 [39:16<2:19:52,  1.70it/s] 19%|█▊        | 3274/17525 [39:16<2:19:50,  1.70it/s] 19%|█▊        | 3275/17525 [39:17<2:19:12,  1.71it/s] 19%|█▊        | 3276/17525 [39:17<2:18:37,  1.71it/s] 19%|█▊        | 3277/17525 [39:18<2:18:17,  1.72it/s] 19%|█▊        | 3278/17525 [39:19<2:18:02,  1.72it/s] 19%|█▊        | 3279/17525 [39:19<2:17:57,  1.72it/s] 19%|█▊        | 3280/17525 [39:20<2:17:50,  1.72it/s]                                                      {'loss': 0.7245, 'grad_norm': 6.7536940574646, 'learning_rate': 1.8340715033409537e-05, 'epoch': 4.68}
 19%|█▊        | 3280/17525 [39:20<2:17:50,  1.72it/s] 19%|█▊        | 3281/17525 [39:20<2:18:05,  1.72it/s] 19%|█▊        | 3282/17525 [39:21<2:17:55,  1.72it/s] 19%|█▊        | 3283/17525 [39:22<2:19:24,  1.70it/s] 19%|█▊        | 3284/17525 [39:22<2:18:55,  1.71it/s] 19%|█▊        | 3285/17525 [39:23<2:21:02,  1.68it/s] 19%|█▉        | 3286/17525 [39:23<2:20:10,  1.69it/s] 19%|█▉        | 3287/17525 [39:24<2:19:20,  1.70it/s] 19%|█▉        | 3288/17525 [39:25<2:20:24,  1.69it/s] 19%|█▉        | 3289/17525 [39:25<2:21:18,  1.68it/s] 19%|█▉        | 3290/17525 [39:26<2:20:13,  1.69it/s]                                                      {'loss': 0.6262, 'grad_norm': 7.543918132781982, 'learning_rate': 1.8330801123568392e-05, 'epoch': 4.69}
 19%|█▉        | 3290/17525 [39:26<2:20:13,  1.69it/s] 19%|█▉        | 3291/17525 [39:26<2:19:33,  1.70it/s] 19%|█▉        | 3292/17525 [39:27<2:19:01,  1.71it/s] 19%|█▉        | 3293/17525 [39:27<2:18:50,  1.71it/s] 19%|█▉        | 3294/17525 [39:28<2:18:32,  1.71it/s] 19%|█▉        | 3295/17525 [39:29<2:51:07,  1.39it/s] 19%|█▉        | 3296/17525 [39:30<2:41:01,  1.47it/s] 19%|█▉        | 3297/17525 [39:30<2:33:54,  1.54it/s] 19%|█▉        | 3298/17525 [39:31<2:29:02,  1.59it/s] 19%|█▉        | 3299/17525 [39:31<2:25:33,  1.63it/s] 19%|█▉        | 3300/17525 [39:32<2:23:14,  1.66it/s]                                                      {'loss': 0.6531, 'grad_norm': 10.779362678527832, 'learning_rate': 1.832086038116377e-05, 'epoch': 4.71}
 19%|█▉        | 3300/17525 [39:32<2:23:14,  1.66it/s][INFO|trainer.py:3512] 2024-06-25 02:42:53,859 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:42:53,859 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:42:53,859 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.76it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8753121495246887, 'eval_runtime': 4.6046, 'eval_samples_per_second': 96.208, 'eval_steps_per_second': 4.126, 'epoch': 4.71}
 19%|█▉        | 3300/17525 [39:37<2:23:14,  1.66it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:42:58,467 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a795d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e6a8cec3-acbc-4ca5-9c5c-2970f6654e13)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:43:08,529 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:43:08,531 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 19%|█▉        | 3301/17525 [39:47<19:54:06,  5.04s/it] 19%|█▉        | 3302/17525 [39:48<14:37:13,  3.70s/it] 19%|█▉        | 3303/17525 [39:49<10:55:12,  2.76s/it] 19%|█▉        | 3304/17525 [39:49<8:19:48,  2.11s/it]  19%|█▉        | 3305/17525 [39:50<6:30:58,  1.65s/it] 19%|█▉        | 3306/17525 [39:50<5:14:52,  1.33s/it] 19%|█▉        | 3307/17525 [39:51<4:21:33,  1.10s/it] 19%|█▉        | 3308/17525 [39:51<3:45:42,  1.05it/s] 19%|█▉        | 3309/17525 [39:52<3:19:28,  1.19it/s] 19%|█▉        | 3310/17525 [39:53<3:00:59,  1.31it/s]                                                      {'loss': 0.6093, 'grad_norm': 9.356241226196289, 'learning_rate': 1.8310892838213656e-05, 'epoch': 4.72}
 19%|█▉        | 3310/17525 [39:53<3:00:59,  1.31it/s] 19%|█▉        | 3311/17525 [39:53<2:47:53,  1.41it/s] 19%|█▉        | 3312/17525 [39:54<2:38:49,  1.49it/s] 19%|█▉        | 3313/17525 [39:54<2:33:38,  1.54it/s] 19%|█▉        | 3314/17525 [39:55<2:28:28,  1.60it/s] 19%|█▉        | 3315/17525 [39:56<2:37:06,  1.51it/s] 19%|█▉        | 3316/17525 [39:56<2:31:00,  1.57it/s] 19%|█▉        | 3317/17525 [39:57<2:26:56,  1.61it/s] 19%|█▉        | 3318/17525 [39:57<2:24:16,  1.64it/s] 19%|█▉        | 3319/17525 [39:58<2:22:29,  1.66it/s] 19%|█▉        | 3320/17525 [39:59<2:20:47,  1.68it/s]                                                      {'loss': 0.5583, 'grad_norm': 7.35589075088501, 'learning_rate': 1.8300898526822385e-05, 'epoch': 4.74}
 19%|█▉        | 3320/17525 [39:59<2:20:47,  1.68it/s] 19%|█▉        | 3321/17525 [39:59<2:19:54,  1.69it/s] 19%|█▉        | 3322/17525 [40:00<2:51:48,  1.38it/s] 19%|█▉        | 3323/17525 [40:01<2:41:36,  1.46it/s] 19%|█▉        | 3324/17525 [40:01<2:34:23,  1.53it/s] 19%|█▉        | 3325/17525 [40:02<2:29:26,  1.58it/s] 19%|█▉        | 3326/17525 [40:03<2:25:51,  1.62it/s] 19%|█▉        | 3327/17525 [40:03<2:23:26,  1.65it/s] 19%|█▉        | 3328/17525 [40:04<2:21:38,  1.67it/s] 19%|█▉        | 3329/17525 [40:04<2:20:19,  1.69it/s] 19%|█▉        | 3330/17525 [40:05<2:19:14,  1.70it/s]                                                      {'loss': 0.7526, 'grad_norm': 6.6244306564331055, 'learning_rate': 1.8290877479180496e-05, 'epoch': 4.75}
 19%|█▉        | 3330/17525 [40:05<2:19:14,  1.70it/s] 19%|█▉        | 3331/17525 [40:05<2:18:50,  1.70it/s] 19%|█▉        | 3332/17525 [40:06<2:18:29,  1.71it/s] 19%|█▉        | 3333/17525 [40:07<2:18:16,  1.71it/s] 19%|█▉        | 3334/17525 [40:07<2:18:09,  1.71it/s] 19%|█▉        | 3335/17525 [40:08<2:17:46,  1.72it/s] 19%|█▉        | 3336/17525 [40:08<2:17:27,  1.72it/s] 19%|█▉        | 3337/17525 [40:09<2:17:16,  1.72it/s] 19%|█▉        | 3338/17525 [40:09<2:17:30,  1.72it/s] 19%|█▉        | 3339/17525 [40:10<2:17:24,  1.72it/s] 19%|█▉        | 3340/17525 [40:11<2:17:18,  1.72it/s]                                                      {'loss': 0.6832, 'grad_norm': 13.578641891479492, 'learning_rate': 1.828082972756464e-05, 'epoch': 4.76}
 19%|█▉        | 3340/17525 [40:11<2:17:18,  1.72it/s] 19%|█▉        | 3341/17525 [40:11<2:17:18,  1.72it/s] 19%|█▉        | 3342/17525 [40:12<2:17:16,  1.72it/s] 19%|█▉        | 3343/17525 [40:12<2:17:08,  1.72it/s] 19%|█▉        | 3344/17525 [40:13<2:17:05,  1.72it/s] 19%|█▉        | 3345/17525 [40:14<2:17:11,  1.72it/s] 19%|█▉        | 3346/17525 [40:14<2:17:13,  1.72it/s] 19%|█▉        | 3347/17525 [40:15<2:17:02,  1.72it/s] 19%|█▉        | 3348/17525 [40:15<2:17:05,  1.72it/s] 19%|█▉        | 3349/17525 [40:16<2:17:15,  1.72it/s] 19%|█▉        | 3350/17525 [40:16<2:19:02,  1.70it/s]                                                      {'loss': 0.6456, 'grad_norm': 13.203399658203125, 'learning_rate': 1.8270755304337493e-05, 'epoch': 4.78}
 19%|█▉        | 3350/17525 [40:16<2:19:02,  1.70it/s] 19%|█▉        | 3351/17525 [40:17<2:18:47,  1.70it/s] 19%|█▉        | 3352/17525 [40:18<2:18:10,  1.71it/s] 19%|█▉        | 3353/17525 [40:18<2:29:04,  1.58it/s] 19%|█▉        | 3354/17525 [40:19<2:25:23,  1.62it/s] 19%|█▉        | 3355/17525 [40:20<2:23:02,  1.65it/s] 19%|█▉        | 3356/17525 [40:20<2:21:07,  1.67it/s] 19%|█▉        | 3357/17525 [40:21<2:19:58,  1.69it/s] 19%|█▉        | 3358/17525 [40:21<2:19:12,  1.70it/s] 19%|█▉        | 3359/17525 [40:22<2:18:56,  1.70it/s] 19%|█▉        | 3360/17525 [40:22<2:18:20,  1.71it/s]                                                      {'loss': 0.6717, 'grad_norm': 5.652001857757568, 'learning_rate': 1.8260654241947616e-05, 'epoch': 4.79}
 19%|█▉        | 3360/17525 [40:22<2:18:20,  1.71it/s] 19%|█▉        | 3361/17525 [40:23<2:18:09,  1.71it/s] 19%|█▉        | 3362/17525 [40:24<2:17:43,  1.71it/s] 19%|█▉        | 3363/17525 [40:24<2:17:20,  1.72it/s] 19%|█▉        | 3364/17525 [40:25<2:17:22,  1.72it/s] 19%|█▉        | 3365/17525 [40:25<2:16:54,  1.72it/s] 19%|█▉        | 3366/17525 [40:26<2:16:54,  1.72it/s] 19%|█▉        | 3367/17525 [40:27<2:16:45,  1.73it/s] 19%|█▉        | 3368/17525 [40:27<2:16:40,  1.73it/s] 19%|█▉        | 3369/17525 [40:28<2:16:58,  1.72it/s] 19%|█▉        | 3370/17525 [40:28<2:16:46,  1.72it/s]                                                      {'loss': 0.7369, 'grad_norm': nan, 'learning_rate': 1.8251540536200484e-05, 'epoch': 4.81}
 19%|█▉        | 3370/17525 [40:28<2:16:46,  1.72it/s] 19%|█▉        | 3371/17525 [40:29<2:17:00,  1.72it/s] 19%|█▉        | 3372/17525 [40:29<2:16:51,  1.72it/s] 19%|█▉        | 3373/17525 [40:30<2:17:09,  1.72it/s] 19%|█▉        | 3374/17525 [40:31<2:42:16,  1.45it/s] 19%|█▉        | 3375/17525 [40:32<2:34:42,  1.52it/s] 19%|█▉        | 3376/17525 [40:32<2:29:26,  1.58it/s] 19%|█▉        | 3377/17525 [40:33<2:25:41,  1.62it/s] 19%|█▉        | 3378/17525 [40:33<2:22:57,  1.65it/s] 19%|█▉        | 3379/17525 [40:34<2:20:59,  1.67it/s] 19%|█▉        | 3380/17525 [40:34<2:19:39,  1.69it/s]                                                      {'loss': 0.6836, 'grad_norm': 7.614043712615967, 'learning_rate': 1.8241388949104458e-05, 'epoch': 4.82}
 19%|█▉        | 3380/17525 [40:34<2:19:39,  1.69it/s] 19%|█▉        | 3381/17525 [40:35<2:19:06,  1.69it/s] 19%|█▉        | 3382/17525 [40:36<2:18:44,  1.70it/s] 19%|█▉        | 3383/17525 [40:36<2:18:20,  1.70it/s] 19%|█▉        | 3384/17525 [40:37<2:17:51,  1.71it/s] 19%|█▉        | 3385/17525 [40:37<2:17:22,  1.72it/s] 19%|█▉        | 3386/17525 [40:38<2:17:13,  1.72it/s] 19%|█▉        | 3387/17525 [40:38<2:16:59,  1.72it/s] 19%|█▉        | 3388/17525 [40:39<2:17:00,  1.72it/s] 19%|█▉        | 3389/17525 [40:40<2:16:47,  1.72it/s] 19%|█▉        | 3390/17525 [40:40<2:16:50,  1.72it/s]                                                      {'loss': 0.6624, 'grad_norm': 9.006425857543945, 'learning_rate': 1.82312108174314e-05, 'epoch': 4.84}
 19%|█▉        | 3390/17525 [40:40<2:16:50,  1.72it/s] 19%|█▉        | 3391/17525 [40:41<2:16:55,  1.72it/s] 19%|█▉        | 3392/17525 [40:41<2:17:15,  1.72it/s] 19%|█▉        | 3393/17525 [40:42<2:17:10,  1.72it/s] 19%|█▉        | 3394/17525 [40:43<2:17:02,  1.72it/s] 19%|█▉        | 3395/17525 [40:43<2:17:05,  1.72it/s] 19%|█▉        | 3396/17525 [40:44<2:17:08,  1.72it/s] 19%|█▉        | 3397/17525 [40:44<2:17:00,  1.72it/s] 19%|█▉        | 3398/17525 [40:45<2:16:47,  1.72it/s] 19%|█▉        | 3399/17525 [40:45<2:16:40,  1.72it/s] 19%|█▉        | 3400/17525 [40:46<2:16:35,  1.72it/s]                                                      {'loss': 0.5803, 'grad_norm': 8.28240966796875, 'learning_rate': 1.822100617396391e-05, 'epoch': 4.85}
 19%|█▉        | 3400/17525 [40:46<2:16:35,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 02:44:07,947 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:44:07,947 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:44:07,947 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8765841126441956, 'eval_runtime': 4.6051, 'eval_samples_per_second': 96.197, 'eval_steps_per_second': 4.126, 'epoch': 4.85}
 19%|█▉        | 3400/17525 [40:51<2:16:35,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 19%|█▉        | 3401/17525 [40:51<7:42:37,  1.97s/it] 19%|█▉        | 3402/17525 [40:52<6:04:54,  1.55s/it] 19%|█▉        | 3403/17525 [40:52<4:56:08,  1.26s/it] 19%|█▉        | 3404/17525 [40:53<4:08:44,  1.06s/it] 19%|█▉        | 3405/17525 [40:54<3:35:23,  1.09it/s] 19%|█▉        | 3406/17525 [40:54<3:11:40,  1.23it/s] 19%|█▉        | 3407/17525 [40:55<2:55:06,  1.34it/s] 19%|█▉        | 3408/17525 [40:55<2:43:39,  1.44it/s] 19%|█▉        | 3409/17525 [40:56<2:35:43,  1.51it/s] 19%|█▉        | 3410/17525 [40:56<2:29:45,  1.57it/s]                                                      {'loss': 0.7619, 'grad_norm': 12.223806381225586, 'learning_rate': 1.8210775051569992e-05, 'epoch': 4.86}
 19%|█▉        | 3410/17525 [40:56<2:29:45,  1.57it/s] 19%|█▉        | 3411/17525 [40:57<2:28:25,  1.58it/s] 19%|█▉        | 3412/17525 [40:58<2:25:17,  1.62it/s] 19%|█▉        | 3413/17525 [40:58<2:22:36,  1.65it/s] 19%|█▉        | 3414/17525 [40:59<2:20:55,  1.67it/s] 19%|█▉        | 3415/17525 [40:59<2:19:31,  1.69it/s] 19%|█▉        | 3416/17525 [41:00<2:18:47,  1.69it/s] 19%|█▉        | 3417/17525 [41:01<2:17:54,  1.70it/s] 20%|█▉        | 3418/17525 [41:01<2:17:34,  1.71it/s] 20%|█▉        | 3419/17525 [41:02<2:17:24,  1.71it/s] 20%|█▉        | 3420/17525 [41:02<2:17:09,  1.71it/s]                                                      {'loss': 0.5997, 'grad_norm': 4.357927322387695, 'learning_rate': 1.8200517483202924e-05, 'epoch': 4.88}
 20%|█▉        | 3420/17525 [41:02<2:17:09,  1.71it/s] 20%|█▉        | 3421/17525 [41:03<2:17:14,  1.71it/s] 20%|█▉        | 3422/17525 [41:04<2:17:07,  1.71it/s] 20%|█▉        | 3423/17525 [41:04<2:17:00,  1.72it/s] 20%|█▉        | 3424/17525 [41:05<2:16:51,  1.72it/s] 20%|█▉        | 3425/17525 [41:05<2:18:08,  1.70it/s] 20%|█▉        | 3426/17525 [41:06<2:17:36,  1.71it/s] 20%|█▉        | 3427/17525 [41:06<2:17:07,  1.71it/s] 20%|█▉        | 3428/17525 [41:07<2:16:56,  1.72it/s] 20%|█▉        | 3429/17525 [41:08<2:16:43,  1.72it/s] 20%|█▉        | 3430/17525 [41:08<2:16:40,  1.72it/s]                                                      {'loss': 0.611, 'grad_norm': 11.498431205749512, 'learning_rate': 1.8190233501901168e-05, 'epoch': 4.89}
 20%|█▉        | 3430/17525 [41:08<2:16:40,  1.72it/s] 20%|█▉        | 3431/17525 [41:10<3:12:48,  1.22it/s] 20%|█▉        | 3432/17525 [41:10<2:55:49,  1.34it/s] 20%|█▉        | 3433/17525 [41:11<2:43:51,  1.43it/s] 20%|█▉        | 3434/17525 [41:11<2:35:20,  1.51it/s] 20%|█▉        | 3435/17525 [41:12<2:29:36,  1.57it/s] 20%|█▉        | 3436/17525 [41:13<2:51:10,  1.37it/s] 20%|█▉        | 3437/17525 [41:13<2:40:43,  1.46it/s] 20%|█▉        | 3438/17525 [41:14<2:33:23,  1.53it/s] 20%|█▉        | 3439/17525 [41:15<2:28:45,  1.58it/s] 20%|█▉        | 3440/17525 [41:15<2:25:03,  1.62it/s]                                                      {'loss': 0.6098, 'grad_norm': 4.821178436279297, 'learning_rate': 1.817992314078826e-05, 'epoch': 4.91}
 20%|█▉        | 3440/17525 [41:15<2:25:03,  1.62it/s] 20%|█▉        | 3441/17525 [41:16<2:22:39,  1.65it/s] 20%|█▉        | 3442/17525 [41:16<2:20:33,  1.67it/s] 20%|█▉        | 3443/17525 [41:17<2:20:55,  1.67it/s] 20%|█▉        | 3444/17525 [41:18<2:21:44,  1.66it/s] 20%|█▉        | 3445/17525 [41:18<2:20:05,  1.68it/s] 20%|█▉        | 3446/17525 [41:19<2:18:47,  1.69it/s] 20%|█▉        | 3447/17525 [41:19<2:17:45,  1.70it/s] 20%|█▉        | 3448/17525 [41:20<2:42:54,  1.44it/s] 20%|█▉        | 3449/17525 [41:21<2:34:53,  1.51it/s] 20%|█▉        | 3450/17525 [41:22<2:52:54,  1.36it/s]                                                      {'loss': 0.6956, 'grad_norm': 7.613898277282715, 'learning_rate': 1.81695864330727e-05, 'epoch': 4.92}
 20%|█▉        | 3450/17525 [41:22<2:52:54,  1.36it/s][INFO|trainer.py:3203] 2024-06-25 02:44:43,586 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79cd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4f03ae89-34e6-4b86-847d-788c73e5a55d)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:44:53,646 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:44:53,648 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 20%|█▉        | 3451/17525 [41:32<14:39:24,  3.75s/it] 20%|█▉        | 3452/17525 [41:33<10:56:21,  2.80s/it] 20%|█▉        | 3453/17525 [41:34<8:20:03,  2.13s/it]  20%|█▉        | 3454/17525 [41:34<6:30:49,  1.67s/it] 20%|█▉        | 3455/17525 [41:35<5:14:19,  1.34s/it] 20%|█▉        | 3456/17525 [41:35<4:20:58,  1.11s/it] 20%|█▉        | 3457/17525 [41:36<3:43:25,  1.05it/s] 20%|█▉        | 3458/17525 [41:37<3:17:22,  1.19it/s] 20%|█▉        | 3459/17525 [41:37<2:58:37,  1.31it/s] 20%|█▉        | 3460/17525 [41:38<2:45:43,  1.41it/s]                                                      {'loss': 0.7185, 'grad_norm': 6.3297200202941895, 'learning_rate': 1.815922341204785e-05, 'epoch': 4.94}
 20%|█▉        | 3460/17525 [41:38<2:45:43,  1.41it/s] 20%|█▉        | 3461/17525 [41:38<2:37:00,  1.49it/s] 20%|█▉        | 3462/17525 [41:39<2:30:34,  1.56it/s] 20%|█▉        | 3463/17525 [41:39<2:26:26,  1.60it/s] 20%|█▉        | 3464/17525 [41:40<2:23:14,  1.64it/s] 20%|█▉        | 3465/17525 [41:41<2:20:58,  1.66it/s] 20%|█▉        | 3466/17525 [41:41<2:19:30,  1.68it/s] 20%|█▉        | 3467/17525 [41:42<2:18:32,  1.69it/s] 20%|█▉        | 3468/17525 [41:43<3:00:56,  1.29it/s] 20%|█▉        | 3469/17525 [41:44<2:47:39,  1.40it/s] 20%|█▉        | 3470/17525 [41:44<2:37:42,  1.49it/s]                                                      {'loss': 0.5918, 'grad_norm': 5.3019795417785645, 'learning_rate': 1.814883411109182e-05, 'epoch': 4.95}
 20%|█▉        | 3470/17525 [41:44<2:37:42,  1.49it/s] 20%|█▉        | 3471/17525 [41:45<2:31:17,  1.55it/s] 20%|█▉        | 3472/17525 [41:45<2:26:27,  1.60it/s] 20%|█▉        | 3473/17525 [41:46<2:23:13,  1.64it/s] 20%|█▉        | 3474/17525 [41:46<2:20:51,  1.66it/s] 20%|█▉        | 3475/17525 [41:47<2:19:22,  1.68it/s] 20%|█▉        | 3476/17525 [41:48<2:18:16,  1.69it/s] 20%|█▉        | 3477/17525 [41:48<2:17:34,  1.70it/s] 20%|█▉        | 3478/17525 [41:49<2:16:53,  1.71it/s] 20%|█▉        | 3479/17525 [41:49<2:16:24,  1.72it/s] 20%|█▉        | 3480/17525 [41:50<2:16:32,  1.71it/s]                                                      {'loss': 0.6097, 'grad_norm': 7.714395046234131, 'learning_rate': 1.813841856366737e-05, 'epoch': 4.96}
 20%|█▉        | 3480/17525 [41:50<2:16:32,  1.71it/s] 20%|█▉        | 3481/17525 [41:50<2:16:32,  1.71it/s] 20%|█▉        | 3482/17525 [41:51<2:16:04,  1.72it/s] 20%|█▉        | 3483/17525 [41:52<2:15:58,  1.72it/s] 20%|█▉        | 3484/17525 [41:52<2:15:46,  1.72it/s] 20%|█▉        | 3485/17525 [41:53<2:16:53,  1.71it/s] 20%|█▉        | 3486/17525 [41:53<2:16:48,  1.71it/s] 20%|█▉        | 3487/17525 [41:54<2:16:32,  1.71it/s] 20%|█▉        | 3488/17525 [41:55<2:16:20,  1.72it/s] 20%|█▉        | 3489/17525 [41:55<2:16:05,  1.72it/s] 20%|█▉        | 3490/17525 [41:56<2:16:10,  1.72it/s]                                                      {'loss': 0.6228, 'grad_norm': 9.957634925842285, 'learning_rate': 1.8127976803321793e-05, 'epoch': 4.98}
 20%|█▉        | 3490/17525 [41:56<2:16:10,  1.72it/s] 20%|█▉        | 3491/17525 [41:56<2:16:10,  1.72it/s] 20%|█▉        | 3492/17525 [41:57<2:15:46,  1.72it/s] 20%|█▉        | 3493/17525 [41:57<2:15:50,  1.72it/s] 20%|█▉        | 3494/17525 [41:58<2:15:55,  1.72it/s] 20%|█▉        | 3495/17525 [41:59<2:15:32,  1.73it/s] 20%|█▉        | 3496/17525 [41:59<2:15:39,  1.72it/s] 20%|█▉        | 3497/17525 [42:00<2:15:36,  1.72it/s] 20%|█▉        | 3498/17525 [42:00<2:15:27,  1.73it/s] 20%|█▉        | 3499/17525 [42:01<2:15:32,  1.72it/s] 20%|█▉        | 3500/17525 [42:02<2:15:26,  1.73it/s]                                                      {'loss': 0.6372, 'grad_norm': 6.560959815979004, 'learning_rate': 1.8117508863686817e-05, 'epoch': 4.99}
 20%|█▉        | 3500/17525 [42:02<2:15:26,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 02:45:23,418 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:45:23,418 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:45:23,418 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                      
                                               [A{'eval_loss': 0.8754372000694275, 'eval_runtime': 4.5956, 'eval_samples_per_second': 96.396, 'eval_steps_per_second': 4.134, 'epoch': 4.99}
 20%|█▉        | 3500/17525 [42:06<2:15:26,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 20%|█▉        | 3501/17525 [42:07<7:38:52,  1.96s/it] 20%|█▉        | 3502/17525 [42:08<6:57:53,  1.79s/it] 20%|█▉        | 3503/17525 [42:09<5:33:20,  1.43s/it] 20%|█▉        | 3504/17525 [42:09<4:34:14,  1.17s/it] 20%|██        | 3505/17525 [42:10<3:52:54,  1.00it/s] 20%|██        | 3506/17525 [42:10<3:23:57,  1.15it/s] 20%|██        | 3507/17525 [42:11<3:03:32,  1.27it/s] 20%|██        | 3508/17525 [42:12<2:49:05,  1.38it/s] 20%|██        | 3509/17525 [42:12<2:39:04,  1.47it/s] 20%|██        | 3510/17525 [42:13<2:32:06,  1.54it/s]                                                      {'loss': 0.5947, 'grad_norm': 5.22432804107666, 'learning_rate': 1.8107014778478474e-05, 'epoch': 5.01}
 20%|██        | 3510/17525 [42:13<2:32:06,  1.54it/s] 20%|██        | 3511/17525 [42:13<2:27:14,  1.59it/s] 20%|██        | 3512/17525 [42:14<2:23:41,  1.63it/s] 20%|██        | 3513/17525 [42:14<2:21:10,  1.65it/s] 20%|██        | 3514/17525 [42:15<2:19:37,  1.67it/s] 20%|██        | 3515/17525 [42:16<2:18:24,  1.69it/s] 20%|██        | 3516/17525 [42:16<2:18:32,  1.69it/s] 20%|██        | 3517/17525 [42:17<2:17:31,  1.70it/s] 20%|██        | 3518/17525 [42:17<2:16:54,  1.71it/s] 20%|██        | 3519/17525 [42:18<2:16:30,  1.71it/s] 20%|██        | 3520/17525 [42:19<2:16:14,  1.71it/s]                                                      {'loss': 0.5634, 'grad_norm': 5.857761859893799, 'learning_rate': 1.8096494581497035e-05, 'epoch': 5.02}
 20%|██        | 3520/17525 [42:19<2:16:14,  1.71it/s] 20%|██        | 3521/17525 [42:19<2:15:59,  1.72it/s] 20%|██        | 3522/17525 [42:20<2:15:39,  1.72it/s] 20%|██        | 3523/17525 [42:20<2:15:51,  1.72it/s] 20%|██        | 3524/17525 [42:21<2:15:47,  1.72it/s] 20%|██        | 3525/17525 [42:21<2:15:38,  1.72it/s] 20%|██        | 3526/17525 [42:22<2:15:36,  1.72it/s] 20%|██        | 3527/17525 [42:23<2:16:50,  1.70it/s] 20%|██        | 3528/17525 [42:23<2:16:25,  1.71it/s] 20%|██        | 3529/17525 [42:24<2:16:09,  1.71it/s] 20%|██        | 3530/17525 [42:24<2:15:58,  1.72it/s]                                                      {'loss': 0.467, 'grad_norm': 5.3021159172058105, 'learning_rate': 1.8085948306626845e-05, 'epoch': 5.04}
 20%|██        | 3530/17525 [42:24<2:15:58,  1.72it/s] 20%|██        | 3531/17525 [42:25<2:15:53,  1.72it/s] 20%|██        | 3532/17525 [42:26<2:15:47,  1.72it/s] 20%|██        | 3533/17525 [42:26<2:15:39,  1.72it/s] 20%|██        | 3534/17525 [42:27<2:15:38,  1.72it/s] 20%|██        | 3535/17525 [42:27<2:15:31,  1.72it/s] 20%|██        | 3536/17525 [42:28<2:16:13,  1.71it/s] 20%|██        | 3537/17525 [42:28<2:16:04,  1.71it/s] 20%|██        | 3538/17525 [42:29<2:15:58,  1.71it/s] 20%|██        | 3539/17525 [42:30<2:15:40,  1.72it/s] 20%|██        | 3540/17525 [42:30<2:15:45,  1.72it/s]                                                      {'loss': 0.6487, 'grad_norm': 3.8667380809783936, 'learning_rate': 1.8075375987836265e-05, 'epoch': 5.05}
 20%|██        | 3540/17525 [42:30<2:15:45,  1.72it/s] 20%|██        | 3541/17525 [42:31<2:16:30,  1.71it/s] 20%|██        | 3542/17525 [42:31<2:16:16,  1.71it/s] 20%|██        | 3543/17525 [42:32<2:16:05,  1.71it/s] 20%|██        | 3544/17525 [42:33<2:15:54,  1.71it/s] 20%|██        | 3545/17525 [42:33<2:15:43,  1.72it/s] 20%|██        | 3546/17525 [42:34<2:40:53,  1.45it/s] 20%|██        | 3547/17525 [42:35<2:33:17,  1.52it/s] 20%|██        | 3548/17525 [42:35<2:28:05,  1.57it/s] 20%|██        | 3549/17525 [42:36<2:24:13,  1.62it/s] 20%|██        | 3550/17525 [42:36<2:22:04,  1.64it/s]                                                      {'loss': 0.6143, 'grad_norm': 5.673979759216309, 'learning_rate': 1.806477765917753e-05, 'epoch': 5.06}
 20%|██        | 3550/17525 [42:36<2:22:04,  1.64it/s] 20%|██        | 3551/17525 [42:37<2:20:19,  1.66it/s] 20%|██        | 3552/17525 [42:38<2:18:48,  1.68it/s] 20%|██        | 3553/17525 [42:38<2:17:45,  1.69it/s] 20%|██        | 3554/17525 [42:39<2:16:39,  1.70it/s] 20%|██        | 3555/17525 [42:39<2:16:01,  1.71it/s] 20%|██        | 3556/17525 [42:40<2:15:38,  1.72it/s] 20%|██        | 3557/17525 [42:40<2:15:32,  1.72it/s] 20%|██        | 3558/17525 [42:41<2:15:30,  1.72it/s] 20%|██        | 3559/17525 [42:42<2:15:33,  1.72it/s] 20%|██        | 3560/17525 [42:42<2:15:22,  1.72it/s]                                                      {'loss': 0.6283, 'grad_norm': 8.788433074951172, 'learning_rate': 1.805415335478665e-05, 'epoch': 5.08}
 20%|██        | 3560/17525 [42:42<2:15:22,  1.72it/s] 20%|██        | 3561/17525 [42:43<2:15:29,  1.72it/s] 20%|██        | 3562/17525 [42:43<2:15:23,  1.72it/s] 20%|██        | 3563/17525 [42:44<2:15:17,  1.72it/s] 20%|██        | 3564/17525 [42:45<2:15:12,  1.72it/s] 20%|██        | 3565/17525 [42:45<2:15:18,  1.72it/s] 20%|██        | 3566/17525 [42:46<2:15:07,  1.72it/s] 20%|██        | 3567/17525 [42:46<2:14:55,  1.72it/s] 20%|██        | 3568/17525 [42:47<2:14:49,  1.73it/s] 20%|██        | 3569/17525 [42:47<2:14:56,  1.72it/s] 20%|██        | 3570/17525 [42:48<2:14:55,  1.72it/s]                                                      {'loss': 0.6521, 'grad_norm': 6.4531636238098145, 'learning_rate': 1.8043503108883306e-05, 'epoch': 5.09}
 20%|██        | 3570/17525 [42:48<2:14:55,  1.72it/s] 20%|██        | 3571/17525 [42:49<2:15:14,  1.72it/s] 20%|██        | 3572/17525 [42:49<2:15:07,  1.72it/s] 20%|██        | 3573/17525 [42:50<2:16:42,  1.70it/s] 20%|██        | 3574/17525 [42:50<2:16:22,  1.71it/s] 20%|██        | 3575/17525 [42:51<2:16:01,  1.71it/s] 20%|██        | 3576/17525 [42:52<2:15:47,  1.71it/s] 20%|██        | 3577/17525 [42:53<2:58:57,  1.30it/s] 20%|██        | 3578/17525 [42:53<2:45:57,  1.40it/s] 20%|██        | 3579/17525 [42:54<2:36:37,  1.48it/s] 20%|██        | 3580/17525 [42:54<2:30:07,  1.55it/s]                                                      {'loss': 0.7128, 'grad_norm': 6.610682964324951, 'learning_rate': 1.8032826955770723e-05, 'epoch': 5.11}
 20%|██        | 3580/17525 [42:54<2:30:07,  1.55it/s] 20%|██        | 3581/17525 [42:55<2:25:46,  1.59it/s] 20%|██        | 3582/17525 [42:56<2:22:22,  1.63it/s] 20%|██        | 3583/17525 [42:56<2:20:06,  1.66it/s] 20%|██        | 3584/17525 [42:57<2:18:31,  1.68it/s] 20%|██        | 3585/17525 [42:57<2:17:27,  1.69it/s] 20%|██        | 3586/17525 [42:58<2:18:14,  1.68it/s] 20%|██        | 3587/17525 [42:59<2:17:12,  1.69it/s] 20%|██        | 3588/17525 [42:59<2:16:21,  1.70it/s] 20%|██        | 3589/17525 [43:01<3:10:27,  1.22it/s] 20%|██        | 3590/17525 [43:01<3:19:07,  1.17it/s]                                                      {'loss': 0.7331, 'grad_norm': 4.815516948699951, 'learning_rate': 1.8022124929835582e-05, 'epoch': 5.12}
 20%|██        | 3590/17525 [43:01<3:19:07,  1.17it/s] 20%|██        | 3591/17525 [43:02<2:59:56,  1.29it/s] 20%|██        | 3592/17525 [43:03<2:46:40,  1.39it/s] 21%|██        | 3593/17525 [43:03<2:37:05,  1.48it/s] 21%|██        | 3594/17525 [43:04<2:30:20,  1.54it/s] 21%|██        | 3595/17525 [43:04<2:26:06,  1.59it/s] 21%|██        | 3596/17525 [43:05<2:22:29,  1.63it/s] 21%|██        | 3597/17525 [43:06<2:20:14,  1.66it/s] 21%|██        | 3598/17525 [43:06<2:18:38,  1.67it/s] 21%|██        | 3599/17525 [43:07<2:17:55,  1.68it/s] 21%|██        | 3600/17525 [43:07<2:17:27,  1.69it/s]                                                      {'loss': 0.574, 'grad_norm': 5.171392440795898, 'learning_rate': 1.8011397065547892e-05, 'epoch': 5.14}
 21%|██        | 3600/17525 [43:07<2:17:27,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 02:46:29,198 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:46:29,198 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:46:29,198 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8759927749633789, 'eval_runtime': 4.6023, 'eval_samples_per_second': 96.257, 'eval_steps_per_second': 4.128, 'epoch': 5.14}
 21%|██        | 3600/17525 [43:12<2:17:27,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:46:33,804 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b288b77d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a5752160-f3df-44db-acfa-bcc6d498b5c5)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:46:43,864 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:46:43,866 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 21%|██        | 3601/17525 [43:23<19:38:49,  5.08s/it] 21%|██        | 3602/17525 [43:23<14:25:48,  3.73s/it] 21%|██        | 3603/17525 [43:24<10:46:20,  2.79s/it] 21%|██        | 3604/17525 [43:25<8:12:44,  2.12s/it]  21%|██        | 3605/17525 [43:25<6:25:33,  1.66s/it] 21%|██        | 3606/17525 [43:26<5:10:12,  1.34s/it] 21%|██        | 3607/17525 [43:26<4:17:23,  1.11s/it] 21%|██        | 3608/17525 [43:27<3:40:44,  1.05it/s] 21%|██        | 3609/17525 [43:28<3:15:04,  1.19it/s] 21%|██        | 3610/17525 [43:28<3:19:27,  1.16it/s]                                                      {'loss': 0.5853, 'grad_norm': 10.914226531982422, 'learning_rate': 1.8000643397460882e-05, 'epoch': 5.15}
 21%|██        | 3610/17525 [43:28<3:19:27,  1.16it/s] 21%|██        | 3611/17525 [43:29<3:00:12,  1.29it/s] 21%|██        | 3612/17525 [43:30<2:46:34,  1.39it/s] 21%|██        | 3613/17525 [43:30<2:37:01,  1.48it/s] 21%|██        | 3614/17525 [43:31<2:30:28,  1.54it/s] 21%|██        | 3615/17525 [43:31<2:25:40,  1.59it/s] 21%|██        | 3616/17525 [43:32<2:22:13,  1.63it/s] 21%|██        | 3617/17525 [43:32<2:20:01,  1.66it/s] 21%|██        | 3618/17525 [43:33<2:18:23,  1.67it/s] 21%|██        | 3619/17525 [43:34<2:17:17,  1.69it/s] 21%|██        | 3620/17525 [43:34<2:16:35,  1.70it/s]                                                      {'loss': 0.6171, 'grad_norm': 9.390579223632812, 'learning_rate': 1.7989863960210895e-05, 'epoch': 5.16}
 21%|██        | 3620/17525 [43:34<2:16:35,  1.70it/s] 21%|██        | 3621/17525 [43:35<2:16:08,  1.70it/s] 21%|██        | 3622/17525 [43:35<2:15:45,  1.71it/s] 21%|██        | 3623/17525 [43:36<2:15:38,  1.71it/s] 21%|██        | 3624/17525 [43:37<2:15:32,  1.71it/s] 21%|██        | 3625/17525 [43:37<2:15:16,  1.71it/s] 21%|██        | 3626/17525 [43:38<2:15:03,  1.72it/s] 21%|██        | 3627/17525 [43:38<2:16:20,  1.70it/s] 21%|██        | 3628/17525 [43:39<2:15:53,  1.70it/s] 21%|██        | 3629/17525 [43:39<2:15:20,  1.71it/s] 21%|██        | 3630/17525 [43:40<2:39:44,  1.45it/s]                                                      {'loss': 0.494, 'grad_norm': 6.592170238494873, 'learning_rate': 1.7979058788517272e-05, 'epoch': 5.18}
 21%|██        | 3630/17525 [43:40<2:39:44,  1.45it/s] 21%|██        | 3631/17525 [43:41<2:32:30,  1.52it/s] 21%|██        | 3632/17525 [43:42<2:27:01,  1.57it/s] 21%|██        | 3633/17525 [43:42<2:23:10,  1.62it/s] 21%|██        | 3634/17525 [43:43<2:20:32,  1.65it/s] 21%|██        | 3635/17525 [43:43<2:18:49,  1.67it/s] 21%|██        | 3636/17525 [43:44<2:17:20,  1.69it/s] 21%|██        | 3637/17525 [43:44<2:16:14,  1.70it/s] 21%|██        | 3638/17525 [43:45<2:16:03,  1.70it/s] 21%|██        | 3639/17525 [43:46<2:15:40,  1.71it/s] 21%|██        | 3640/17525 [43:46<2:15:22,  1.71it/s]                                                      {'loss': 0.5768, 'grad_norm': 7.92479133605957, 'learning_rate': 1.796822791718225e-05, 'epoch': 5.19}
 21%|██        | 3640/17525 [43:46<2:15:22,  1.71it/s] 21%|██        | 3641/17525 [43:47<2:16:45,  1.69it/s] 21%|██        | 3642/17525 [43:47<2:15:55,  1.70it/s] 21%|██        | 3643/17525 [43:48<2:15:27,  1.71it/s] 21%|██        | 3644/17525 [43:49<2:15:09,  1.71it/s] 21%|██        | 3645/17525 [43:49<2:14:52,  1.72it/s] 21%|██        | 3646/17525 [43:50<2:28:58,  1.55it/s] 21%|██        | 3647/17525 [43:51<2:24:53,  1.60it/s] 21%|██        | 3648/17525 [43:51<2:35:04,  1.49it/s] 21%|██        | 3649/17525 [43:52<2:28:49,  1.55it/s] 21%|██        | 3650/17525 [43:52<2:24:45,  1.60it/s]                                                      {'loss': 0.6515, 'grad_norm': 19.56123161315918, 'learning_rate': 1.7957371381090825e-05, 'epoch': 5.21}
 21%|██        | 3650/17525 [43:52<2:24:45,  1.60it/s] 21%|██        | 3651/17525 [43:53<2:21:51,  1.63it/s] 21%|██        | 3652/17525 [43:54<2:19:38,  1.66it/s] 21%|██        | 3653/17525 [43:54<2:30:09,  1.54it/s] 21%|██        | 3654/17525 [43:55<2:25:30,  1.59it/s] 21%|██        | 3655/17525 [43:56<2:22:10,  1.63it/s] 21%|██        | 3656/17525 [43:56<2:19:48,  1.65it/s] 21%|██        | 3657/17525 [43:57<2:18:03,  1.67it/s] 21%|██        | 3658/17525 [43:57<2:16:55,  1.69it/s] 21%|██        | 3659/17525 [43:58<2:16:17,  1.70it/s] 21%|██        | 3660/17525 [43:58<2:15:42,  1.70it/s]                                                      {'loss': 0.617, 'grad_norm': 4.730590343475342, 'learning_rate': 1.794648921521067e-05, 'epoch': 5.22}
 21%|██        | 3660/17525 [43:58<2:15:42,  1.70it/s] 21%|██        | 3661/17525 [43:59<2:15:27,  1.71it/s] 21%|██        | 3662/17525 [44:00<2:15:06,  1.71it/s] 21%|██        | 3663/17525 [44:00<2:14:57,  1.71it/s] 21%|██        | 3664/17525 [44:01<2:14:52,  1.71it/s] 21%|██        | 3665/17525 [44:01<2:14:32,  1.72it/s] 21%|██        | 3666/17525 [44:02<2:14:20,  1.72it/s] 21%|██        | 3667/17525 [44:03<2:14:18,  1.72it/s] 21%|██        | 3668/17525 [44:03<2:14:39,  1.72it/s] 21%|██        | 3669/17525 [44:04<2:14:15,  1.72it/s] 21%|██        | 3670/17525 [44:04<2:14:28,  1.72it/s]                                                      {'loss': 0.5732, 'grad_norm': 13.427905082702637, 'learning_rate': 1.7935581454592005e-05, 'epoch': 5.24}
 21%|██        | 3670/17525 [44:04<2:14:28,  1.72it/s] 21%|██        | 3671/17525 [44:05<2:14:30,  1.72it/s] 21%|██        | 3672/17525 [44:05<2:14:22,  1.72it/s] 21%|██        | 3673/17525 [44:06<2:14:22,  1.72it/s] 21%|██        | 3674/17525 [44:07<2:48:39,  1.37it/s] 21%|██        | 3675/17525 [44:08<2:38:21,  1.46it/s] 21%|██        | 3676/17525 [44:08<2:30:58,  1.53it/s] 21%|██        | 3677/17525 [44:09<2:25:42,  1.58it/s] 21%|██        | 3678/17525 [44:09<2:22:01,  1.62it/s] 21%|██        | 3679/17525 [44:10<2:19:42,  1.65it/s] 21%|██        | 3680/17525 [44:11<2:17:38,  1.68it/s]                                                      {'loss': 0.6412, 'grad_norm': 6.949006080627441, 'learning_rate': 1.7924648134367485e-05, 'epoch': 5.25}
 21%|██        | 3680/17525 [44:11<2:17:38,  1.68it/s] 21%|██        | 3681/17525 [44:11<2:16:37,  1.69it/s] 21%|██        | 3682/17525 [44:12<2:15:49,  1.70it/s] 21%|██        | 3683/17525 [44:12<2:15:20,  1.70it/s] 21%|██        | 3684/17525 [44:13<2:15:13,  1.71it/s] 21%|██        | 3685/17525 [44:13<2:15:05,  1.71it/s] 21%|██        | 3686/17525 [44:14<2:15:08,  1.71it/s] 21%|██        | 3687/17525 [44:15<2:15:01,  1.71it/s] 21%|██        | 3688/17525 [44:15<2:14:48,  1.71it/s] 21%|██        | 3689/17525 [44:16<2:14:28,  1.71it/s] 21%|██        | 3690/17525 [44:16<2:14:18,  1.72it/s]                                                      {'loss': 0.645, 'grad_norm': 13.080677032470703, 'learning_rate': 1.7913689289752093e-05, 'epoch': 5.26}
 21%|██        | 3690/17525 [44:16<2:14:18,  1.72it/s] 21%|██        | 3691/17525 [44:17<2:14:17,  1.72it/s] 21%|██        | 3692/17525 [44:18<2:14:00,  1.72it/s] 21%|██        | 3693/17525 [44:18<2:13:54,  1.72it/s] 21%|██        | 3694/17525 [44:19<2:42:14,  1.42it/s] 21%|██        | 3695/17525 [44:20<2:58:30,  1.29it/s] 21%|██        | 3696/17525 [44:21<2:45:18,  1.39it/s] 21%|██        | 3697/17525 [44:21<2:37:26,  1.46it/s] 21%|██        | 3698/17525 [44:22<2:30:18,  1.53it/s] 21%|██        | 3699/17525 [44:22<2:25:22,  1.59it/s] 21%|██        | 3700/17525 [44:23<2:21:46,  1.63it/s]                                                      {'loss': 0.6551, 'grad_norm': 7.487515449523926, 'learning_rate': 1.7902704956043023e-05, 'epoch': 5.28}
 21%|██        | 3700/17525 [44:23<2:21:46,  1.63it/s][INFO|trainer.py:3512] 2024-06-25 02:47:44,902 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:47:44,902 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:47:44,902 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8792399168014526, 'eval_runtime': 4.5985, 'eval_samples_per_second': 96.336, 'eval_steps_per_second': 4.132, 'epoch': 5.28}
 21%|██        | 3700/17525 [44:28<2:21:46,  1.63it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 21%|██        | 3701/17525 [44:28<7:37:57,  1.99s/it] 21%|██        | 3702/17525 [44:29<6:00:40,  1.57s/it] 21%|██        | 3703/17525 [44:29<4:52:48,  1.27s/it] 21%|██        | 3704/17525 [44:30<4:05:06,  1.06s/it] 21%|██        | 3705/17525 [44:31<3:31:41,  1.09it/s] 21%|██        | 3706/17525 [44:31<3:08:03,  1.22it/s] 21%|██        | 3707/17525 [44:32<2:52:21,  1.34it/s] 21%|██        | 3708/17525 [44:33<3:06:17,  1.24it/s] 21%|██        | 3709/17525 [44:33<2:50:39,  1.35it/s] 21%|██        | 3710/17525 [44:34<2:40:50,  1.43it/s]                                                      {'loss': 0.6679, 'grad_norm': 8.822524070739746, 'learning_rate': 1.7891695168619564e-05, 'epoch': 5.29}
 21%|██        | 3710/17525 [44:34<2:40:50,  1.43it/s] 21%|██        | 3711/17525 [44:34<2:32:49,  1.51it/s] 21%|██        | 3712/17525 [44:35<2:56:53,  1.30it/s] 21%|██        | 3713/17525 [44:36<2:44:02,  1.40it/s] 21%|██        | 3714/17525 [44:37<2:34:40,  1.49it/s] 21%|██        | 3715/17525 [44:37<2:28:19,  1.55it/s] 21%|██        | 3716/17525 [44:38<2:23:58,  1.60it/s] 21%|██        | 3717/17525 [44:38<2:20:47,  1.63it/s] 21%|██        | 3718/17525 [44:39<2:19:19,  1.65it/s] 21%|██        | 3719/17525 [44:39<2:17:42,  1.67it/s] 21%|██        | 3720/17525 [44:40<2:16:38,  1.68it/s]                                                      {'loss': 0.5951, 'grad_norm': 9.349400520324707, 'learning_rate': 1.7880659962942987e-05, 'epoch': 5.31}
 21%|██        | 3720/17525 [44:40<2:16:38,  1.68it/s] 21%|██        | 3721/17525 [44:41<2:15:53,  1.69it/s] 21%|██        | 3722/17525 [44:41<2:15:06,  1.70it/s] 21%|██        | 3723/17525 [44:42<2:14:45,  1.71it/s] 21%|██        | 3724/17525 [44:42<2:14:25,  1.71it/s] 21%|██▏       | 3725/17525 [44:43<2:14:12,  1.71it/s] 21%|██▏       | 3726/17525 [44:44<2:14:02,  1.72it/s] 21%|██▏       | 3727/17525 [44:44<2:13:56,  1.72it/s] 21%|██▏       | 3728/17525 [44:45<2:14:09,  1.71it/s] 21%|██▏       | 3729/17525 [44:45<2:14:10,  1.71it/s] 21%|██▏       | 3730/17525 [44:46<2:13:50,  1.72it/s]                                                      {'loss': 0.6279, 'grad_norm': 17.941320419311523, 'learning_rate': 1.786959937455644e-05, 'epoch': 5.32}
 21%|██▏       | 3730/17525 [44:46<2:13:50,  1.72it/s] 21%|██▏       | 3731/17525 [44:46<2:13:45,  1.72it/s] 21%|██▏       | 3732/17525 [44:47<2:13:32,  1.72it/s] 21%|██▏       | 3733/17525 [44:48<2:13:45,  1.72it/s] 21%|██▏       | 3734/17525 [44:48<2:13:39,  1.72it/s] 21%|██▏       | 3735/17525 [44:49<2:13:33,  1.72it/s] 21%|██▏       | 3736/17525 [44:49<2:13:21,  1.72it/s] 21%|██▏       | 3737/17525 [44:50<2:13:15,  1.72it/s] 21%|██▏       | 3738/17525 [44:51<2:13:42,  1.72it/s] 21%|██▏       | 3739/17525 [44:51<2:13:59,  1.71it/s] 21%|██▏       | 3740/17525 [44:52<2:13:59,  1.71it/s]                                                      {'loss': 0.6213, 'grad_norm': 6.291675567626953, 'learning_rate': 1.7858513439084818e-05, 'epoch': 5.34}
 21%|██▏       | 3740/17525 [44:52<2:13:59,  1.71it/s] 21%|██▏       | 3741/17525 [44:52<2:14:10,  1.71it/s] 21%|██▏       | 3742/17525 [44:53<2:14:22,  1.71it/s] 21%|██▏       | 3743/17525 [44:53<2:13:47,  1.72it/s] 21%|██▏       | 3744/17525 [44:54<2:13:50,  1.72it/s] 21%|██▏       | 3745/17525 [44:55<2:13:38,  1.72it/s] 21%|██▏       | 3746/17525 [44:55<2:13:37,  1.72it/s] 21%|██▏       | 3747/17525 [44:56<2:15:35,  1.69it/s] 21%|██▏       | 3748/17525 [44:56<2:15:10,  1.70it/s] 21%|██▏       | 3749/17525 [44:57<2:14:59,  1.70it/s] 21%|██▏       | 3750/17525 [44:58<2:15:02,  1.70it/s]                                                      {'loss': 0.598, 'grad_norm': 7.173884391784668, 'learning_rate': 1.7847402192234663e-05, 'epoch': 5.35}
 21%|██▏       | 3750/17525 [44:58<2:15:02,  1.70it/s][INFO|trainer.py:3203] 2024-06-25 02:48:19,470 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a799f8d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6bc6553f-8740-4e8e-b093-ae76178b8750)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:48:29,531 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:48:29,534 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 21%|██▏       | 3751/17525 [45:08<13:56:28,  3.64s/it] 21%|██▏       | 3752/17525 [45:09<10:25:36,  2.73s/it] 21%|██▏       | 3753/17525 [45:10<7:57:51,  2.08s/it]  21%|██▏       | 3754/17525 [45:10<6:14:34,  1.63s/it] 21%|██▏       | 3755/17525 [45:11<5:02:04,  1.32s/it] 21%|██▏       | 3756/17525 [45:11<4:11:28,  1.10s/it] 21%|██▏       | 3757/17525 [45:12<3:35:48,  1.06it/s] 21%|██▏       | 3758/17525 [45:12<3:10:54,  1.20it/s] 21%|██▏       | 3759/17525 [45:13<2:54:04,  1.32it/s] 21%|██▏       | 3760/17525 [45:14<2:41:47,  1.42it/s]                                                      {'loss': 0.6982, 'grad_norm': 6.065556526184082, 'learning_rate': 1.7836265669794032e-05, 'epoch': 5.36}
 21%|██▏       | 3760/17525 [45:14<2:41:47,  1.42it/s] 21%|██▏       | 3761/17525 [45:15<3:17:16,  1.16it/s] 21%|██▏       | 3762/17525 [45:15<2:57:52,  1.29it/s] 21%|██▏       | 3763/17525 [45:16<3:13:36,  1.18it/s] 21%|██▏       | 3764/17525 [45:17<2:55:31,  1.31it/s] 21%|██▏       | 3765/17525 [45:18<2:42:49,  1.41it/s] 21%|██▏       | 3766/17525 [45:18<2:33:38,  1.49it/s] 21%|██▏       | 3767/17525 [45:19<2:27:39,  1.55it/s] 22%|██▏       | 3768/17525 [45:19<2:31:47,  1.51it/s] 22%|██▏       | 3769/17525 [45:20<2:26:23,  1.57it/s] 22%|██▏       | 3770/17525 [45:21<2:22:25,  1.61it/s]                                                      {'loss': 0.6237, 'grad_norm': 8.761763572692871, 'learning_rate': 1.7825103907632403e-05, 'epoch': 5.38}
 22%|██▏       | 3770/17525 [45:21<2:22:25,  1.61it/s] 22%|██▏       | 3771/17525 [45:21<2:19:44,  1.64it/s] 22%|██▏       | 3772/17525 [45:22<2:38:31,  1.45it/s] 22%|██▏       | 3773/17525 [45:23<2:30:57,  1.52it/s] 22%|██▏       | 3774/17525 [45:23<2:25:24,  1.58it/s] 22%|██▏       | 3775/17525 [45:24<2:21:29,  1.62it/s] 22%|██▏       | 3776/17525 [45:24<2:18:54,  1.65it/s] 22%|██▏       | 3777/17525 [45:25<2:17:08,  1.67it/s] 22%|██▏       | 3778/17525 [45:26<2:16:06,  1.68it/s] 22%|██▏       | 3779/17525 [45:26<2:15:06,  1.70it/s] 22%|██▏       | 3780/17525 [45:27<2:24:52,  1.58it/s]                                                      {'loss': 0.6384, 'grad_norm': 7.981852054595947, 'learning_rate': 1.781391694170054e-05, 'epoch': 5.39}
 22%|██▏       | 3780/17525 [45:27<2:24:52,  1.58it/s] 22%|██▏       | 3781/17525 [45:27<2:21:24,  1.62it/s] 22%|██▏       | 3782/17525 [45:28<2:21:04,  1.62it/s] 22%|██▏       | 3783/17525 [45:29<2:18:38,  1.65it/s] 22%|██▏       | 3784/17525 [45:29<2:16:40,  1.68it/s] 22%|██▏       | 3785/17525 [45:30<2:15:32,  1.69it/s] 22%|██▏       | 3786/17525 [45:30<2:14:44,  1.70it/s] 22%|██▏       | 3787/17525 [45:31<2:14:15,  1.71it/s] 22%|██▏       | 3788/17525 [45:32<2:13:56,  1.71it/s] 22%|██▏       | 3789/17525 [45:32<2:13:43,  1.71it/s] 22%|██▏       | 3790/17525 [45:33<2:13:08,  1.72it/s]                                                      {'loss': 0.7115, 'grad_norm': 20.047752380371094, 'learning_rate': 1.7802704808030393e-05, 'epoch': 5.41}
 22%|██▏       | 3790/17525 [45:33<2:13:08,  1.72it/s] 22%|██▏       | 3791/17525 [45:34<2:37:34,  1.45it/s] 22%|██▏       | 3792/17525 [45:34<2:29:59,  1.53it/s] 22%|██▏       | 3793/17525 [45:35<2:24:33,  1.58it/s] 22%|██▏       | 3794/17525 [45:35<2:21:00,  1.62it/s] 22%|██▏       | 3795/17525 [45:36<2:20:28,  1.63it/s] 22%|██▏       | 3796/17525 [45:37<2:19:15,  1.64it/s] 22%|██▏       | 3797/17525 [45:37<2:18:26,  1.65it/s] 22%|██▏       | 3798/17525 [45:38<2:17:35,  1.66it/s] 22%|██▏       | 3799/17525 [45:38<2:16:50,  1.67it/s] 22%|██▏       | 3800/17525 [45:39<2:16:15,  1.68it/s]                                                      {'loss': 0.6254, 'grad_norm': 5.2188849449157715, 'learning_rate': 1.7791467542734962e-05, 'epoch': 5.42}
 22%|██▏       | 3800/17525 [45:39<2:16:15,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 02:49:00,810 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:49:00,811 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:49:00,811 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8708390593528748, 'eval_runtime': 4.5984, 'eval_samples_per_second': 96.338, 'eval_steps_per_second': 4.132, 'epoch': 5.42}
 22%|██▏       | 3800/17525 [45:44<2:16:15,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 22%|██▏       | 3801/17525 [45:44<7:32:15,  1.98s/it] 22%|██▏       | 3802/17525 [45:45<5:56:53,  1.56s/it] 22%|██▏       | 3803/17525 [45:45<4:50:30,  1.27s/it] 22%|██▏       | 3804/17525 [45:46<4:03:48,  1.07s/it] 22%|██▏       | 3805/17525 [45:46<3:30:57,  1.08it/s] 22%|██▏       | 3806/17525 [45:47<3:08:04,  1.22it/s] 22%|██▏       | 3807/17525 [45:48<2:51:54,  1.33it/s] 22%|██▏       | 3808/17525 [45:49<3:05:08,  1.23it/s] 22%|██▏       | 3809/17525 [45:49<2:50:19,  1.34it/s] 22%|██▏       | 3810/17525 [45:50<2:40:10,  1.43it/s]                                                      {'loss': 0.5784, 'grad_norm': 5.229526042938232, 'learning_rate': 1.7780205182008214e-05, 'epoch': 5.44}
 22%|██▏       | 3810/17525 [45:50<2:40:10,  1.43it/s] 22%|██▏       | 3811/17525 [45:50<2:33:07,  1.49it/s] 22%|██▏       | 3812/17525 [45:51<2:28:57,  1.53it/s] 22%|██▏       | 3813/17525 [45:52<2:24:38,  1.58it/s] 22%|██▏       | 3814/17525 [45:52<2:21:51,  1.61it/s] 22%|██▏       | 3815/17525 [45:53<2:20:11,  1.63it/s] 22%|██▏       | 3816/17525 [45:53<2:18:46,  1.65it/s] 22%|██▏       | 3817/17525 [45:54<2:18:12,  1.65it/s] 22%|██▏       | 3818/17525 [45:55<2:17:22,  1.66it/s] 22%|██▏       | 3819/17525 [45:55<2:16:18,  1.68it/s] 22%|██▏       | 3820/17525 [45:56<2:16:07,  1.68it/s]                                                      {'loss': 0.5627, 'grad_norm': 6.802831172943115, 'learning_rate': 1.7768917762124916e-05, 'epoch': 5.45}
 22%|██▏       | 3820/17525 [45:56<2:16:07,  1.68it/s] 22%|██▏       | 3821/17525 [45:56<2:15:25,  1.69it/s] 22%|██▏       | 3822/17525 [45:57<2:16:32,  1.67it/s] 22%|██▏       | 3823/17525 [45:58<2:16:09,  1.68it/s] 22%|██▏       | 3824/17525 [45:58<2:15:22,  1.69it/s] 22%|██▏       | 3825/17525 [45:59<2:15:18,  1.69it/s] 22%|██▏       | 3826/17525 [45:59<2:14:54,  1.69it/s] 22%|██▏       | 3827/17525 [46:00<2:14:54,  1.69it/s] 22%|██▏       | 3828/17525 [46:00<2:14:48,  1.69it/s] 22%|██▏       | 3829/17525 [46:01<2:15:02,  1.69it/s] 22%|██▏       | 3830/17525 [46:02<2:14:28,  1.70it/s]                                                      {'loss': 0.7293, 'grad_norm': 13.915635108947754, 'learning_rate': 1.7757605319440578e-05, 'epoch': 5.46}
 22%|██▏       | 3830/17525 [46:02<2:14:28,  1.70it/s] 22%|██▏       | 3831/17525 [46:02<2:14:27,  1.70it/s] 22%|██▏       | 3832/17525 [46:03<2:14:23,  1.70it/s] 22%|██▏       | 3833/17525 [46:03<2:14:05,  1.70it/s] 22%|██▏       | 3834/17525 [46:04<2:14:15,  1.70it/s] 22%|██▏       | 3835/17525 [46:05<2:13:45,  1.71it/s] 22%|██▏       | 3836/17525 [46:05<2:13:15,  1.71it/s] 22%|██▏       | 3837/17525 [46:06<2:13:52,  1.70it/s] 22%|██▏       | 3838/17525 [46:06<2:13:32,  1.71it/s] 22%|██▏       | 3839/17525 [46:07<2:13:06,  1.71it/s] 22%|██▏       | 3840/17525 [46:07<2:12:59,  1.72it/s]                                                      {'loss': 0.5202, 'grad_norm': 7.294612407684326, 'learning_rate': 1.7746267890391286e-05, 'epoch': 5.48}
 22%|██▏       | 3840/17525 [46:07<2:12:59,  1.72it/s] 22%|██▏       | 3841/17525 [46:08<2:13:39,  1.71it/s] 22%|██▏       | 3842/17525 [46:09<2:13:13,  1.71it/s] 22%|██▏       | 3843/17525 [46:09<2:13:09,  1.71it/s] 22%|██▏       | 3844/17525 [46:10<2:12:50,  1.72it/s] 22%|██▏       | 3845/17525 [46:10<2:12:54,  1.72it/s] 22%|██▏       | 3846/17525 [46:11<2:13:35,  1.71it/s] 22%|██▏       | 3847/17525 [46:12<2:12:59,  1.71it/s] 22%|██▏       | 3848/17525 [46:12<2:12:31,  1.72it/s] 22%|██▏       | 3849/17525 [46:13<2:12:46,  1.72it/s] 22%|██▏       | 3850/17525 [46:13<2:12:31,  1.72it/s]                                                      {'loss': 0.7046, 'grad_norm': 13.902779579162598, 'learning_rate': 1.7734905511493614e-05, 'epoch': 5.49}
 22%|██▏       | 3850/17525 [46:13<2:12:31,  1.72it/s] 22%|██▏       | 3851/17525 [46:14<2:12:19,  1.72it/s] 22%|██▏       | 3852/17525 [46:14<2:12:17,  1.72it/s] 22%|██▏       | 3853/17525 [46:16<3:06:34,  1.22it/s] 22%|██▏       | 3854/17525 [46:16<2:51:24,  1.33it/s] 22%|██▏       | 3855/17525 [46:17<2:40:08,  1.42it/s] 22%|██▏       | 3856/17525 [46:18<2:32:03,  1.50it/s] 22%|██▏       | 3857/17525 [46:18<2:36:27,  1.46it/s] 22%|██▏       | 3858/17525 [46:19<2:29:55,  1.52it/s] 22%|██▏       | 3859/17525 [46:20<2:25:30,  1.57it/s] 22%|██▏       | 3860/17525 [46:20<2:22:12,  1.60it/s]                                                      {'loss': 0.5564, 'grad_norm': 5.32059383392334, 'learning_rate': 1.772351821934449e-05, 'epoch': 5.51}
 22%|██▏       | 3860/17525 [46:20<2:22:12,  1.60it/s] 22%|██▏       | 3861/17525 [46:21<2:20:43,  1.62it/s] 22%|██▏       | 3862/17525 [46:21<2:18:27,  1.64it/s] 22%|██▏       | 3863/17525 [46:22<2:16:45,  1.67it/s] 22%|██▏       | 3864/17525 [46:22<2:15:24,  1.68it/s] 22%|██▏       | 3865/17525 [46:23<2:14:46,  1.69it/s] 22%|██▏       | 3866/17525 [46:24<2:14:11,  1.70it/s] 22%|██▏       | 3867/17525 [46:24<2:13:45,  1.70it/s] 22%|██▏       | 3868/17525 [46:25<2:13:32,  1.70it/s] 22%|██▏       | 3869/17525 [46:26<2:25:29,  1.56it/s] 22%|██▏       | 3870/17525 [46:26<2:22:07,  1.60it/s]                                                      {'loss': 0.5357, 'grad_norm': 10.418156623840332, 'learning_rate': 1.771210605062109e-05, 'epoch': 5.52}
 22%|██▏       | 3870/17525 [46:26<2:22:07,  1.60it/s] 22%|██▏       | 3871/17525 [46:27<2:19:34,  1.63it/s] 22%|██▏       | 3872/17525 [46:27<2:17:58,  1.65it/s] 22%|██▏       | 3873/17525 [46:28<2:16:55,  1.66it/s] 22%|██▏       | 3874/17525 [46:29<2:16:06,  1.67it/s] 22%|██▏       | 3875/17525 [46:29<2:15:05,  1.68it/s] 22%|██▏       | 3876/17525 [46:30<2:14:18,  1.69it/s] 22%|██▏       | 3877/17525 [46:30<2:13:39,  1.70it/s] 22%|██▏       | 3878/17525 [46:31<2:13:41,  1.70it/s] 22%|██▏       | 3879/17525 [46:31<2:13:37,  1.70it/s] 22%|██▏       | 3880/17525 [46:32<2:13:47,  1.70it/s]                                                      {'loss': 0.6387, 'grad_norm': 7.73942232131958, 'learning_rate': 1.770066904208071e-05, 'epoch': 5.53}
 22%|██▏       | 3880/17525 [46:32<2:13:47,  1.70it/s] 22%|██▏       | 3881/17525 [46:33<2:13:36,  1.70it/s] 22%|██▏       | 3882/17525 [46:33<2:25:22,  1.56it/s] 22%|██▏       | 3883/17525 [46:34<2:22:29,  1.60it/s] 22%|██▏       | 3884/17525 [46:35<2:19:57,  1.62it/s] 22%|██▏       | 3885/17525 [46:35<2:18:10,  1.65it/s] 22%|██▏       | 3886/17525 [46:36<2:16:54,  1.66it/s] 22%|██▏       | 3887/17525 [46:36<2:15:50,  1.67it/s] 22%|██▏       | 3888/17525 [46:37<2:15:28,  1.68it/s] 22%|██▏       | 3889/17525 [46:38<2:15:06,  1.68it/s] 22%|██▏       | 3890/17525 [46:38<2:15:53,  1.67it/s]                                                      {'loss': 0.6704, 'grad_norm': 4.480504512786865, 'learning_rate': 1.768920723056065e-05, 'epoch': 5.55}
 22%|██▏       | 3890/17525 [46:38<2:15:53,  1.67it/s] 22%|██▏       | 3891/17525 [46:39<2:15:22,  1.68it/s] 22%|██▏       | 3892/17525 [46:39<2:15:04,  1.68it/s] 22%|██▏       | 3893/17525 [46:40<2:14:33,  1.69it/s] 22%|██▏       | 3894/17525 [46:40<2:14:27,  1.69it/s] 22%|██▏       | 3895/17525 [46:41<2:14:44,  1.69it/s] 22%|██▏       | 3896/17525 [46:42<2:14:15,  1.69it/s] 22%|██▏       | 3897/17525 [46:42<2:13:53,  1.70it/s] 22%|██▏       | 3898/17525 [46:43<2:14:22,  1.69it/s] 22%|██▏       | 3899/17525 [46:43<2:14:10,  1.69it/s] 22%|██▏       | 3900/17525 [46:44<2:21:35,  1.60it/s]                                                      {'loss': 0.6212, 'grad_norm': 8.475601196289062, 'learning_rate': 1.7677720652978112e-05, 'epoch': 5.56}
 22%|██▏       | 3900/17525 [46:44<2:21:35,  1.60it/s][INFO|trainer.py:3512] 2024-06-25 02:50:06,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:50:06,047 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:50:06,047 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8771056532859802, 'eval_runtime': 4.6055, 'eval_samples_per_second': 96.189, 'eval_steps_per_second': 4.125, 'epoch': 5.56}
 22%|██▏       | 3900/17525 [46:49<2:21:35,  1.60it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:50:10,657 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79f6710>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f462bde1-18dd-4a16-8656-6321fd5304fd)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:50:20,720 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:50:20,722 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-3900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 22%|██▏       | 3901/17525 [47:00<19:19:06,  5.10s/it] 22%|██▏       | 3902/17525 [47:00<14:10:50,  3.75s/it] 22%|██▏       | 3903/17525 [47:01<10:35:07,  2.80s/it] 22%|██▏       | 3904/17525 [47:01<8:04:18,  2.13s/it]  22%|██▏       | 3905/17525 [47:02<6:18:25,  1.67s/it] 22%|██▏       | 3906/17525 [47:03<5:04:31,  1.34s/it] 22%|██▏       | 3907/17525 [47:03<4:12:50,  1.11s/it] 22%|██▏       | 3908/17525 [47:04<3:36:23,  1.05it/s] 22%|██▏       | 3909/17525 [47:04<3:11:03,  1.19it/s] 22%|██▏       | 3910/17525 [47:05<2:53:17,  1.31it/s]                                                      {'loss': 0.6707, 'grad_norm': 14.552000999450684, 'learning_rate': 1.766620934633005e-05, 'epoch': 5.58}
 22%|██▏       | 3910/17525 [47:05<2:53:17,  1.31it/s] 22%|██▏       | 3911/17525 [47:06<2:41:31,  1.40it/s] 22%|██▏       | 3912/17525 [47:06<2:32:35,  1.49it/s] 22%|██▏       | 3913/17525 [47:07<2:26:06,  1.55it/s] 22%|██▏       | 3914/17525 [47:07<2:21:44,  1.60it/s] 22%|██▏       | 3915/17525 [47:08<2:18:42,  1.64it/s] 22%|██▏       | 3916/17525 [47:08<2:16:12,  1.67it/s] 22%|██▏       | 3917/17525 [47:09<2:14:52,  1.68it/s] 22%|██▏       | 3918/17525 [47:10<2:13:48,  1.69it/s] 22%|██▏       | 3919/17525 [47:10<2:13:11,  1.70it/s] 22%|██▏       | 3920/17525 [47:11<2:12:47,  1.71it/s]                                                      {'loss': 0.6278, 'grad_norm': 6.433883190155029, 'learning_rate': 1.7654673347693078e-05, 'epoch': 5.59}
 22%|██▏       | 3920/17525 [47:11<2:12:47,  1.71it/s] 22%|██▏       | 3921/17525 [47:11<2:12:50,  1.71it/s] 22%|██▏       | 3922/17525 [47:12<2:12:39,  1.71it/s] 22%|██▏       | 3923/17525 [47:12<2:12:04,  1.72it/s] 22%|██▏       | 3924/17525 [47:13<2:11:57,  1.72it/s] 22%|██▏       | 3925/17525 [47:14<2:12:17,  1.71it/s] 22%|██▏       | 3926/17525 [47:14<2:12:56,  1.70it/s] 22%|██▏       | 3927/17525 [47:15<2:13:08,  1.70it/s] 22%|██▏       | 3928/17525 [47:15<2:12:32,  1.71it/s] 22%|██▏       | 3929/17525 [47:16<2:12:08,  1.71it/s] 22%|██▏       | 3930/17525 [47:17<2:11:51,  1.72it/s]                                                      {'loss': 0.5029, 'grad_norm': 5.318560600280762, 'learning_rate': 1.764311269422333e-05, 'epoch': 5.61}
 22%|██▏       | 3930/17525 [47:17<2:11:51,  1.72it/s] 22%|██▏       | 3931/17525 [47:17<2:12:06,  1.72it/s] 22%|██▏       | 3932/17525 [47:18<2:11:56,  1.72it/s] 22%|██▏       | 3933/17525 [47:18<2:11:42,  1.72it/s] 22%|██▏       | 3934/17525 [47:19<2:11:23,  1.72it/s] 22%|██▏       | 3935/17525 [47:19<2:11:14,  1.73it/s] 22%|██▏       | 3936/17525 [47:20<2:11:28,  1.72it/s] 22%|██▏       | 3937/17525 [47:21<2:11:36,  1.72it/s] 22%|██▏       | 3938/17525 [47:21<2:11:37,  1.72it/s] 22%|██▏       | 3939/17525 [47:22<2:11:31,  1.72it/s] 22%|██▏       | 3940/17525 [47:22<2:11:26,  1.72it/s]                                                      {'loss': 0.6773, 'grad_norm': 9.95389461517334, 'learning_rate': 1.763152742315637e-05, 'epoch': 5.62}
 22%|██▏       | 3940/17525 [47:22<2:11:26,  1.72it/s] 22%|██▏       | 3941/17525 [47:23<2:11:23,  1.72it/s] 22%|██▏       | 3942/17525 [47:24<2:11:18,  1.72it/s] 22%|██▏       | 3943/17525 [47:24<2:11:15,  1.72it/s] 23%|██▎       | 3944/17525 [47:25<2:10:57,  1.73it/s] 23%|██▎       | 3945/17525 [47:25<2:10:53,  1.73it/s] 23%|██▎       | 3946/17525 [47:26<2:11:07,  1.73it/s] 23%|██▎       | 3947/17525 [47:26<2:10:59,  1.73it/s] 23%|██▎       | 3948/17525 [47:27<2:11:01,  1.73it/s] 23%|██▎       | 3949/17525 [47:28<2:11:30,  1.72it/s] 23%|██▎       | 3950/17525 [47:28<2:11:27,  1.72it/s]                                                      {'loss': 0.7147, 'grad_norm': 8.7549467086792, 'learning_rate': 1.7619917571807023e-05, 'epoch': 5.63}
 23%|██▎       | 3950/17525 [47:28<2:11:27,  1.72it/s] 23%|██▎       | 3951/17525 [47:29<2:11:33,  1.72it/s] 23%|██▎       | 3952/17525 [47:29<2:11:27,  1.72it/s] 23%|██▎       | 3953/17525 [47:30<2:11:22,  1.72it/s] 23%|██▎       | 3954/17525 [47:31<2:11:24,  1.72it/s] 23%|██▎       | 3955/17525 [47:31<2:21:27,  1.60it/s] 23%|██▎       | 3956/17525 [47:32<2:18:31,  1.63it/s] 23%|██▎       | 3957/17525 [47:32<2:16:15,  1.66it/s] 23%|██▎       | 3958/17525 [47:33<2:14:36,  1.68it/s] 23%|██▎       | 3959/17525 [47:34<2:13:43,  1.69it/s] 23%|██▎       | 3960/17525 [47:35<3:24:41,  1.10it/s]                                                      {'loss': 0.7136, 'grad_norm': 5.760511875152588, 'learning_rate': 1.7608283177569313e-05, 'epoch': 5.65}
 23%|██▎       | 3960/17525 [47:35<3:24:41,  1.10it/s] 23%|██▎       | 3961/17525 [47:36<3:02:46,  1.24it/s] 23%|██▎       | 3962/17525 [47:36<2:48:46,  1.34it/s] 23%|██▎       | 3963/17525 [47:37<2:37:24,  1.44it/s] 23%|██▎       | 3964/17525 [47:38<2:29:24,  1.51it/s] 23%|██▎       | 3965/17525 [47:38<2:23:59,  1.57it/s] 23%|██▎       | 3966/17525 [47:39<2:19:53,  1.62it/s] 23%|██▎       | 3967/17525 [47:39<2:17:29,  1.64it/s] 23%|██▎       | 3968/17525 [47:40<2:15:32,  1.67it/s] 23%|██▎       | 3969/17525 [47:40<2:14:29,  1.68it/s] 23%|██▎       | 3970/17525 [47:41<2:13:48,  1.69it/s]                                                      {'loss': 0.6323, 'grad_norm': 5.436862468719482, 'learning_rate': 1.7596624277916293e-05, 'epoch': 5.66}
 23%|██▎       | 3970/17525 [47:41<2:13:48,  1.69it/s] 23%|██▎       | 3971/17525 [47:42<2:13:26,  1.69it/s] 23%|██▎       | 3972/17525 [47:42<2:13:00,  1.70it/s] 23%|██▎       | 3973/17525 [47:43<2:12:43,  1.70it/s] 23%|██▎       | 3974/17525 [47:43<2:12:24,  1.71it/s] 23%|██▎       | 3975/17525 [47:44<2:12:02,  1.71it/s] 23%|██▎       | 3976/17525 [47:45<2:11:42,  1.71it/s] 23%|██▎       | 3977/17525 [47:45<2:23:39,  1.57it/s] 23%|██▎       | 3978/17525 [47:46<2:19:58,  1.61it/s] 23%|██▎       | 3979/17525 [47:46<2:17:31,  1.64it/s] 23%|██▎       | 3980/17525 [47:47<2:15:45,  1.66it/s]                                                      {'loss': 0.6876, 'grad_norm': 9.287540435791016, 'learning_rate': 1.7584940910399957e-05, 'epoch': 5.68}
 23%|██▎       | 3980/17525 [47:47<2:15:45,  1.66it/s] 23%|██▎       | 3981/17525 [47:48<2:14:38,  1.68it/s] 23%|██▎       | 3982/17525 [47:48<2:13:26,  1.69it/s] 23%|██▎       | 3983/17525 [47:49<2:13:17,  1.69it/s] 23%|██▎       | 3984/17525 [47:49<2:12:29,  1.70it/s] 23%|██▎       | 3985/17525 [47:50<2:12:00,  1.71it/s] 23%|██▎       | 3986/17525 [47:51<2:11:46,  1.71it/s] 23%|██▎       | 3987/17525 [47:51<2:11:15,  1.72it/s] 23%|██▎       | 3988/17525 [47:52<2:10:54,  1.72it/s] 23%|██▎       | 3989/17525 [47:53<3:05:24,  1.22it/s] 23%|██▎       | 3990/17525 [47:54<2:49:15,  1.33it/s]                                                      {'loss': 0.6547, 'grad_norm': 8.358716011047363, 'learning_rate': 1.757323311265111e-05, 'epoch': 5.69}
 23%|██▎       | 3990/17525 [47:54<2:49:15,  1.33it/s] 23%|██▎       | 3991/17525 [47:54<2:38:07,  1.43it/s] 23%|██▎       | 3992/17525 [47:55<2:30:07,  1.50it/s] 23%|██▎       | 3993/17525 [47:55<2:24:35,  1.56it/s] 23%|██▎       | 3994/17525 [47:56<2:20:39,  1.60it/s] 23%|██▎       | 3995/17525 [47:57<2:18:03,  1.63it/s] 23%|██▎       | 3996/17525 [47:57<2:16:00,  1.66it/s] 23%|██▎       | 3997/17525 [47:58<2:14:25,  1.68it/s] 23%|██▎       | 3998/17525 [47:59<3:25:20,  1.10it/s] 23%|██▎       | 3999/17525 [48:00<3:03:08,  1.23it/s] 23%|██▎       | 4000/17525 [48:01<2:47:14,  1.35it/s]                                                      {'loss': 0.6605, 'grad_norm': 12.034896850585938, 'learning_rate': 1.7561500922379226e-05, 'epoch': 5.71}
 23%|██▎       | 4000/17525 [48:01<2:47:14,  1.35it/s][INFO|trainer.py:3512] 2024-06-25 02:51:22,448 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:51:22,449 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:51:22,449 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                      
                                               [A{'eval_loss': 0.8786085844039917, 'eval_runtime': 4.5994, 'eval_samples_per_second': 96.318, 'eval_steps_per_second': 4.131, 'epoch': 5.71}
 23%|██▎       | 4000/17525 [48:05<2:47:14,  1.35it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 23%|██▎       | 4001/17525 [48:06<7:48:10,  2.08s/it] 23%|██▎       | 4002/17525 [48:06<6:06:55,  1.63s/it] 23%|██▎       | 4003/17525 [48:07<4:56:04,  1.31s/it] 23%|██▎       | 4004/17525 [48:07<4:06:36,  1.09s/it] 23%|██▎       | 4005/17525 [48:08<3:31:54,  1.06it/s] 23%|██▎       | 4006/17525 [48:09<3:08:03,  1.20it/s] 23%|██▎       | 4007/17525 [48:09<2:50:39,  1.32it/s] 23%|██▎       | 4008/17525 [48:10<2:38:42,  1.42it/s] 23%|██▎       | 4009/17525 [48:10<2:30:01,  1.50it/s] 23%|██▎       | 4010/17525 [48:11<2:48:54,  1.33it/s]                                                      {'loss': 0.7246, 'grad_norm': 5.5038299560546875, 'learning_rate': 1.754974437737236e-05, 'epoch': 5.72}
 23%|██▎       | 4010/17525 [48:11<2:48:54,  1.33it/s] 23%|██▎       | 4011/17525 [48:12<2:37:46,  1.43it/s] 23%|██▎       | 4012/17525 [48:13<2:29:38,  1.50it/s] 23%|██▎       | 4013/17525 [48:13<2:24:26,  1.56it/s] 23%|██▎       | 4014/17525 [48:14<2:43:29,  1.38it/s] 23%|██▎       | 4015/17525 [48:15<2:33:57,  1.46it/s] 23%|██▎       | 4016/17525 [48:15<2:27:34,  1.53it/s] 23%|██▎       | 4017/17525 [48:16<2:23:07,  1.57it/s] 23%|██▎       | 4018/17525 [48:16<2:19:26,  1.61it/s] 23%|██▎       | 4019/17525 [48:17<2:38:16,  1.42it/s] 23%|██▎       | 4020/17525 [48:18<2:30:09,  1.50it/s]                                                      {'loss': 0.6545, 'grad_norm': 11.089993476867676, 'learning_rate': 1.7537963515497014e-05, 'epoch': 5.73}
 23%|██▎       | 4020/17525 [48:18<2:30:09,  1.50it/s] 23%|██▎       | 4021/17525 [48:18<2:24:29,  1.56it/s] 23%|██▎       | 4022/17525 [48:19<2:20:36,  1.60it/s] 23%|██▎       | 4023/17525 [48:20<2:17:20,  1.64it/s] 23%|██▎       | 4024/17525 [48:20<2:15:13,  1.66it/s] 23%|██▎       | 4025/17525 [48:21<2:13:54,  1.68it/s] 23%|██▎       | 4026/17525 [48:21<2:12:52,  1.69it/s] 23%|██▎       | 4027/17525 [48:22<2:12:12,  1.70it/s] 23%|██▎       | 4028/17525 [48:22<2:11:46,  1.71it/s] 23%|██▎       | 4029/17525 [48:24<2:44:04,  1.37it/s] 23%|██▎       | 4030/17525 [48:24<2:34:17,  1.46it/s]                                                      {'loss': 0.565, 'grad_norm': 6.481344699859619, 'learning_rate': 1.7526158374697997e-05, 'epoch': 5.75}
 23%|██▎       | 4030/17525 [48:24<2:34:17,  1.46it/s] 23%|██▎       | 4031/17525 [48:25<2:28:18,  1.52it/s] 23%|██▎       | 4032/17525 [48:25<2:22:46,  1.58it/s] 23%|██▎       | 4033/17525 [48:26<2:19:44,  1.61it/s] 23%|██▎       | 4034/17525 [48:26<2:17:07,  1.64it/s] 23%|██▎       | 4035/17525 [48:27<2:15:31,  1.66it/s] 23%|██▎       | 4036/17525 [48:28<2:14:44,  1.67it/s] 23%|██▎       | 4037/17525 [48:28<2:13:15,  1.69it/s] 23%|██▎       | 4038/17525 [48:29<2:12:22,  1.70it/s] 23%|██▎       | 4039/17525 [48:29<2:11:53,  1.70it/s] 23%|██▎       | 4040/17525 [48:30<2:11:37,  1.71it/s]                                                      {'loss': 0.5054, 'grad_norm': 5.696126461029053, 'learning_rate': 1.751432899299833e-05, 'epoch': 5.76}
 23%|██▎       | 4040/17525 [48:30<2:11:37,  1.71it/s] 23%|██▎       | 4041/17525 [48:31<2:11:30,  1.71it/s] 23%|██▎       | 4042/17525 [48:31<2:11:24,  1.71it/s] 23%|██▎       | 4043/17525 [48:32<2:10:58,  1.72it/s] 23%|██▎       | 4044/17525 [48:32<2:10:53,  1.72it/s] 23%|██▎       | 4045/17525 [48:33<2:11:09,  1.71it/s] 23%|██▎       | 4046/17525 [48:33<2:10:42,  1.72it/s] 23%|██▎       | 4047/17525 [48:34<2:10:45,  1.72it/s] 23%|██▎       | 4048/17525 [48:35<2:10:38,  1.72it/s] 23%|██▎       | 4049/17525 [48:35<2:10:18,  1.72it/s] 23%|██▎       | 4050/17525 [48:36<2:10:28,  1.72it/s]                                                      {'loss': 0.6595, 'grad_norm': 7.161329746246338, 'learning_rate': 1.7502475408499107e-05, 'epoch': 5.78}
 23%|██▎       | 4050/17525 [48:36<2:10:28,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 02:51:57,695 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a12f10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 0cc44763-2d32-4ab7-9deb-b0c649a64108)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:52:07,812 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:52:07,814 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 23%|██▎       | 4051/17525 [48:47<13:41:08,  3.66s/it] 23%|██▎       | 4052/17525 [48:47<10:13:44,  2.73s/it] 23%|██▎       | 4053/17525 [48:48<7:50:16,  2.09s/it]  23%|██▎       | 4054/17525 [48:48<6:08:05,  1.64s/it] 23%|██▎       | 4055/17525 [48:49<4:56:49,  1.32s/it] 23%|██▎       | 4056/17525 [48:50<4:08:10,  1.11s/it] 23%|██▎       | 4057/17525 [48:50<3:32:33,  1.06it/s] 23%|██▎       | 4058/17525 [48:51<3:07:59,  1.19it/s] 23%|██▎       | 4059/17525 [48:51<2:50:29,  1.32it/s] 23%|██▎       | 4060/17525 [48:52<2:38:27,  1.42it/s]                                                      {'loss': 0.6343, 'grad_norm': 7.7557244300842285, 'learning_rate': 1.7490597659379374e-05, 'epoch': 5.79}
 23%|██▎       | 4060/17525 [48:52<2:38:27,  1.42it/s] 23%|██▎       | 4061/17525 [48:52<2:29:49,  1.50it/s] 23%|██▎       | 4062/17525 [48:53<2:23:39,  1.56it/s] 23%|██▎       | 4063/17525 [48:54<2:20:37,  1.60it/s] 23%|██▎       | 4064/17525 [48:54<2:17:24,  1.63it/s] 23%|██▎       | 4065/17525 [48:55<2:14:57,  1.66it/s] 23%|██▎       | 4066/17525 [48:55<2:13:09,  1.68it/s] 23%|██▎       | 4067/17525 [48:56<2:12:02,  1.70it/s] 23%|██▎       | 4068/17525 [48:57<2:11:24,  1.71it/s] 23%|██▎       | 4069/17525 [48:57<2:10:56,  1.71it/s] 23%|██▎       | 4070/17525 [48:58<2:10:34,  1.72it/s]                                                      {'loss': 0.5459, 'grad_norm': 14.51995849609375, 'learning_rate': 1.7478695783896008e-05, 'epoch': 5.81}
 23%|██▎       | 4070/17525 [48:58<2:10:34,  1.72it/s] 23%|██▎       | 4071/17525 [48:58<2:10:46,  1.71it/s] 23%|██▎       | 4072/17525 [48:59<2:10:44,  1.71it/s] 23%|██▎       | 4073/17525 [48:59<2:10:38,  1.72it/s] 23%|██▎       | 4074/17525 [49:00<2:09:49,  1.73it/s] 23%|██▎       | 4075/17525 [49:01<2:09:36,  1.73it/s] 23%|██▎       | 4076/17525 [49:01<2:09:41,  1.73it/s] 23%|██▎       | 4077/17525 [49:02<2:09:58,  1.72it/s] 23%|██▎       | 4078/17525 [49:02<2:09:39,  1.73it/s] 23%|██▎       | 4079/17525 [49:03<2:09:27,  1.73it/s] 23%|██▎       | 4080/17525 [49:03<2:09:12,  1.73it/s]                                                      {'loss': 0.5647, 'grad_norm': 12.808476448059082, 'learning_rate': 1.7466769820383606e-05, 'epoch': 5.82}
 23%|██▎       | 4080/17525 [49:03<2:09:12,  1.73it/s] 23%|██▎       | 4081/17525 [49:04<2:09:30,  1.73it/s] 23%|██▎       | 4082/17525 [49:05<2:09:21,  1.73it/s] 23%|██▎       | 4083/17525 [49:05<2:09:29,  1.73it/s] 23%|██▎       | 4084/17525 [49:06<2:09:26,  1.73it/s] 23%|██▎       | 4085/17525 [49:06<2:09:14,  1.73it/s] 23%|██▎       | 4086/17525 [49:07<2:09:05,  1.74it/s] 23%|██▎       | 4087/17525 [49:08<2:09:19,  1.73it/s] 23%|██▎       | 4088/17525 [49:08<2:09:29,  1.73it/s] 23%|██▎       | 4089/17525 [49:09<2:09:25,  1.73it/s] 23%|██▎       | 4090/17525 [49:09<2:09:31,  1.73it/s]                                                      {'loss': 0.5958, 'grad_norm': 11.432719230651855, 'learning_rate': 1.745481980725433e-05, 'epoch': 5.83}
 23%|██▎       | 4090/17525 [49:09<2:09:31,  1.73it/s] 23%|██▎       | 4091/17525 [49:10<2:09:29,  1.73it/s] 23%|██▎       | 4092/17525 [49:10<2:09:18,  1.73it/s] 23%|██▎       | 4093/17525 [49:11<2:09:20,  1.73it/s] 23%|██▎       | 4094/17525 [49:12<2:09:12,  1.73it/s] 23%|██▎       | 4095/17525 [49:12<2:09:14,  1.73it/s] 23%|██▎       | 4096/17525 [49:13<2:09:21,  1.73it/s] 23%|██▎       | 4097/17525 [49:13<2:08:59,  1.73it/s] 23%|██▎       | 4098/17525 [49:14<2:08:47,  1.74it/s] 23%|██▎       | 4099/17525 [49:14<2:08:51,  1.74it/s] 23%|██▎       | 4100/17525 [49:15<2:08:56,  1.74it/s]                                                      {'loss': 0.7318, 'grad_norm': 9.870573997497559, 'learning_rate': 1.7442845782997827e-05, 'epoch': 5.85}
 23%|██▎       | 4100/17525 [49:15<2:08:56,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 02:52:36,914 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:52:36,914 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:52:36,914 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8765724301338196, 'eval_runtime': 4.5958, 'eval_samples_per_second': 96.393, 'eval_steps_per_second': 4.134, 'epoch': 5.85}
 23%|██▎       | 4100/17525 [49:20<2:08:56,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 23%|██▎       | 4101/17525 [49:20<7:20:02,  1.97s/it] 23%|██▎       | 4102/17525 [49:21<5:47:24,  1.55s/it] 23%|██▎       | 4103/17525 [49:21<4:42:09,  1.26s/it] 23%|██▎       | 4104/17525 [49:22<3:56:35,  1.06s/it] 23%|██▎       | 4105/17525 [49:23<3:25:01,  1.09it/s] 23%|██▎       | 4106/17525 [49:23<3:02:47,  1.22it/s] 23%|██▎       | 4107/17525 [49:24<2:47:00,  1.34it/s] 23%|██▎       | 4108/17525 [49:24<2:36:00,  1.43it/s] 23%|██▎       | 4109/17525 [49:25<2:28:10,  1.51it/s] 23%|██▎       | 4110/17525 [49:25<2:22:42,  1.57it/s]                                                      {'loss': 0.4923, 'grad_norm': 8.032609939575195, 'learning_rate': 1.7430847786181055e-05, 'epoch': 5.86}
 23%|██▎       | 4110/17525 [49:25<2:22:42,  1.57it/s] 23%|██▎       | 4111/17525 [49:26<2:20:21,  1.59it/s] 23%|██▎       | 4112/17525 [49:27<2:17:05,  1.63it/s] 23%|██▎       | 4113/17525 [49:27<2:14:58,  1.66it/s] 23%|██▎       | 4114/17525 [49:28<2:13:29,  1.67it/s] 23%|██▎       | 4115/17525 [49:28<2:12:40,  1.68it/s] 23%|██▎       | 4116/17525 [49:29<2:11:46,  1.70it/s] 23%|██▎       | 4117/17525 [49:30<2:11:08,  1.70it/s] 23%|██▎       | 4118/17525 [49:30<2:10:32,  1.71it/s] 24%|██▎       | 4119/17525 [49:31<2:10:14,  1.72it/s] 24%|██▎       | 4120/17525 [49:31<2:10:11,  1.72it/s]                                                      {'loss': 0.6917, 'grad_norm': 6.106341361999512, 'learning_rate': 1.7418825855448208e-05, 'epoch': 5.88}
 24%|██▎       | 4120/17525 [49:31<2:10:11,  1.72it/s] 24%|██▎       | 4121/17525 [49:32<2:11:34,  1.70it/s] 24%|██▎       | 4122/17525 [49:32<2:10:51,  1.71it/s] 24%|██▎       | 4123/17525 [49:33<2:10:27,  1.71it/s] 24%|██▎       | 4124/17525 [49:34<2:10:16,  1.71it/s] 24%|██▎       | 4125/17525 [49:34<2:10:36,  1.71it/s] 24%|██▎       | 4126/17525 [49:35<2:10:36,  1.71it/s] 24%|██▎       | 4127/17525 [49:35<2:10:26,  1.71it/s] 24%|██▎       | 4128/17525 [49:36<2:10:23,  1.71it/s] 24%|██▎       | 4129/17525 [49:37<2:10:06,  1.72it/s] 24%|██▎       | 4130/17525 [49:37<2:10:10,  1.72it/s]                                                      {'loss': 0.6371, 'grad_norm': 12.514571189880371, 'learning_rate': 1.740678002952055e-05, 'epoch': 5.89}
 24%|██▎       | 4130/17525 [49:37<2:10:10,  1.72it/s] 24%|██▎       | 4131/17525 [49:38<2:10:26,  1.71it/s] 24%|██▎       | 4132/17525 [49:38<2:10:32,  1.71it/s] 24%|██▎       | 4133/17525 [49:39<2:10:23,  1.71it/s] 24%|██▎       | 4134/17525 [49:39<2:10:16,  1.71it/s] 24%|██▎       | 4135/17525 [49:40<2:10:32,  1.71it/s] 24%|██▎       | 4136/17525 [49:41<2:10:16,  1.71it/s] 24%|██▎       | 4137/17525 [49:41<2:10:17,  1.71it/s] 24%|██▎       | 4138/17525 [49:42<2:10:16,  1.71it/s] 24%|██▎       | 4139/17525 [49:42<2:12:22,  1.69it/s] 24%|██▎       | 4140/17525 [49:43<2:39:56,  1.39it/s]                                                      {'loss': 0.5879, 'grad_norm': 9.203505516052246, 'learning_rate': 1.739471034719632e-05, 'epoch': 5.91}
 24%|██▎       | 4140/17525 [49:43<2:39:56,  1.39it/s] 24%|██▎       | 4141/17525 [49:44<2:31:07,  1.48it/s] 24%|██▎       | 4142/17525 [49:45<2:24:52,  1.54it/s] 24%|██▎       | 4143/17525 [49:45<2:20:30,  1.59it/s] 24%|██▎       | 4144/17525 [49:46<2:17:15,  1.62it/s] 24%|██▎       | 4145/17525 [49:47<2:24:51,  1.54it/s] 24%|██▎       | 4146/17525 [49:47<2:20:30,  1.59it/s] 24%|██▎       | 4147/17525 [49:48<3:08:45,  1.18it/s] 24%|██▎       | 4148/17525 [49:49<2:51:13,  1.30it/s] 24%|██▎       | 4149/17525 [49:50<2:40:25,  1.39it/s] 24%|██▎       | 4150/17525 [49:50<2:30:56,  1.48it/s]                                                      {'loss': 0.5808, 'grad_norm': 10.922821044921875, 'learning_rate': 1.73826168473506e-05, 'epoch': 5.92}
 24%|██▎       | 4150/17525 [49:50<2:30:56,  1.48it/s] 24%|██▎       | 4151/17525 [49:51<2:24:51,  1.54it/s] 24%|██▎       | 4152/17525 [49:51<2:20:14,  1.59it/s] 24%|██▎       | 4153/17525 [49:52<2:16:52,  1.63it/s] 24%|██▎       | 4154/17525 [49:53<2:14:37,  1.66it/s] 24%|██▎       | 4155/17525 [49:53<2:14:59,  1.65it/s] 24%|██▎       | 4156/17525 [49:54<2:13:14,  1.67it/s] 24%|██▎       | 4157/17525 [49:54<2:12:16,  1.68it/s] 24%|██▎       | 4158/17525 [49:55<2:11:18,  1.70it/s] 24%|██▎       | 4159/17525 [49:55<2:10:42,  1.70it/s] 24%|██▎       | 4160/17525 [49:56<2:10:25,  1.71it/s]                                                      {'loss': 0.6729, 'grad_norm': 12.117010116577148, 'learning_rate': 1.7370499568935168e-05, 'epoch': 5.93}
 24%|██▎       | 4160/17525 [49:56<2:10:25,  1.71it/s] 24%|██▎       | 4161/17525 [49:57<2:10:19,  1.71it/s] 24%|██▎       | 4162/17525 [49:57<2:10:08,  1.71it/s] 24%|██▍       | 4163/17525 [49:58<2:10:15,  1.71it/s] 24%|██▍       | 4164/17525 [49:58<2:09:42,  1.72it/s] 24%|██▍       | 4165/17525 [49:59<2:09:14,  1.72it/s] 24%|██▍       | 4166/17525 [50:00<2:09:24,  1.72it/s] 24%|██▍       | 4167/17525 [50:00<2:09:10,  1.72it/s] 24%|██▍       | 4168/17525 [50:01<2:08:57,  1.73it/s] 24%|██▍       | 4169/17525 [50:01<2:08:50,  1.73it/s] 24%|██▍       | 4170/17525 [50:02<2:10:19,  1.71it/s]                                                      {'loss': 0.5863, 'grad_norm': 5.452136039733887, 'learning_rate': 1.735835855097841e-05, 'epoch': 5.95}
 24%|██▍       | 4170/17525 [50:02<2:10:19,  1.71it/s] 24%|██▍       | 4171/17525 [50:02<2:09:53,  1.71it/s] 24%|██▍       | 4172/17525 [50:03<2:09:17,  1.72it/s] 24%|██▍       | 4173/17525 [50:04<2:09:02,  1.72it/s] 24%|██▍       | 4174/17525 [50:04<2:09:11,  1.72it/s] 24%|██▍       | 4175/17525 [50:05<2:09:08,  1.72it/s] 24%|██▍       | 4176/17525 [50:05<2:09:14,  1.72it/s] 24%|██▍       | 4177/17525 [50:06<2:09:16,  1.72it/s] 24%|██▍       | 4178/17525 [50:07<2:09:12,  1.72it/s] 24%|██▍       | 4179/17525 [50:07<2:08:59,  1.72it/s] 24%|██▍       | 4180/17525 [50:08<2:08:42,  1.73it/s]                                                      {'loss': 0.6487, 'grad_norm': 17.46473503112793, 'learning_rate': 1.7346193832585155e-05, 'epoch': 5.96}
 24%|██▍       | 4180/17525 [50:08<2:08:42,  1.73it/s] 24%|██▍       | 4181/17525 [50:08<2:08:45,  1.73it/s] 24%|██▍       | 4182/17525 [50:09<2:08:32,  1.73it/s] 24%|██▍       | 4183/17525 [50:09<2:08:27,  1.73it/s] 24%|██▍       | 4184/17525 [50:10<2:08:30,  1.73it/s] 24%|██▍       | 4185/17525 [50:11<2:08:14,  1.73it/s] 24%|██▍       | 4186/17525 [50:11<2:08:37,  1.73it/s] 24%|██▍       | 4187/17525 [50:12<2:33:15,  1.45it/s] 24%|██▍       | 4188/17525 [50:13<2:26:22,  1.52it/s] 24%|██▍       | 4189/17525 [50:13<2:21:32,  1.57it/s] 24%|██▍       | 4190/17525 [50:14<2:18:15,  1.61it/s]                                                      {'loss': 0.6259, 'grad_norm': 11.373626708984375, 'learning_rate': 1.7334005452936585e-05, 'epoch': 5.98}
 24%|██▍       | 4190/17525 [50:14<2:18:15,  1.61it/s] 24%|██▍       | 4191/17525 [50:14<2:16:20,  1.63it/s] 24%|██▍       | 4192/17525 [50:15<2:14:42,  1.65it/s] 24%|██▍       | 4193/17525 [50:16<2:13:20,  1.67it/s] 24%|██▍       | 4194/17525 [50:16<2:14:09,  1.66it/s] 24%|██▍       | 4195/17525 [50:17<2:13:03,  1.67it/s] 24%|██▍       | 4196/17525 [50:17<2:12:15,  1.68it/s] 24%|██▍       | 4197/17525 [50:18<2:11:41,  1.69it/s] 24%|██▍       | 4198/17525 [50:19<2:11:10,  1.69it/s] 24%|██▍       | 4199/17525 [50:19<2:11:03,  1.69it/s] 24%|██▍       | 4200/17525 [50:20<2:10:38,  1.70it/s]                                                      {'loss': 0.5654, 'grad_norm': 4.796290397644043, 'learning_rate': 1.7321793451290082e-05, 'epoch': 5.99}
 24%|██▍       | 4200/17525 [50:20<2:10:38,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:53:41,657 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:53:41,658 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:53:41,658 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8774102330207825, 'eval_runtime': 4.6045, 'eval_samples_per_second': 96.21, 'eval_steps_per_second': 4.126, 'epoch': 5.99}
 24%|██▍       | 4200/17525 [50:24<2:10:38,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:53:46,266 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a799d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a9769967-ac47-4193-b647-5e4829b1188f)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:53:56,331 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:53:56,354 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 24%|██▍       | 4201/17525 [50:35<18:38:19,  5.04s/it] 24%|██▍       | 4202/17525 [50:36<13:41:53,  3.70s/it] 24%|██▍       | 4203/17525 [50:37<10:25:51,  2.82s/it] 24%|██▍       | 4204/17525 [50:37<7:56:56,  2.15s/it]  24%|██▍       | 4205/17525 [50:38<6:12:59,  1.68s/it] 24%|██▍       | 4206/17525 [50:38<5:00:09,  1.35s/it] 24%|██▍       | 4207/17525 [50:39<4:09:23,  1.12s/it] 24%|██▍       | 4208/17525 [50:39<3:33:45,  1.04it/s] 24%|██▍       | 4209/17525 [50:40<3:08:38,  1.18it/s] 24%|██▍       | 4210/17525 [50:41<3:44:04,  1.01s/it]                                                      {'loss': 0.6155, 'grad_norm': 7.1619720458984375, 'learning_rate': 1.7309557866979113e-05, 'epoch': 6.01}
 24%|██▍       | 4210/17525 [50:41<3:44:04,  1.01s/it] 24%|██▍       | 4211/17525 [50:42<3:16:14,  1.13it/s] 24%|██▍       | 4212/17525 [50:43<3:48:34,  1.03s/it] 24%|██▍       | 4213/17525 [50:44<3:19:00,  1.11it/s] 24%|██▍       | 4214/17525 [50:45<2:58:08,  1.25it/s] 24%|██▍       | 4215/17525 [50:45<2:43:32,  1.36it/s] 24%|██▍       | 4216/17525 [50:46<2:33:09,  1.45it/s] 24%|██▍       | 4217/17525 [50:46<2:25:45,  1.52it/s] 24%|██▍       | 4218/17525 [50:47<2:20:39,  1.58it/s] 24%|██▍       | 4219/17525 [50:47<2:17:17,  1.62it/s] 24%|██▍       | 4220/17525 [50:48<2:14:55,  1.64it/s]                                                      {'loss': 0.548, 'grad_norm': 4.894312858581543, 'learning_rate': 1.7297298739413114e-05, 'epoch': 6.02}
 24%|██▍       | 4220/17525 [50:48<2:14:55,  1.64it/s] 24%|██▍       | 4221/17525 [50:49<2:13:05,  1.67it/s] 24%|██▍       | 4222/17525 [50:49<2:11:44,  1.68it/s] 24%|██▍       | 4223/17525 [50:50<2:10:37,  1.70it/s] 24%|██▍       | 4224/17525 [50:50<2:10:12,  1.70it/s] 24%|██▍       | 4225/17525 [50:51<2:09:51,  1.71it/s] 24%|██▍       | 4226/17525 [50:52<2:09:20,  1.71it/s] 24%|██▍       | 4227/17525 [50:52<2:11:40,  1.68it/s] 24%|██▍       | 4228/17525 [50:53<2:10:43,  1.70it/s] 24%|██▍       | 4229/17525 [50:53<2:10:00,  1.70it/s] 24%|██▍       | 4230/17525 [50:54<2:09:37,  1.71it/s]                                                      {'loss': 0.6083, 'grad_norm': 8.93569278717041, 'learning_rate': 1.728501610807733e-05, 'epoch': 6.03}
 24%|██▍       | 4230/17525 [50:54<2:09:37,  1.71it/s] 24%|██▍       | 4231/17525 [50:54<2:09:22,  1.71it/s] 24%|██▍       | 4232/17525 [50:55<2:08:47,  1.72it/s] 24%|██▍       | 4233/17525 [50:56<2:08:43,  1.72it/s] 24%|██▍       | 4234/17525 [50:56<2:09:28,  1.71it/s] 24%|██▍       | 4235/17525 [50:57<2:09:25,  1.71it/s] 24%|██▍       | 4236/17525 [50:57<2:09:53,  1.71it/s] 24%|██▍       | 4237/17525 [50:58<2:09:33,  1.71it/s] 24%|██▍       | 4238/17525 [50:59<2:09:06,  1.72it/s] 24%|██▍       | 4239/17525 [50:59<2:08:44,  1.72it/s] 24%|██▍       | 4240/17525 [51:00<2:08:51,  1.72it/s]                                                      {'loss': 0.5759, 'grad_norm': 7.846548080444336, 'learning_rate': 1.7272710012532732e-05, 'epoch': 6.05}
 24%|██▍       | 4240/17525 [51:00<2:08:51,  1.72it/s] 24%|██▍       | 4241/17525 [51:00<2:08:49,  1.72it/s] 24%|██▍       | 4242/17525 [51:01<2:08:44,  1.72it/s] 24%|██▍       | 4243/17525 [51:01<2:08:34,  1.72it/s] 24%|██▍       | 4244/17525 [51:02<2:09:17,  1.71it/s] 24%|██▍       | 4245/17525 [51:03<2:09:06,  1.71it/s] 24%|██▍       | 4246/17525 [51:03<2:09:00,  1.72it/s] 24%|██▍       | 4247/17525 [51:04<2:08:41,  1.72it/s] 24%|██▍       | 4248/17525 [51:04<2:08:30,  1.72it/s] 24%|██▍       | 4249/17525 [51:05<2:08:18,  1.72it/s] 24%|██▍       | 4250/17525 [51:06<2:08:12,  1.73it/s]                                                      {'loss': 0.5718, 'grad_norm': 10.692265510559082, 'learning_rate': 1.726038049241584e-05, 'epoch': 6.06}
 24%|██▍       | 4250/17525 [51:06<2:08:12,  1.73it/s] 24%|██▍       | 4251/17525 [51:06<2:08:04,  1.73it/s] 24%|██▍       | 4252/17525 [51:07<2:07:47,  1.73it/s] 24%|██▍       | 4253/17525 [51:07<2:07:36,  1.73it/s] 24%|██▍       | 4254/17525 [51:08<2:07:55,  1.73it/s] 24%|██▍       | 4255/17525 [51:08<2:07:54,  1.73it/s] 24%|██▍       | 4256/17525 [51:09<2:07:53,  1.73it/s] 24%|██▍       | 4257/17525 [51:10<2:07:37,  1.73it/s] 24%|██▍       | 4258/17525 [51:10<2:07:31,  1.73it/s] 24%|██▍       | 4259/17525 [51:11<2:07:33,  1.73it/s] 24%|██▍       | 4260/17525 [51:11<2:07:22,  1.74it/s]                                                      {'loss': 0.6392, 'grad_norm': 8.12126636505127, 'learning_rate': 1.7248027587438652e-05, 'epoch': 6.08}
 24%|██▍       | 4260/17525 [51:11<2:07:22,  1.74it/s] 24%|██▍       | 4261/17525 [51:12<2:07:28,  1.73it/s] 24%|██▍       | 4262/17525 [51:12<2:07:19,  1.74it/s] 24%|██▍       | 4263/17525 [51:13<2:07:17,  1.74it/s] 24%|██▍       | 4264/17525 [51:14<2:07:24,  1.73it/s] 24%|██▍       | 4265/17525 [51:14<2:07:36,  1.73it/s] 24%|██▍       | 4266/17525 [51:15<2:07:26,  1.73it/s] 24%|██▍       | 4267/17525 [51:15<2:09:14,  1.71it/s] 24%|██▍       | 4268/17525 [51:16<2:08:36,  1.72it/s] 24%|██▍       | 4269/17525 [51:17<2:08:05,  1.72it/s] 24%|██▍       | 4270/17525 [51:18<3:16:49,  1.12it/s]                                                      {'loss': 0.5378, 'grad_norm': 13.270578384399414, 'learning_rate': 1.7235651337388467e-05, 'epoch': 6.09}
 24%|██▍       | 4270/17525 [51:18<3:16:49,  1.12it/s] 24%|██▍       | 4271/17525 [51:19<2:55:48,  1.26it/s] 24%|██▍       | 4272/17525 [51:19<2:41:05,  1.37it/s] 24%|██▍       | 4273/17525 [51:20<2:30:39,  1.47it/s] 24%|██▍       | 4274/17525 [51:20<2:24:00,  1.53it/s] 24%|██▍       | 4275/17525 [51:21<2:19:12,  1.59it/s] 24%|██▍       | 4276/17525 [51:22<2:15:31,  1.63it/s] 24%|██▍       | 4277/17525 [51:22<2:13:13,  1.66it/s] 24%|██▍       | 4278/17525 [51:23<2:11:20,  1.68it/s] 24%|██▍       | 4279/17525 [51:23<2:21:03,  1.57it/s] 24%|██▍       | 4280/17525 [51:24<2:17:05,  1.61it/s]                                                      {'loss': 0.5343, 'grad_norm': 14.684488296508789, 'learning_rate': 1.722325178212777e-05, 'epoch': 6.11}
 24%|██▍       | 4280/17525 [51:24<2:17:05,  1.61it/s] 24%|██▍       | 4281/17525 [51:25<2:14:01,  1.65it/s] 24%|██▍       | 4282/17525 [51:25<2:11:56,  1.67it/s] 24%|██▍       | 4283/17525 [51:26<2:10:29,  1.69it/s] 24%|██▍       | 4284/17525 [51:26<2:10:56,  1.69it/s] 24%|██▍       | 4285/17525 [51:27<2:09:51,  1.70it/s] 24%|██▍       | 4286/17525 [51:28<2:32:13,  1.45it/s] 24%|██▍       | 4287/17525 [51:28<2:24:45,  1.52it/s] 24%|██▍       | 4288/17525 [51:29<2:19:37,  1.58it/s] 24%|██▍       | 4289/17525 [51:30<2:16:34,  1.62it/s] 24%|██▍       | 4290/17525 [51:30<2:13:47,  1.65it/s]                                                      {'loss': 0.5818, 'grad_norm': 13.116837501525879, 'learning_rate': 1.721082896159413e-05, 'epoch': 6.12}
 24%|██▍       | 4290/17525 [51:30<2:13:47,  1.65it/s] 24%|██▍       | 4291/17525 [51:31<2:11:53,  1.67it/s] 24%|██▍       | 4292/17525 [51:31<2:10:17,  1.69it/s] 24%|██▍       | 4293/17525 [51:32<2:09:12,  1.71it/s] 25%|██▍       | 4294/17525 [51:33<2:08:59,  1.71it/s] 25%|██▍       | 4295/17525 [51:33<2:08:18,  1.72it/s] 25%|██▍       | 4296/17525 [51:34<2:09:36,  1.70it/s] 25%|██▍       | 4297/17525 [51:34<2:08:36,  1.71it/s] 25%|██▍       | 4298/17525 [51:35<2:08:19,  1.72it/s] 25%|██▍       | 4299/17525 [51:35<2:07:50,  1.72it/s] 25%|██▍       | 4300/17525 [51:36<2:07:42,  1.73it/s]                                                      {'loss': 0.6261, 'grad_norm': 16.106815338134766, 'learning_rate': 1.7198382915800034e-05, 'epoch': 6.13}
 25%|██▍       | 4300/17525 [51:36<2:07:42,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 02:54:57,895 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:54:57,895 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:54:57,895 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8805615901947021, 'eval_runtime': 4.6037, 'eval_samples_per_second': 96.227, 'eval_steps_per_second': 4.127, 'epoch': 6.13}
 25%|██▍       | 4300/17525 [51:41<2:07:42,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 25%|██▍       | 4301/17525 [51:41<7:12:32,  1.96s/it] 25%|██▍       | 4302/17525 [51:42<5:40:29,  1.55s/it] 25%|██▍       | 4303/17525 [51:42<4:35:57,  1.25s/it] 25%|██▍       | 4304/17525 [51:43<3:51:14,  1.05s/it] 25%|██▍       | 4305/17525 [51:43<3:19:51,  1.10it/s] 25%|██▍       | 4306/17525 [51:44<2:57:53,  1.24it/s] 25%|██▍       | 4307/17525 [51:45<2:42:34,  1.36it/s] 25%|██▍       | 4308/17525 [51:45<2:31:47,  1.45it/s] 25%|██▍       | 4309/17525 [51:46<2:24:14,  1.53it/s] 25%|██▍       | 4310/17525 [51:46<2:18:57,  1.59it/s]                                                      {'loss': 0.5625, 'grad_norm': 8.345218658447266, 'learning_rate': 1.7185913684832782e-05, 'epoch': 6.15}
 25%|██▍       | 4310/17525 [51:46<2:18:57,  1.59it/s] 25%|██▍       | 4311/17525 [51:47<2:15:31,  1.63it/s] 25%|██▍       | 4312/17525 [51:48<2:12:41,  1.66it/s] 25%|██▍       | 4313/17525 [51:48<2:10:36,  1.69it/s] 25%|██▍       | 4314/17525 [51:49<2:09:26,  1.70it/s] 25%|██▍       | 4315/17525 [51:49<2:08:31,  1.71it/s] 25%|██▍       | 4316/17525 [51:50<2:07:45,  1.72it/s] 25%|██▍       | 4317/17525 [51:50<2:07:30,  1.73it/s] 25%|██▍       | 4318/17525 [51:51<2:07:14,  1.73it/s] 25%|██▍       | 4319/17525 [51:52<2:07:01,  1.73it/s] 25%|██▍       | 4320/17525 [51:52<2:07:03,  1.73it/s]                                                      {'loss': 0.6778, 'grad_norm': 5.864658355712891, 'learning_rate': 1.7173421308854353e-05, 'epoch': 6.16}
 25%|██▍       | 4320/17525 [51:52<2:07:03,  1.73it/s] 25%|██▍       | 4321/17525 [51:53<2:06:54,  1.73it/s] 25%|██▍       | 4322/17525 [51:53<2:06:41,  1.74it/s] 25%|██▍       | 4323/17525 [51:54<2:06:34,  1.74it/s] 25%|██▍       | 4324/17525 [51:54<2:06:20,  1.74it/s] 25%|██▍       | 4325/17525 [51:55<2:38:25,  1.39it/s] 25%|██▍       | 4326/17525 [51:56<2:28:57,  1.48it/s] 25%|██▍       | 4327/17525 [51:57<2:22:06,  1.55it/s] 25%|██▍       | 4328/17525 [51:57<2:17:13,  1.60it/s] 25%|██▍       | 4329/17525 [51:58<2:14:14,  1.64it/s] 25%|██▍       | 4330/17525 [51:58<2:11:47,  1.67it/s]                                                      {'loss': 0.5959, 'grad_norm': 14.829180717468262, 'learning_rate': 1.7160905828101263e-05, 'epoch': 6.18}
 25%|██▍       | 4330/17525 [51:58<2:11:47,  1.67it/s] 25%|██▍       | 4331/17525 [51:59<2:10:17,  1.69it/s] 25%|██▍       | 4332/17525 [51:59<2:09:00,  1.70it/s] 25%|██▍       | 4333/17525 [52:00<2:08:18,  1.71it/s] 25%|██▍       | 4334/17525 [52:01<2:07:49,  1.72it/s] 25%|██▍       | 4335/17525 [52:01<2:07:19,  1.73it/s] 25%|██▍       | 4336/17525 [52:02<2:07:08,  1.73it/s] 25%|██▍       | 4337/17525 [52:02<2:06:48,  1.73it/s] 25%|██▍       | 4338/17525 [52:03<2:06:40,  1.73it/s] 25%|██▍       | 4339/17525 [52:04<2:30:18,  1.46it/s] 25%|██▍       | 4340/17525 [52:04<2:22:55,  1.54it/s]                                                      {'loss': 0.4972, 'grad_norm': 15.200481414794922, 'learning_rate': 1.714836728288446e-05, 'epoch': 6.19}
 25%|██▍       | 4340/17525 [52:04<2:22:55,  1.54it/s] 25%|██▍       | 4341/17525 [52:05<2:18:07,  1.59it/s] 25%|██▍       | 4342/17525 [52:06<2:14:39,  1.63it/s] 25%|██▍       | 4343/17525 [52:06<2:12:04,  1.66it/s] 25%|██▍       | 4344/17525 [52:07<2:10:07,  1.69it/s] 25%|██▍       | 4345/17525 [52:07<2:08:51,  1.70it/s] 25%|██▍       | 4346/17525 [52:08<2:07:51,  1.72it/s] 25%|██▍       | 4347/17525 [52:08<2:07:17,  1.73it/s] 25%|██▍       | 4348/17525 [52:09<2:06:53,  1.73it/s] 25%|██▍       | 4349/17525 [52:10<2:06:49,  1.73it/s] 25%|██▍       | 4350/17525 [52:10<2:06:34,  1.73it/s]                                                      {'loss': 0.5953, 'grad_norm': 6.243561267852783, 'learning_rate': 1.7135805713589174e-05, 'epoch': 6.21}
 25%|██▍       | 4350/17525 [52:10<2:06:34,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 02:55:32,082 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79cd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 9ec98d21-612a-431f-8c35-f27c9b816317)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:55:42,136 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:55:42,138 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 25%|██▍       | 4351/17525 [52:21<13:16:58,  3.63s/it] 25%|██▍       | 4352/17525 [52:22<9:55:30,  2.71s/it]  25%|██▍       | 4353/17525 [52:22<7:34:44,  2.07s/it] 25%|██▍       | 4354/17525 [52:23<5:56:09,  1.62s/it] 25%|██▍       | 4355/17525 [52:23<4:47:09,  1.31s/it] 25%|██▍       | 4356/17525 [52:24<3:58:40,  1.09s/it] 25%|██▍       | 4357/17525 [52:24<3:24:42,  1.07it/s] 25%|██▍       | 4358/17525 [52:25<3:01:12,  1.21it/s] 25%|██▍       | 4359/17525 [52:26<2:44:35,  1.33it/s] 25%|██▍       | 4360/17525 [52:26<2:33:09,  1.43it/s]                                                      {'loss': 0.4841, 'grad_norm': 4.702234268188477, 'learning_rate': 1.7123221160674784e-05, 'epoch': 6.22}
 25%|██▍       | 4360/17525 [52:26<2:33:09,  1.43it/s] 25%|██▍       | 4361/17525 [52:27<2:25:02,  1.51it/s] 25%|██▍       | 4362/17525 [52:27<2:19:17,  1.58it/s] 25%|██▍       | 4363/17525 [52:28<2:15:25,  1.62it/s] 25%|██▍       | 4364/17525 [52:28<2:12:31,  1.66it/s] 25%|██▍       | 4365/17525 [52:29<2:12:23,  1.66it/s] 25%|██▍       | 4366/17525 [52:30<2:10:34,  1.68it/s] 25%|██▍       | 4367/17525 [52:30<2:09:10,  1.70it/s] 25%|██▍       | 4368/17525 [52:31<2:08:24,  1.71it/s] 25%|██▍       | 4369/17525 [52:31<2:07:42,  1.72it/s] 25%|██▍       | 4370/17525 [52:32<2:07:11,  1.72it/s]                                                      {'loss': 0.5766, 'grad_norm': 7.775239944458008, 'learning_rate': 1.711061366467471e-05, 'epoch': 6.23}
 25%|██▍       | 4370/17525 [52:32<2:07:11,  1.72it/s] 25%|██▍       | 4371/17525 [52:32<2:06:55,  1.73it/s] 25%|██▍       | 4372/17525 [52:33<2:06:38,  1.73it/s] 25%|██▍       | 4373/17525 [52:34<2:06:24,  1.73it/s] 25%|██▍       | 4374/17525 [52:34<2:06:16,  1.74it/s] 25%|██▍       | 4375/17525 [52:35<2:06:03,  1.74it/s] 25%|██▍       | 4376/17525 [52:35<2:06:03,  1.74it/s] 25%|██▍       | 4377/17525 [52:36<2:06:05,  1.74it/s] 25%|██▍       | 4378/17525 [52:36<2:05:54,  1.74it/s] 25%|██▍       | 4379/17525 [52:37<2:06:17,  1.73it/s] 25%|██▍       | 4380/17525 [52:38<2:06:12,  1.74it/s]                                                      {'loss': 0.6977, 'grad_norm': 9.1375150680542, 'learning_rate': 1.709798326619626e-05, 'epoch': 6.25}
 25%|██▍       | 4380/17525 [52:38<2:06:12,  1.74it/s] 25%|██▍       | 4381/17525 [52:38<2:06:04,  1.74it/s] 25%|██▌       | 4382/17525 [52:39<2:05:53,  1.74it/s] 25%|██▌       | 4383/17525 [52:39<2:05:57,  1.74it/s] 25%|██▌       | 4384/17525 [52:40<2:06:00,  1.74it/s] 25%|██▌       | 4385/17525 [52:41<2:05:57,  1.74it/s] 25%|██▌       | 4386/17525 [52:41<2:05:53,  1.74it/s] 25%|██▌       | 4387/17525 [52:42<2:05:56,  1.74it/s] 25%|██▌       | 4388/17525 [52:42<2:08:44,  1.70it/s] 25%|██▌       | 4389/17525 [52:43<2:08:14,  1.71it/s] 25%|██▌       | 4390/17525 [52:43<2:07:30,  1.72it/s]                                                      {'loss': 0.5623, 'grad_norm': 8.237519264221191, 'learning_rate': 1.7085330005920516e-05, 'epoch': 6.26}
 25%|██▌       | 4390/17525 [52:43<2:07:30,  1.72it/s] 25%|██▌       | 4391/17525 [52:44<2:07:13,  1.72it/s] 25%|██▌       | 4392/17525 [52:45<2:06:44,  1.73it/s] 25%|██▌       | 4393/17525 [52:45<2:06:18,  1.73it/s] 25%|██▌       | 4394/17525 [52:46<2:06:01,  1.74it/s] 25%|██▌       | 4395/17525 [52:46<2:18:19,  1.58it/s] 25%|██▌       | 4396/17525 [52:47<2:14:40,  1.62it/s] 25%|██▌       | 4397/17525 [52:48<2:11:53,  1.66it/s] 25%|██▌       | 4398/17525 [52:48<2:09:59,  1.68it/s] 25%|██▌       | 4399/17525 [52:49<2:08:39,  1.70it/s] 25%|██▌       | 4400/17525 [52:49<2:07:41,  1.71it/s]                                                      {'loss': 0.6248, 'grad_norm': 16.944766998291016, 'learning_rate': 1.7072653924602186e-05, 'epoch': 6.28}
 25%|██▌       | 4400/17525 [52:49<2:07:41,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 02:56:11,266 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:56:11,266 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:56:11,266 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.885927140712738, 'eval_runtime': 4.6011, 'eval_samples_per_second': 96.282, 'eval_steps_per_second': 4.129, 'epoch': 6.28}
 25%|██▌       | 4400/17525 [52:54<2:07:41,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 25%|██▌       | 4401/17525 [52:55<7:09:54,  1.97s/it] 25%|██▌       | 4402/17525 [52:55<5:39:55,  1.55s/it] 25%|██▌       | 4403/17525 [52:56<4:35:45,  1.26s/it] 25%|██▌       | 4404/17525 [52:56<3:50:45,  1.06s/it] 25%|██▌       | 4405/17525 [52:57<3:19:15,  1.10it/s] 25%|██▌       | 4406/17525 [52:57<2:57:10,  1.23it/s] 25%|██▌       | 4407/17525 [52:58<2:41:45,  1.35it/s] 25%|██▌       | 4408/17525 [52:59<2:31:01,  1.45it/s] 25%|██▌       | 4409/17525 [52:59<2:23:25,  1.52it/s] 25%|██▌       | 4410/17525 [53:00<2:30:42,  1.45it/s]                                                      {'loss': 0.5965, 'grad_norm': 13.985723495483398, 'learning_rate': 1.7059955063069497e-05, 'epoch': 6.29}
 25%|██▌       | 4410/17525 [53:00<2:30:42,  1.45it/s] 25%|██▌       | 4411/17525 [53:01<2:23:09,  1.53it/s] 25%|██▌       | 4412/17525 [53:01<2:17:56,  1.58it/s] 25%|██▌       | 4413/17525 [53:02<2:14:20,  1.63it/s] 25%|██▌       | 4414/17525 [53:02<2:11:41,  1.66it/s] 25%|██▌       | 4415/17525 [53:03<2:12:33,  1.65it/s] 25%|██▌       | 4416/17525 [53:03<2:10:26,  1.67it/s] 25%|██▌       | 4417/17525 [53:04<2:08:58,  1.69it/s] 25%|██▌       | 4418/17525 [53:05<2:07:49,  1.71it/s] 25%|██▌       | 4419/17525 [53:05<2:07:05,  1.72it/s] 25%|██▌       | 4420/17525 [53:06<2:06:30,  1.73it/s]                                                      {'loss': 0.6214, 'grad_norm': 7.314836025238037, 'learning_rate': 1.7047233462224025e-05, 'epoch': 6.31}
 25%|██▌       | 4420/17525 [53:06<2:06:30,  1.73it/s] 25%|██▌       | 4421/17525 [53:06<2:07:17,  1.72it/s] 25%|██▌       | 4422/17525 [53:07<2:06:40,  1.72it/s] 25%|██▌       | 4423/17525 [53:07<2:06:19,  1.73it/s] 25%|██▌       | 4424/17525 [53:08<2:07:09,  1.72it/s] 25%|██▌       | 4425/17525 [53:09<2:06:39,  1.72it/s] 25%|██▌       | 4426/17525 [53:09<2:06:18,  1.73it/s] 25%|██▌       | 4427/17525 [53:10<2:05:55,  1.73it/s] 25%|██▌       | 4428/17525 [53:10<2:07:40,  1.71it/s] 25%|██▌       | 4429/17525 [53:11<2:07:02,  1.72it/s] 25%|██▌       | 4430/17525 [53:12<2:06:37,  1.72it/s]                                                      {'loss': 0.5949, 'grad_norm': 7.195822715759277, 'learning_rate': 1.703448916304061e-05, 'epoch': 6.32}
 25%|██▌       | 4430/17525 [53:12<2:06:37,  1.72it/s] 25%|██▌       | 4431/17525 [53:12<2:06:16,  1.73it/s] 25%|██▌       | 4432/17525 [53:13<2:06:10,  1.73it/s] 25%|██▌       | 4433/17525 [53:13<2:05:51,  1.73it/s] 25%|██▌       | 4434/17525 [53:14<2:05:32,  1.74it/s] 25%|██▌       | 4435/17525 [53:14<2:05:26,  1.74it/s] 25%|██▌       | 4436/17525 [53:15<2:05:21,  1.74it/s] 25%|██▌       | 4437/17525 [53:16<2:05:07,  1.74it/s] 25%|██▌       | 4438/17525 [53:16<2:05:07,  1.74it/s] 25%|██▌       | 4439/17525 [53:17<2:05:19,  1.74it/s] 25%|██▌       | 4440/17525 [53:17<2:05:25,  1.74it/s]                                                      {'loss': 0.5167, 'grad_norm': 8.963051795959473, 'learning_rate': 1.7021722206567185e-05, 'epoch': 6.33}
 25%|██▌       | 4440/17525 [53:17<2:05:25,  1.74it/s] 25%|██▌       | 4441/17525 [53:18<2:05:35,  1.74it/s] 25%|██▌       | 4442/17525 [53:18<2:05:31,  1.74it/s] 25%|██▌       | 4443/17525 [53:19<2:05:21,  1.74it/s] 25%|██▌       | 4444/17525 [53:20<2:05:13,  1.74it/s] 25%|██▌       | 4445/17525 [53:20<2:05:20,  1.74it/s] 25%|██▌       | 4446/17525 [53:21<2:17:49,  1.58it/s] 25%|██▌       | 4447/17525 [53:22<2:14:14,  1.62it/s] 25%|██▌       | 4448/17525 [53:22<2:11:44,  1.65it/s] 25%|██▌       | 4449/17525 [53:23<2:09:52,  1.68it/s] 25%|██▌       | 4450/17525 [53:23<2:08:20,  1.70it/s]                                                      {'loss': 0.6227, 'grad_norm': 6.04102897644043, 'learning_rate': 1.7008932633924672e-05, 'epoch': 6.35}
 25%|██▌       | 4450/17525 [53:23<2:08:20,  1.70it/s] 25%|██▌       | 4451/17525 [53:24<2:07:37,  1.71it/s] 25%|██▌       | 4452/17525 [53:24<2:06:59,  1.72it/s] 25%|██▌       | 4453/17525 [53:25<2:06:20,  1.72it/s] 25%|██▌       | 4454/17525 [53:26<2:05:58,  1.73it/s] 25%|██▌       | 4455/17525 [53:26<2:05:49,  1.73it/s] 25%|██▌       | 4456/17525 [53:27<2:05:35,  1.73it/s] 25%|██▌       | 4457/17525 [53:27<2:05:17,  1.74it/s] 25%|██▌       | 4458/17525 [53:28<2:05:26,  1.74it/s] 25%|██▌       | 4459/17525 [53:29<2:15:09,  1.61it/s] 25%|██▌       | 4460/17525 [53:29<2:12:21,  1.65it/s]                                                      {'loss': 0.5349, 'grad_norm': 5.6779866218566895, 'learning_rate': 1.6996120486306826e-05, 'epoch': 6.36}
 25%|██▌       | 4460/17525 [53:29<2:12:21,  1.65it/s] 25%|██▌       | 4461/17525 [53:30<2:10:38,  1.67it/s] 25%|██▌       | 4462/17525 [53:30<2:08:59,  1.69it/s] 25%|██▌       | 4463/17525 [53:31<2:07:37,  1.71it/s] 25%|██▌       | 4464/17525 [53:31<2:06:47,  1.72it/s] 25%|██▌       | 4465/17525 [53:32<2:06:18,  1.72it/s] 25%|██▌       | 4466/17525 [53:33<2:05:52,  1.73it/s] 25%|██▌       | 4467/17525 [53:33<2:05:36,  1.73it/s] 25%|██▌       | 4468/17525 [53:34<2:05:34,  1.73it/s] 26%|██▌       | 4469/17525 [53:34<2:05:25,  1.73it/s] 26%|██▌       | 4470/17525 [53:35<2:05:38,  1.73it/s]                                                      {'loss': 0.6012, 'grad_norm': 6.26968240737915, 'learning_rate': 1.698328580498012e-05, 'epoch': 6.38}
 26%|██▌       | 4470/17525 [53:35<2:05:38,  1.73it/s] 26%|██▌       | 4471/17525 [53:35<2:05:47,  1.73it/s] 26%|██▌       | 4472/17525 [53:36<2:05:27,  1.73it/s] 26%|██▌       | 4473/17525 [53:37<2:05:24,  1.73it/s] 26%|██▌       | 4474/17525 [53:37<2:05:48,  1.73it/s] 26%|██▌       | 4475/17525 [53:38<2:06:39,  1.72it/s] 26%|██▌       | 4476/17525 [53:38<2:06:12,  1.72it/s] 26%|██▌       | 4477/17525 [53:39<2:05:49,  1.73it/s] 26%|██▌       | 4478/17525 [53:40<2:05:27,  1.73it/s] 26%|██▌       | 4479/17525 [53:40<2:05:20,  1.73it/s] 26%|██▌       | 4480/17525 [53:41<2:05:06,  1.74it/s]                                                      {'loss': 0.5118, 'grad_norm': 14.151957511901855, 'learning_rate': 1.6970428631283602e-05, 'epoch': 6.39}
 26%|██▌       | 4480/17525 [53:41<2:05:06,  1.74it/s] 26%|██▌       | 4481/17525 [53:42<2:32:55,  1.42it/s] 26%|██▌       | 4482/17525 [53:42<2:24:20,  1.51it/s] 26%|██▌       | 4483/17525 [53:43<2:18:45,  1.57it/s] 26%|██▌       | 4484/17525 [53:43<2:14:45,  1.61it/s] 26%|██▌       | 4485/17525 [53:44<2:23:46,  1.51it/s] 26%|██▌       | 4486/17525 [53:45<2:18:16,  1.57it/s] 26%|██▌       | 4487/17525 [53:45<2:14:15,  1.62it/s] 26%|██▌       | 4488/17525 [53:46<2:11:20,  1.65it/s] 26%|██▌       | 4489/17525 [53:46<2:09:38,  1.68it/s] 26%|██▌       | 4490/17525 [53:47<2:08:26,  1.69it/s]                                                      {'loss': 0.6432, 'grad_norm': 15.70667839050293, 'learning_rate': 1.6957549006628767e-05, 'epoch': 6.41}
 26%|██▌       | 4490/17525 [53:47<2:08:26,  1.69it/s] 26%|██▌       | 4491/17525 [53:48<2:07:33,  1.70it/s] 26%|██▌       | 4492/17525 [53:48<2:06:27,  1.72it/s] 26%|██▌       | 4493/17525 [53:49<2:06:00,  1.72it/s] 26%|██▌       | 4494/17525 [53:49<2:05:37,  1.73it/s] 26%|██▌       | 4495/17525 [53:50<2:05:28,  1.73it/s] 26%|██▌       | 4496/17525 [53:50<2:05:18,  1.73it/s] 26%|██▌       | 4497/17525 [53:51<2:05:06,  1.74it/s] 26%|██▌       | 4498/17525 [53:52<2:05:04,  1.74it/s] 26%|██▌       | 4499/17525 [53:52<2:05:03,  1.74it/s] 26%|██▌       | 4500/17525 [53:53<2:05:03,  1.74it/s]                                                      {'loss': 0.6345, 'grad_norm': 16.054668426513672, 'learning_rate': 1.6944646972499428e-05, 'epoch': 6.42}
 26%|██▌       | 4500/17525 [53:53<2:05:03,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 02:57:14,690 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:57:14,690 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:57:14,690 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                      
                                               [A{'eval_loss': 0.8745816946029663, 'eval_runtime': 4.6052, 'eval_samples_per_second': 96.195, 'eval_steps_per_second': 4.126, 'epoch': 6.42}
 26%|██▌       | 4500/17525 [53:57<2:05:03,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 02:57:19,301 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79ad990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: fac85c07-e736-4e83-b081-5eeebb1c3fef)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:57:29,357 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:57:29,359 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 26%|██▌       | 4501/17525 [54:08<18:08:32,  5.01s/it] 26%|██▌       | 4502/17525 [54:09<13:19:21,  3.68s/it] 26%|██▌       | 4503/17525 [54:09<9:56:56,  2.75s/it]  26%|██▌       | 4504/17525 [54:10<8:03:05,  2.23s/it] 26%|██▌       | 4505/17525 [54:11<6:15:35,  1.73s/it] 26%|██▌       | 4506/17525 [54:11<5:00:15,  1.38s/it] 26%|██▌       | 4507/17525 [54:12<4:07:48,  1.14s/it] 26%|██▌       | 4508/17525 [54:13<3:30:57,  1.03it/s] 26%|██▌       | 4509/17525 [54:13<3:05:15,  1.17it/s] 26%|██▌       | 4510/17525 [54:14<3:10:56,  1.14it/s]                                                      {'loss': 0.6441, 'grad_norm': 10.427490234375, 'learning_rate': 1.6931722570451563e-05, 'epoch': 6.43}
 26%|██▌       | 4510/17525 [54:14<3:10:56,  1.14it/s] 26%|██▌       | 4511/17525 [54:15<2:51:26,  1.27it/s] 26%|██▌       | 4512/17525 [54:15<2:37:32,  1.38it/s] 26%|██▌       | 4513/17525 [54:16<2:28:25,  1.46it/s] 26%|██▌       | 4514/17525 [54:16<2:21:20,  1.53it/s] 26%|██▌       | 4515/17525 [54:17<2:16:31,  1.59it/s] 26%|██▌       | 4516/17525 [54:18<2:13:11,  1.63it/s] 26%|██▌       | 4517/17525 [54:18<2:23:19,  1.51it/s] 26%|██▌       | 4518/17525 [54:19<2:17:41,  1.57it/s] 26%|██▌       | 4519/17525 [54:20<2:13:43,  1.62it/s] 26%|██▌       | 4520/17525 [54:20<2:11:02,  1.65it/s]                                                      {'loss': 0.5474, 'grad_norm': 5.151461124420166, 'learning_rate': 1.6918775842113207e-05, 'epoch': 6.45}
 26%|██▌       | 4520/17525 [54:20<2:11:02,  1.65it/s] 26%|██▌       | 4521/17525 [54:21<2:09:21,  1.68it/s] 26%|██▌       | 4522/17525 [54:21<2:07:54,  1.69it/s] 26%|██▌       | 4523/17525 [54:22<2:07:03,  1.71it/s] 26%|██▌       | 4524/17525 [54:22<2:06:13,  1.72it/s] 26%|██▌       | 4525/17525 [54:23<2:05:44,  1.72it/s] 26%|██▌       | 4526/17525 [54:24<2:05:26,  1.73it/s] 26%|██▌       | 4527/17525 [54:25<3:11:31,  1.13it/s] 26%|██▌       | 4528/17525 [54:26<3:03:28,  1.18it/s] 26%|██▌       | 4529/17525 [54:26<2:45:49,  1.31it/s] 26%|██▌       | 4530/17525 [54:27<2:33:06,  1.41it/s]                                                      {'loss': 0.6322, 'grad_norm': 10.709429740905762, 'learning_rate': 1.6905806829184296e-05, 'epoch': 6.46}
 26%|██▌       | 4530/17525 [54:27<2:33:06,  1.41it/s] 26%|██▌       | 4531/17525 [54:28<2:24:34,  1.50it/s] 26%|██▌       | 4532/17525 [54:28<2:18:29,  1.56it/s] 26%|██▌       | 4533/17525 [54:29<2:37:25,  1.38it/s] 26%|██▌       | 4534/17525 [54:30<2:27:43,  1.47it/s] 26%|██▌       | 4535/17525 [54:30<2:20:39,  1.54it/s] 26%|██▌       | 4536/17525 [54:31<2:15:32,  1.60it/s] 26%|██▌       | 4537/17525 [54:31<2:12:08,  1.64it/s] 26%|██▌       | 4538/17525 [54:32<2:37:33,  1.37it/s] 26%|██▌       | 4539/17525 [54:33<2:27:32,  1.47it/s] 26%|██▌       | 4540/17525 [54:34<2:20:59,  1.54it/s]                                                      {'loss': 0.5988, 'grad_norm': 21.321247100830078, 'learning_rate': 1.6892815573436548e-05, 'epoch': 6.48}
 26%|██▌       | 4540/17525 [54:34<2:20:59,  1.54it/s] 26%|██▌       | 4541/17525 [54:34<2:16:04,  1.59it/s] 26%|██▌       | 4542/17525 [54:35<2:12:27,  1.63it/s] 26%|██▌       | 4543/17525 [54:35<2:09:58,  1.66it/s] 26%|██▌       | 4544/17525 [54:36<2:08:21,  1.69it/s] 26%|██▌       | 4545/17525 [54:36<2:07:05,  1.70it/s] 26%|██▌       | 4546/17525 [54:37<2:29:43,  1.44it/s] 26%|██▌       | 4547/17525 [54:38<2:22:03,  1.52it/s] 26%|██▌       | 4548/17525 [54:39<2:16:38,  1.58it/s] 26%|██▌       | 4549/17525 [54:39<2:12:43,  1.63it/s] 26%|██▌       | 4550/17525 [54:40<2:10:17,  1.66it/s]                                                      {'loss': 0.535, 'grad_norm': 6.414671421051025, 'learning_rate': 1.6879802116713323e-05, 'epoch': 6.49}
 26%|██▌       | 4550/17525 [54:40<2:10:17,  1.66it/s] 26%|██▌       | 4551/17525 [54:40<2:08:34,  1.68it/s] 26%|██▌       | 4552/17525 [54:41<2:08:07,  1.69it/s] 26%|██▌       | 4553/17525 [54:41<2:06:38,  1.71it/s] 26%|██▌       | 4554/17525 [54:42<2:05:47,  1.72it/s] 26%|██▌       | 4555/17525 [54:43<2:05:23,  1.72it/s] 26%|██▌       | 4556/17525 [54:43<2:05:01,  1.73it/s] 26%|██▌       | 4557/17525 [54:44<2:04:52,  1.73it/s] 26%|██▌       | 4558/17525 [54:44<2:04:39,  1.73it/s] 26%|██▌       | 4559/17525 [54:45<2:04:27,  1.74it/s] 26%|██▌       | 4560/17525 [54:45<2:04:11,  1.74it/s]                                                      {'loss': 0.5672, 'grad_norm': 15.34627914428711, 'learning_rate': 1.6866766500929484e-05, 'epoch': 6.5}
 26%|██▌       | 4560/17525 [54:45<2:04:11,  1.74it/s] 26%|██▌       | 4561/17525 [54:46<2:04:26,  1.74it/s] 26%|██▌       | 4562/17525 [54:47<2:04:22,  1.74it/s] 26%|██▌       | 4563/17525 [54:47<2:04:15,  1.74it/s] 26%|██▌       | 4564/17525 [54:48<2:04:17,  1.74it/s] 26%|██▌       | 4565/17525 [54:49<2:26:17,  1.48it/s] 26%|██▌       | 4566/17525 [54:49<2:19:39,  1.55it/s] 26%|██▌       | 4567/17525 [54:50<2:16:40,  1.58it/s] 26%|██▌       | 4568/17525 [54:50<2:12:54,  1.62it/s] 26%|██▌       | 4569/17525 [54:51<2:10:10,  1.66it/s] 26%|██▌       | 4570/17525 [54:52<2:08:10,  1.68it/s]                                                      {'loss': 0.5462, 'grad_norm': 11.319382667541504, 'learning_rate': 1.6853708768071265e-05, 'epoch': 6.52}
 26%|██▌       | 4570/17525 [54:52<2:08:10,  1.68it/s] 26%|██▌       | 4571/17525 [54:53<2:30:19,  1.44it/s] 26%|██▌       | 4572/17525 [54:53<2:22:20,  1.52it/s] 26%|██▌       | 4573/17525 [54:54<2:16:58,  1.58it/s] 26%|██▌       | 4574/17525 [54:54<2:13:03,  1.62it/s] 26%|██▌       | 4575/17525 [54:55<2:10:21,  1.66it/s] 26%|██▌       | 4576/17525 [54:55<2:08:24,  1.68it/s] 26%|██▌       | 4577/17525 [54:56<2:07:06,  1.70it/s] 26%|██▌       | 4578/17525 [54:57<2:06:06,  1.71it/s] 26%|██▌       | 4579/17525 [54:57<2:05:25,  1.72it/s] 26%|██▌       | 4580/17525 [54:58<2:05:04,  1.72it/s]                                                      {'loss': 0.4703, 'grad_norm': 5.318815231323242, 'learning_rate': 1.6840628960196145e-05, 'epoch': 6.53}
 26%|██▌       | 4580/17525 [54:58<2:05:04,  1.72it/s] 26%|██▌       | 4581/17525 [54:58<2:04:45,  1.73it/s] 26%|██▌       | 4582/17525 [54:59<2:04:28,  1.73it/s] 26%|██▌       | 4583/17525 [54:59<2:04:23,  1.73it/s] 26%|██▌       | 4584/17525 [55:00<2:04:16,  1.74it/s] 26%|██▌       | 4585/17525 [55:01<2:04:25,  1.73it/s] 26%|██▌       | 4586/17525 [55:01<2:04:45,  1.73it/s] 26%|██▌       | 4587/17525 [55:02<2:04:30,  1.73it/s] 26%|██▌       | 4588/17525 [55:02<2:04:13,  1.74it/s] 26%|██▌       | 4589/17525 [55:03<2:04:16,  1.73it/s] 26%|██▌       | 4590/17525 [55:03<2:04:09,  1.74it/s]                                                      {'loss': 0.5048, 'grad_norm': 10.604138374328613, 'learning_rate': 1.6827527119432698e-05, 'epoch': 6.55}
 26%|██▌       | 4590/17525 [55:03<2:04:09,  1.74it/s] 26%|██▌       | 4591/17525 [55:04<2:04:02,  1.74it/s] 26%|██▌       | 4592/17525 [55:05<2:31:32,  1.42it/s] 26%|██▌       | 4593/17525 [55:06<2:24:57,  1.49it/s] 26%|██▌       | 4594/17525 [55:06<2:28:21,  1.45it/s] 26%|██▌       | 4595/17525 [55:07<2:20:52,  1.53it/s] 26%|██▌       | 4596/17525 [55:07<2:15:47,  1.59it/s] 26%|██▌       | 4597/17525 [55:08<2:12:09,  1.63it/s] 26%|██▌       | 4598/17525 [55:09<2:09:32,  1.66it/s] 26%|██▌       | 4599/17525 [55:09<2:07:49,  1.69it/s] 26%|██▌       | 4600/17525 [55:10<2:06:35,  1.70it/s]                                                      {'loss': 0.5547, 'grad_norm': 6.116321563720703, 'learning_rate': 1.681440328798046e-05, 'epoch': 6.56}
 26%|██▌       | 4600/17525 [55:10<2:06:35,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 02:58:31,688 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:58:31,689 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:58:31,689 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8826241493225098, 'eval_runtime': 4.5999, 'eval_samples_per_second': 96.306, 'eval_steps_per_second': 4.131, 'epoch': 6.56}
 26%|██▌       | 4600/17525 [55:14<2:06:35,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 26%|██▋       | 4601/17525 [55:15<7:03:39,  1.97s/it] 26%|██▋       | 4602/17525 [55:16<5:33:44,  1.55s/it] 26%|██▋       | 4603/17525 [55:16<4:30:44,  1.26s/it] 26%|██▋       | 4604/17525 [55:17<3:46:34,  1.05s/it] 26%|██▋       | 4605/17525 [55:17<3:15:36,  1.10it/s] 26%|██▋       | 4606/17525 [55:18<2:54:09,  1.24it/s] 26%|██▋       | 4607/17525 [55:18<2:39:03,  1.35it/s] 26%|██▋       | 4608/17525 [55:19<2:28:32,  1.45it/s] 26%|██▋       | 4609/17525 [55:20<2:21:06,  1.53it/s] 26%|██▋       | 4610/17525 [55:20<2:15:52,  1.58it/s]                                                      {'loss': 0.6798, 'grad_norm': 9.728074073791504, 'learning_rate': 1.6801257508109803e-05, 'epoch': 6.58}
 26%|██▋       | 4610/17525 [55:20<2:15:52,  1.58it/s] 26%|██▋       | 4611/17525 [55:21<2:12:27,  1.62it/s] 26%|██▋       | 4612/17525 [55:21<2:09:49,  1.66it/s] 26%|██▋       | 4613/17525 [55:22<2:07:53,  1.68it/s] 26%|██▋       | 4614/17525 [55:22<2:06:36,  1.70it/s] 26%|██▋       | 4615/17525 [55:23<2:05:47,  1.71it/s] 26%|██▋       | 4616/17525 [55:24<2:04:57,  1.72it/s] 26%|██▋       | 4617/17525 [55:24<2:04:27,  1.73it/s] 26%|██▋       | 4618/17525 [55:25<2:04:12,  1.73it/s] 26%|██▋       | 4619/17525 [55:26<2:44:10,  1.31it/s] 26%|██▋       | 4620/17525 [55:27<2:31:53,  1.42it/s]                                                      {'loss': 0.5445, 'grad_norm': 7.729608535766602, 'learning_rate': 1.678808982216179e-05, 'epoch': 6.59}
 26%|██▋       | 4620/17525 [55:27<2:31:53,  1.42it/s] 26%|██▋       | 4621/17525 [55:27<2:23:26,  1.50it/s] 26%|██▋       | 4622/17525 [55:28<2:17:26,  1.56it/s] 26%|██▋       | 4623/17525 [55:28<2:13:15,  1.61it/s] 26%|██▋       | 4624/17525 [55:29<2:10:18,  1.65it/s] 26%|██▋       | 4625/17525 [55:29<2:08:17,  1.68it/s] 26%|██▋       | 4626/17525 [55:30<2:06:53,  1.69it/s] 26%|██▋       | 4627/17525 [55:31<2:05:53,  1.71it/s] 26%|██▋       | 4628/17525 [55:31<2:05:11,  1.72it/s] 26%|██▋       | 4629/17525 [55:32<2:44:36,  1.31it/s] 26%|██▋       | 4630/17525 [55:33<2:32:25,  1.41it/s]                                                      {'loss': 0.5545, 'grad_norm': 7.030055999755859, 'learning_rate': 1.6774900272548037e-05, 'epoch': 6.6}
 26%|██▋       | 4630/17525 [55:33<2:32:25,  1.41it/s] 26%|██▋       | 4631/17525 [55:33<2:23:47,  1.49it/s] 26%|██▋       | 4632/17525 [55:34<2:17:29,  1.56it/s] 26%|██▋       | 4633/17525 [55:35<2:13:20,  1.61it/s] 26%|██▋       | 4634/17525 [55:35<2:12:19,  1.62it/s] 26%|██▋       | 4635/17525 [55:36<2:09:36,  1.66it/s] 26%|██▋       | 4636/17525 [55:36<2:07:31,  1.68it/s] 26%|██▋       | 4637/17525 [55:37<2:06:17,  1.70it/s] 26%|██▋       | 4638/17525 [55:38<2:05:13,  1.72it/s] 26%|██▋       | 4639/17525 [55:38<2:04:40,  1.72it/s] 26%|██▋       | 4640/17525 [55:39<2:04:15,  1.73it/s]                                                      {'loss': 0.6415, 'grad_norm': 11.090136528015137, 'learning_rate': 1.6761688901750587e-05, 'epoch': 6.62}
 26%|██▋       | 4640/17525 [55:39<2:04:15,  1.73it/s] 26%|██▋       | 4641/17525 [55:39<2:07:33,  1.68it/s] 26%|██▋       | 4642/17525 [55:40<2:06:10,  1.70it/s] 26%|██▋       | 4643/17525 [55:40<2:05:27,  1.71it/s] 26%|██▋       | 4644/17525 [55:41<2:14:00,  1.60it/s] 27%|██▋       | 4645/17525 [55:42<2:10:48,  1.64it/s] 27%|██▋       | 4646/17525 [55:42<2:08:29,  1.67it/s] 27%|██▋       | 4647/17525 [55:43<2:07:09,  1.69it/s] 27%|██▋       | 4648/17525 [55:43<2:05:58,  1.70it/s] 27%|██▋       | 4649/17525 [55:44<2:05:14,  1.71it/s] 27%|██▋       | 4650/17525 [55:45<2:05:13,  1.71it/s]                                                      {'loss': 0.6261, 'grad_norm': 10.949134826660156, 'learning_rate': 1.6748455752321763e-05, 'epoch': 6.63}
 27%|██▋       | 4650/17525 [55:45<2:05:13,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 02:59:06,508 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a12090>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 08971578-ed72-481d-a7a1-f302f96628bd)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 02:59:16,563 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 02:59:16,565 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 27%|██▋       | 4651/17525 [55:55<13:00:01,  3.64s/it] 27%|██▋       | 4652/17525 [55:56<10:05:35,  2.82s/it] 27%|██▋       | 4653/17525 [55:57<7:40:56,  2.15s/it]  27%|██▋       | 4654/17525 [55:57<5:59:32,  1.68s/it] 27%|██▋       | 4655/17525 [55:58<4:48:32,  1.35s/it] 27%|██▋       | 4656/17525 [55:59<3:58:51,  1.11s/it] 27%|██▋       | 4657/17525 [55:59<3:24:09,  1.05it/s] 27%|██▋       | 4658/17525 [56:00<3:00:00,  1.19it/s] 27%|██▋       | 4659/17525 [56:00<2:42:56,  1.32it/s] 27%|██▋       | 4660/17525 [56:01<2:31:02,  1.42it/s]                                                      {'loss': 0.4693, 'grad_norm': 9.765728950500488, 'learning_rate': 1.6735200866884037e-05, 'epoch': 6.65}
 27%|██▋       | 4660/17525 [56:01<2:31:02,  1.42it/s] 27%|██▋       | 4661/17525 [56:01<2:22:50,  1.50it/s] 27%|██▋       | 4662/17525 [56:02<2:16:48,  1.57it/s] 27%|██▋       | 4663/17525 [56:03<2:22:22,  1.51it/s] 27%|██▋       | 4664/17525 [56:03<2:16:34,  1.57it/s] 27%|██▋       | 4665/17525 [56:04<2:12:49,  1.61it/s] 27%|██▋       | 4666/17525 [56:05<2:11:00,  1.64it/s] 27%|██▋       | 4667/17525 [56:05<2:08:40,  1.67it/s] 27%|██▋       | 4668/17525 [56:06<2:07:02,  1.69it/s] 27%|██▋       | 4669/17525 [56:06<2:05:52,  1.70it/s] 27%|██▋       | 4670/17525 [56:07<2:06:12,  1.70it/s]                                                      {'loss': 0.6423, 'grad_norm': 8.555145263671875, 'learning_rate': 1.6721924288129887e-05, 'epoch': 6.66}
 27%|██▋       | 4670/17525 [56:07<2:06:12,  1.70it/s] 27%|██▋       | 4671/17525 [56:07<2:05:33,  1.71it/s] 27%|██▋       | 4672/17525 [56:08<2:04:50,  1.72it/s] 27%|██▋       | 4673/17525 [56:09<2:04:20,  1.72it/s] 27%|██▋       | 4674/17525 [56:09<2:04:05,  1.73it/s] 27%|██▋       | 4675/17525 [56:10<2:03:48,  1.73it/s] 27%|██▋       | 4676/17525 [56:10<2:03:38,  1.73it/s] 27%|██▋       | 4677/17525 [56:11<2:03:29,  1.73it/s] 27%|██▋       | 4678/17525 [56:11<2:03:22,  1.74it/s] 27%|██▋       | 4679/17525 [56:12<2:03:02,  1.74it/s] 27%|██▋       | 4680/17525 [56:13<2:03:09,  1.74it/s]                                                      {'loss': 0.554, 'grad_norm': 14.19680404663086, 'learning_rate': 1.6708626058821663e-05, 'epoch': 6.68}
 27%|██▋       | 4680/17525 [56:13<2:03:09,  1.74it/s] 27%|██▋       | 4681/17525 [56:14<2:26:17,  1.46it/s] 27%|██▋       | 4682/17525 [56:14<2:19:42,  1.53it/s] 27%|██▋       | 4683/17525 [56:15<2:14:59,  1.59it/s] 27%|██▋       | 4684/17525 [56:15<2:11:35,  1.63it/s] 27%|██▋       | 4685/17525 [56:16<2:09:27,  1.65it/s] 27%|██▋       | 4686/17525 [56:16<2:07:44,  1.68it/s] 27%|██▋       | 4687/17525 [56:17<2:06:33,  1.69it/s] 27%|██▋       | 4688/17525 [56:18<2:05:21,  1.71it/s] 27%|██▋       | 4689/17525 [56:18<2:04:40,  1.72it/s] 27%|██▋       | 4690/17525 [56:19<2:04:05,  1.72it/s]                                                      {'loss': 0.6695, 'grad_norm': 8.420793533325195, 'learning_rate': 1.6695306221791453e-05, 'epoch': 6.69}
 27%|██▋       | 4690/17525 [56:19<2:04:05,  1.72it/s] 27%|██▋       | 4691/17525 [56:19<2:03:52,  1.73it/s] 27%|██▋       | 4692/17525 [56:20<2:03:40,  1.73it/s] 27%|██▋       | 4693/17525 [56:20<2:03:33,  1.73it/s] 27%|██▋       | 4694/17525 [56:21<2:03:23,  1.73it/s] 27%|██▋       | 4695/17525 [56:22<2:03:18,  1.73it/s] 27%|██▋       | 4696/17525 [56:22<2:03:23,  1.73it/s] 27%|██▋       | 4697/17525 [56:23<2:03:13,  1.74it/s] 27%|██▋       | 4698/17525 [56:23<2:03:11,  1.74it/s] 27%|██▋       | 4699/17525 [56:24<2:02:55,  1.74it/s] 27%|██▋       | 4700/17525 [56:25<2:53:10,  1.23it/s]                                                      {'loss': 0.5906, 'grad_norm': 19.211923599243164, 'learning_rate': 1.6681964819940933e-05, 'epoch': 6.7}
 27%|██▋       | 4700/17525 [56:25<2:53:10,  1.23it/s][INFO|trainer.py:3512] 2024-06-25 02:59:47,156 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 02:59:47,156 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 02:59:47,156 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.05it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.882719874382019, 'eval_runtime': 4.5968, 'eval_samples_per_second': 96.372, 'eval_steps_per_second': 4.133, 'epoch': 6.7}
 27%|██▋       | 4700/17525 [56:30<2:53:10,  1.23it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 27%|██▋       | 4701/17525 [56:30<7:33:22,  2.12s/it] 27%|██▋       | 4702/17525 [56:31<5:54:28,  1.66s/it] 27%|██▋       | 4703/17525 [56:32<4:44:59,  1.33s/it] 27%|██▋       | 4704/17525 [56:32<3:56:33,  1.11s/it] 27%|██▋       | 4705/17525 [56:33<3:22:31,  1.06it/s] 27%|██▋       | 4706/17525 [56:33<2:58:38,  1.20it/s] 27%|██▋       | 4707/17525 [56:34<2:42:03,  1.32it/s] 27%|██▋       | 4708/17525 [56:34<2:30:22,  1.42it/s] 27%|██▋       | 4709/17525 [56:35<2:22:08,  1.50it/s] 27%|██▋       | 4710/17525 [56:36<2:16:27,  1.57it/s]                                                      {'loss': 0.6129, 'grad_norm': 19.39677619934082, 'learning_rate': 1.6668601896241246e-05, 'epoch': 6.72}
 27%|██▋       | 4710/17525 [56:36<2:16:27,  1.57it/s] 27%|██▋       | 4711/17525 [56:36<2:12:26,  1.61it/s] 27%|██▋       | 4712/17525 [56:37<2:09:24,  1.65it/s] 27%|██▋       | 4713/17525 [56:37<2:07:09,  1.68it/s] 27%|██▋       | 4714/17525 [56:38<2:05:56,  1.70it/s] 27%|██▋       | 4715/17525 [56:39<2:04:59,  1.71it/s] 27%|██▋       | 4716/17525 [56:39<2:04:18,  1.72it/s] 27%|██▋       | 4717/17525 [56:40<2:04:00,  1.72it/s] 27%|██▋       | 4718/17525 [56:40<2:03:34,  1.73it/s] 27%|██▋       | 4719/17525 [56:41<2:03:15,  1.73it/s] 27%|██▋       | 4720/17525 [56:41<2:02:50,  1.74it/s]                                                      {'loss': 0.6723, 'grad_norm': 13.755375862121582, 'learning_rate': 1.6655217493732848e-05, 'epoch': 6.73}
 27%|██▋       | 4720/17525 [56:41<2:02:50,  1.74it/s] 27%|██▋       | 4721/17525 [56:42<2:02:54,  1.74it/s] 27%|██▋       | 4722/17525 [56:43<2:02:58,  1.74it/s] 27%|██▋       | 4723/17525 [56:43<2:02:51,  1.74it/s] 27%|██▋       | 4724/17525 [56:44<2:02:48,  1.74it/s] 27%|██▋       | 4725/17525 [56:44<2:02:44,  1.74it/s] 27%|██▋       | 4726/17525 [56:45<2:02:42,  1.74it/s] 27%|██▋       | 4727/17525 [56:45<2:04:14,  1.72it/s] 27%|██▋       | 4728/17525 [56:46<2:03:40,  1.72it/s] 27%|██▋       | 4729/17525 [56:47<2:03:19,  1.73it/s] 27%|██▋       | 4730/17525 [56:47<2:04:53,  1.71it/s]                                                      {'loss': 0.5034, 'grad_norm': 4.662473201751709, 'learning_rate': 1.664181165552538e-05, 'epoch': 6.75}
 27%|██▋       | 4730/17525 [56:47<2:04:53,  1.71it/s] 27%|██▋       | 4731/17525 [56:48<2:04:12,  1.72it/s] 27%|██▋       | 4732/17525 [56:48<2:03:33,  1.73it/s] 27%|██▋       | 4733/17525 [56:49<2:03:36,  1.72it/s] 27%|██▋       | 4734/17525 [56:49<2:03:22,  1.73it/s] 27%|██▋       | 4735/17525 [56:50<2:03:10,  1.73it/s] 27%|██▋       | 4736/17525 [56:51<2:03:10,  1.73it/s] 27%|██▋       | 4737/17525 [56:51<2:03:05,  1.73it/s] 27%|██▋       | 4738/17525 [56:52<2:02:55,  1.73it/s] 27%|██▋       | 4739/17525 [56:53<2:34:56,  1.38it/s] 27%|██▋       | 4740/17525 [56:53<2:25:34,  1.46it/s]                                                      {'loss': 0.6193, 'grad_norm': 11.281911849975586, 'learning_rate': 1.6628384424797527e-05, 'epoch': 6.76}
 27%|██▋       | 4740/17525 [56:53<2:25:34,  1.46it/s] 27%|██▋       | 4741/17525 [56:54<2:19:14,  1.53it/s] 27%|██▋       | 4742/17525 [56:55<2:14:43,  1.58it/s] 27%|██▋       | 4743/17525 [56:55<2:11:20,  1.62it/s] 27%|██▋       | 4744/17525 [56:56<2:10:10,  1.64it/s] 27%|██▋       | 4745/17525 [56:56<2:08:18,  1.66it/s] 27%|██▋       | 4746/17525 [56:57<2:30:34,  1.41it/s] 27%|██▋       | 4747/17525 [56:58<2:22:14,  1.50it/s] 27%|██▋       | 4748/17525 [56:58<2:16:36,  1.56it/s] 27%|██▋       | 4749/17525 [56:59<2:12:36,  1.61it/s] 27%|██▋       | 4750/17525 [57:00<2:11:07,  1.62it/s]                                                      {'loss': 0.6406, 'grad_norm': 10.387849807739258, 'learning_rate': 1.6614935844796863e-05, 'epoch': 6.78}
 27%|██▋       | 4750/17525 [57:00<2:11:07,  1.62it/s] 27%|██▋       | 4751/17525 [57:00<2:08:44,  1.65it/s] 27%|██▋       | 4752/17525 [57:01<2:07:06,  1.67it/s] 27%|██▋       | 4753/17525 [57:01<2:05:38,  1.69it/s] 27%|██▋       | 4754/17525 [57:02<2:04:34,  1.71it/s] 27%|██▋       | 4755/17525 [57:03<2:03:54,  1.72it/s] 27%|██▋       | 4756/17525 [57:03<2:03:22,  1.72it/s] 27%|██▋       | 4757/17525 [57:04<2:03:22,  1.72it/s] 27%|██▋       | 4758/17525 [57:04<2:03:12,  1.73it/s] 27%|██▋       | 4759/17525 [57:05<2:03:35,  1.72it/s] 27%|██▋       | 4760/17525 [57:05<2:03:20,  1.72it/s]                                                      {'loss': 0.6416, 'grad_norm': 6.315466403961182, 'learning_rate': 1.6601465958839746e-05, 'epoch': 6.79}
 27%|██▋       | 4760/17525 [57:05<2:03:20,  1.72it/s] 27%|██▋       | 4761/17525 [57:06<2:03:17,  1.73it/s] 27%|██▋       | 4762/17525 [57:07<2:03:01,  1.73it/s] 27%|██▋       | 4763/17525 [57:07<2:02:41,  1.73it/s] 27%|██▋       | 4764/17525 [57:08<2:02:48,  1.73it/s] 27%|██▋       | 4765/17525 [57:08<2:02:31,  1.74it/s] 27%|██▋       | 4766/17525 [57:09<2:02:30,  1.74it/s] 27%|██▋       | 4767/17525 [57:09<2:02:40,  1.73it/s] 27%|██▋       | 4768/17525 [57:10<2:02:47,  1.73it/s] 27%|██▋       | 4769/17525 [57:11<2:02:52,  1.73it/s] 27%|██▋       | 4770/17525 [57:11<2:04:23,  1.71it/s]                                                      {'loss': 0.6445, 'grad_norm': 10.897111892700195, 'learning_rate': 1.6587974810311135e-05, 'epoch': 6.8}
 27%|██▋       | 4770/17525 [57:11<2:04:23,  1.71it/s] 27%|██▋       | 4771/17525 [57:12<2:04:00,  1.71it/s] 27%|██▋       | 4772/17525 [57:12<2:03:44,  1.72it/s] 27%|██▋       | 4773/17525 [57:13<2:03:25,  1.72it/s] 27%|██▋       | 4774/17525 [57:14<2:03:04,  1.73it/s] 27%|██▋       | 4775/17525 [57:14<2:02:50,  1.73it/s] 27%|██▋       | 4776/17525 [57:15<2:02:35,  1.73it/s] 27%|██▋       | 4777/17525 [57:15<2:02:41,  1.73it/s] 27%|██▋       | 4778/17525 [57:16<2:02:35,  1.73it/s] 27%|██▋       | 4779/17525 [57:16<2:02:30,  1.73it/s] 27%|██▋       | 4780/17525 [57:17<2:02:28,  1.73it/s]                                                      {'loss': 0.5684, 'grad_norm': 8.380037307739258, 'learning_rate': 1.6574462442664502e-05, 'epoch': 6.82}
 27%|██▋       | 4780/17525 [57:17<2:02:28,  1.73it/s] 27%|██▋       | 4781/17525 [57:18<2:02:40,  1.73it/s] 27%|██▋       | 4782/17525 [57:18<2:02:21,  1.74it/s] 27%|██▋       | 4783/17525 [57:19<2:02:19,  1.74it/s] 27%|██▋       | 4784/17525 [57:19<2:02:23,  1.74it/s] 27%|██▋       | 4785/17525 [57:20<2:02:37,  1.73it/s] 27%|██▋       | 4786/17525 [57:20<2:02:26,  1.73it/s] 27%|██▋       | 4787/17525 [57:21<2:02:11,  1.74it/s] 27%|██▋       | 4788/17525 [57:22<2:02:20,  1.74it/s] 27%|██▋       | 4789/17525 [57:22<2:02:27,  1.73it/s] 27%|██▋       | 4790/17525 [57:23<2:03:59,  1.71it/s]                                                      {'loss': 0.5916, 'grad_norm': 6.1650285720825195, 'learning_rate': 1.6560928899421633e-05, 'epoch': 6.83}
 27%|██▋       | 4790/17525 [57:23<2:03:59,  1.71it/s] 27%|██▋       | 4791/17525 [57:23<2:03:35,  1.72it/s] 27%|██▋       | 4792/17525 [57:24<2:03:05,  1.72it/s] 27%|██▋       | 4793/17525 [57:25<2:03:14,  1.72it/s] 27%|██▋       | 4794/17525 [57:25<2:02:44,  1.73it/s] 27%|██▋       | 4795/17525 [57:26<2:02:40,  1.73it/s] 27%|██▋       | 4796/17525 [57:26<2:02:41,  1.73it/s] 27%|██▋       | 4797/17525 [57:27<2:02:34,  1.73it/s] 27%|██▋       | 4798/17525 [57:27<2:02:21,  1.73it/s] 27%|██▋       | 4799/17525 [57:28<2:03:56,  1.71it/s] 27%|██▋       | 4800/17525 [57:29<2:03:19,  1.72it/s]                                                      {'loss': 0.5028, 'grad_norm': 8.756266593933105, 'learning_rate': 1.6547374224172537e-05, 'epoch': 6.85}
 27%|██▋       | 4800/17525 [57:29<2:03:19,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:00:50,480 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:00:50,480 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:00:50,480 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                      
                                               [A{'eval_loss': 0.88062983751297, 'eval_runtime': 4.6098, 'eval_samples_per_second': 96.1, 'eval_steps_per_second': 4.122, 'epoch': 6.85}
 27%|██▋       | 4800/17525 [57:33<2:03:19,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:00:55,094 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a45990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f792be20-a055-44f4-aa16-7df1252deda3)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:01:05,164 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:01:05,166 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 27%|██▋       | 4801/17525 [57:44<17:46:36,  5.03s/it] 27%|██▋       | 4802/17525 [57:45<13:03:15,  3.69s/it] 27%|██▋       | 4803/17525 [57:45<9:44:54,  2.76s/it]  27%|██▋       | 4804/17525 [57:46<7:26:03,  2.10s/it] 27%|██▋       | 4805/17525 [57:46<5:48:53,  1.65s/it] 27%|██▋       | 4806/17525 [57:47<4:40:58,  1.33s/it] 27%|██▋       | 4807/17525 [57:47<3:53:15,  1.10s/it] 27%|██▋       | 4808/17525 [57:48<3:19:47,  1.06it/s] 27%|██▋       | 4809/17525 [57:49<2:56:26,  1.20it/s] 27%|██▋       | 4810/17525 [57:49<2:40:10,  1.32it/s]                                                      {'loss': 0.5894, 'grad_norm': 10.465367317199707, 'learning_rate': 1.6533798460575285e-05, 'epoch': 6.86}
 27%|██▋       | 4810/17525 [57:49<2:40:10,  1.32it/s] 27%|██▋       | 4811/17525 [57:50<2:28:49,  1.42it/s] 27%|██▋       | 4812/17525 [57:50<2:22:34,  1.49it/s] 27%|██▋       | 4813/17525 [57:51<2:16:31,  1.55it/s] 27%|██▋       | 4814/17525 [57:52<2:12:11,  1.60it/s] 27%|██▋       | 4815/17525 [57:52<2:09:05,  1.64it/s] 27%|██▋       | 4816/17525 [57:53<2:06:59,  1.67it/s] 27%|██▋       | 4817/17525 [57:53<2:05:34,  1.69it/s] 27%|██▋       | 4818/17525 [57:54<2:04:30,  1.70it/s] 27%|██▋       | 4819/17525 [57:54<2:03:33,  1.71it/s] 28%|██▊       | 4820/17525 [57:55<2:03:06,  1.72it/s]                                                      {'loss': 0.6171, 'grad_norm': 4.326815128326416, 'learning_rate': 1.652020165235587e-05, 'epoch': 6.88}
 28%|██▊       | 4820/17525 [57:55<2:03:06,  1.72it/s] 28%|██▊       | 4821/17525 [57:56<2:03:46,  1.71it/s] 28%|██▊       | 4822/17525 [57:56<2:03:07,  1.72it/s] 28%|██▊       | 4823/17525 [57:57<2:02:32,  1.73it/s] 28%|██▊       | 4824/17525 [57:57<2:02:20,  1.73it/s] 28%|██▊       | 4825/17525 [57:58<2:02:08,  1.73it/s] 28%|██▊       | 4826/17525 [57:58<2:02:09,  1.73it/s] 28%|██▊       | 4827/17525 [57:59<2:11:04,  1.61it/s] 28%|██▊       | 4828/17525 [58:00<2:08:26,  1.65it/s] 28%|██▊       | 4829/17525 [58:00<2:06:29,  1.67it/s] 28%|██▊       | 4830/17525 [58:01<2:05:03,  1.69it/s]                                                      {'loss': 0.5913, 'grad_norm': 4.47622013092041, 'learning_rate': 1.6506583843308058e-05, 'epoch': 6.89}
 28%|██▊       | 4830/17525 [58:01<2:05:03,  1.69it/s] 28%|██▊       | 4831/17525 [58:01<2:04:40,  1.70it/s] 28%|██▊       | 4832/17525 [58:02<2:03:44,  1.71it/s] 28%|██▊       | 4833/17525 [58:03<2:03:09,  1.72it/s] 28%|██▊       | 4834/17525 [58:03<2:02:31,  1.73it/s] 28%|██▊       | 4835/17525 [58:04<2:02:25,  1.73it/s] 28%|██▊       | 4836/17525 [58:04<2:02:21,  1.73it/s] 28%|██▊       | 4837/17525 [58:05<2:02:12,  1.73it/s] 28%|██▊       | 4838/17525 [58:06<2:02:03,  1.73it/s] 28%|██▊       | 4839/17525 [58:06<2:24:33,  1.46it/s] 28%|██▊       | 4840/17525 [58:07<2:17:48,  1.53it/s]                                                      {'loss': 0.5977, 'grad_norm': 8.3724946975708, 'learning_rate': 1.649294507729327e-05, 'epoch': 6.9}
 28%|██▊       | 4840/17525 [58:07<2:17:48,  1.53it/s] 28%|██▊       | 4841/17525 [58:08<2:13:01,  1.59it/s] 28%|██▊       | 4842/17525 [58:08<2:09:41,  1.63it/s] 28%|██▊       | 4843/17525 [58:09<2:28:14,  1.43it/s] 28%|██▊       | 4844/17525 [58:10<2:21:53,  1.49it/s] 28%|██▊       | 4845/17525 [58:10<2:15:47,  1.56it/s] 28%|██▊       | 4846/17525 [58:11<2:11:28,  1.61it/s] 28%|██▊       | 4847/17525 [58:12<2:28:31,  1.42it/s] 28%|██▊       | 4848/17525 [58:12<2:20:21,  1.51it/s] 28%|██▊       | 4849/17525 [58:13<2:15:13,  1.56it/s] 28%|██▊       | 4850/17525 [58:13<2:11:20,  1.61it/s]                                                      {'loss': 0.6245, 'grad_norm': 10.423442840576172, 'learning_rate': 1.647928539824042e-05, 'epoch': 6.92}
 28%|██▊       | 4850/17525 [58:13<2:11:20,  1.61it/s] 28%|██▊       | 4851/17525 [58:14<2:09:25,  1.63it/s] 28%|██▊       | 4852/17525 [58:15<2:07:14,  1.66it/s] 28%|██▊       | 4853/17525 [58:15<2:05:32,  1.68it/s] 28%|██▊       | 4854/17525 [58:16<2:05:48,  1.68it/s] 28%|██▊       | 4855/17525 [58:16<2:04:38,  1.69it/s] 28%|██▊       | 4856/17525 [58:17<2:03:35,  1.71it/s] 28%|██▊       | 4857/17525 [58:18<2:03:16,  1.71it/s] 28%|██▊       | 4858/17525 [58:18<2:02:51,  1.72it/s] 28%|██▊       | 4859/17525 [58:19<2:02:35,  1.72it/s] 28%|██▊       | 4860/17525 [58:19<2:02:20,  1.73it/s]                                                      {'loss': 0.6602, 'grad_norm': 16.762250900268555, 'learning_rate': 1.6465604850145785e-05, 'epoch': 6.93}
 28%|██▊       | 4860/17525 [58:19<2:02:20,  1.73it/s] 28%|██▊       | 4861/17525 [58:20<2:02:29,  1.72it/s] 28%|██▊       | 4862/17525 [58:20<2:02:18,  1.73it/s] 28%|██▊       | 4863/17525 [58:21<2:02:47,  1.72it/s] 28%|██▊       | 4864/17525 [58:22<2:02:15,  1.73it/s] 28%|██▊       | 4865/17525 [58:22<2:01:54,  1.73it/s] 28%|██▊       | 4866/17525 [58:23<2:01:46,  1.73it/s] 28%|██▊       | 4867/17525 [58:23<2:01:41,  1.73it/s] 28%|██▊       | 4868/17525 [58:24<2:01:26,  1.74it/s] 28%|██▊       | 4869/17525 [58:24<2:01:11,  1.74it/s] 28%|██▊       | 4870/17525 [58:25<2:01:08,  1.74it/s]                                                      {'loss': 0.6709, 'grad_norm': 7.9366960525512695, 'learning_rate': 1.6451903477072848e-05, 'epoch': 6.95}
 28%|██▊       | 4870/17525 [58:25<2:01:08,  1.74it/s] 28%|██▊       | 4871/17525 [58:26<2:01:05,  1.74it/s] 28%|██▊       | 4872/17525 [58:26<2:01:24,  1.74it/s] 28%|██▊       | 4873/17525 [58:27<2:01:13,  1.74it/s] 28%|██▊       | 4874/17525 [58:27<2:01:21,  1.74it/s] 28%|██▊       | 4875/17525 [58:28<2:01:26,  1.74it/s] 28%|██▊       | 4876/17525 [58:28<2:01:25,  1.74it/s] 28%|██▊       | 4877/17525 [58:29<2:01:06,  1.74it/s] 28%|██▊       | 4878/17525 [58:30<2:01:01,  1.74it/s] 28%|██▊       | 4879/17525 [58:31<2:59:12,  1.18it/s] 28%|██▊       | 4880/17525 [58:32<2:42:01,  1.30it/s]                                                      {'loss': 0.6587, 'grad_norm': 6.202267169952393, 'learning_rate': 1.6438181323152176e-05, 'epoch': 6.96}
 28%|██▊       | 4880/17525 [58:32<2:42:01,  1.30it/s] 28%|██▊       | 4881/17525 [58:32<2:30:04,  1.40it/s] 28%|██▊       | 4882/17525 [58:33<2:21:24,  1.49it/s] 28%|██▊       | 4883/17525 [58:33<2:15:34,  1.55it/s] 28%|██▊       | 4884/17525 [58:34<2:11:13,  1.61it/s] 28%|██▊       | 4885/17525 [58:35<2:08:16,  1.64it/s] 28%|██▊       | 4886/17525 [58:35<2:06:04,  1.67it/s] 28%|██▊       | 4887/17525 [58:36<2:04:28,  1.69it/s] 28%|██▊       | 4888/17525 [58:36<2:03:32,  1.70it/s] 28%|██▊       | 4889/17525 [58:37<2:25:21,  1.45it/s] 28%|██▊       | 4890/17525 [58:38<2:18:06,  1.52it/s]                                                      {'loss': 0.6716, 'grad_norm': 6.808158874511719, 'learning_rate': 1.642443843258127e-05, 'epoch': 6.98}
 28%|██▊       | 4890/17525 [58:38<2:18:06,  1.52it/s] 28%|██▊       | 4891/17525 [58:38<2:13:07,  1.58it/s] 28%|██▊       | 4892/17525 [58:39<2:09:33,  1.63it/s] 28%|██▊       | 4893/17525 [58:40<2:08:11,  1.64it/s] 28%|██▊       | 4894/17525 [58:40<2:06:04,  1.67it/s] 28%|██▊       | 4895/17525 [58:41<2:14:00,  1.57it/s] 28%|██▊       | 4896/17525 [58:41<2:10:06,  1.62it/s] 28%|██▊       | 4897/17525 [58:42<2:07:11,  1.65it/s] 28%|██▊       | 4898/17525 [58:43<2:05:22,  1.68it/s] 28%|██▊       | 4899/17525 [58:43<2:03:55,  1.70it/s] 28%|██▊       | 4900/17525 [58:44<2:03:13,  1.71it/s]                                                      {'loss': 0.6161, 'grad_norm': 7.628984451293945, 'learning_rate': 1.6410674849624418e-05, 'epoch': 6.99}
 28%|██▊       | 4900/17525 [58:44<2:03:13,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 03:02:05,630 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:02:05,631 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:02:05,631 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.61it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.86it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.880927324295044, 'eval_runtime': 4.6061, 'eval_samples_per_second': 96.176, 'eval_steps_per_second': 4.125, 'epoch': 6.99}
 28%|██▊       | 4900/17525 [58:48<2:03:13,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 28%|██▊       | 4901/17525 [58:49<6:53:53,  1.97s/it] 28%|██▊       | 4902/17525 [58:50<5:26:07,  1.55s/it] 28%|██▊       | 4903/17525 [58:50<4:24:25,  1.26s/it] 28%|██▊       | 4904/17525 [58:51<3:41:59,  1.06s/it] 28%|██▊       | 4905/17525 [58:51<3:11:46,  1.10it/s] 28%|██▊       | 4906/17525 [58:52<2:50:34,  1.23it/s] 28%|██▊       | 4907/17525 [58:52<2:36:04,  1.35it/s] 28%|██▊       | 4908/17525 [58:53<2:25:35,  1.44it/s] 28%|██▊       | 4909/17525 [58:54<2:18:21,  1.52it/s] 28%|██▊       | 4910/17525 [58:54<2:13:01,  1.58it/s]                                                      {'loss': 0.6273, 'grad_norm': 4.509006977081299, 'learning_rate': 1.639689061861256e-05, 'epoch': 7.0}
 28%|██▊       | 4910/17525 [58:54<2:13:01,  1.58it/s] 28%|██▊       | 4911/17525 [58:55<2:09:42,  1.62it/s] 28%|██▊       | 4912/17525 [58:55<2:07:05,  1.65it/s] 28%|██▊       | 4913/17525 [58:56<2:05:15,  1.68it/s] 28%|██▊       | 4914/17525 [58:56<2:03:48,  1.70it/s] 28%|██▊       | 4915/17525 [58:57<2:02:58,  1.71it/s] 28%|██▊       | 4916/17525 [58:58<2:03:40,  1.70it/s] 28%|██▊       | 4917/17525 [58:58<2:02:55,  1.71it/s] 28%|██▊       | 4918/17525 [58:59<2:02:15,  1.72it/s] 28%|██▊       | 4919/17525 [58:59<2:01:59,  1.72it/s] 28%|██▊       | 4920/17525 [59:00<2:01:46,  1.73it/s]                                                      {'loss': 0.5543, 'grad_norm': 9.15009880065918, 'learning_rate': 1.638308578394313e-05, 'epoch': 7.02}
 28%|██▊       | 4920/17525 [59:00<2:01:46,  1.73it/s] 28%|██▊       | 4921/17525 [59:00<2:01:47,  1.72it/s] 28%|██▊       | 4922/17525 [59:01<2:01:38,  1.73it/s] 28%|██▊       | 4923/17525 [59:02<2:01:23,  1.73it/s] 28%|██▊       | 4924/17525 [59:02<2:01:02,  1.73it/s] 28%|██▊       | 4925/17525 [59:03<2:01:08,  1.73it/s] 28%|██▊       | 4926/17525 [59:03<2:01:03,  1.73it/s] 28%|██▊       | 4927/17525 [59:04<2:00:58,  1.74it/s] 28%|██▊       | 4928/17525 [59:05<2:01:17,  1.73it/s] 28%|██▊       | 4929/17525 [59:05<2:01:07,  1.73it/s] 28%|██▊       | 4930/17525 [59:06<2:01:14,  1.73it/s]                                                      {'loss': 0.5507, 'grad_norm': 6.144349575042725, 'learning_rate': 1.6369260390079933e-05, 'epoch': 7.03}
 28%|██▊       | 4930/17525 [59:06<2:01:14,  1.73it/s] 28%|██▊       | 4931/17525 [59:06<2:01:08,  1.73it/s] 28%|██▊       | 4932/17525 [59:07<2:09:29,  1.62it/s] 28%|██▊       | 4933/17525 [59:08<2:07:48,  1.64it/s] 28%|██▊       | 4934/17525 [59:08<2:05:48,  1.67it/s] 28%|██▊       | 4935/17525 [59:09<2:04:18,  1.69it/s] 28%|██▊       | 4936/17525 [59:09<2:03:02,  1.71it/s] 28%|██▊       | 4937/17525 [59:10<2:02:23,  1.71it/s] 28%|██▊       | 4938/17525 [59:10<2:01:49,  1.72it/s] 28%|██▊       | 4939/17525 [59:11<2:01:28,  1.73it/s] 28%|██▊       | 4940/17525 [59:12<2:01:21,  1.73it/s]                                                      {'loss': 0.5691, 'grad_norm': 11.548606872558594, 'learning_rate': 1.635541448155299e-05, 'epoch': 7.05}
 28%|██▊       | 4940/17525 [59:12<2:01:21,  1.73it/s] 28%|██▊       | 4941/17525 [59:12<2:01:26,  1.73it/s] 28%|██▊       | 4942/17525 [59:13<2:01:36,  1.72it/s] 28%|██▊       | 4943/17525 [59:13<2:01:35,  1.72it/s] 28%|██▊       | 4944/17525 [59:14<2:01:27,  1.73it/s] 28%|██▊       | 4945/17525 [59:14<2:01:07,  1.73it/s] 28%|██▊       | 4946/17525 [59:15<2:02:02,  1.72it/s] 28%|██▊       | 4947/17525 [59:16<2:02:02,  1.72it/s] 28%|██▊       | 4948/17525 [59:16<2:01:42,  1.72it/s] 28%|██▊       | 4949/17525 [59:17<2:01:32,  1.72it/s] 28%|██▊       | 4950/17525 [59:17<2:01:35,  1.72it/s]                                                      {'loss': 0.5436, 'grad_norm': 8.737807273864746, 'learning_rate': 1.6341548102958404e-05, 'epoch': 7.06}
 28%|██▊       | 4950/17525 [59:17<2:01:35,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 03:02:39,281 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a72f10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e7b1f33d-fa0b-42bc-aa8f-edd5af5c54c9)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:02:49,388 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:02:49,390 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-4950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 28%|██▊       | 4951/17525 [59:28<12:45:55,  3.65s/it] 28%|██▊       | 4952/17525 [59:29<9:32:23,  2.73s/it]  28%|██▊       | 4953/17525 [59:29<7:16:47,  2.08s/it] 28%|██▊       | 4954/17525 [59:30<5:41:54,  1.63s/it] 28%|██▊       | 4955/17525 [59:31<4:37:13,  1.32s/it] 28%|██▊       | 4956/17525 [59:32<4:56:28,  1.42s/it] 28%|██▊       | 4957/17525 [59:33<4:04:27,  1.17s/it] 28%|██▊       | 4958/17525 [59:33<3:27:21,  1.01it/s] 28%|██▊       | 4959/17525 [59:34<3:01:21,  1.15it/s] 28%|██▊       | 4960/17525 [59:34<2:43:13,  1.28it/s]                                                      {'loss': 0.4951, 'grad_norm': 12.4540376663208, 'learning_rate': 1.6327661298958205e-05, 'epoch': 7.08}
 28%|██▊       | 4960/17525 [59:34<2:43:13,  1.28it/s] 28%|██▊       | 4961/17525 [59:35<2:30:36,  1.39it/s] 28%|██▊       | 4962/17525 [59:36<2:21:39,  1.48it/s] 28%|██▊       | 4963/17525 [59:36<2:15:11,  1.55it/s] 28%|██▊       | 4964/17525 [59:37<2:10:45,  1.60it/s] 28%|██▊       | 4965/17525 [59:37<2:07:45,  1.64it/s] 28%|██▊       | 4966/17525 [59:38<2:05:34,  1.67it/s] 28%|██▊       | 4967/17525 [59:39<2:04:12,  1.69it/s] 28%|██▊       | 4968/17525 [59:39<2:05:50,  1.66it/s] 28%|██▊       | 4969/17525 [59:40<2:04:22,  1.68it/s] 28%|██▊       | 4970/17525 [59:40<2:03:23,  1.70it/s]                                                      {'loss': 0.5855, 'grad_norm': 11.502779006958008, 'learning_rate': 1.63137541142802e-05, 'epoch': 7.09}
 28%|██▊       | 4970/17525 [59:40<2:03:23,  1.70it/s] 28%|██▊       | 4971/17525 [59:41<2:02:40,  1.71it/s] 28%|██▊       | 4972/17525 [59:41<2:01:51,  1.72it/s] 28%|██▊       | 4973/17525 [59:42<2:01:12,  1.73it/s] 28%|██▊       | 4974/17525 [59:43<2:01:05,  1.73it/s] 28%|██▊       | 4975/17525 [59:43<2:00:47,  1.73it/s] 28%|██▊       | 4976/17525 [59:44<2:00:30,  1.74it/s] 28%|██▊       | 4977/17525 [59:44<2:00:17,  1.74it/s] 28%|██▊       | 4978/17525 [59:45<2:00:41,  1.73it/s] 28%|██▊       | 4979/17525 [59:45<2:00:37,  1.73it/s] 28%|██▊       | 4980/17525 [59:46<2:00:48,  1.73it/s]                                                      {'loss': 0.6074, 'grad_norm': 5.238650321960449, 'learning_rate': 1.629982659371786e-05, 'epoch': 7.1}
 28%|██▊       | 4980/17525 [59:46<2:00:48,  1.73it/s] 28%|██▊       | 4981/17525 [59:47<2:01:27,  1.72it/s] 28%|██▊       | 4982/17525 [59:47<2:01:11,  1.73it/s] 28%|██▊       | 4983/17525 [59:48<2:01:02,  1.73it/s] 28%|██▊       | 4984/17525 [59:48<2:01:04,  1.73it/s] 28%|██▊       | 4985/17525 [59:49<2:01:01,  1.73it/s] 28%|██▊       | 4986/17525 [59:50<2:00:42,  1.73it/s] 28%|██▊       | 4987/17525 [59:51<2:28:33,  1.41it/s] 28%|██▊       | 4988/17525 [59:51<2:20:04,  1.49it/s] 28%|██▊       | 4989/17525 [59:52<2:15:33,  1.54it/s] 28%|██▊       | 4990/17525 [59:52<2:10:58,  1.60it/s]                                                      {'loss': 0.4746, 'grad_norm': 18.207412719726562, 'learning_rate': 1.628587878213014e-05, 'epoch': 7.12}
 28%|██▊       | 4990/17525 [59:52<2:10:58,  1.60it/s] 28%|██▊       | 4991/17525 [59:53<2:07:44,  1.64it/s] 28%|██▊       | 4992/17525 [59:53<2:05:11,  1.67it/s] 28%|██▊       | 4993/17525 [59:54<2:05:37,  1.66it/s] 28%|██▊       | 4994/17525 [59:55<2:04:07,  1.68it/s] 29%|██▊       | 4995/17525 [59:55<2:02:53,  1.70it/s] 29%|██▊       | 4996/17525 [59:56<2:02:05,  1.71it/s] 29%|██▊       | 4997/17525 [59:56<2:01:47,  1.71it/s] 29%|██▊       | 4998/17525 [59:57<2:01:18,  1.72it/s] 29%|██▊       | 4999/17525 [59:58<2:00:57,  1.73it/s] 29%|██▊       | 5000/17525 [59:58<2:00:54,  1.73it/s]                                                      {'loss': 0.4201, 'grad_norm': 13.029526710510254, 'learning_rate': 1.627191072444136e-05, 'epoch': 7.13}
 29%|██▊       | 5000/17525 [59:58<2:00:54,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:03:20,001 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:03:20,001 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:03:20,001 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                      
                                               [A{'eval_loss': 0.8932812213897705, 'eval_runtime': 4.5968, 'eval_samples_per_second': 96.372, 'eval_steps_per_second': 4.133, 'epoch': 7.13}
 29%|██▊       | 5000/17525 [1:00:03<2:00:54,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 29%|██▊       | 5001/17525 [1:00:03<6:49:03,  1.96s/it] 29%|██▊       | 5002/17525 [1:00:04<5:22:22,  1.54s/it] 29%|██▊       | 5003/17525 [1:00:04<4:21:34,  1.25s/it] 29%|██▊       | 5004/17525 [1:00:05<3:38:58,  1.05s/it] 29%|██▊       | 5005/17525 [1:00:06<3:09:10,  1.10it/s] 29%|██▊       | 5006/17525 [1:00:06<2:49:07,  1.23it/s] 29%|██▊       | 5007/17525 [1:00:07<2:34:10,  1.35it/s] 29%|██▊       | 5008/17525 [1:00:07<2:23:49,  1.45it/s] 29%|██▊       | 5009/17525 [1:00:08<2:16:43,  1.53it/s] 29%|██▊       | 5010/17525 [1:00:08<2:11:39,  1.58it/s]                                                        {'loss': 0.5602, 'grad_norm': 11.521580696105957, 'learning_rate': 1.6257922465641044e-05, 'epoch': 7.15}
 29%|██▊       | 5010/17525 [1:00:08<2:11:39,  1.58it/s] 29%|██▊       | 5011/17525 [1:00:09<2:08:18,  1.63it/s] 29%|██▊       | 5012/17525 [1:00:10<2:33:30,  1.36it/s] 29%|██▊       | 5013/17525 [1:00:11<2:23:24,  1.45it/s] 29%|██▊       | 5014/17525 [1:00:11<2:16:13,  1.53it/s] 29%|██▊       | 5015/17525 [1:00:12<2:11:09,  1.59it/s] 29%|██▊       | 5016/17525 [1:00:12<2:07:36,  1.63it/s] 29%|██▊       | 5017/17525 [1:00:13<2:05:19,  1.66it/s] 29%|██▊       | 5018/17525 [1:00:14<2:03:29,  1.69it/s] 29%|██▊       | 5019/17525 [1:00:14<2:25:57,  1.43it/s] 29%|██▊       | 5020/17525 [1:00:15<2:18:02,  1.51it/s]                                                        {'loss': 0.4597, 'grad_norm': 4.952755928039551, 'learning_rate': 1.6243914050783783e-05, 'epoch': 7.16}
 29%|██▊       | 5020/17525 [1:00:15<2:18:02,  1.51it/s] 29%|██▊       | 5021/17525 [1:00:16<2:12:48,  1.57it/s] 29%|██▊       | 5022/17525 [1:00:16<2:08:50,  1.62it/s] 29%|██▊       | 5023/17525 [1:00:17<2:06:08,  1.65it/s] 29%|██▊       | 5024/17525 [1:00:17<2:04:13,  1.68it/s] 29%|██▊       | 5025/17525 [1:00:18<2:03:07,  1.69it/s] 29%|██▊       | 5026/17525 [1:00:18<2:01:55,  1.71it/s] 29%|██▊       | 5027/17525 [1:00:19<2:01:13,  1.72it/s] 29%|██▊       | 5028/17525 [1:00:20<2:00:41,  1.73it/s] 29%|██▊       | 5029/17525 [1:00:20<2:00:21,  1.73it/s] 29%|██▊       | 5030/17525 [1:00:21<1:59:58,  1.74it/s]                                                        {'loss': 0.4946, 'grad_norm': 5.661981105804443, 'learning_rate': 1.6229885524989087e-05, 'epoch': 7.18}
 29%|██▊       | 5030/17525 [1:00:21<1:59:58,  1.74it/s] 29%|██▊       | 5031/17525 [1:00:22<2:09:27,  1.61it/s] 29%|██▊       | 5032/17525 [1:00:22<2:06:36,  1.64it/s] 29%|██▊       | 5033/17525 [1:00:23<2:04:28,  1.67it/s] 29%|██▊       | 5034/17525 [1:00:23<2:02:49,  1.69it/s] 29%|██▊       | 5035/17525 [1:00:24<2:01:41,  1.71it/s] 29%|██▊       | 5036/17525 [1:00:24<2:00:50,  1.72it/s] 29%|██▊       | 5037/17525 [1:00:25<2:00:21,  1.73it/s] 29%|██▊       | 5038/17525 [1:00:26<2:00:27,  1.73it/s] 29%|██▉       | 5039/17525 [1:00:26<2:00:08,  1.73it/s] 29%|██▉       | 5040/17525 [1:00:27<2:00:02,  1.73it/s]                                                        {'loss': 0.5504, 'grad_norm': 7.039178848266602, 'learning_rate': 1.621583693344125e-05, 'epoch': 7.19}
 29%|██▉       | 5040/17525 [1:00:27<2:00:02,  1.73it/s] 29%|██▉       | 5041/17525 [1:00:27<1:59:54,  1.74it/s] 29%|██▉       | 5042/17525 [1:00:28<2:22:28,  1.46it/s] 29%|██▉       | 5043/17525 [1:00:29<2:15:14,  1.54it/s] 29%|██▉       | 5044/17525 [1:00:29<2:10:14,  1.60it/s] 29%|██▉       | 5045/17525 [1:00:30<2:06:57,  1.64it/s] 29%|██▉       | 5046/17525 [1:00:30<2:04:26,  1.67it/s] 29%|██▉       | 5047/17525 [1:00:31<2:02:57,  1.69it/s] 29%|██▉       | 5048/17525 [1:00:32<2:01:44,  1.71it/s] 29%|██▉       | 5049/17525 [1:00:32<2:00:58,  1.72it/s] 29%|██▉       | 5050/17525 [1:00:33<2:00:15,  1.73it/s]                                                        {'loss': 0.5141, 'grad_norm': 10.445145606994629, 'learning_rate': 1.6201768321389183e-05, 'epoch': 7.2}
 29%|██▉       | 5050/17525 [1:00:33<2:00:15,  1.73it/s] 29%|██▉       | 5051/17525 [1:00:33<2:00:04,  1.73it/s] 29%|██▉       | 5052/17525 [1:00:34<2:01:13,  1.71it/s] 29%|██▉       | 5053/17525 [1:00:35<2:00:55,  1.72it/s] 29%|██▉       | 5054/17525 [1:00:35<2:00:15,  1.73it/s] 29%|██▉       | 5055/17525 [1:00:36<1:59:42,  1.74it/s] 29%|██▉       | 5056/17525 [1:00:36<1:59:31,  1.74it/s] 29%|██▉       | 5057/17525 [1:00:37<1:59:18,  1.74it/s] 29%|██▉       | 5058/17525 [1:00:37<2:00:46,  1.72it/s] 29%|██▉       | 5059/17525 [1:00:38<2:00:19,  1.73it/s] 29%|██▉       | 5060/17525 [1:00:39<1:59:56,  1.73it/s]                                                        {'loss': 0.5517, 'grad_norm': 14.458395004272461, 'learning_rate': 1.6187679734146288e-05, 'epoch': 7.22}
 29%|██▉       | 5060/17525 [1:00:39<1:59:56,  1.73it/s] 29%|██▉       | 5061/17525 [1:00:39<1:59:53,  1.73it/s] 29%|██▉       | 5062/17525 [1:00:40<1:59:22,  1.74it/s] 29%|██▉       | 5063/17525 [1:00:40<1:59:19,  1.74it/s] 29%|██▉       | 5064/17525 [1:00:41<1:58:54,  1.75it/s] 29%|██▉       | 5065/17525 [1:00:41<1:59:02,  1.74it/s] 29%|██▉       | 5066/17525 [1:00:42<1:59:06,  1.74it/s] 29%|██▉       | 5067/17525 [1:00:43<1:59:05,  1.74it/s] 29%|██▉       | 5068/17525 [1:00:43<1:59:00,  1.74it/s] 29%|██▉       | 5069/17525 [1:00:44<1:58:54,  1.75it/s] 29%|██▉       | 5070/17525 [1:00:44<1:58:54,  1.75it/s]                                                        {'loss': 0.5265, 'grad_norm': 12.365863800048828, 'learning_rate': 1.61735712170903e-05, 'epoch': 7.23}
 29%|██▉       | 5070/17525 [1:00:44<1:58:54,  1.75it/s] 29%|██▉       | 5071/17525 [1:00:45<1:59:02,  1.74it/s] 29%|██▉       | 5072/17525 [1:00:46<2:20:55,  1.47it/s] 29%|██▉       | 5073/17525 [1:00:46<2:14:32,  1.54it/s] 29%|██▉       | 5074/17525 [1:00:47<2:09:48,  1.60it/s] 29%|██▉       | 5075/17525 [1:00:47<2:06:23,  1.64it/s] 29%|██▉       | 5076/17525 [1:00:48<2:04:19,  1.67it/s] 29%|██▉       | 5077/17525 [1:00:49<2:14:13,  1.55it/s] 29%|██▉       | 5078/17525 [1:00:49<2:09:31,  1.60it/s] 29%|██▉       | 5079/17525 [1:00:50<2:06:26,  1.64it/s] 29%|██▉       | 5080/17525 [1:00:51<2:04:26,  1.67it/s]                                                        {'loss': 0.5555, 'grad_norm': 13.052342414855957, 'learning_rate': 1.615944281566315e-05, 'epoch': 7.25}
 29%|██▉       | 5080/17525 [1:00:51<2:04:26,  1.67it/s] 29%|██▉       | 5081/17525 [1:00:51<2:02:45,  1.69it/s] 29%|██▉       | 5082/17525 [1:00:52<2:01:35,  1.71it/s] 29%|██▉       | 5083/17525 [1:00:52<2:00:37,  1.72it/s] 29%|██▉       | 5084/17525 [1:00:53<1:59:56,  1.73it/s] 29%|██▉       | 5085/17525 [1:00:53<1:59:35,  1.73it/s] 29%|██▉       | 5086/17525 [1:00:54<1:59:34,  1.73it/s] 29%|██▉       | 5087/17525 [1:00:55<1:59:20,  1.74it/s] 29%|██▉       | 5088/17525 [1:00:55<1:59:09,  1.74it/s] 29%|██▉       | 5089/17525 [1:00:56<1:59:01,  1.74it/s] 29%|██▉       | 5090/17525 [1:00:56<1:58:45,  1.75it/s]                                                        {'loss': 0.5037, 'grad_norm': 15.445481300354004, 'learning_rate': 1.614529457537082e-05, 'epoch': 7.26}
 29%|██▉       | 5090/17525 [1:00:56<1:58:45,  1.75it/s] 29%|██▉       | 5091/17525 [1:00:57<2:00:00,  1.73it/s] 29%|██▉       | 5092/17525 [1:00:57<1:59:29,  1.73it/s] 29%|██▉       | 5093/17525 [1:00:58<1:59:12,  1.74it/s] 29%|██▉       | 5094/17525 [1:00:59<1:59:05,  1.74it/s] 29%|██▉       | 5095/17525 [1:00:59<1:59:04,  1.74it/s] 29%|██▉       | 5096/17525 [1:01:00<1:59:03,  1.74it/s] 29%|██▉       | 5097/17525 [1:01:00<1:59:01,  1.74it/s] 29%|██▉       | 5098/17525 [1:01:01<1:58:59,  1.74it/s] 29%|██▉       | 5099/17525 [1:01:01<1:58:56,  1.74it/s] 29%|██▉       | 5100/17525 [1:01:02<1:58:58,  1.74it/s]                                                        {'loss': 0.5251, 'grad_norm': 10.108530044555664, 'learning_rate': 1.6131126541783174e-05, 'epoch': 7.28}
 29%|██▉       | 5100/17525 [1:01:02<1:58:58,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 03:04:23,926 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:04:23,926 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:04:23,926 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.8982316851615906, 'eval_runtime': 4.6012, 'eval_samples_per_second': 96.278, 'eval_steps_per_second': 4.129, 'epoch': 7.28}
 29%|██▉       | 5100/17525 [1:01:07<1:58:58,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:04:28,531 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a519d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5eb3437b-e4c6-4070-94e7-9adbeb926972)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:04:38,591 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:04:38,594 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 29%|██▉       | 5101/17525 [1:01:17<17:18:10,  5.01s/it] 29%|██▉       | 5102/17525 [1:01:18<12:42:15,  3.68s/it] 29%|██▉       | 5103/17525 [1:01:19<9:29:05,  2.75s/it]  29%|██▉       | 5104/17525 [1:01:19<7:13:37,  2.09s/it] 29%|██▉       | 5105/17525 [1:01:20<6:27:01,  1.87s/it] 29%|██▉       | 5106/17525 [1:01:21<5:06:21,  1.48s/it] 29%|██▉       | 5107/17525 [1:01:22<4:10:07,  1.21s/it] 29%|██▉       | 5108/17525 [1:01:22<3:30:46,  1.02s/it] 29%|██▉       | 5109/17525 [1:01:23<3:41:11,  1.07s/it] 29%|██▉       | 5110/17525 [1:01:24<3:10:27,  1.09it/s]                                                        {'loss': 0.4674, 'grad_norm': 17.86658477783203, 'learning_rate': 1.6116938760533843e-05, 'epoch': 7.29}
 29%|██▉       | 5110/17525 [1:01:24<3:10:27,  1.09it/s] 29%|██▉       | 5111/17525 [1:01:25<2:49:18,  1.22it/s] 29%|██▉       | 5112/17525 [1:01:25<2:34:00,  1.34it/s] 29%|██▉       | 5113/17525 [1:01:26<2:23:23,  1.44it/s] 29%|██▉       | 5114/17525 [1:01:26<2:15:56,  1.52it/s] 29%|██▉       | 5115/17525 [1:01:27<2:10:40,  1.58it/s] 29%|██▉       | 5116/17525 [1:01:28<2:28:24,  1.39it/s] 29%|██▉       | 5117/17525 [1:01:28<2:19:35,  1.48it/s] 29%|██▉       | 5118/17525 [1:01:29<2:33:36,  1.35it/s] 29%|██▉       | 5119/17525 [1:01:30<2:22:57,  1.45it/s] 29%|██▉       | 5120/17525 [1:01:30<2:15:36,  1.52it/s]                                                        {'loss': 0.6358, 'grad_norm': 14.9244384765625, 'learning_rate': 1.6102731277320056e-05, 'epoch': 7.3}
 29%|██▉       | 5120/17525 [1:01:30<2:15:36,  1.52it/s] 29%|██▉       | 5121/17525 [1:01:31<2:10:37,  1.58it/s] 29%|██▉       | 5122/17525 [1:01:32<2:07:00,  1.63it/s] 29%|██▉       | 5123/17525 [1:01:32<2:04:27,  1.66it/s] 29%|██▉       | 5124/17525 [1:01:33<2:02:26,  1.69it/s] 29%|██▉       | 5125/17525 [1:01:33<2:01:20,  1.70it/s] 29%|██▉       | 5126/17525 [1:01:34<2:00:30,  1.71it/s] 29%|██▉       | 5127/17525 [1:01:34<1:59:59,  1.72it/s] 29%|██▉       | 5128/17525 [1:01:35<1:59:34,  1.73it/s] 29%|██▉       | 5129/17525 [1:01:36<1:59:41,  1.73it/s] 29%|██▉       | 5130/17525 [1:01:36<1:59:15,  1.73it/s]                                                        {'loss': 0.4554, 'grad_norm': 7.488326549530029, 'learning_rate': 1.60885041379025e-05, 'epoch': 7.32}
 29%|██▉       | 5130/17525 [1:01:36<1:59:15,  1.73it/s] 29%|██▉       | 5131/17525 [1:01:37<1:59:02,  1.74it/s] 29%|██▉       | 5132/17525 [1:01:37<1:58:45,  1.74it/s] 29%|██▉       | 5133/17525 [1:01:38<1:58:45,  1.74it/s] 29%|██▉       | 5134/17525 [1:01:38<1:58:40,  1.74it/s] 29%|██▉       | 5135/17525 [1:01:40<2:47:15,  1.23it/s] 29%|██▉       | 5136/17525 [1:01:40<2:32:29,  1.35it/s] 29%|██▉       | 5137/17525 [1:01:41<2:22:17,  1.45it/s] 29%|██▉       | 5138/17525 [1:01:41<2:15:12,  1.53it/s] 29%|██▉       | 5139/17525 [1:01:42<2:10:03,  1.59it/s] 29%|██▉       | 5140/17525 [1:01:43<2:28:16,  1.39it/s]                                                        {'loss': 0.5143, 'grad_norm': 9.329551696777344, 'learning_rate': 1.607425738810518e-05, 'epoch': 7.33}
 29%|██▉       | 5140/17525 [1:01:43<2:28:16,  1.39it/s] 29%|██▉       | 5141/17525 [1:01:44<2:19:20,  1.48it/s] 29%|██▉       | 5142/17525 [1:01:44<2:12:51,  1.55it/s] 29%|██▉       | 5143/17525 [1:01:45<2:08:19,  1.61it/s] 29%|██▉       | 5144/17525 [1:01:45<2:06:48,  1.63it/s] 29%|██▉       | 5145/17525 [1:01:46<2:04:15,  1.66it/s] 29%|██▉       | 5146/17525 [1:01:46<2:02:22,  1.69it/s] 29%|██▉       | 5147/17525 [1:01:47<2:00:56,  1.71it/s] 29%|██▉       | 5148/17525 [1:01:48<1:59:58,  1.72it/s] 29%|██▉       | 5149/17525 [1:01:48<1:59:14,  1.73it/s] 29%|██▉       | 5150/17525 [1:01:49<1:59:03,  1.73it/s]                                                        {'loss': 0.5851, 'grad_norm': 5.220775127410889, 'learning_rate': 1.6059991073815253e-05, 'epoch': 7.35}
 29%|██▉       | 5150/17525 [1:01:49<1:59:03,  1.73it/s] 29%|██▉       | 5151/17525 [1:01:49<1:58:42,  1.74it/s] 29%|██▉       | 5152/17525 [1:01:50<1:58:37,  1.74it/s] 29%|██▉       | 5153/17525 [1:01:50<1:58:34,  1.74it/s] 29%|██▉       | 5154/17525 [1:01:51<1:58:33,  1.74it/s] 29%|██▉       | 5155/17525 [1:01:52<2:19:40,  1.48it/s] 29%|██▉       | 5156/17525 [1:01:53<3:02:04,  1.13it/s] 29%|██▉       | 5157/17525 [1:01:54<2:42:51,  1.27it/s] 29%|██▉       | 5158/17525 [1:01:54<2:29:19,  1.38it/s] 29%|██▉       | 5159/17525 [1:01:55<2:20:07,  1.47it/s] 29%|██▉       | 5160/17525 [1:01:56<2:13:35,  1.54it/s]                                                        {'loss': 0.5798, 'grad_norm': 7.986781597137451, 'learning_rate': 1.6045705240982898e-05, 'epoch': 7.36}
 29%|██▉       | 5160/17525 [1:01:56<2:13:35,  1.54it/s] 29%|██▉       | 5161/17525 [1:01:56<2:09:04,  1.60it/s] 29%|██▉       | 5162/17525 [1:01:57<2:05:39,  1.64it/s] 29%|██▉       | 5163/17525 [1:01:57<2:03:25,  1.67it/s] 29%|██▉       | 5164/17525 [1:01:58<2:01:58,  1.69it/s] 29%|██▉       | 5165/17525 [1:01:58<2:00:51,  1.70it/s] 29%|██▉       | 5166/17525 [1:01:59<2:00:01,  1.72it/s] 29%|██▉       | 5167/17525 [1:02:00<1:59:27,  1.72it/s] 29%|██▉       | 5168/17525 [1:02:00<1:59:09,  1.73it/s] 29%|██▉       | 5169/17525 [1:02:01<1:58:47,  1.73it/s] 30%|██▉       | 5170/17525 [1:02:01<1:58:34,  1.74it/s]                                                        {'loss': 0.5996, 'grad_norm': 11.951361656188965, 'learning_rate': 1.6031399935621156e-05, 'epoch': 7.38}
 30%|██▉       | 5170/17525 [1:02:01<1:58:34,  1.74it/s] 30%|██▉       | 5171/17525 [1:02:02<1:59:53,  1.72it/s] 30%|██▉       | 5172/17525 [1:02:02<1:59:08,  1.73it/s] 30%|██▉       | 5173/17525 [1:02:03<1:58:50,  1.73it/s] 30%|██▉       | 5174/17525 [1:02:04<1:58:33,  1.74it/s] 30%|██▉       | 5175/17525 [1:02:04<1:58:15,  1.74it/s] 30%|██▉       | 5176/17525 [1:02:05<1:58:00,  1.74it/s] 30%|██▉       | 5177/17525 [1:02:05<1:58:13,  1.74it/s] 30%|██▉       | 5178/17525 [1:02:06<1:58:14,  1.74it/s] 30%|██▉       | 5179/17525 [1:02:07<1:58:07,  1.74it/s] 30%|██▉       | 5180/17525 [1:02:07<1:57:52,  1.75it/s]                                                        {'loss': 0.513, 'grad_norm': 8.946308135986328, 'learning_rate': 1.6017075203805784e-05, 'epoch': 7.39}
 30%|██▉       | 5180/17525 [1:02:07<1:57:52,  1.75it/s] 30%|██▉       | 5181/17525 [1:02:08<1:58:00,  1.74it/s] 30%|██▉       | 5182/17525 [1:02:08<1:57:53,  1.75it/s] 30%|██▉       | 5183/17525 [1:02:09<1:57:45,  1.75it/s] 30%|██▉       | 5184/17525 [1:02:09<1:57:46,  1.75it/s] 30%|██▉       | 5185/17525 [1:02:10<1:57:44,  1.75it/s] 30%|██▉       | 5186/17525 [1:02:11<1:57:51,  1.74it/s] 30%|██▉       | 5187/17525 [1:02:11<1:57:50,  1.74it/s] 30%|██▉       | 5188/17525 [1:02:12<1:57:42,  1.75it/s] 30%|██▉       | 5189/17525 [1:02:12<2:00:16,  1.71it/s] 30%|██▉       | 5190/17525 [1:02:13<1:59:52,  1.72it/s]                                                        {'loss': 0.5717, 'grad_norm': 10.961662292480469, 'learning_rate': 1.600273109167513e-05, 'epoch': 7.4}
 30%|██▉       | 5190/17525 [1:02:13<1:59:52,  1.72it/s] 30%|██▉       | 5191/17525 [1:02:13<1:59:47,  1.72it/s] 30%|██▉       | 5192/17525 [1:02:14<1:59:12,  1.72it/s] 30%|██▉       | 5193/17525 [1:02:15<1:58:41,  1.73it/s] 30%|██▉       | 5194/17525 [1:02:15<1:58:17,  1.74it/s] 30%|██▉       | 5195/17525 [1:02:16<1:58:15,  1.74it/s] 30%|██▉       | 5196/17525 [1:02:16<1:58:07,  1.74it/s] 30%|██▉       | 5197/17525 [1:02:17<1:58:04,  1.74it/s] 30%|██▉       | 5198/17525 [1:02:18<2:07:33,  1.61it/s] 30%|██▉       | 5199/17525 [1:02:18<2:04:37,  1.65it/s] 30%|██▉       | 5200/17525 [1:02:19<2:02:31,  1.68it/s]                                                        {'loss': 0.5781, 'grad_norm': 14.392440795898438, 'learning_rate': 1.5988367645429938e-05, 'epoch': 7.42}
 30%|██▉       | 5200/17525 [1:02:19<2:02:31,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 03:05:40,651 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:05:40,651 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:05:40,651 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9026705026626587, 'eval_runtime': 4.5968, 'eval_samples_per_second': 96.372, 'eval_steps_per_second': 4.133, 'epoch': 7.42}
 30%|██▉       | 5200/17525 [1:02:23<2:02:31,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 30%|██▉       | 5201/17525 [1:02:24<6:46:25,  1.98s/it] 30%|██▉       | 5202/17525 [1:02:25<5:20:00,  1.56s/it] 30%|██▉       | 5203/17525 [1:02:25<4:30:04,  1.32s/it] 30%|██▉       | 5204/17525 [1:02:26<3:44:24,  1.09s/it] 30%|██▉       | 5205/17525 [1:02:26<3:12:23,  1.07it/s] 30%|██▉       | 5206/17525 [1:02:27<2:49:58,  1.21it/s] 30%|██▉       | 5207/17525 [1:02:28<2:34:24,  1.33it/s] 30%|██▉       | 5208/17525 [1:02:28<2:23:28,  1.43it/s] 30%|██▉       | 5209/17525 [1:02:29<2:15:35,  1.51it/s] 30%|██▉       | 5210/17525 [1:02:29<2:10:07,  1.58it/s]                                                        {'loss': 0.4972, 'grad_norm': 19.677536010742188, 'learning_rate': 1.5973984911333237e-05, 'epoch': 7.43}
 30%|██▉       | 5210/17525 [1:02:29<2:10:07,  1.58it/s] 30%|██▉       | 5211/17525 [1:02:30<2:08:26,  1.60it/s] 30%|██▉       | 5212/17525 [1:02:30<2:06:25,  1.62it/s] 30%|██▉       | 5213/17525 [1:02:31<2:03:41,  1.66it/s] 30%|██▉       | 5214/17525 [1:02:32<2:03:25,  1.66it/s] 30%|██▉       | 5215/17525 [1:02:32<2:01:36,  1.69it/s] 30%|██▉       | 5216/17525 [1:02:33<2:00:27,  1.70it/s] 30%|██▉       | 5217/17525 [1:02:33<1:59:23,  1.72it/s] 30%|██▉       | 5218/17525 [1:02:34<2:21:39,  1.45it/s] 30%|██▉       | 5219/17525 [1:02:35<2:14:13,  1.53it/s] 30%|██▉       | 5220/17525 [1:02:36<2:17:26,  1.49it/s]                                                        {'loss': 0.6143, 'grad_norm': 6.841948986053467, 'learning_rate': 1.595958293571018e-05, 'epoch': 7.45}
 30%|██▉       | 5220/17525 [1:02:36<2:17:26,  1.49it/s] 30%|██▉       | 5221/17525 [1:02:36<2:22:35,  1.44it/s] 30%|██▉       | 5222/17525 [1:02:37<2:15:03,  1.52it/s] 30%|██▉       | 5223/17525 [1:02:37<2:09:42,  1.58it/s] 30%|██▉       | 5224/17525 [1:02:38<2:05:50,  1.63it/s] 30%|██▉       | 5225/17525 [1:02:39<2:03:11,  1.66it/s] 30%|██▉       | 5226/17525 [1:02:39<2:14:19,  1.53it/s] 30%|██▉       | 5227/17525 [1:02:40<2:09:14,  1.59it/s] 30%|██▉       | 5228/17525 [1:02:41<2:05:33,  1.63it/s] 30%|██▉       | 5229/17525 [1:02:41<2:03:03,  1.67it/s] 30%|██▉       | 5230/17525 [1:02:42<2:01:14,  1.69it/s]                                                        {'loss': 0.6162, 'grad_norm': 7.029820919036865, 'learning_rate': 1.5945161764947893e-05, 'epoch': 7.46}
 30%|██▉       | 5230/17525 [1:02:42<2:01:14,  1.69it/s] 30%|██▉       | 5231/17525 [1:02:42<2:01:37,  1.68it/s] 30%|██▉       | 5232/17525 [1:02:43<2:08:55,  1.59it/s] 30%|██▉       | 5233/17525 [1:02:44<2:05:25,  1.63it/s] 30%|██▉       | 5234/17525 [1:02:44<2:02:59,  1.67it/s] 30%|██▉       | 5235/17525 [1:02:45<2:01:14,  1.69it/s] 30%|██▉       | 5236/17525 [1:02:45<2:00:03,  1.71it/s] 30%|██▉       | 5237/17525 [1:02:46<1:59:16,  1.72it/s] 30%|██▉       | 5238/17525 [1:02:46<1:58:32,  1.73it/s] 30%|██▉       | 5239/17525 [1:02:47<1:58:13,  1.73it/s] 30%|██▉       | 5240/17525 [1:02:48<1:57:59,  1.74it/s]                                                        {'loss': 0.6377, 'grad_norm': 11.968799591064453, 'learning_rate': 1.593072144549533e-05, 'epoch': 7.48}
 30%|██▉       | 5240/17525 [1:02:48<1:57:59,  1.74it/s] 30%|██▉       | 5241/17525 [1:02:48<1:59:05,  1.72it/s] 30%|██▉       | 5242/17525 [1:02:49<1:58:50,  1.72it/s] 30%|██▉       | 5243/17525 [1:02:49<1:58:26,  1.73it/s] 30%|██▉       | 5244/17525 [1:02:50<1:57:57,  1.74it/s] 30%|██▉       | 5245/17525 [1:02:50<1:57:45,  1.74it/s] 30%|██▉       | 5246/17525 [1:02:51<1:57:38,  1.74it/s] 30%|██▉       | 5247/17525 [1:02:52<1:57:24,  1.74it/s] 30%|██▉       | 5248/17525 [1:02:52<1:57:24,  1.74it/s] 30%|██▉       | 5249/17525 [1:02:53<1:57:17,  1.74it/s] 30%|██▉       | 5250/17525 [1:02:53<1:57:15,  1.74it/s]                                                        {'loss': 0.5632, 'grad_norm': 10.663022994995117, 'learning_rate': 1.5916262023863115e-05, 'epoch': 7.49}
 30%|██▉       | 5250/17525 [1:02:53<1:57:15,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 03:06:15,257 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79f9590>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2a9c3f26-b3f6-4156-8467-f689b041cd00)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:06:25,495 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:06:25,498 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 30%|██▉       | 5251/17525 [1:03:04<12:34:47,  3.69s/it] 30%|██▉       | 5252/17525 [1:03:05<9:23:25,  2.75s/it]  30%|██▉       | 5253/17525 [1:03:05<7:09:40,  2.10s/it] 30%|██▉       | 5254/17525 [1:03:06<5:35:51,  1.64s/it] 30%|██▉       | 5255/17525 [1:03:07<4:59:59,  1.47s/it] 30%|██▉       | 5256/17525 [1:03:08<4:05:03,  1.20s/it] 30%|██▉       | 5257/17525 [1:03:08<3:29:17,  1.02s/it] 30%|███       | 5258/17525 [1:03:09<3:12:40,  1.06it/s] 30%|███       | 5259/17525 [1:03:10<2:49:58,  1.20it/s] 30%|███       | 5260/17525 [1:03:10<2:34:01,  1.33it/s]                                                        {'loss': 0.6056, 'grad_norm': 16.097585678100586, 'learning_rate': 1.5901783546623403e-05, 'epoch': 7.5}
 30%|███       | 5260/17525 [1:03:10<2:34:01,  1.33it/s] 30%|███       | 5261/17525 [1:03:11<2:23:52,  1.42it/s] 30%|███       | 5262/17525 [1:03:11<2:15:39,  1.51it/s] 30%|███       | 5263/17525 [1:03:12<2:10:08,  1.57it/s] 30%|███       | 5264/17525 [1:03:12<2:06:46,  1.61it/s] 30%|███       | 5265/17525 [1:03:13<2:04:12,  1.65it/s] 30%|███       | 5266/17525 [1:03:14<2:02:01,  1.67it/s] 30%|███       | 5267/17525 [1:03:14<2:00:31,  1.70it/s] 30%|███       | 5268/17525 [1:03:15<1:59:21,  1.71it/s] 30%|███       | 5269/17525 [1:03:15<1:58:53,  1.72it/s] 30%|███       | 5270/17525 [1:03:16<1:58:32,  1.72it/s]                                                        {'loss': 0.6399, 'grad_norm': 9.366799354553223, 'learning_rate': 1.5887286060409724e-05, 'epoch': 7.52}
 30%|███       | 5270/17525 [1:03:16<1:58:32,  1.72it/s] 30%|███       | 5271/17525 [1:03:17<1:58:13,  1.73it/s] 30%|███       | 5272/17525 [1:03:17<1:57:47,  1.73it/s] 30%|███       | 5273/17525 [1:03:18<1:57:36,  1.74it/s] 30%|███       | 5274/17525 [1:03:18<1:57:18,  1.74it/s] 30%|███       | 5275/17525 [1:03:19<1:57:15,  1.74it/s] 30%|███       | 5276/17525 [1:03:19<1:59:10,  1.71it/s] 30%|███       | 5277/17525 [1:03:20<1:58:27,  1.72it/s] 30%|███       | 5278/17525 [1:03:21<1:57:55,  1.73it/s] 30%|███       | 5279/17525 [1:03:21<1:57:23,  1.74it/s] 30%|███       | 5280/17525 [1:03:22<1:57:10,  1.74it/s]                                                        {'loss': 0.5497, 'grad_norm': 7.281660556793213, 'learning_rate': 1.5872769611916835e-05, 'epoch': 7.53}
 30%|███       | 5280/17525 [1:03:22<1:57:10,  1.74it/s] 30%|███       | 5281/17525 [1:03:22<1:58:19,  1.72it/s] 30%|███       | 5282/17525 [1:03:23<1:57:42,  1.73it/s] 30%|███       | 5283/17525 [1:03:23<1:57:13,  1.74it/s] 30%|███       | 5284/17525 [1:03:24<1:57:10,  1.74it/s] 30%|███       | 5285/17525 [1:03:25<1:56:53,  1.75it/s] 30%|███       | 5286/17525 [1:03:25<1:56:41,  1.75it/s] 30%|███       | 5287/17525 [1:03:26<1:56:42,  1.75it/s] 30%|███       | 5288/17525 [1:03:26<2:07:53,  1.59it/s] 30%|███       | 5289/17525 [1:03:27<2:04:23,  1.64it/s] 30%|███       | 5290/17525 [1:03:28<2:02:09,  1.67it/s]                                                        {'loss': 0.5116, 'grad_norm': 11.952025413513184, 'learning_rate': 1.585823424790056e-05, 'epoch': 7.55}
 30%|███       | 5290/17525 [1:03:28<2:02:09,  1.67it/s] 30%|███       | 5291/17525 [1:03:28<2:00:37,  1.69it/s] 30%|███       | 5292/17525 [1:03:29<1:59:35,  1.70it/s] 30%|███       | 5293/17525 [1:03:29<1:59:02,  1.71it/s] 30%|███       | 5294/17525 [1:03:30<1:58:18,  1.72it/s] 30%|███       | 5295/17525 [1:03:30<1:57:47,  1.73it/s] 30%|███       | 5296/17525 [1:03:31<1:57:38,  1.73it/s] 30%|███       | 5297/17525 [1:03:32<1:57:27,  1.74it/s] 30%|███       | 5298/17525 [1:03:32<1:57:03,  1.74it/s] 30%|███       | 5299/17525 [1:03:33<1:56:52,  1.74it/s] 30%|███       | 5300/17525 [1:03:33<1:56:50,  1.74it/s]                                                        {'loss': 0.5084, 'grad_norm': 4.348861217498779, 'learning_rate': 1.5843680015177666e-05, 'epoch': 7.56}
 30%|███       | 5300/17525 [1:03:33<1:56:50,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 03:06:55,263 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:06:55,263 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:06:55,263 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:02<00:04,  2.66it/s][A
 42%|████▏     | 8/19 [00:02<00:03,  2.88it/s][A
 47%|████▋     | 9/19 [00:02<00:02,  3.35it/s][A
 53%|█████▎    | 10/19 [00:02<00:02,  3.73it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.01it/s][A
 63%|██████▎   | 12/19 [00:03<00:01,  4.27it/s][A
 68%|██████▊   | 13/19 [00:03<00:01,  4.48it/s][A
 74%|███████▎  | 14/19 [00:03<00:01,  4.73it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  4.92it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.04it/s][A
 89%|████████▉ | 17/19 [00:04<00:00,  3.56it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.97it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A                                                        
                                               [A{'eval_loss': 0.897686779499054, 'eval_runtime': 5.1429, 'eval_samples_per_second': 86.138, 'eval_steps_per_second': 3.694, 'epoch': 7.56}
 30%|███       | 5300/17525 [1:03:39<1:56:50,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A
                                               [A 30%|███       | 5301/17525 [1:03:39<7:17:44,  2.15s/it] 30%|███       | 5302/17525 [1:03:40<5:41:22,  1.68s/it] 30%|███       | 5303/17525 [1:03:40<4:33:53,  1.34s/it] 30%|███       | 5304/17525 [1:03:41<3:46:44,  1.11s/it] 30%|███       | 5305/17525 [1:03:41<3:13:52,  1.05it/s] 30%|███       | 5306/17525 [1:03:42<2:50:33,  1.19it/s] 30%|███       | 5307/17525 [1:03:43<2:34:38,  1.32it/s] 30%|███       | 5308/17525 [1:03:43<2:23:18,  1.42it/s] 30%|███       | 5309/17525 [1:03:44<2:15:21,  1.50it/s] 30%|███       | 5310/17525 [1:03:44<2:09:43,  1.57it/s]                                                        {'loss': 0.6139, 'grad_norm': 11.38270092010498, 'learning_rate': 1.582910696062567e-05, 'epoch': 7.57}
 30%|███       | 5310/17525 [1:03:44<2:09:43,  1.57it/s] 30%|███       | 5311/17525 [1:03:45<2:32:56,  1.33it/s] 30%|███       | 5312/17525 [1:03:46<2:31:38,  1.34it/s] 30%|███       | 5313/17525 [1:03:47<2:21:15,  1.44it/s] 30%|███       | 5314/17525 [1:03:47<2:13:50,  1.52it/s] 30%|███       | 5315/17525 [1:03:48<2:08:37,  1.58it/s] 30%|███       | 5316/17525 [1:03:48<2:05:05,  1.63it/s] 30%|███       | 5317/17525 [1:03:49<2:02:27,  1.66it/s] 30%|███       | 5318/17525 [1:03:50<2:25:55,  1.39it/s] 30%|███       | 5319/17525 [1:03:51<2:17:11,  1.48it/s] 30%|███       | 5320/17525 [1:03:51<2:10:54,  1.55it/s]                                                        {'loss': 0.4905, 'grad_norm': 10.113369941711426, 'learning_rate': 1.5814515131182727e-05, 'epoch': 7.59}
 30%|███       | 5320/17525 [1:03:51<2:10:54,  1.55it/s] 30%|███       | 5321/17525 [1:03:52<2:06:50,  1.60it/s] 30%|███       | 5322/17525 [1:03:52<2:03:47,  1.64it/s] 30%|███       | 5323/17525 [1:03:53<2:01:30,  1.67it/s] 30%|███       | 5324/17525 [1:03:53<1:59:58,  1.69it/s] 30%|███       | 5325/17525 [1:03:54<1:58:52,  1.71it/s] 30%|███       | 5326/17525 [1:03:55<1:58:05,  1.72it/s] 30%|███       | 5327/17525 [1:03:55<1:57:33,  1.73it/s] 30%|███       | 5328/17525 [1:03:56<2:02:38,  1.66it/s] 30%|███       | 5329/17525 [1:03:56<2:07:56,  1.59it/s] 30%|███       | 5330/17525 [1:03:57<2:10:33,  1.56it/s]                                                        {'loss': 0.6226, 'grad_norm': 13.34443187713623, 'learning_rate': 1.5799904573847466e-05, 'epoch': 7.6}
 30%|███       | 5330/17525 [1:03:57<2:10:33,  1.56it/s] 30%|███       | 5331/17525 [1:03:58<2:31:11,  1.34it/s] 30%|███       | 5332/17525 [1:03:59<2:23:50,  1.41it/s] 30%|███       | 5333/17525 [1:03:59<2:19:57,  1.45it/s] 30%|███       | 5334/17525 [1:04:00<2:16:42,  1.49it/s] 30%|███       | 5335/17525 [1:04:01<2:14:41,  1.51it/s] 30%|███       | 5336/17525 [1:04:01<2:11:42,  1.54it/s] 30%|███       | 5337/17525 [1:04:02<2:10:34,  1.56it/s] 30%|███       | 5338/17525 [1:04:02<2:07:43,  1.59it/s] 30%|███       | 5339/17525 [1:04:03<2:06:52,  1.60it/s] 30%|███       | 5340/17525 [1:04:04<2:13:09,  1.53it/s]                                                        {'loss': 0.5474, 'grad_norm': 15.933403968811035, 'learning_rate': 1.5785275335678826e-05, 'epoch': 7.62}
 30%|███       | 5340/17525 [1:04:04<2:13:09,  1.53it/s] 30%|███       | 5341/17525 [1:04:04<2:11:15,  1.55it/s] 30%|███       | 5342/17525 [1:04:05<2:08:54,  1.58it/s] 30%|███       | 5343/17525 [1:04:06<2:08:55,  1.57it/s] 30%|███       | 5344/17525 [1:04:06<2:08:00,  1.59it/s] 30%|███       | 5345/17525 [1:04:07<2:20:25,  1.45it/s] 31%|███       | 5346/17525 [1:04:08<2:15:19,  1.50it/s] 31%|███       | 5347/17525 [1:04:08<2:12:10,  1.54it/s] 31%|███       | 5348/17525 [1:04:09<2:11:16,  1.55it/s] 31%|███       | 5349/17525 [1:04:10<2:08:50,  1.58it/s] 31%|███       | 5350/17525 [1:04:10<2:06:22,  1.61it/s]                                                        {'loss': 0.5767, 'grad_norm': 12.29504680633545, 'learning_rate': 1.5770627463795928e-05, 'epoch': 7.63}
 31%|███       | 5350/17525 [1:04:10<2:06:22,  1.61it/s] 31%|███       | 5351/17525 [1:04:11<2:07:50,  1.59it/s] 31%|███       | 5352/17525 [1:04:11<2:06:30,  1.60it/s] 31%|███       | 5353/17525 [1:04:12<2:05:18,  1.62it/s] 31%|███       | 5354/17525 [1:04:13<2:04:59,  1.62it/s] 31%|███       | 5355/17525 [1:04:13<2:02:50,  1.65it/s] 31%|███       | 5356/17525 [1:04:14<2:01:14,  1.67it/s] 31%|███       | 5357/17525 [1:04:14<2:03:41,  1.64it/s] 31%|███       | 5358/17525 [1:04:15<2:01:30,  1.67it/s] 31%|███       | 5359/17525 [1:04:16<2:00:30,  1.68it/s] 31%|███       | 5360/17525 [1:04:16<2:00:22,  1.68it/s]                                                        {'loss': 0.6433, 'grad_norm': 10.660611152648926, 'learning_rate': 1.5755961005377893e-05, 'epoch': 7.65}
 31%|███       | 5360/17525 [1:04:16<2:00:22,  1.68it/s] 31%|███       | 5361/17525 [1:04:17<2:01:19,  1.67it/s] 31%|███       | 5362/17525 [1:04:17<2:01:42,  1.67it/s] 31%|███       | 5363/17525 [1:04:18<2:04:26,  1.63it/s] 31%|███       | 5364/17525 [1:04:19<2:05:12,  1.62it/s] 31%|███       | 5365/17525 [1:04:19<2:06:03,  1.61it/s] 31%|███       | 5366/17525 [1:04:20<2:05:03,  1.62it/s] 31%|███       | 5367/17525 [1:04:21<2:06:14,  1.61it/s] 31%|███       | 5368/17525 [1:04:21<2:04:40,  1.63it/s] 31%|███       | 5369/17525 [1:04:22<2:03:07,  1.65it/s] 31%|███       | 5370/17525 [1:04:22<2:02:17,  1.66it/s]                                                        {'loss': 0.5816, 'grad_norm': 12.25851058959961, 'learning_rate': 1.5741276007663723e-05, 'epoch': 7.66}
 31%|███       | 5370/17525 [1:04:22<2:02:17,  1.66it/s] 31%|███       | 5371/17525 [1:04:23<2:01:15,  1.67it/s] 31%|███       | 5372/17525 [1:04:24<2:02:28,  1.65it/s] 31%|███       | 5373/17525 [1:04:24<2:04:33,  1.63it/s] 31%|███       | 5374/17525 [1:04:25<2:04:24,  1.63it/s] 31%|███       | 5375/17525 [1:04:25<2:02:29,  1.65it/s] 31%|███       | 5376/17525 [1:04:26<2:14:43,  1.50it/s] 31%|███       | 5377/17525 [1:04:27<2:10:50,  1.55it/s] 31%|███       | 5378/17525 [1:04:27<2:09:31,  1.56it/s] 31%|███       | 5379/17525 [1:04:28<2:08:47,  1.57it/s] 31%|███       | 5380/17525 [1:04:29<2:06:02,  1.61it/s]                                                        {'loss': 0.5746, 'grad_norm': 13.933101654052734, 'learning_rate': 1.5726572517952122e-05, 'epoch': 7.67}
 31%|███       | 5380/17525 [1:04:29<2:06:02,  1.61it/s] 31%|███       | 5381/17525 [1:04:29<2:07:20,  1.59it/s] 31%|███       | 5382/17525 [1:04:30<2:04:44,  1.62it/s] 31%|███       | 5383/17525 [1:04:31<2:07:25,  1.59it/s] 31%|███       | 5384/17525 [1:04:31<2:08:02,  1.58it/s] 31%|███       | 5385/17525 [1:04:32<2:07:57,  1.58it/s] 31%|███       | 5386/17525 [1:04:33<2:54:02,  1.16it/s] 31%|███       | 5387/17525 [1:04:34<2:38:57,  1.27it/s] 31%|███       | 5388/17525 [1:04:34<2:29:37,  1.35it/s] 31%|███       | 5389/17525 [1:04:35<2:22:04,  1.42it/s] 31%|███       | 5390/17525 [1:04:36<2:15:31,  1.49it/s]                                                        {'loss': 0.5855, 'grad_norm': 12.524470329284668, 'learning_rate': 1.5711850583601365e-05, 'epoch': 7.69}
 31%|███       | 5390/17525 [1:04:36<2:15:31,  1.49it/s] 31%|███       | 5391/17525 [1:04:36<2:10:42,  1.55it/s] 31%|███       | 5392/17525 [1:04:37<2:08:10,  1.58it/s] 31%|███       | 5393/17525 [1:04:37<2:06:19,  1.60it/s] 31%|███       | 5394/17525 [1:04:38<2:04:19,  1.63it/s] 31%|███       | 5395/17525 [1:04:39<2:03:35,  1.64it/s] 31%|███       | 5396/17525 [1:04:39<2:02:28,  1.65it/s] 31%|███       | 5397/17525 [1:04:40<2:04:39,  1.62it/s] 31%|███       | 5398/17525 [1:04:40<2:03:12,  1.64it/s] 31%|███       | 5399/17525 [1:04:41<2:05:35,  1.61it/s] 31%|███       | 5400/17525 [1:04:42<2:04:19,  1.63it/s]                                                        {'loss': 0.5921, 'grad_norm': 13.429269790649414, 'learning_rate': 1.569711025202912e-05, 'epoch': 7.7}
 31%|███       | 5400/17525 [1:04:42<2:04:19,  1.63it/s][INFO|trainer.py:3512] 2024-06-25 03:08:03,638 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:08:03,638 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:08:03,638 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:03,  4.88it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.25it/s][A
 21%|██        | 4/19 [00:01<00:03,  3.78it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.00it/s][A
 32%|███▏      | 6/19 [00:01<00:03,  4.30it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.62it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.02it/s][A
 47%|████▋     | 9/19 [00:02<00:02,  4.28it/s][A
 53%|█████▎    | 10/19 [00:02<00:02,  4.40it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.52it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.61it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.44it/s][A
 74%|███████▎  | 14/19 [00:03<00:01,  4.69it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  4.87it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  4.78it/s][A
 89%|████████▉ | 17/19 [00:04<00:00,  3.46it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.88it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.67it/s][A                                                        
                                               [A{'eval_loss': 0.8986043930053711, 'eval_runtime': 4.9426, 'eval_samples_per_second': 89.629, 'eval_steps_per_second': 3.844, 'epoch': 7.7}
 31%|███       | 5400/17525 [1:04:47<2:04:19,  1.63it/s]
100%|██████████| 19/19 [00:04<00:00,  3.67it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:08:08,584 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a63890>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f9e63824-ad0e-4ab2-b4b2-e7e86fe08797)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:08:19,111 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:08:19,114 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 31%|███       | 5401/17525 [1:04:59<18:50:22,  5.59s/it] 31%|███       | 5402/17525 [1:05:00<13:48:01,  4.10s/it] 31%|███       | 5403/17525 [1:05:00<10:17:33,  3.06s/it] 31%|███       | 5404/17525 [1:05:01<7:59:28,  2.37s/it]  31%|███       | 5405/17525 [1:05:02<6:17:52,  1.87s/it] 31%|███       | 5406/17525 [1:05:03<5:16:21,  1.57s/it] 31%|███       | 5407/17525 [1:05:03<4:17:12,  1.27s/it] 31%|███       | 5408/17525 [1:05:04<3:43:11,  1.11s/it] 31%|███       | 5409/17525 [1:05:04<3:11:43,  1.05it/s] 31%|███       | 5410/17525 [1:05:05<2:55:34,  1.15it/s]                                                        {'loss': 0.5716, 'grad_norm': 26.67466163635254, 'learning_rate': 1.56838282632282e-05, 'epoch': 7.72}
 31%|███       | 5410/17525 [1:05:05<2:55:34,  1.15it/s] 31%|███       | 5411/17525 [1:05:07<3:35:19,  1.07s/it] 31%|███       | 5412/17525 [1:05:07<3:10:46,  1.06it/s] 31%|███       | 5413/17525 [1:05:08<2:51:38,  1.18it/s] 31%|███       | 5414/17525 [1:05:09<2:35:55,  1.29it/s] 31%|███       | 5415/17525 [1:05:09<2:32:33,  1.32it/s] 31%|███       | 5416/17525 [1:05:10<2:24:54,  1.39it/s] 31%|███       | 5417/17525 [1:05:10<2:17:48,  1.46it/s] 31%|███       | 5418/17525 [1:05:11<2:18:23,  1.46it/s] 31%|███       | 5419/17525 [1:05:12<2:12:28,  1.52it/s] 31%|███       | 5420/17525 [1:05:12<2:16:14,  1.48it/s]                                                        {'loss': 0.5404, 'grad_norm': 7.9201860427856445, 'learning_rate': 1.5669053107782944e-05, 'epoch': 7.73}
 31%|███       | 5420/17525 [1:05:12<2:16:14,  1.48it/s] 31%|███       | 5421/17525 [1:05:13<2:11:24,  1.54it/s] 31%|███       | 5422/17525 [1:05:14<2:06:32,  1.59it/s] 31%|███       | 5423/17525 [1:05:15<2:25:22,  1.39it/s] 31%|███       | 5424/17525 [1:05:15<2:16:23,  1.48it/s] 31%|███       | 5425/17525 [1:05:16<2:20:53,  1.43it/s] 31%|███       | 5426/17525 [1:05:17<2:16:51,  1.47it/s] 31%|███       | 5427/17525 [1:05:17<2:10:30,  1.55it/s] 31%|███       | 5428/17525 [1:05:18<2:07:37,  1.58it/s] 31%|███       | 5429/17525 [1:05:18<2:05:18,  1.61it/s] 31%|███       | 5430/17525 [1:05:19<2:02:36,  1.64it/s]                                                        {'loss': 0.6273, 'grad_norm': 12.867527961730957, 'learning_rate': 1.5654259692962006e-05, 'epoch': 7.75}
 31%|███       | 5430/17525 [1:05:19<2:02:36,  1.64it/s] 31%|███       | 5431/17525 [1:05:19<2:01:47,  1.66it/s] 31%|███       | 5432/17525 [1:05:20<2:01:00,  1.67it/s] 31%|███       | 5433/17525 [1:05:21<2:01:27,  1.66it/s] 31%|███       | 5434/17525 [1:05:21<2:01:20,  1.66it/s] 31%|███       | 5435/17525 [1:05:22<1:59:27,  1.69it/s] 31%|███       | 5436/17525 [1:05:22<2:00:16,  1.68it/s] 31%|███       | 5437/17525 [1:05:23<2:00:19,  1.67it/s] 31%|███       | 5438/17525 [1:05:24<2:02:39,  1.64it/s] 31%|███       | 5439/17525 [1:05:24<2:00:50,  1.67it/s] 31%|███       | 5440/17525 [1:05:25<2:00:25,  1.67it/s]                                                        {'loss': 0.5371, 'grad_norm': 9.551616668701172, 'learning_rate': 1.56394480664133e-05, 'epoch': 7.76}
 31%|███       | 5440/17525 [1:05:25<2:00:25,  1.67it/s] 31%|███       | 5441/17525 [1:05:25<1:59:46,  1.68it/s] 31%|███       | 5442/17525 [1:05:26<1:58:46,  1.70it/s] 31%|███       | 5443/17525 [1:05:27<2:00:15,  1.67it/s] 31%|███       | 5444/17525 [1:05:27<1:59:53,  1.68it/s] 31%|███       | 5445/17525 [1:05:28<1:58:30,  1.70it/s] 31%|███       | 5446/17525 [1:05:28<1:58:16,  1.70it/s] 31%|███       | 5447/17525 [1:05:29<1:59:51,  1.68it/s] 31%|███       | 5448/17525 [1:05:30<2:03:20,  1.63it/s] 31%|███       | 5449/17525 [1:05:30<2:00:43,  1.67it/s] 31%|███       | 5450/17525 [1:05:31<1:59:38,  1.68it/s]                                                        {'loss': 0.6061, 'grad_norm': 10.119640350341797, 'learning_rate': 1.5624618275843393e-05, 'epoch': 7.77}
 31%|███       | 5450/17525 [1:05:31<1:59:38,  1.68it/s] 31%|███       | 5451/17525 [1:05:31<2:00:04,  1.68it/s] 31%|███       | 5452/17525 [1:05:32<2:00:19,  1.67it/s] 31%|███       | 5453/17525 [1:05:33<1:58:52,  1.69it/s] 31%|███       | 5454/17525 [1:05:33<1:57:46,  1.71it/s] 31%|███       | 5455/17525 [1:05:34<1:56:47,  1.72it/s] 31%|███       | 5456/17525 [1:05:34<1:56:59,  1.72it/s] 31%|███       | 5457/17525 [1:05:35<1:57:11,  1.72it/s] 31%|███       | 5458/17525 [1:05:35<1:57:14,  1.72it/s] 31%|███       | 5459/17525 [1:05:36<1:58:44,  1.69it/s] 31%|███       | 5460/17525 [1:05:37<1:58:37,  1.70it/s]                                                        {'loss': 0.5151, 'grad_norm': 7.341588973999023, 'learning_rate': 1.5609770369017346e-05, 'epoch': 7.79}
 31%|███       | 5460/17525 [1:05:37<1:58:37,  1.70it/s] 31%|███       | 5461/17525 [1:05:37<1:57:46,  1.71it/s] 31%|███       | 5462/17525 [1:05:38<1:56:53,  1.72it/s] 31%|███       | 5463/17525 [1:05:38<1:56:35,  1.72it/s] 31%|███       | 5464/17525 [1:05:39<1:57:35,  1.71it/s] 31%|███       | 5465/17525 [1:05:40<1:57:59,  1.70it/s] 31%|███       | 5466/17525 [1:05:40<1:57:19,  1.71it/s] 31%|███       | 5467/17525 [1:05:41<1:56:42,  1.72it/s] 31%|███       | 5468/17525 [1:05:41<1:57:03,  1.72it/s] 31%|███       | 5469/17525 [1:05:42<1:58:37,  1.69it/s] 31%|███       | 5470/17525 [1:05:43<2:02:10,  1.64it/s]                                                        {'loss': 0.6246, 'grad_norm': 11.869498252868652, 'learning_rate': 1.5594904393758586e-05, 'epoch': 7.8}
 31%|███       | 5470/17525 [1:05:43<2:02:10,  1.64it/s] 31%|███       | 5471/17525 [1:05:43<2:00:13,  1.67it/s] 31%|███       | 5472/17525 [1:05:44<1:59:13,  1.68it/s] 31%|███       | 5473/17525 [1:05:44<1:58:36,  1.69it/s] 31%|███       | 5474/17525 [1:05:45<1:57:24,  1.71it/s] 31%|███       | 5475/17525 [1:05:45<1:56:41,  1.72it/s] 31%|███       | 5476/17525 [1:05:46<1:56:09,  1.73it/s] 31%|███▏      | 5477/17525 [1:05:47<1:59:48,  1.68it/s] 31%|███▏      | 5478/17525 [1:05:47<2:01:04,  1.66it/s] 31%|███▏      | 5479/17525 [1:05:48<2:00:11,  1.67it/s] 31%|███▏      | 5480/17525 [1:05:48<2:00:05,  1.67it/s]                                                        {'loss': 0.5804, 'grad_norm': 14.442461967468262, 'learning_rate': 1.558002039794873e-05, 'epoch': 7.82}
 31%|███▏      | 5480/17525 [1:05:48<2:00:05,  1.67it/s] 31%|███▏      | 5481/17525 [1:05:49<1:58:38,  1.69it/s] 31%|███▏      | 5482/17525 [1:05:50<1:58:24,  1.70it/s] 31%|███▏      | 5483/17525 [1:05:50<1:58:05,  1.70it/s] 31%|███▏      | 5484/17525 [1:05:51<1:58:22,  1.70it/s] 31%|███▏      | 5485/17525 [1:05:51<1:58:19,  1.70it/s] 31%|███▏      | 5486/17525 [1:05:52<1:57:15,  1.71it/s] 31%|███▏      | 5487/17525 [1:05:53<1:56:33,  1.72it/s] 31%|███▏      | 5488/17525 [1:05:53<1:56:01,  1.73it/s] 31%|███▏      | 5489/17525 [1:05:54<1:57:32,  1.71it/s] 31%|███▏      | 5490/17525 [1:05:54<1:57:20,  1.71it/s]                                                        {'loss': 0.5674, 'grad_norm': 7.493210792541504, 'learning_rate': 1.5565118429527433e-05, 'epoch': 7.83}
 31%|███▏      | 5490/17525 [1:05:54<1:57:20,  1.71it/s] 31%|███▏      | 5491/17525 [1:05:55<1:56:51,  1.72it/s] 31%|███▏      | 5492/17525 [1:05:55<1:56:49,  1.72it/s] 31%|███▏      | 5493/17525 [1:05:56<1:58:00,  1.70it/s] 31%|███▏      | 5494/17525 [1:05:57<1:58:49,  1.69it/s] 31%|███▏      | 5495/17525 [1:05:57<1:58:46,  1.69it/s] 31%|███▏      | 5496/17525 [1:05:58<1:57:53,  1.70it/s] 31%|███▏      | 5497/17525 [1:05:58<1:57:25,  1.71it/s] 31%|███▏      | 5498/17525 [1:05:59<1:58:08,  1.70it/s] 31%|███▏      | 5499/17525 [1:06:00<2:34:31,  1.30it/s] 31%|███▏      | 5500/17525 [1:06:01<2:23:23,  1.40it/s]                                                        {'loss': 0.5585, 'grad_norm': 20.00709342956543, 'learning_rate': 1.5550198536492244e-05, 'epoch': 7.85}
 31%|███▏      | 5500/17525 [1:06:01<2:23:23,  1.40it/s][INFO|trainer.py:3512] 2024-06-25 03:09:23,162 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:09:23,162 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:09:23,163 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.8932992815971375, 'eval_runtime': 5.0184, 'eval_samples_per_second': 88.275, 'eval_steps_per_second': 3.786, 'epoch': 7.85}
 31%|███▏      | 5500/17525 [1:06:06<2:23:23,  1.40it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 31%|███▏      | 5501/17525 [1:06:07<7:48:16,  2.34s/it] 31%|███▏      | 5502/17525 [1:06:07<6:02:42,  1.81s/it] 31%|███▏      | 5503/17525 [1:06:08<4:48:10,  1.44s/it] 31%|███▏      | 5504/17525 [1:06:09<3:56:29,  1.18s/it] 31%|███▏      | 5505/17525 [1:06:09<3:20:30,  1.00s/it] 31%|███▏      | 5506/17525 [1:06:10<2:54:57,  1.14it/s] 31%|███▏      | 5507/17525 [1:06:10<2:40:25,  1.25it/s] 31%|███▏      | 5508/17525 [1:06:11<2:28:10,  1.35it/s] 31%|███▏      | 5509/17525 [1:06:12<2:18:33,  1.45it/s] 31%|███▏      | 5510/17525 [1:06:12<2:18:03,  1.45it/s]                                                        {'loss': 0.6254, 'grad_norm': 16.268329620361328, 'learning_rate': 1.553526076689844e-05, 'epoch': 7.86}
 31%|███▏      | 5510/17525 [1:06:12<2:18:03,  1.45it/s] 31%|███▏      | 5511/17525 [1:06:13<2:11:23,  1.52it/s] 31%|███▏      | 5512/17525 [1:06:13<2:07:22,  1.57it/s] 31%|███▏      | 5513/17525 [1:06:14<2:03:44,  1.62it/s] 31%|███▏      | 5514/17525 [1:06:15<2:01:19,  1.65it/s] 31%|███▏      | 5515/17525 [1:06:15<1:59:31,  1.67it/s] 31%|███▏      | 5516/17525 [1:06:16<2:03:17,  1.62it/s] 31%|███▏      | 5517/17525 [1:06:16<2:01:05,  1.65it/s] 31%|███▏      | 5518/17525 [1:06:17<1:59:14,  1.68it/s] 31%|███▏      | 5519/17525 [1:06:18<1:58:07,  1.69it/s] 31%|███▏      | 5520/17525 [1:06:18<1:57:29,  1.70it/s]                                                        {'loss': 0.4928, 'grad_norm': 9.938486099243164, 'learning_rate': 1.5520305168858886e-05, 'epoch': 7.87}
 31%|███▏      | 5520/17525 [1:06:18<1:57:29,  1.70it/s] 32%|███▏      | 5521/17525 [1:06:19<1:57:22,  1.70it/s] 32%|███▏      | 5522/17525 [1:06:19<1:57:41,  1.70it/s] 32%|███▏      | 5523/17525 [1:06:20<1:57:59,  1.70it/s] 32%|███▏      | 5524/17525 [1:06:21<1:57:59,  1.70it/s] 32%|███▏      | 5525/17525 [1:06:21<1:57:13,  1.71it/s] 32%|███▏      | 5526/17525 [1:06:22<1:58:10,  1.69it/s] 32%|███▏      | 5527/17525 [1:06:22<1:58:12,  1.69it/s] 32%|███▏      | 5528/17525 [1:06:23<1:57:17,  1.70it/s] 32%|███▏      | 5529/17525 [1:06:23<1:56:34,  1.71it/s] 32%|███▏      | 5530/17525 [1:06:24<1:55:55,  1.72it/s]                                                        {'loss': 0.5966, 'grad_norm': 49.55164337158203, 'learning_rate': 1.5505331790543853e-05, 'epoch': 7.89}
 32%|███▏      | 5530/17525 [1:06:24<1:55:55,  1.72it/s] 32%|███▏      | 5531/17525 [1:06:25<1:55:55,  1.72it/s] 32%|███▏      | 5532/17525 [1:06:25<1:58:01,  1.69it/s] 32%|███▏      | 5533/17525 [1:06:26<1:57:09,  1.71it/s] 32%|███▏      | 5534/17525 [1:06:26<1:56:38,  1.71it/s] 32%|███▏      | 5535/17525 [1:06:27<1:56:24,  1.72it/s] 32%|███▏      | 5536/17525 [1:06:28<1:55:59,  1.72it/s] 32%|███▏      | 5537/17525 [1:06:28<1:56:33,  1.71it/s] 32%|███▏      | 5538/17525 [1:06:29<1:57:40,  1.70it/s] 32%|███▏      | 5539/17525 [1:06:29<1:57:12,  1.70it/s] 32%|███▏      | 5540/17525 [1:06:30<1:57:33,  1.70it/s]                                                        {'loss': 0.622, 'grad_norm': 26.896360397338867, 'learning_rate': 1.5490340680180897e-05, 'epoch': 7.9}
 32%|███▏      | 5540/17525 [1:06:30<1:57:33,  1.70it/s] 32%|███▏      | 5541/17525 [1:06:30<1:57:12,  1.70it/s] 32%|███▏      | 5542/17525 [1:06:31<1:56:33,  1.71it/s] 32%|███▏      | 5543/17525 [1:06:32<1:58:36,  1.68it/s] 32%|███▏      | 5544/17525 [1:06:32<1:57:12,  1.70it/s] 32%|███▏      | 5545/17525 [1:06:33<1:56:21,  1.72it/s] 32%|███▏      | 5546/17525 [1:06:33<1:56:48,  1.71it/s] 32%|███▏      | 5547/17525 [1:06:34<1:56:07,  1.72it/s] 32%|███▏      | 5548/17525 [1:06:35<1:55:43,  1.72it/s] 32%|███▏      | 5549/17525 [1:06:35<1:55:54,  1.72it/s] 32%|███▏      | 5550/17525 [1:06:36<1:55:31,  1.73it/s]                                                        {'loss': 0.7211, 'grad_norm': 12.144693374633789, 'learning_rate': 1.547533188605468e-05, 'epoch': 7.92}
 32%|███▏      | 5550/17525 [1:06:36<1:55:31,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 03:09:57,592 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5550
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a64110>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 15df9815-0670-4cbb-935f-e8dd48b17769)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:10:08,411 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:10:08,414 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5550/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 32%|███▏      | 5551/17525 [1:06:51<16:21:10,  4.92s/it] 32%|███▏      | 5552/17525 [1:06:51<12:01:33,  3.62s/it] 32%|███▏      | 5553/17525 [1:06:52<8:59:39,  2.70s/it]  32%|███▏      | 5554/17525 [1:06:53<7:01:10,  2.11s/it] 32%|███▏      | 5555/17525 [1:06:53<5:29:38,  1.65s/it] 32%|███▏      | 5556/17525 [1:06:54<4:55:28,  1.48s/it] 32%|███▏      | 5557/17525 [1:06:55<4:01:26,  1.21s/it] 32%|███▏      | 5558/17525 [1:06:55<3:24:05,  1.02s/it] 32%|███▏      | 5559/17525 [1:06:56<3:06:20,  1.07it/s] 32%|███▏      | 5560/17525 [1:06:57<2:45:25,  1.21it/s]                                                        {'loss': 0.5578, 'grad_norm': 8.330301284790039, 'learning_rate': 1.546030545650682e-05, 'epoch': 7.93}
 32%|███▏      | 5560/17525 [1:06:57<2:45:25,  1.21it/s] 32%|███▏      | 5561/17525 [1:06:58<2:45:57,  1.20it/s] 32%|███▏      | 5562/17525 [1:06:59<2:53:12,  1.15it/s] 32%|███▏      | 5563/17525 [1:06:59<2:35:52,  1.28it/s] 32%|███▏      | 5564/17525 [1:07:00<2:23:40,  1.39it/s] 32%|███▏      | 5565/17525 [1:07:00<2:15:05,  1.48it/s] 32%|███▏      | 5566/17525 [1:07:01<2:09:04,  1.54it/s] 32%|███▏      | 5567/17525 [1:07:01<2:05:23,  1.59it/s] 32%|███▏      | 5568/17525 [1:07:02<2:02:09,  1.63it/s] 32%|███▏      | 5569/17525 [1:07:03<2:00:05,  1.66it/s] 32%|███▏      | 5570/17525 [1:07:03<1:58:23,  1.68it/s]                                                        {'loss': 0.5659, 'grad_norm': 7.2364068031311035, 'learning_rate': 1.544526143993574e-05, 'epoch': 7.95}
 32%|███▏      | 5570/17525 [1:07:03<1:58:23,  1.68it/s] 32%|███▏      | 5571/17525 [1:07:04<1:58:11,  1.69it/s] 32%|███▏      | 5572/17525 [1:07:04<1:56:57,  1.70it/s] 32%|███▏      | 5573/17525 [1:07:05<2:05:03,  1.59it/s] 32%|███▏      | 5574/17525 [1:07:06<2:01:55,  1.63it/s] 32%|███▏      | 5575/17525 [1:07:06<2:01:20,  1.64it/s] 32%|███▏      | 5576/17525 [1:07:07<2:04:20,  1.60it/s] 32%|███▏      | 5577/17525 [1:07:08<2:24:21,  1.38it/s] 32%|███▏      | 5578/17525 [1:07:08<2:18:29,  1.44it/s] 32%|███▏      | 5579/17525 [1:07:10<3:13:14,  1.03it/s] 32%|███▏      | 5580/17525 [1:07:11<2:49:37,  1.17it/s]                                                        {'loss': 0.6424, 'grad_norm': 10.081376075744629, 'learning_rate': 1.5430199884796502e-05, 'epoch': 7.96}
 32%|███▏      | 5580/17525 [1:07:11<2:49:37,  1.17it/s] 32%|███▏      | 5581/17525 [1:07:11<2:33:11,  1.30it/s] 32%|███▏      | 5582/17525 [1:07:12<2:21:23,  1.41it/s] 32%|███▏      | 5583/17525 [1:07:12<2:13:44,  1.49it/s] 32%|███▏      | 5584/17525 [1:07:13<2:08:00,  1.55it/s] 32%|███▏      | 5585/17525 [1:07:14<2:03:49,  1.61it/s] 32%|███▏      | 5586/17525 [1:07:14<2:00:59,  1.64it/s] 32%|███▏      | 5587/17525 [1:07:15<2:00:26,  1.65it/s] 32%|███▏      | 5588/17525 [1:07:15<1:58:41,  1.68it/s] 32%|███▏      | 5589/17525 [1:07:16<1:57:29,  1.69it/s] 32%|███▏      | 5590/17525 [1:07:16<1:56:25,  1.71it/s]                                                        {'loss': 0.5892, 'grad_norm': 6.497267723083496, 'learning_rate': 1.5415120839600676e-05, 'epoch': 7.97}
 32%|███▏      | 5590/17525 [1:07:16<1:56:25,  1.71it/s] 32%|███▏      | 5591/17525 [1:07:17<1:55:48,  1.72it/s] 32%|███▏      | 5592/17525 [1:07:18<1:55:18,  1.72it/s] 32%|███▏      | 5593/17525 [1:07:18<1:55:03,  1.73it/s] 32%|███▏      | 5594/17525 [1:07:19<1:54:46,  1.73it/s] 32%|███▏      | 5595/17525 [1:07:19<1:54:38,  1.73it/s] 32%|███▏      | 5596/17525 [1:07:20<1:55:56,  1.71it/s] 32%|███▏      | 5597/17525 [1:07:21<1:55:33,  1.72it/s] 32%|███▏      | 5598/17525 [1:07:21<1:55:26,  1.72it/s] 32%|███▏      | 5599/17525 [1:07:22<1:54:58,  1.73it/s] 32%|███▏      | 5600/17525 [1:07:22<1:54:49,  1.73it/s]                                                        {'loss': 0.5534, 'grad_norm': 5.989782333374023, 'learning_rate': 1.540002435291614e-05, 'epoch': 7.99}
 32%|███▏      | 5600/17525 [1:07:22<1:54:49,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:10:44,142 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:10:44,142 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:10:44,143 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:03,  4.75it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.39it/s][A
 21%|██        | 4/19 [00:00<00:03,  3.84it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.23it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.51it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.78it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.29it/s][A
 47%|████▋     | 9/19 [00:02<00:02,  4.55it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:03<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.8859160542488098, 'eval_runtime': 5.0047, 'eval_samples_per_second': 88.516, 'eval_steps_per_second': 3.796, 'epoch': 7.99}
 32%|███▏      | 5600/17525 [1:07:27<1:54:49,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 32%|███▏      | 5601/17525 [1:07:28<6:57:37,  2.10s/it] 32%|███▏      | 5602/17525 [1:07:28<5:26:34,  1.64s/it] 32%|███▏      | 5603/17525 [1:07:29<4:22:54,  1.32s/it] 32%|███▏      | 5604/17525 [1:07:30<3:41:48,  1.12s/it] 32%|███▏      | 5605/17525 [1:07:30<3:09:46,  1.05it/s] 32%|███▏      | 5606/17525 [1:07:31<2:47:07,  1.19it/s] 32%|███▏      | 5607/17525 [1:07:31<2:31:16,  1.31it/s] 32%|███▏      | 5608/17525 [1:07:32<2:31:59,  1.31it/s] 32%|███▏      | 5609/17525 [1:07:33<2:20:42,  1.41it/s] 32%|███▏      | 5610/17525 [1:07:33<2:13:23,  1.49it/s]                                                        {'loss': 0.5826, 'grad_norm': 9.96005916595459, 'learning_rate': 1.538491047336697e-05, 'epoch': 8.0}
 32%|███▏      | 5610/17525 [1:07:33<2:13:23,  1.49it/s] 32%|███▏      | 5611/17525 [1:07:34<2:09:24,  1.53it/s] 32%|███▏      | 5612/17525 [1:07:35<2:04:53,  1.59it/s] 32%|███▏      | 5613/17525 [1:07:35<2:01:41,  1.63it/s] 32%|███▏      | 5614/17525 [1:07:36<2:02:24,  1.62it/s] 32%|███▏      | 5615/17525 [1:07:37<2:48:24,  1.18it/s] 32%|███▏      | 5616/17525 [1:07:38<2:32:11,  1.30it/s] 32%|███▏      | 5617/17525 [1:07:38<2:20:50,  1.41it/s] 32%|███▏      | 5618/17525 [1:07:39<2:12:38,  1.50it/s] 32%|███▏      | 5619/17525 [1:07:39<2:06:58,  1.56it/s] 32%|███▏      | 5620/17525 [1:07:40<2:03:05,  1.61it/s]                                                        {'loss': 0.5246, 'grad_norm': 11.14950942993164, 'learning_rate': 1.5369779249633246e-05, 'epoch': 8.02}
 32%|███▏      | 5620/17525 [1:07:40<2:03:05,  1.61it/s] 32%|███▏      | 5621/17525 [1:07:41<2:00:33,  1.65it/s] 32%|███▏      | 5622/17525 [1:07:41<1:58:36,  1.67it/s] 32%|███▏      | 5623/17525 [1:07:42<1:57:21,  1.69it/s] 32%|███▏      | 5624/17525 [1:07:42<1:58:00,  1.68it/s] 32%|███▏      | 5625/17525 [1:07:43<1:56:56,  1.70it/s] 32%|███▏      | 5626/17525 [1:07:43<1:56:18,  1.71it/s] 32%|███▏      | 5627/17525 [1:07:44<1:55:41,  1.71it/s] 32%|███▏      | 5628/17525 [1:07:45<1:55:10,  1.72it/s] 32%|███▏      | 5629/17525 [1:07:45<1:54:52,  1.73it/s] 32%|███▏      | 5630/17525 [1:07:46<1:54:28,  1.73it/s]                                                        {'loss': 0.5507, 'grad_norm': 16.022628784179688, 'learning_rate': 1.5354630730450926e-05, 'epoch': 8.03}
 32%|███▏      | 5630/17525 [1:07:46<1:54:28,  1.73it/s] 32%|███▏      | 5631/17525 [1:07:46<1:54:25,  1.73it/s] 32%|███▏      | 5632/17525 [1:07:47<1:54:10,  1.74it/s] 32%|███▏      | 5633/17525 [1:07:48<1:54:06,  1.74it/s] 32%|███▏      | 5634/17525 [1:07:48<1:54:02,  1.74it/s] 32%|███▏      | 5635/17525 [1:07:49<1:54:00,  1.74it/s] 32%|███▏      | 5636/17525 [1:07:49<1:54:26,  1.73it/s] 32%|███▏      | 5637/17525 [1:07:51<2:40:50,  1.23it/s] 32%|███▏      | 5638/17525 [1:07:51<2:26:48,  1.35it/s] 32%|███▏      | 5639/17525 [1:07:52<2:16:55,  1.45it/s] 32%|███▏      | 5640/17525 [1:07:52<2:10:04,  1.52it/s]                                                        {'loss': 0.492, 'grad_norm': 5.6815924644470215, 'learning_rate': 1.5339464964611663e-05, 'epoch': 8.05}
 32%|███▏      | 5640/17525 [1:07:52<2:10:04,  1.52it/s] 32%|███▏      | 5641/17525 [1:07:53<2:05:22,  1.58it/s] 32%|███▏      | 5642/17525 [1:07:53<2:01:55,  1.62it/s] 32%|███▏      | 5643/17525 [1:07:54<2:01:08,  1.63it/s] 32%|███▏      | 5644/17525 [1:07:55<1:58:57,  1.66it/s] 32%|███▏      | 5645/17525 [1:07:55<1:57:22,  1.69it/s] 32%|███▏      | 5646/17525 [1:07:56<1:57:07,  1.69it/s] 32%|███▏      | 5647/17525 [1:07:56<1:56:07,  1.70it/s] 32%|███▏      | 5648/17525 [1:07:57<1:55:39,  1.71it/s] 32%|███▏      | 5649/17525 [1:07:58<1:55:10,  1.72it/s] 32%|███▏      | 5650/17525 [1:07:58<1:54:49,  1.72it/s]                                                        {'loss': 0.5506, 'grad_norm': 6.3107008934021, 'learning_rate': 1.5324282000962672e-05, 'epoch': 8.06}
 32%|███▏      | 5650/17525 [1:07:58<1:54:49,  1.72it/s] 32%|███▏      | 5651/17525 [1:07:59<1:54:53,  1.72it/s] 32%|███▏      | 5652/17525 [1:07:59<1:54:36,  1.73it/s] 32%|███▏      | 5653/17525 [1:08:00<1:54:21,  1.73it/s] 32%|███▏      | 5654/17525 [1:08:00<1:54:10,  1.73it/s] 32%|███▏      | 5655/17525 [1:08:01<1:53:51,  1.74it/s] 32%|███▏      | 5656/17525 [1:08:02<1:53:39,  1.74it/s] 32%|███▏      | 5657/17525 [1:08:02<1:53:43,  1.74it/s] 32%|███▏      | 5658/17525 [1:08:03<1:53:42,  1.74it/s] 32%|███▏      | 5659/17525 [1:08:03<1:53:35,  1.74it/s] 32%|███▏      | 5660/17525 [1:08:04<1:53:37,  1.74it/s]                                                        {'loss': 0.5563, 'grad_norm': 23.105449676513672, 'learning_rate': 1.530908188840655e-05, 'epoch': 8.07}
 32%|███▏      | 5660/17525 [1:08:04<1:53:37,  1.74it/s] 32%|███▏      | 5661/17525 [1:08:04<1:53:44,  1.74it/s] 32%|███▏      | 5662/17525 [1:08:05<1:53:37,  1.74it/s] 32%|███▏      | 5663/17525 [1:08:06<1:53:40,  1.74it/s] 32%|███▏      | 5664/17525 [1:08:06<1:53:43,  1.74it/s] 32%|███▏      | 5665/17525 [1:08:08<2:56:21,  1.12it/s] 32%|███▏      | 5666/17525 [1:08:08<2:37:51,  1.25it/s] 32%|███▏      | 5667/17525 [1:08:09<2:24:38,  1.37it/s] 32%|███▏      | 5668/17525 [1:08:10<2:15:18,  1.46it/s] 32%|███▏      | 5669/17525 [1:08:10<2:08:57,  1.53it/s] 32%|███▏      | 5670/17525 [1:08:11<2:09:22,  1.53it/s]                                                        {'loss': 0.5889, 'grad_norm': 8.803359031677246, 'learning_rate': 1.5293864675901132e-05, 'epoch': 8.09}
 32%|███▏      | 5670/17525 [1:08:11<2:09:22,  1.53it/s] 32%|███▏      | 5671/17525 [1:08:11<2:06:11,  1.57it/s] 32%|███▏      | 5672/17525 [1:08:12<2:02:58,  1.61it/s] 32%|███▏      | 5673/17525 [1:08:13<2:00:06,  1.64it/s] 32%|███▏      | 5674/17525 [1:08:13<1:58:04,  1.67it/s] 32%|███▏      | 5675/17525 [1:08:14<1:56:47,  1.69it/s] 32%|███▏      | 5676/17525 [1:08:14<1:55:41,  1.71it/s] 32%|███▏      | 5677/17525 [1:08:15<1:54:58,  1.72it/s] 32%|███▏      | 5678/17525 [1:08:15<1:54:29,  1.72it/s] 32%|███▏      | 5679/17525 [1:08:16<1:54:11,  1.73it/s] 32%|███▏      | 5680/17525 [1:08:17<1:53:58,  1.73it/s]                                                        {'loss': 0.4871, 'grad_norm': 6.590709209442139, 'learning_rate': 1.5278630412459324e-05, 'epoch': 8.1}
 32%|███▏      | 5680/17525 [1:08:17<1:53:58,  1.73it/s] 32%|███▏      | 5681/17525 [1:08:17<1:54:30,  1.72it/s] 32%|███▏      | 5682/17525 [1:08:18<1:54:06,  1.73it/s] 32%|███▏      | 5683/17525 [1:08:18<1:53:47,  1.73it/s] 32%|███▏      | 5684/17525 [1:08:19<1:53:44,  1.74it/s] 32%|███▏      | 5685/17525 [1:08:20<2:13:02,  1.48it/s] 32%|███▏      | 5686/17525 [1:08:20<2:07:21,  1.55it/s] 32%|███▏      | 5687/17525 [1:08:21<2:03:07,  1.60it/s] 32%|███▏      | 5688/17525 [1:08:21<2:00:19,  1.64it/s] 32%|███▏      | 5689/17525 [1:08:22<1:58:22,  1.67it/s] 32%|███▏      | 5690/17525 [1:08:23<1:56:56,  1.69it/s]                                                        {'loss': 0.4972, 'grad_norm': 11.330329895019531, 'learning_rate': 1.5263379147148965e-05, 'epoch': 8.12}
 32%|███▏      | 5690/17525 [1:08:23<1:56:56,  1.69it/s] 32%|███▏      | 5691/17525 [1:08:23<1:55:59,  1.70it/s] 32%|███▏      | 5692/17525 [1:08:24<1:55:18,  1.71it/s] 32%|███▏      | 5693/17525 [1:08:24<1:54:36,  1.72it/s] 32%|███▏      | 5694/17525 [1:08:25<1:54:19,  1.72it/s] 32%|███▏      | 5695/17525 [1:08:26<1:54:01,  1.73it/s] 33%|███▎      | 5696/17525 [1:08:26<1:53:49,  1.73it/s] 33%|███▎      | 5697/17525 [1:08:27<1:53:50,  1.73it/s] 33%|███▎      | 5698/17525 [1:08:27<1:53:47,  1.73it/s] 33%|███▎      | 5699/17525 [1:08:28<1:53:34,  1.74it/s] 33%|███▎      | 5700/17525 [1:08:28<1:53:34,  1.74it/s]                                                        {'loss': 0.5724, 'grad_norm': 4.720895767211914, 'learning_rate': 1.5248110929092645e-05, 'epoch': 8.13}
 33%|███▎      | 5700/17525 [1:08:28<1:53:34,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 03:11:50,303 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:11:50,303 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:11:50,303 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9138801693916321, 'eval_runtime': 4.5955, 'eval_samples_per_second': 96.399, 'eval_steps_per_second': 4.134, 'epoch': 8.13}
 33%|███▎      | 5700/17525 [1:08:33<1:53:34,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:11:54,902 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5700
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a99dd0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2393af3b-6f0f-4783-ae9f-7f0fb8a481cb)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:12:04,960 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:12:04,963 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5700/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 33%|███▎      | 5701/17525 [1:08:44<16:31:33,  5.03s/it] 33%|███▎      | 5702/17525 [1:08:44<12:09:05,  3.70s/it] 33%|███▎      | 5703/17525 [1:08:45<9:04:29,  2.76s/it]  33%|███▎      | 5704/17525 [1:08:46<6:55:19,  2.11s/it] 33%|███▎      | 5705/17525 [1:08:46<5:24:43,  1.65s/it] 33%|███▎      | 5706/17525 [1:08:47<4:21:23,  1.33s/it] 33%|███▎      | 5707/17525 [1:08:47<3:37:18,  1.10s/it] 33%|███▎      | 5708/17525 [1:08:48<3:06:12,  1.06it/s] 33%|███▎      | 5709/17525 [1:08:49<2:46:03,  1.19it/s] 33%|███▎      | 5710/17525 [1:08:49<2:30:20,  1.31it/s]                                                        {'loss': 0.5244, 'grad_norm': 7.831418991088867, 'learning_rate': 1.5232825807467556e-05, 'epoch': 8.15}
 33%|███▎      | 5710/17525 [1:08:49<2:30:20,  1.31it/s] 33%|███▎      | 5711/17525 [1:08:50<2:19:26,  1.41it/s] 33%|███▎      | 5712/17525 [1:08:50<2:11:41,  1.50it/s] 33%|███▎      | 5713/17525 [1:08:51<2:06:25,  1.56it/s] 33%|███▎      | 5714/17525 [1:08:51<2:02:34,  1.61it/s] 33%|███▎      | 5715/17525 [1:08:52<1:59:49,  1.64it/s] 33%|███▎      | 5716/17525 [1:08:53<1:58:15,  1.66it/s] 33%|███▎      | 5717/17525 [1:08:53<1:57:07,  1.68it/s] 33%|███▎      | 5718/17525 [1:08:54<1:55:48,  1.70it/s] 33%|███▎      | 5719/17525 [1:08:54<1:55:53,  1.70it/s] 33%|███▎      | 5720/17525 [1:08:55<2:16:13,  1.44it/s]                                                        {'loss': 0.696, 'grad_norm': 8.58354663848877, 'learning_rate': 1.5217523831505343e-05, 'epoch': 8.16}
 33%|███▎      | 5720/17525 [1:08:55<2:16:13,  1.44it/s] 33%|███▎      | 5721/17525 [1:08:56<2:10:26,  1.51it/s] 33%|███▎      | 5722/17525 [1:08:56<2:06:37,  1.55it/s] 33%|███▎      | 5723/17525 [1:08:57<2:30:11,  1.31it/s] 33%|███▎      | 5724/17525 [1:08:58<2:19:24,  1.41it/s] 33%|███▎      | 5725/17525 [1:08:59<2:11:28,  1.50it/s] 33%|███▎      | 5726/17525 [1:08:59<2:06:19,  1.56it/s] 33%|███▎      | 5727/17525 [1:09:00<2:02:13,  1.61it/s] 33%|███▎      | 5728/17525 [1:09:00<1:59:28,  1.65it/s] 33%|███▎      | 5729/17525 [1:09:01<1:57:38,  1.67it/s] 33%|███▎      | 5730/17525 [1:09:02<1:56:12,  1.69it/s]                                                        {'loss': 0.5558, 'grad_norm': 9.841499328613281, 'learning_rate': 1.5202205050491926e-05, 'epoch': 8.17}
 33%|███▎      | 5730/17525 [1:09:02<1:56:12,  1.69it/s] 33%|███▎      | 5731/17525 [1:09:02<1:55:21,  1.70it/s] 33%|███▎      | 5732/17525 [1:09:03<1:54:40,  1.71it/s] 33%|███▎      | 5733/17525 [1:09:03<1:54:06,  1.72it/s] 33%|███▎      | 5734/17525 [1:09:04<1:53:40,  1.73it/s] 33%|███▎      | 5735/17525 [1:09:04<1:53:28,  1.73it/s] 33%|███▎      | 5736/17525 [1:09:05<1:53:23,  1.73it/s] 33%|███▎      | 5737/17525 [1:09:06<1:53:39,  1.73it/s] 33%|███▎      | 5738/17525 [1:09:06<1:53:35,  1.73it/s] 33%|███▎      | 5739/17525 [1:09:07<1:53:30,  1.73it/s] 33%|███▎      | 5740/17525 [1:09:07<1:53:23,  1.73it/s]                                                        {'loss': 0.5049, 'grad_norm': 10.887933731079102, 'learning_rate': 1.5186869513767357e-05, 'epoch': 8.19}
 33%|███▎      | 5740/17525 [1:09:07<1:53:23,  1.73it/s] 33%|███▎      | 5741/17525 [1:09:08<1:53:27,  1.73it/s] 33%|███▎      | 5742/17525 [1:09:09<2:16:59,  1.43it/s] 33%|███▎      | 5743/17525 [1:09:09<2:09:53,  1.51it/s] 33%|███▎      | 5744/17525 [1:09:10<2:04:50,  1.57it/s] 33%|███▎      | 5745/17525 [1:09:11<2:01:28,  1.62it/s] 33%|███▎      | 5746/17525 [1:09:11<2:09:43,  1.51it/s] 33%|███▎      | 5747/17525 [1:09:12<2:04:52,  1.57it/s] 33%|███▎      | 5748/17525 [1:09:12<2:01:13,  1.62it/s] 33%|███▎      | 5749/17525 [1:09:13<1:58:39,  1.65it/s] 33%|███▎      | 5750/17525 [1:09:14<2:18:40,  1.42it/s]                                                        {'loss': 0.523, 'grad_norm': 9.918001174926758, 'learning_rate': 1.517151727072566e-05, 'epoch': 8.2}
 33%|███▎      | 5750/17525 [1:09:14<2:18:40,  1.42it/s] 33%|███▎      | 5751/17525 [1:09:15<2:11:05,  1.50it/s] 33%|███▎      | 5752/17525 [1:09:15<2:05:33,  1.56it/s] 33%|███▎      | 5753/17525 [1:09:16<2:02:15,  1.60it/s] 33%|███▎      | 5754/17525 [1:09:16<1:59:29,  1.64it/s] 33%|███▎      | 5755/17525 [1:09:17<1:57:24,  1.67it/s] 33%|███▎      | 5756/17525 [1:09:17<1:56:24,  1.69it/s] 33%|███▎      | 5757/17525 [1:09:18<1:55:22,  1.70it/s] 33%|███▎      | 5758/17525 [1:09:19<1:54:35,  1.71it/s] 33%|███▎      | 5759/17525 [1:09:19<1:54:08,  1.72it/s] 33%|███▎      | 5760/17525 [1:09:20<1:53:43,  1.72it/s]                                                        {'loss': 0.5467, 'grad_norm': 9.977428436279297, 'learning_rate': 1.5156148370814663e-05, 'epoch': 8.22}
 33%|███▎      | 5760/17525 [1:09:20<1:53:43,  1.72it/s] 33%|███▎      | 5761/17525 [1:09:20<1:53:43,  1.72it/s] 33%|███▎      | 5762/17525 [1:09:21<1:53:21,  1.73it/s] 33%|███▎      | 5763/17525 [1:09:21<1:53:12,  1.73it/s] 33%|███▎      | 5764/17525 [1:09:22<1:53:10,  1.73it/s] 33%|███▎      | 5765/17525 [1:09:23<1:52:57,  1.74it/s] 33%|███▎      | 5766/17525 [1:09:23<1:54:52,  1.71it/s] 33%|███▎      | 5767/17525 [1:09:24<1:54:21,  1.71it/s] 33%|███▎      | 5768/17525 [1:09:24<1:53:58,  1.72it/s] 33%|███▎      | 5769/17525 [1:09:25<1:53:42,  1.72it/s] 33%|███▎      | 5770/17525 [1:09:26<1:53:23,  1.73it/s]                                                        {'loss': 0.5563, 'grad_norm': 10.553650856018066, 'learning_rate': 1.5140762863535844e-05, 'epoch': 8.23}
 33%|███▎      | 5770/17525 [1:09:26<1:53:23,  1.73it/s] 33%|███▎      | 5771/17525 [1:09:26<1:53:53,  1.72it/s] 33%|███▎      | 5772/17525 [1:09:27<1:53:35,  1.72it/s] 33%|███▎      | 5773/17525 [1:09:27<1:53:09,  1.73it/s] 33%|███▎      | 5774/17525 [1:09:28<1:53:10,  1.73it/s] 33%|███▎      | 5775/17525 [1:09:28<1:53:09,  1.73it/s] 33%|███▎      | 5776/17525 [1:09:29<1:53:06,  1.73it/s] 33%|███▎      | 5777/17525 [1:09:30<1:53:06,  1.73it/s] 33%|███▎      | 5778/17525 [1:09:30<1:53:08,  1.73it/s] 33%|███▎      | 5779/17525 [1:09:31<1:53:06,  1.73it/s] 33%|███▎      | 5780/17525 [1:09:31<1:52:56,  1.73it/s]                                                        {'loss': 0.5646, 'grad_norm': 7.799926280975342, 'learning_rate': 1.5125360798444178e-05, 'epoch': 8.25}
 33%|███▎      | 5780/17525 [1:09:31<1:52:56,  1.73it/s] 33%|███▎      | 5781/17525 [1:09:32<1:52:52,  1.73it/s] 33%|███▎      | 5782/17525 [1:09:32<1:52:49,  1.73it/s] 33%|███▎      | 5783/17525 [1:09:33<1:52:45,  1.74it/s] 33%|███▎      | 5784/17525 [1:09:34<1:52:47,  1.74it/s] 33%|███▎      | 5785/17525 [1:09:34<1:52:41,  1.74it/s] 33%|███▎      | 5786/17525 [1:09:35<1:52:45,  1.74it/s] 33%|███▎      | 5787/17525 [1:09:35<1:52:53,  1.73it/s] 33%|███▎      | 5788/17525 [1:09:36<1:52:48,  1.73it/s] 33%|███▎      | 5789/17525 [1:09:37<1:52:42,  1.74it/s] 33%|███▎      | 5790/17525 [1:09:37<1:52:43,  1.74it/s]                                                        {'loss': 0.4605, 'grad_norm': 8.855127334594727, 'learning_rate': 1.510994222514796e-05, 'epoch': 8.26}
 33%|███▎      | 5790/17525 [1:09:37<1:52:43,  1.74it/s] 33%|███▎      | 5791/17525 [1:09:38<1:52:55,  1.73it/s] 33%|███▎      | 5792/17525 [1:09:38<1:52:52,  1.73it/s] 33%|███▎      | 5793/17525 [1:09:39<1:52:38,  1.74it/s] 33%|███▎      | 5794/17525 [1:09:39<1:52:37,  1.74it/s] 33%|███▎      | 5795/17525 [1:09:40<2:01:03,  1.61it/s] 33%|███▎      | 5796/17525 [1:09:41<1:58:40,  1.65it/s] 33%|███▎      | 5797/17525 [1:09:41<1:56:43,  1.67it/s] 33%|███▎      | 5798/17525 [1:09:42<1:55:31,  1.69it/s] 33%|███▎      | 5799/17525 [1:09:42<1:54:30,  1.71it/s] 33%|███▎      | 5800/17525 [1:09:43<1:53:52,  1.72it/s]                                                        {'loss': 0.5985, 'grad_norm': 8.746116638183594, 'learning_rate': 1.5094507193308667e-05, 'epoch': 8.27}
 33%|███▎      | 5800/17525 [1:09:43<1:53:52,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:13:04,893 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:13:04,893 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:13:04,893 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.8929629921913147, 'eval_runtime': 4.6009, 'eval_samples_per_second': 96.287, 'eval_steps_per_second': 4.13, 'epoch': 8.27}
 33%|███▎      | 5800/17525 [1:09:48<1:53:52,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 33%|███▎      | 5801/17525 [1:09:48<6:23:38,  1.96s/it] 33%|███▎      | 5802/17525 [1:09:49<5:03:25,  1.55s/it] 33%|███▎      | 5803/17525 [1:09:49<4:06:03,  1.26s/it] 33%|███▎      | 5804/17525 [1:09:50<3:26:07,  1.06s/it] 33%|███▎      | 5805/17525 [1:09:51<2:58:07,  1.10it/s] 33%|███▎      | 5806/17525 [1:09:51<2:38:35,  1.23it/s] 33%|███▎      | 5807/17525 [1:09:52<2:24:37,  1.35it/s] 33%|███▎      | 5808/17525 [1:09:52<2:14:54,  1.45it/s] 33%|███▎      | 5809/17525 [1:09:53<2:08:04,  1.52it/s] 33%|███▎      | 5810/17525 [1:09:53<2:03:22,  1.58it/s]                                                        {'loss': 0.4435, 'grad_norm': 13.838447570800781, 'learning_rate': 1.5079055752640781e-05, 'epoch': 8.29}
 33%|███▎      | 5810/17525 [1:09:53<2:03:22,  1.58it/s] 33%|███▎      | 5811/17525 [1:09:54<2:00:15,  1.62it/s] 33%|███▎      | 5812/17525 [1:09:55<1:57:57,  1.65it/s] 33%|███▎      | 5813/17525 [1:09:55<1:56:15,  1.68it/s] 33%|███▎      | 5814/17525 [1:09:56<1:55:08,  1.70it/s] 33%|███▎      | 5815/17525 [1:09:57<2:18:15,  1.41it/s] 33%|███▎      | 5816/17525 [1:09:57<2:10:36,  1.49it/s] 33%|███▎      | 5817/17525 [1:09:58<2:05:12,  1.56it/s] 33%|███▎      | 5818/17525 [1:09:58<2:02:03,  1.60it/s] 33%|███▎      | 5819/17525 [1:09:59<1:59:08,  1.64it/s] 33%|███▎      | 5820/17525 [1:10:00<1:57:16,  1.66it/s]                                                        {'loss': 0.403, 'grad_norm': 4.815113067626953, 'learning_rate': 1.5063587952911634e-05, 'epoch': 8.3}
 33%|███▎      | 5820/17525 [1:10:00<1:57:16,  1.66it/s] 33%|███▎      | 5821/17525 [1:10:00<1:56:05,  1.68it/s] 33%|███▎      | 5822/17525 [1:10:01<1:55:00,  1.70it/s] 33%|███▎      | 5823/17525 [1:10:01<1:54:12,  1.71it/s] 33%|███▎      | 5824/17525 [1:10:02<1:53:34,  1.72it/s] 33%|███▎      | 5825/17525 [1:10:03<2:13:46,  1.46it/s] 33%|███▎      | 5826/17525 [1:10:03<2:07:22,  1.53it/s] 33%|███▎      | 5827/17525 [1:10:04<2:02:44,  1.59it/s] 33%|███▎      | 5828/17525 [1:10:05<2:08:32,  1.52it/s] 33%|███▎      | 5829/17525 [1:10:05<2:03:46,  1.57it/s] 33%|███▎      | 5830/17525 [1:10:06<2:00:19,  1.62it/s]                                                        {'loss': 0.479, 'grad_norm': 21.343505859375, 'learning_rate': 1.5048103843941256e-05, 'epoch': 8.32}
 33%|███▎      | 5830/17525 [1:10:06<2:00:19,  1.62it/s] 33%|███▎      | 5831/17525 [1:10:06<1:58:04,  1.65it/s] 33%|███▎      | 5832/17525 [1:10:07<1:56:22,  1.67it/s] 33%|███▎      | 5833/17525 [1:10:08<1:55:04,  1.69it/s] 33%|███▎      | 5834/17525 [1:10:08<1:54:05,  1.71it/s] 33%|███▎      | 5835/17525 [1:10:09<1:53:37,  1.71it/s] 33%|███▎      | 5836/17525 [1:10:09<1:52:58,  1.72it/s] 33%|███▎      | 5837/17525 [1:10:11<2:29:43,  1.30it/s] 33%|███▎      | 5838/17525 [1:10:11<2:18:26,  1.41it/s] 33%|███▎      | 5839/17525 [1:10:12<2:10:19,  1.49it/s] 33%|███▎      | 5840/17525 [1:10:12<2:04:59,  1.56it/s]                                                        {'loss': 0.4574, 'grad_norm': 10.179064750671387, 'learning_rate': 1.5032603475602192e-05, 'epoch': 8.33}
 33%|███▎      | 5840/17525 [1:10:12<2:04:59,  1.56it/s] 33%|███▎      | 5841/17525 [1:10:13<2:01:14,  1.61it/s] 33%|███▎      | 5842/17525 [1:10:13<1:58:31,  1.64it/s] 33%|███▎      | 5843/17525 [1:10:14<1:57:34,  1.66it/s] 33%|███▎      | 5844/17525 [1:10:15<1:56:03,  1.68it/s] 33%|███▎      | 5845/17525 [1:10:15<1:54:43,  1.70it/s] 33%|███▎      | 5846/17525 [1:10:16<1:54:01,  1.71it/s] 33%|███▎      | 5847/17525 [1:10:16<1:53:27,  1.72it/s] 33%|███▎      | 5848/17525 [1:10:17<1:52:58,  1.72it/s] 33%|███▎      | 5849/17525 [1:10:17<1:52:59,  1.72it/s] 33%|███▎      | 5850/17525 [1:10:18<1:52:39,  1.73it/s]                                                        {'loss': 0.4788, 'grad_norm': 9.51119613647461, 'learning_rate': 1.5017086897819378e-05, 'epoch': 8.35}
 33%|███▎      | 5850/17525 [1:10:18<1:52:39,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 03:13:39,916 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5850
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79af950>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5ebe8478-f507-46af-99ef-15dff97b74ac)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:13:50,079 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:13:50,081 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-5850/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 33%|███▎      | 5851/17525 [1:10:29<11:53:33,  3.67s/it] 33%|███▎      | 5852/17525 [1:10:29<8:53:18,  2.74s/it]  33%|███▎      | 5853/17525 [1:10:30<6:46:50,  2.09s/it] 33%|███▎      | 5854/17525 [1:10:31<5:18:28,  1.64s/it] 33%|███▎      | 5855/17525 [1:10:31<4:16:36,  1.32s/it] 33%|███▎      | 5856/17525 [1:10:32<3:33:08,  1.10s/it] 33%|███▎      | 5857/17525 [1:10:32<3:02:40,  1.06it/s] 33%|███▎      | 5858/17525 [1:10:33<2:42:28,  1.20it/s] 33%|███▎      | 5859/17525 [1:10:34<2:27:48,  1.32it/s] 33%|███▎      | 5860/17525 [1:10:34<2:28:44,  1.31it/s]                                                        {'loss': 0.5533, 'grad_norm': 11.6229248046875, 'learning_rate': 1.5001554160569938e-05, 'epoch': 8.36}
 33%|███▎      | 5860/17525 [1:10:34<2:28:44,  1.31it/s] 33%|███▎      | 5861/17525 [1:10:35<2:25:56,  1.33it/s] 33%|███▎      | 5862/17525 [1:10:36<2:15:49,  1.43it/s] 33%|███▎      | 5863/17525 [1:10:36<2:08:49,  1.51it/s] 33%|███▎      | 5864/17525 [1:10:37<2:03:48,  1.57it/s] 33%|███▎      | 5865/17525 [1:10:37<2:00:10,  1.62it/s] 33%|███▎      | 5866/17525 [1:10:38<1:57:48,  1.65it/s] 33%|███▎      | 5867/17525 [1:10:39<2:04:53,  1.56it/s] 33%|███▎      | 5868/17525 [1:10:39<2:01:02,  1.61it/s] 33%|███▎      | 5869/17525 [1:10:40<1:58:04,  1.65it/s] 33%|███▎      | 5870/17525 [1:10:40<1:56:10,  1.67it/s]                                                        {'loss': 0.5471, 'grad_norm': 11.023393630981445, 'learning_rate': 1.4986005313883057e-05, 'epoch': 8.37}
 33%|███▎      | 5870/17525 [1:10:40<1:56:10,  1.67it/s] 34%|███▎      | 5871/17525 [1:10:41<1:54:57,  1.69it/s] 34%|███▎      | 5872/17525 [1:10:42<1:53:51,  1.71it/s] 34%|███▎      | 5873/17525 [1:10:42<1:53:11,  1.72it/s] 34%|███▎      | 5874/17525 [1:10:43<1:53:43,  1.71it/s] 34%|███▎      | 5875/17525 [1:10:43<1:53:22,  1.71it/s] 34%|███▎      | 5876/17525 [1:10:44<1:52:54,  1.72it/s] 34%|███▎      | 5877/17525 [1:10:44<1:52:35,  1.72it/s] 34%|███▎      | 5878/17525 [1:10:45<1:52:39,  1.72it/s] 34%|███▎      | 5879/17525 [1:10:46<2:03:56,  1.57it/s] 34%|███▎      | 5880/17525 [1:10:46<2:00:14,  1.61it/s]                                                        {'loss': 0.4974, 'grad_norm': 12.977548599243164, 'learning_rate': 1.49704404078398e-05, 'epoch': 8.39}
 34%|███▎      | 5880/17525 [1:10:46<2:00:14,  1.61it/s] 34%|███▎      | 5881/17525 [1:10:47<1:57:52,  1.65it/s] 34%|███▎      | 5882/17525 [1:10:47<1:56:00,  1.67it/s] 34%|███▎      | 5883/17525 [1:10:48<1:54:38,  1.69it/s] 34%|███▎      | 5884/17525 [1:10:49<1:53:48,  1.70it/s] 34%|███▎      | 5885/17525 [1:10:49<1:53:13,  1.71it/s] 34%|███▎      | 5886/17525 [1:10:50<1:52:46,  1.72it/s] 34%|███▎      | 5887/17525 [1:10:50<1:53:56,  1.70it/s] 34%|███▎      | 5888/17525 [1:10:51<1:53:14,  1.71it/s] 34%|███▎      | 5889/17525 [1:10:52<1:52:46,  1.72it/s] 34%|███▎      | 5890/17525 [1:10:52<1:52:30,  1.72it/s]                                                        {'loss': 0.5763, 'grad_norm': 4.349644184112549, 'learning_rate': 1.495485949257297e-05, 'epoch': 8.4}
 34%|███▎      | 5890/17525 [1:10:52<1:52:30,  1.72it/s] 34%|███▎      | 5891/17525 [1:10:53<1:52:25,  1.72it/s] 34%|███▎      | 5892/17525 [1:10:53<1:52:14,  1.73it/s] 34%|███▎      | 5893/17525 [1:10:54<1:51:57,  1.73it/s] 34%|███▎      | 5894/17525 [1:10:54<1:51:55,  1.73it/s] 34%|███▎      | 5895/17525 [1:10:55<1:51:56,  1.73it/s] 34%|███▎      | 5896/17525 [1:10:56<1:51:52,  1.73it/s] 34%|███▎      | 5897/17525 [1:10:56<1:51:38,  1.74it/s] 34%|███▎      | 5898/17525 [1:10:57<1:51:33,  1.74it/s] 34%|███▎      | 5899/17525 [1:10:57<1:51:37,  1.74it/s] 34%|███▎      | 5900/17525 [1:10:58<1:51:44,  1.73it/s]                                                        {'loss': 0.4988, 'grad_norm': 9.651623725891113, 'learning_rate': 1.4939262618266914e-05, 'epoch': 8.42}
 34%|███▎      | 5900/17525 [1:10:58<1:51:44,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:14:19,793 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:14:19,793 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:14:19,794 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9029542207717896, 'eval_runtime': 4.5953, 'eval_samples_per_second': 96.403, 'eval_steps_per_second': 4.135, 'epoch': 8.42}
 34%|███▎      | 5900/17525 [1:11:02<1:51:44,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 34%|███▎      | 5901/17525 [1:11:03<6:19:20,  1.96s/it] 34%|███▎      | 5902/17525 [1:11:04<4:59:01,  1.54s/it] 34%|███▎      | 5903/17525 [1:11:04<4:03:53,  1.26s/it] 34%|███▎      | 5904/17525 [1:11:05<3:24:00,  1.05s/it] 34%|███▎      | 5905/17525 [1:11:05<2:56:17,  1.10it/s] 34%|███▎      | 5906/17525 [1:11:06<2:36:55,  1.23it/s] 34%|███▎      | 5907/17525 [1:11:07<2:23:17,  1.35it/s] 34%|███▎      | 5908/17525 [1:11:07<2:13:49,  1.45it/s] 34%|███▎      | 5909/17525 [1:11:08<2:07:10,  1.52it/s] 34%|███▎      | 5910/17525 [1:11:08<2:02:27,  1.58it/s]                                                        {'loss': 0.5993, 'grad_norm': 11.106703758239746, 'learning_rate': 1.4923649835157392e-05, 'epoch': 8.43}
 34%|███▎      | 5910/17525 [1:11:08<2:02:27,  1.58it/s] 34%|███▎      | 5911/17525 [1:11:09<1:59:19,  1.62it/s] 34%|███▎      | 5912/17525 [1:11:09<1:56:51,  1.66it/s] 34%|███▎      | 5913/17525 [1:11:10<1:55:04,  1.68it/s] 34%|███▎      | 5914/17525 [1:11:11<1:53:55,  1.70it/s] 34%|███▍      | 5915/17525 [1:11:11<1:53:09,  1.71it/s] 34%|███▍      | 5916/17525 [1:11:12<1:53:54,  1.70it/s] 34%|███▍      | 5917/17525 [1:11:12<1:53:07,  1.71it/s] 34%|███▍      | 5918/17525 [1:11:13<2:01:13,  1.60it/s] 34%|███▍      | 5919/17525 [1:11:14<1:58:07,  1.64it/s] 34%|███▍      | 5920/17525 [1:11:14<1:55:56,  1.67it/s]                                                        {'loss': 0.4667, 'grad_norm': 11.104351043701172, 'learning_rate': 1.4908021193531409e-05, 'epoch': 8.45}
 34%|███▍      | 5920/17525 [1:11:14<1:55:56,  1.67it/s] 34%|███▍      | 5921/17525 [1:11:15<1:54:33,  1.69it/s] 34%|███▍      | 5922/17525 [1:11:15<1:53:31,  1.70it/s] 34%|███▍      | 5923/17525 [1:11:16<1:52:52,  1.71it/s] 34%|███▍      | 5924/17525 [1:11:17<2:17:25,  1.41it/s] 34%|███▍      | 5925/17525 [1:11:18<2:09:41,  1.49it/s] 34%|███▍      | 5926/17525 [1:11:18<2:04:04,  1.56it/s] 34%|███▍      | 5927/17525 [1:11:19<2:00:04,  1.61it/s] 34%|███▍      | 5928/17525 [1:11:19<1:57:22,  1.65it/s] 34%|███▍      | 5929/17525 [1:11:20<1:55:30,  1.67it/s] 34%|███▍      | 5930/17525 [1:11:20<1:54:16,  1.69it/s]                                                        {'loss': 0.476, 'grad_norm': 24.312517166137695, 'learning_rate': 1.4892376743727038e-05, 'epoch': 8.46}
 34%|███▍      | 5930/17525 [1:11:20<1:54:16,  1.69it/s] 34%|███▍      | 5931/17525 [1:11:21<1:53:39,  1.70it/s] 34%|███▍      | 5932/17525 [1:11:22<1:52:58,  1.71it/s] 34%|███▍      | 5933/17525 [1:11:22<1:52:26,  1.72it/s] 34%|███▍      | 5934/17525 [1:11:23<1:52:08,  1.72it/s] 34%|███▍      | 5935/17525 [1:11:23<1:51:55,  1.73it/s] 34%|███▍      | 5936/17525 [1:11:24<1:51:40,  1.73it/s] 34%|███▍      | 5937/17525 [1:11:24<1:51:22,  1.73it/s] 34%|███▍      | 5938/17525 [1:11:25<1:51:08,  1.74it/s] 34%|███▍      | 5939/17525 [1:11:26<1:51:20,  1.73it/s] 34%|███▍      | 5940/17525 [1:11:26<1:51:10,  1.74it/s]                                                        {'loss': 0.5478, 'grad_norm': 13.937092781066895, 'learning_rate': 1.4876716536133278e-05, 'epoch': 8.47}
 34%|███▍      | 5940/17525 [1:11:26<1:51:10,  1.74it/s] 34%|███▍      | 5941/17525 [1:11:27<1:51:20,  1.73it/s] 34%|███▍      | 5942/17525 [1:11:27<1:51:03,  1.74it/s] 34%|███▍      | 5943/17525 [1:11:28<1:51:06,  1.74it/s] 34%|███▍      | 5944/17525 [1:11:28<1:51:12,  1.74it/s] 34%|███▍      | 5945/17525 [1:11:29<1:51:04,  1.74it/s] 34%|███▍      | 5946/17525 [1:11:30<1:50:59,  1.74it/s] 34%|███▍      | 5947/17525 [1:11:30<1:50:54,  1.74it/s] 34%|███▍      | 5948/17525 [1:11:31<1:51:00,  1.74it/s] 34%|███▍      | 5949/17525 [1:11:31<1:50:51,  1.74it/s] 34%|███▍      | 5950/17525 [1:11:32<1:50:39,  1.74it/s]                                                        {'loss': 0.6034, 'grad_norm': 8.628544807434082, 'learning_rate': 1.4861040621189876e-05, 'epoch': 8.49}
 34%|███▍      | 5950/17525 [1:11:32<1:50:39,  1.74it/s] 34%|███▍      | 5951/17525 [1:11:32<1:50:53,  1.74it/s] 34%|███▍      | 5952/17525 [1:11:33<1:51:14,  1.73it/s] 34%|███▍      | 5953/17525 [1:11:34<1:51:11,  1.73it/s] 34%|███▍      | 5954/17525 [1:11:34<1:51:02,  1.74it/s] 34%|███▍      | 5955/17525 [1:11:35<1:50:57,  1.74it/s] 34%|███▍      | 5956/17525 [1:11:35<1:51:10,  1.73it/s] 34%|███▍      | 5957/17525 [1:11:36<1:51:12,  1.73it/s] 34%|███▍      | 5958/17525 [1:11:37<2:10:33,  1.48it/s] 34%|███▍      | 5959/17525 [1:11:37<2:04:39,  1.55it/s] 34%|███▍      | 5960/17525 [1:11:38<2:00:26,  1.60it/s]                                                        {'loss': 0.6713, 'grad_norm': 15.332695960998535, 'learning_rate': 1.484534904938717e-05, 'epoch': 8.5}
 34%|███▍      | 5960/17525 [1:11:38<2:00:26,  1.60it/s] 34%|███▍      | 5961/17525 [1:11:39<1:57:35,  1.64it/s] 34%|███▍      | 5962/17525 [1:11:39<1:55:36,  1.67it/s] 34%|███▍      | 5963/17525 [1:11:40<1:54:02,  1.69it/s] 34%|███▍      | 5964/17525 [1:11:40<1:53:07,  1.70it/s] 34%|███▍      | 5965/17525 [1:11:41<1:52:20,  1.72it/s] 34%|███▍      | 5966/17525 [1:11:41<1:51:49,  1.72it/s] 34%|███▍      | 5967/17525 [1:11:42<1:51:32,  1.73it/s] 34%|███▍      | 5968/17525 [1:11:43<2:11:01,  1.47it/s] 34%|███▍      | 5969/17525 [1:11:44<2:04:50,  1.54it/s] 34%|███▍      | 5970/17525 [1:11:44<2:00:32,  1.60it/s]                                                        {'loss': 0.5521, 'grad_norm': 16.65338134765625, 'learning_rate': 1.482964187126593e-05, 'epoch': 8.52}
 34%|███▍      | 5970/17525 [1:11:44<2:00:32,  1.60it/s] 34%|███▍      | 5971/17525 [1:11:45<1:57:55,  1.63it/s] 34%|███▍      | 5972/17525 [1:11:45<1:55:46,  1.66it/s] 34%|███▍      | 5973/17525 [1:11:46<1:54:08,  1.69it/s] 34%|███▍      | 5974/17525 [1:11:46<1:53:09,  1.70it/s] 34%|███▍      | 5975/17525 [1:11:47<1:52:24,  1.71it/s] 34%|███▍      | 5976/17525 [1:11:48<1:51:42,  1.72it/s] 34%|███▍      | 5977/17525 [1:11:48<1:51:22,  1.73it/s] 34%|███▍      | 5978/17525 [1:11:49<1:52:21,  1.71it/s] 34%|███▍      | 5979/17525 [1:11:49<1:51:54,  1.72it/s] 34%|███▍      | 5980/17525 [1:11:50<1:51:24,  1.73it/s]                                                        {'loss': 0.5393, 'grad_norm': 14.243352890014648, 'learning_rate': 1.4813919137417192e-05, 'epoch': 8.53}
 34%|███▍      | 5980/17525 [1:11:50<1:51:24,  1.73it/s] 34%|███▍      | 5981/17525 [1:11:50<1:51:41,  1.72it/s] 34%|███▍      | 5982/17525 [1:11:51<1:53:02,  1.70it/s] 34%|███▍      | 5983/17525 [1:11:52<1:52:31,  1.71it/s] 34%|███▍      | 5984/17525 [1:11:52<1:52:19,  1.71it/s] 34%|███▍      | 5985/17525 [1:11:53<1:51:55,  1.72it/s] 34%|███▍      | 5986/17525 [1:11:53<1:51:33,  1.72it/s] 34%|███▍      | 5987/17525 [1:11:54<1:51:19,  1.73it/s] 34%|███▍      | 5988/17525 [1:11:55<1:51:05,  1.73it/s] 34%|███▍      | 5989/17525 [1:11:55<1:50:56,  1.73it/s] 34%|███▍      | 5990/17525 [1:11:56<1:50:42,  1.74it/s]                                                        {'loss': 0.5035, 'grad_norm': 11.486454963684082, 'learning_rate': 1.4798180898482098e-05, 'epoch': 8.54}
 34%|███▍      | 5990/17525 [1:11:56<1:50:42,  1.74it/s] 34%|███▍      | 5991/17525 [1:11:56<1:51:04,  1.73it/s] 34%|███▍      | 5992/17525 [1:11:57<1:52:59,  1.70it/s] 34%|███▍      | 5993/17525 [1:11:58<2:52:35,  1.11it/s] 34%|███▍      | 5994/17525 [1:11:59<2:33:57,  1.25it/s] 34%|███▍      | 5995/17525 [1:12:00<2:20:40,  1.37it/s] 34%|███▍      | 5996/17525 [1:12:00<2:11:39,  1.46it/s] 34%|███▍      | 5997/17525 [1:12:01<2:05:18,  1.53it/s] 34%|███▍      | 5998/17525 [1:12:01<2:00:52,  1.59it/s] 34%|███▍      | 5999/17525 [1:12:02<2:15:39,  1.42it/s] 34%|███▍      | 6000/17525 [1:12:03<2:08:12,  1.50it/s]                                                        {'loss': 0.5456, 'grad_norm': 8.387060165405273, 'learning_rate': 1.4782427205151718e-05, 'epoch': 8.56}
 34%|███▍      | 6000/17525 [1:12:03<2:08:12,  1.50it/s][INFO|trainer.py:3512] 2024-06-25 03:15:24,708 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:15:24,708 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:15:24,708 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9013397693634033, 'eval_runtime': 4.6009, 'eval_samples_per_second': 96.286, 'eval_steps_per_second': 4.13, 'epoch': 8.56}
 34%|███▍      | 6000/17525 [1:12:07<2:08:12,  1.50it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:15:29,313 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6000
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a45990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ad6cd9e7-a0d5-42d9-b91a-13f03120f9a2)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:15:39,372 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:15:39,375 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6000/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 34%|███▍      | 6001/17525 [1:12:18<16:15:37,  5.08s/it] 34%|███▍      | 6002/17525 [1:12:19<11:56:03,  3.73s/it] 34%|███▍      | 6003/17525 [1:12:20<9:06:02,  2.84s/it]  34%|███▍      | 6004/17525 [1:12:20<6:55:28,  2.16s/it] 34%|███▍      | 6005/17525 [1:12:21<5:24:23,  1.69s/it] 34%|███▍      | 6006/17525 [1:12:21<4:20:37,  1.36s/it] 34%|███▍      | 6007/17525 [1:12:22<3:35:52,  1.12s/it] 34%|███▍      | 6008/17525 [1:12:22<3:04:30,  1.04it/s] 34%|███▍      | 6009/17525 [1:12:23<2:42:23,  1.18it/s] 34%|███▍      | 6010/17525 [1:12:24<2:27:00,  1.31it/s]                                                        {'loss': 0.5868, 'grad_norm': 5.2878570556640625, 'learning_rate': 1.4766658108166918e-05, 'epoch': 8.57}
 34%|███▍      | 6010/17525 [1:12:24<2:27:00,  1.31it/s] 34%|███▍      | 6011/17525 [1:12:24<2:16:09,  1.41it/s] 34%|███▍      | 6012/17525 [1:12:25<2:08:30,  1.49it/s] 34%|███▍      | 6013/17525 [1:12:25<2:03:18,  1.56it/s] 34%|███▍      | 6014/17525 [1:12:26<2:00:08,  1.60it/s] 34%|███▍      | 6015/17525 [1:12:26<1:57:10,  1.64it/s] 34%|███▍      | 6016/17525 [1:12:27<1:56:27,  1.65it/s] 34%|███▍      | 6017/17525 [1:12:28<1:54:54,  1.67it/s] 34%|███▍      | 6018/17525 [1:12:28<1:53:47,  1.69it/s] 34%|███▍      | 6019/17525 [1:12:29<1:52:51,  1.70it/s] 34%|███▍      | 6020/17525 [1:12:29<1:52:15,  1.71it/s]                                                        {'loss': 0.403, 'grad_norm': 8.763895988464355, 'learning_rate': 1.475087365831816e-05, 'epoch': 8.59}
 34%|███▍      | 6020/17525 [1:12:29<1:52:15,  1.71it/s] 34%|███▍      | 6021/17525 [1:12:30<1:51:50,  1.71it/s] 34%|███▍      | 6022/17525 [1:12:31<1:51:27,  1.72it/s] 34%|███▍      | 6023/17525 [1:12:31<1:51:12,  1.72it/s] 34%|███▍      | 6024/17525 [1:12:32<1:51:00,  1.73it/s] 34%|███▍      | 6025/17525 [1:12:32<1:50:59,  1.73it/s] 34%|███▍      | 6026/17525 [1:12:33<1:50:43,  1.73it/s] 34%|███▍      | 6027/17525 [1:12:33<1:50:39,  1.73it/s] 34%|███▍      | 6028/17525 [1:12:34<1:50:25,  1.74it/s] 34%|███▍      | 6029/17525 [1:12:35<1:50:26,  1.73it/s] 34%|███▍      | 6030/17525 [1:12:35<1:50:28,  1.73it/s]                                                        {'loss': 0.4721, 'grad_norm': 7.047266960144043, 'learning_rate': 1.4735073906445365e-05, 'epoch': 8.6}
 34%|███▍      | 6030/17525 [1:12:35<1:50:28,  1.73it/s] 34%|███▍      | 6031/17525 [1:12:36<1:50:39,  1.73it/s] 34%|███▍      | 6032/17525 [1:12:36<1:50:51,  1.73it/s] 34%|███▍      | 6033/17525 [1:12:37<1:50:56,  1.73it/s] 34%|███▍      | 6034/17525 [1:12:37<1:50:50,  1.73it/s] 34%|███▍      | 6035/17525 [1:12:38<1:50:48,  1.73it/s] 34%|███▍      | 6036/17525 [1:12:39<1:50:36,  1.73it/s] 34%|███▍      | 6037/17525 [1:12:39<1:50:33,  1.73it/s] 34%|███▍      | 6038/17525 [1:12:40<1:50:30,  1.73it/s] 34%|███▍      | 6039/17525 [1:12:40<1:50:23,  1.73it/s] 34%|███▍      | 6040/17525 [1:12:41<1:50:24,  1.73it/s]                                                        {'loss': 0.5079, 'grad_norm': 19.822216033935547, 'learning_rate': 1.4719258903437737e-05, 'epoch': 8.62}
 34%|███▍      | 6040/17525 [1:12:41<1:50:24,  1.73it/s] 34%|███▍      | 6041/17525 [1:12:42<1:51:03,  1.72it/s] 34%|███▍      | 6042/17525 [1:12:42<1:50:56,  1.73it/s] 34%|███▍      | 6043/17525 [1:12:43<1:50:54,  1.73it/s] 34%|███▍      | 6044/17525 [1:12:43<1:51:41,  1.71it/s] 34%|███▍      | 6045/17525 [1:12:44<1:51:21,  1.72it/s] 34%|███▍      | 6046/17525 [1:12:44<1:51:06,  1.72it/s] 35%|███▍      | 6047/17525 [1:12:45<1:50:57,  1.72it/s] 35%|███▍      | 6048/17525 [1:12:46<1:50:58,  1.72it/s] 35%|███▍      | 6049/17525 [1:12:46<1:50:47,  1.73it/s] 35%|███▍      | 6050/17525 [1:12:47<1:50:43,  1.73it/s]                                                        {'loss': 0.5761, 'grad_norm': 19.314668655395508, 'learning_rate': 1.4703428700233602e-05, 'epoch': 8.63}
 35%|███▍      | 6050/17525 [1:12:47<1:50:43,  1.73it/s] 35%|███▍      | 6051/17525 [1:12:47<1:50:37,  1.73it/s] 35%|███▍      | 6052/17525 [1:12:48<2:16:18,  1.40it/s] 35%|███▍      | 6053/17525 [1:12:50<2:54:43,  1.09it/s] 35%|███▍      | 6054/17525 [1:12:50<2:35:26,  1.23it/s] 35%|███▍      | 6055/17525 [1:12:51<2:21:43,  1.35it/s] 35%|███▍      | 6056/17525 [1:12:51<2:12:08,  1.45it/s] 35%|███▍      | 6057/17525 [1:12:52<2:05:23,  1.52it/s] 35%|███▍      | 6058/17525 [1:12:53<2:00:55,  1.58it/s] 35%|███▍      | 6059/17525 [1:12:53<1:57:28,  1.63it/s] 35%|███▍      | 6060/17525 [1:12:54<1:55:17,  1.66it/s]                                                        {'loss': 0.4777, 'grad_norm': 16.25726318359375, 'learning_rate': 1.468758334782025e-05, 'epoch': 8.64}
 35%|███▍      | 6060/17525 [1:12:54<1:55:17,  1.66it/s] 35%|███▍      | 6061/17525 [1:12:54<1:53:49,  1.68it/s] 35%|███▍      | 6062/17525 [1:12:55<1:52:38,  1.70it/s] 35%|███▍      | 6063/17525 [1:12:56<1:51:44,  1.71it/s] 35%|███▍      | 6064/17525 [1:12:56<1:51:15,  1.72it/s] 35%|███▍      | 6065/17525 [1:12:57<1:50:55,  1.72it/s] 35%|███▍      | 6066/17525 [1:12:57<1:50:52,  1.72it/s] 35%|███▍      | 6067/17525 [1:12:58<1:50:41,  1.73it/s] 35%|███▍      | 6068/17525 [1:12:58<1:50:24,  1.73it/s] 35%|███▍      | 6069/17525 [1:12:59<1:51:24,  1.71it/s] 35%|███▍      | 6070/17525 [1:13:00<1:51:04,  1.72it/s]                                                        {'loss': 0.5823, 'grad_norm': 7.239813804626465, 'learning_rate': 1.4671722897233753e-05, 'epoch': 8.66}
 35%|███▍      | 6070/17525 [1:13:00<1:51:04,  1.72it/s] 35%|███▍      | 6071/17525 [1:13:00<1:50:41,  1.72it/s] 35%|███▍      | 6072/17525 [1:13:01<1:50:30,  1.73it/s] 35%|███▍      | 6073/17525 [1:13:01<1:50:36,  1.73it/s] 35%|███▍      | 6074/17525 [1:13:02<1:50:18,  1.73it/s] 35%|███▍      | 6075/17525 [1:13:02<1:50:10,  1.73it/s] 35%|███▍      | 6076/17525 [1:13:03<1:50:07,  1.73it/s] 35%|███▍      | 6077/17525 [1:13:04<1:50:10,  1.73it/s] 35%|███▍      | 6078/17525 [1:13:04<1:50:07,  1.73it/s] 35%|███▍      | 6079/17525 [1:13:05<1:49:55,  1.74it/s] 35%|███▍      | 6080/17525 [1:13:05<1:50:05,  1.73it/s]                                                        {'loss': 0.5145, 'grad_norm': 15.21072006225586, 'learning_rate': 1.4655847399558827e-05, 'epoch': 8.67}
 35%|███▍      | 6080/17525 [1:13:05<1:50:05,  1.73it/s] 35%|███▍      | 6081/17525 [1:13:06<1:50:10,  1.73it/s] 35%|███▍      | 6082/17525 [1:13:06<1:50:04,  1.73it/s] 35%|███▍      | 6083/17525 [1:13:07<1:49:53,  1.74it/s] 35%|███▍      | 6084/17525 [1:13:08<1:49:54,  1.73it/s] 35%|███▍      | 6085/17525 [1:13:08<1:49:39,  1.74it/s] 35%|███▍      | 6086/17525 [1:13:09<1:49:42,  1.74it/s] 35%|███▍      | 6087/17525 [1:13:09<1:49:45,  1.74it/s] 35%|███▍      | 6088/17525 [1:13:10<1:49:31,  1.74it/s] 35%|███▍      | 6089/17525 [1:13:11<1:49:38,  1.74it/s] 35%|███▍      | 6090/17525 [1:13:11<1:49:40,  1.74it/s]                                                        {'loss': 0.4378, 'grad_norm': 4.864022254943848, 'learning_rate': 1.4641546628651353e-05, 'epoch': 8.69}
 35%|███▍      | 6090/17525 [1:13:11<1:49:40,  1.74it/s] 35%|███▍      | 6091/17525 [1:13:12<2:15:14,  1.41it/s] 35%|███▍      | 6092/17525 [1:13:13<2:08:04,  1.49it/s] 35%|███▍      | 6093/17525 [1:13:13<2:02:48,  1.55it/s] 35%|███▍      | 6094/17525 [1:13:15<2:44:04,  1.16it/s] 35%|███▍      | 6095/17525 [1:13:15<2:28:34,  1.28it/s] 35%|███▍      | 6096/17525 [1:13:16<2:17:06,  1.39it/s] 35%|███▍      | 6097/17525 [1:13:16<2:09:04,  1.48it/s] 35%|███▍      | 6098/17525 [1:13:17<2:04:11,  1.53it/s] 35%|███▍      | 6099/17525 [1:13:18<1:59:59,  1.59it/s] 35%|███▍      | 6100/17525 [1:13:18<1:57:10,  1.62it/s]                                                        {'loss': 0.4751, 'grad_norm': 21.884313583374023, 'learning_rate': 1.462564268242022e-05, 'epoch': 8.7}
 35%|███▍      | 6100/17525 [1:13:18<1:57:10,  1.62it/s][INFO|trainer.py:3512] 2024-06-25 03:16:40,047 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:16:40,047 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:16:40,047 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.37it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.61it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                        
                                               [A{'eval_loss': 0.9080119729042053, 'eval_runtime': 4.6106, 'eval_samples_per_second': 96.083, 'eval_steps_per_second': 4.121, 'epoch': 8.7}
 35%|███▍      | 6100/17525 [1:13:23<1:57:10,  1.62it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 35%|███▍      | 6101/17525 [1:13:23<6:19:25,  1.99s/it] 35%|███▍      | 6102/17525 [1:13:24<4:59:16,  1.57s/it] 35%|███▍      | 6103/17525 [1:13:25<4:02:36,  1.27s/it] 35%|███▍      | 6104/17525 [1:13:25<3:22:56,  1.07s/it] 35%|███▍      | 6105/17525 [1:13:26<2:55:28,  1.08it/s] 35%|███▍      | 6106/17525 [1:13:26<2:35:54,  1.22it/s] 35%|███▍      | 6107/17525 [1:13:27<2:22:14,  1.34it/s] 35%|███▍      | 6108/17525 [1:13:27<2:12:48,  1.43it/s] 35%|███▍      | 6109/17525 [1:13:28<2:06:06,  1.51it/s] 35%|███▍      | 6110/17525 [1:13:29<2:01:18,  1.57it/s]                                                        {'loss': 0.5925, 'grad_norm': 21.73540496826172, 'learning_rate': 1.460972383751979e-05, 'epoch': 8.72}
 35%|███▍      | 6110/17525 [1:13:29<2:01:18,  1.57it/s] 35%|███▍      | 6111/17525 [1:13:29<1:58:13,  1.61it/s] 35%|███▍      | 6112/17525 [1:13:30<1:55:51,  1.64it/s] 35%|███▍      | 6113/17525 [1:13:30<1:55:06,  1.65it/s] 35%|███▍      | 6114/17525 [1:13:31<1:53:40,  1.67it/s] 35%|███▍      | 6115/17525 [1:13:32<1:52:33,  1.69it/s] 35%|███▍      | 6116/17525 [1:13:32<1:51:52,  1.70it/s] 35%|███▍      | 6117/17525 [1:13:33<1:51:15,  1.71it/s] 35%|███▍      | 6118/17525 [1:13:33<1:50:46,  1.72it/s] 35%|███▍      | 6119/17525 [1:13:34<1:52:35,  1.69it/s] 35%|███▍      | 6120/17525 [1:13:35<2:12:07,  1.44it/s]                                                        {'loss': 0.5904, 'grad_norm': 7.511752605438232, 'learning_rate': 1.459379014522285e-05, 'epoch': 8.73}
 35%|███▍      | 6120/17525 [1:13:35<2:12:07,  1.44it/s] 35%|███▍      | 6121/17525 [1:13:35<2:05:51,  1.51it/s] 35%|███▍      | 6122/17525 [1:13:36<2:01:14,  1.57it/s] 35%|███▍      | 6123/17525 [1:13:37<1:57:46,  1.61it/s] 35%|███▍      | 6124/17525 [1:13:37<1:55:30,  1.65it/s] 35%|███▍      | 6125/17525 [1:13:38<1:53:43,  1.67it/s] 35%|███▍      | 6126/17525 [1:13:38<1:52:41,  1.69it/s] 35%|███▍      | 6127/17525 [1:13:39<1:51:55,  1.70it/s] 35%|███▍      | 6128/17525 [1:13:39<1:52:27,  1.69it/s] 35%|███▍      | 6129/17525 [1:13:40<1:51:45,  1.70it/s] 35%|███▍      | 6130/17525 [1:13:41<1:51:08,  1.71it/s]                                                        {'loss': 0.5409, 'grad_norm': 18.849533081054688, 'learning_rate': 1.4577841656850014e-05, 'epoch': 8.74}
 35%|███▍      | 6130/17525 [1:13:41<1:51:08,  1.71it/s] 35%|███▍      | 6131/17525 [1:13:41<1:50:48,  1.71it/s] 35%|███▍      | 6132/17525 [1:13:42<1:50:58,  1.71it/s] 35%|███▍      | 6133/17525 [1:13:42<1:50:44,  1.71it/s] 35%|███▌      | 6134/17525 [1:13:43<1:52:42,  1.68it/s] 35%|███▌      | 6135/17525 [1:13:44<1:51:40,  1.70it/s] 35%|███▌      | 6136/17525 [1:13:44<1:51:00,  1.71it/s] 35%|███▌      | 6137/17525 [1:13:45<1:50:36,  1.72it/s] 35%|███▌      | 6138/17525 [1:13:45<1:51:14,  1.71it/s] 35%|███▌      | 6139/17525 [1:13:46<1:51:54,  1.70it/s] 35%|███▌      | 6140/17525 [1:13:46<1:51:21,  1.70it/s]                                                        {'loss': 0.5876, 'grad_norm': 13.287120819091797, 'learning_rate': 1.4561878423769549e-05, 'epoch': 8.76}
 35%|███▌      | 6140/17525 [1:13:46<1:51:21,  1.70it/s] 35%|███▌      | 6141/17525 [1:13:47<2:11:17,  1.45it/s] 35%|███▌      | 6142/17525 [1:13:48<2:04:51,  1.52it/s] 35%|███▌      | 6143/17525 [1:13:49<2:00:24,  1.58it/s] 35%|███▌      | 6144/17525 [1:13:49<1:57:18,  1.62it/s] 35%|███▌      | 6145/17525 [1:13:50<1:54:59,  1.65it/s] 35%|███▌      | 6146/17525 [1:13:50<1:53:22,  1.67it/s] 35%|███▌      | 6147/17525 [1:13:51<1:52:17,  1.69it/s] 35%|███▌      | 6148/17525 [1:13:51<1:51:35,  1.70it/s] 35%|███▌      | 6149/17525 [1:13:52<1:51:08,  1.71it/s] 35%|███▌      | 6150/17525 [1:13:53<1:50:46,  1.71it/s]                                                        {'loss': 0.5912, 'grad_norm': 7.32047176361084, 'learning_rate': 1.4545900497397214e-05, 'epoch': 8.77}
 35%|███▌      | 6150/17525 [1:13:53<1:50:46,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 03:17:14,530 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a83110>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a6ba677c-b479-45fb-a336-144c57e3708e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:17:24,586 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:17:24,588 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 35%|███▌      | 6151/17525 [1:14:03<11:29:50,  3.64s/it] 35%|███▌      | 6152/17525 [1:14:04<8:35:55,  2.72s/it]  35%|███▌      | 6153/17525 [1:14:05<6:33:57,  2.08s/it] 35%|███▌      | 6154/17525 [1:14:05<5:08:32,  1.63s/it] 35%|███▌      | 6155/17525 [1:14:06<4:09:06,  1.31s/it] 35%|███▌      | 6156/17525 [1:14:06<3:27:36,  1.10s/it] 35%|███▌      | 6157/17525 [1:14:07<3:18:06,  1.05s/it] 35%|███▌      | 6158/17525 [1:14:08<2:51:48,  1.10it/s] 35%|███▌      | 6159/17525 [1:14:08<2:33:18,  1.24it/s] 35%|███▌      | 6160/17525 [1:14:09<2:20:16,  1.35it/s]                                                        {'loss': 0.5344, 'grad_norm': 5.268870830535889, 'learning_rate': 1.4529907929196097e-05, 'epoch': 8.79}
 35%|███▌      | 6160/17525 [1:14:09<2:20:16,  1.35it/s] 35%|███▌      | 6161/17525 [1:14:10<2:11:39,  1.44it/s] 35%|███▌      | 6162/17525 [1:14:10<2:05:11,  1.51it/s] 35%|███▌      | 6163/17525 [1:14:11<2:00:29,  1.57it/s] 35%|███▌      | 6164/17525 [1:14:11<1:57:32,  1.61it/s] 35%|███▌      | 6165/17525 [1:14:12<1:54:50,  1.65it/s] 35%|███▌      | 6166/17525 [1:14:12<1:53:13,  1.67it/s] 35%|███▌      | 6167/17525 [1:14:13<1:52:19,  1.69it/s] 35%|███▌      | 6168/17525 [1:14:14<1:51:17,  1.70it/s] 35%|███▌      | 6169/17525 [1:14:14<1:50:38,  1.71it/s] 35%|███▌      | 6170/17525 [1:14:15<1:50:28,  1.71it/s]                                                        {'loss': 0.4758, 'grad_norm': 10.683403015136719, 'learning_rate': 1.4513900770676437e-05, 'epoch': 8.8}
 35%|███▌      | 6170/17525 [1:14:15<1:50:28,  1.71it/s] 35%|███▌      | 6171/17525 [1:14:15<1:50:17,  1.72it/s] 35%|███▌      | 6172/17525 [1:14:16<1:49:54,  1.72it/s] 35%|███▌      | 6173/17525 [1:14:17<1:49:44,  1.72it/s] 35%|███▌      | 6174/17525 [1:14:17<1:49:46,  1.72it/s] 35%|███▌      | 6175/17525 [1:14:18<1:49:42,  1.72it/s] 35%|███▌      | 6176/17525 [1:14:18<1:51:09,  1.70it/s] 35%|███▌      | 6177/17525 [1:14:19<1:50:42,  1.71it/s] 35%|███▌      | 6178/17525 [1:14:19<1:50:24,  1.71it/s] 35%|███▌      | 6179/17525 [1:14:20<1:50:04,  1.72it/s] 35%|███▌      | 6180/17525 [1:14:21<1:49:54,  1.72it/s]                                                        {'loss': 0.4884, 'grad_norm': 6.839686870574951, 'learning_rate': 1.4497879073395476e-05, 'epoch': 8.82}
 35%|███▌      | 6180/17525 [1:14:21<1:49:54,  1.72it/s] 35%|███▌      | 6181/17525 [1:14:21<1:50:10,  1.72it/s] 35%|███▌      | 6182/17525 [1:14:22<1:50:26,  1.71it/s] 35%|███▌      | 6183/17525 [1:14:22<1:50:20,  1.71it/s] 35%|███▌      | 6184/17525 [1:14:23<1:49:55,  1.72it/s] 35%|███▌      | 6185/17525 [1:14:24<2:13:57,  1.41it/s] 35%|███▌      | 6186/17525 [1:14:25<2:06:42,  1.49it/s] 35%|███▌      | 6187/17525 [1:14:25<2:01:22,  1.56it/s] 35%|███▌      | 6188/17525 [1:14:26<1:57:52,  1.60it/s] 35%|███▌      | 6189/17525 [1:14:26<1:55:12,  1.64it/s] 35%|███▌      | 6190/17525 [1:14:27<1:53:21,  1.67it/s]                                                        {'loss': 0.509, 'grad_norm': 12.522331237792969, 'learning_rate': 1.4481842888957277e-05, 'epoch': 8.83}
 35%|███▌      | 6190/17525 [1:14:27<1:53:21,  1.67it/s] 35%|███▌      | 6191/17525 [1:14:27<1:52:10,  1.68it/s] 35%|███▌      | 6192/17525 [1:14:28<1:51:21,  1.70it/s] 35%|███▌      | 6193/17525 [1:14:29<1:50:45,  1.71it/s] 35%|███▌      | 6194/17525 [1:14:29<2:00:30,  1.57it/s] 35%|███▌      | 6195/17525 [1:14:30<1:57:02,  1.61it/s] 35%|███▌      | 6196/17525 [1:14:30<1:54:57,  1.64it/s] 35%|███▌      | 6197/17525 [1:14:31<1:53:05,  1.67it/s] 35%|███▌      | 6198/17525 [1:14:32<1:52:30,  1.68it/s] 35%|███▌      | 6199/17525 [1:14:32<2:02:01,  1.55it/s] 35%|███▌      | 6200/17525 [1:14:33<1:58:20,  1.60it/s]                                                        {'loss': 0.6313, 'grad_norm': 6.5836710929870605, 'learning_rate': 1.4465792269012571e-05, 'epoch': 8.84}
 35%|███▌      | 6200/17525 [1:14:33<1:58:20,  1.60it/s][INFO|trainer.py:3512] 2024-06-25 03:17:54,894 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:17:54,894 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:17:54,894 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9136989116668701, 'eval_runtime': 4.5931, 'eval_samples_per_second': 96.45, 'eval_steps_per_second': 4.137, 'epoch': 8.84}
 35%|███▌      | 6200/17525 [1:14:38<1:58:20,  1.60it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 35%|███▌      | 6201/17525 [1:14:38<6:16:21,  1.99s/it] 35%|███▌      | 6202/17525 [1:14:39<4:56:16,  1.57s/it] 35%|███▌      | 6203/17525 [1:14:39<4:00:52,  1.28s/it] 35%|███▌      | 6204/17525 [1:14:40<3:21:19,  1.07s/it] 35%|███▌      | 6205/17525 [1:14:41<2:53:40,  1.09it/s] 35%|███▌      | 6206/17525 [1:14:41<2:34:03,  1.22it/s] 35%|███▌      | 6207/17525 [1:14:42<2:20:37,  1.34it/s] 35%|███▌      | 6208/17525 [1:14:42<2:11:13,  1.44it/s] 35%|███▌      | 6209/17525 [1:14:43<2:04:45,  1.51it/s] 35%|███▌      | 6210/17525 [1:14:43<1:59:57,  1.57it/s]                                                        {'loss': 0.515, 'grad_norm': 20.3864803314209, 'learning_rate': 1.444972726525858e-05, 'epoch': 8.86}
 35%|███▌      | 6210/17525 [1:14:43<1:59:57,  1.57it/s] 35%|███▌      | 6211/17525 [1:14:44<1:57:17,  1.61it/s] 35%|███▌      | 6212/17525 [1:14:45<1:55:01,  1.64it/s] 35%|███▌      | 6213/17525 [1:14:45<1:53:13,  1.67it/s] 35%|███▌      | 6214/17525 [1:14:46<1:51:56,  1.68it/s] 35%|███▌      | 6215/17525 [1:14:46<1:51:05,  1.70it/s] 35%|███▌      | 6216/17525 [1:14:47<1:50:31,  1.71it/s] 35%|███▌      | 6217/17525 [1:14:47<1:50:12,  1.71it/s] 35%|███▌      | 6218/17525 [1:14:48<1:51:00,  1.70it/s] 35%|███▌      | 6219/17525 [1:14:49<1:50:34,  1.70it/s] 35%|███▌      | 6220/17525 [1:14:49<1:50:20,  1.71it/s]                                                        {'loss': 0.5254, 'grad_norm': 6.754281044006348, 'learning_rate': 1.443364792943885e-05, 'epoch': 8.87}
 35%|███▌      | 6220/17525 [1:14:49<1:50:20,  1.71it/s] 35%|███▌      | 6221/17525 [1:14:50<1:50:27,  1.71it/s] 36%|███▌      | 6222/17525 [1:14:50<1:50:24,  1.71it/s] 36%|███▌      | 6223/17525 [1:14:51<1:50:06,  1.71it/s] 36%|███▌      | 6224/17525 [1:14:52<1:49:58,  1.71it/s] 36%|███▌      | 6225/17525 [1:14:52<1:49:44,  1.72it/s] 36%|███▌      | 6226/17525 [1:14:53<1:52:48,  1.67it/s] 36%|███▌      | 6227/17525 [1:14:54<2:18:56,  1.36it/s] 36%|███▌      | 6228/17525 [1:14:54<2:10:00,  1.45it/s] 36%|███▌      | 6229/17525 [1:14:55<2:13:36,  1.41it/s] 36%|███▌      | 6230/17525 [1:14:56<2:06:11,  1.49it/s]                                                        {'loss': 0.4787, 'grad_norm': 13.328965187072754, 'learning_rate': 1.4417554313343098e-05, 'epoch': 8.89}
 36%|███▌      | 6230/17525 [1:14:56<2:06:11,  1.49it/s] 36%|███▌      | 6231/17525 [1:14:56<2:01:03,  1.55it/s] 36%|███▌      | 6232/17525 [1:14:57<1:57:29,  1.60it/s] 36%|███▌      | 6233/17525 [1:14:58<1:55:22,  1.63it/s] 36%|███▌      | 6234/17525 [1:14:58<1:53:31,  1.66it/s] 36%|███▌      | 6235/17525 [1:14:59<1:52:04,  1.68it/s] 36%|███▌      | 6236/17525 [1:14:59<1:51:12,  1.69it/s] 36%|███▌      | 6237/17525 [1:15:00<1:50:27,  1.70it/s] 36%|███▌      | 6238/17525 [1:15:01<2:10:41,  1.44it/s] 36%|███▌      | 6239/17525 [1:15:01<2:04:17,  1.51it/s] 36%|███▌      | 6240/17525 [1:15:02<1:59:39,  1.57it/s]                                                        {'loss': 0.5515, 'grad_norm': 21.728296279907227, 'learning_rate': 1.4401446468807034e-05, 'epoch': 8.9}
 36%|███▌      | 6240/17525 [1:15:02<1:59:39,  1.57it/s] 36%|███▌      | 6241/17525 [1:15:03<1:56:39,  1.61it/s] 36%|███▌      | 6242/17525 [1:15:03<1:54:41,  1.64it/s] 36%|███▌      | 6243/17525 [1:15:04<1:54:13,  1.65it/s] 36%|███▌      | 6244/17525 [1:15:04<1:52:36,  1.67it/s] 36%|███▌      | 6245/17525 [1:15:05<1:52:01,  1.68it/s] 36%|███▌      | 6246/17525 [1:15:05<1:51:24,  1.69it/s] 36%|███▌      | 6247/17525 [1:15:06<1:50:44,  1.70it/s] 36%|███▌      | 6248/17525 [1:15:07<1:50:14,  1.70it/s] 36%|███▌      | 6249/17525 [1:15:07<1:49:53,  1.71it/s] 36%|███▌      | 6250/17525 [1:15:08<1:49:38,  1.71it/s]                                                        {'loss': 0.5746, 'grad_norm': 18.862995147705078, 'learning_rate': 1.438532444771219e-05, 'epoch': 8.92}
 36%|███▌      | 6250/17525 [1:15:08<1:49:38,  1.71it/s] 36%|███▌      | 6251/17525 [1:15:08<1:49:42,  1.71it/s] 36%|███▌      | 6252/17525 [1:15:09<1:49:21,  1.72it/s] 36%|███▌      | 6253/17525 [1:15:10<1:49:13,  1.72it/s] 36%|███▌      | 6254/17525 [1:15:10<1:49:10,  1.72it/s] 36%|███▌      | 6255/17525 [1:15:11<1:52:55,  1.66it/s] 36%|███▌      | 6256/17525 [1:15:11<1:51:35,  1.68it/s] 36%|███▌      | 6257/17525 [1:15:12<1:50:52,  1.69it/s] 36%|███▌      | 6258/17525 [1:15:12<1:50:19,  1.70it/s] 36%|███▌      | 6259/17525 [1:15:13<1:49:47,  1.71it/s] 36%|███▌      | 6260/17525 [1:15:14<1:49:32,  1.71it/s]                                                        {'loss': 0.5834, 'grad_norm': 19.364702224731445, 'learning_rate': 1.4369188301985769e-05, 'epoch': 8.93}
 36%|███▌      | 6260/17525 [1:15:14<1:49:32,  1.71it/s] 36%|███▌      | 6261/17525 [1:15:14<1:49:27,  1.72it/s] 36%|███▌      | 6262/17525 [1:15:15<1:49:16,  1.72it/s] 36%|███▌      | 6263/17525 [1:15:15<1:49:04,  1.72it/s] 36%|███▌      | 6264/17525 [1:15:16<1:49:03,  1.72it/s] 36%|███▌      | 6265/17525 [1:15:17<1:48:49,  1.72it/s] 36%|███▌      | 6266/17525 [1:15:17<1:48:44,  1.73it/s] 36%|███▌      | 6267/17525 [1:15:18<1:49:52,  1.71it/s] 36%|███▌      | 6268/17525 [1:15:18<1:49:29,  1.71it/s] 36%|███▌      | 6269/17525 [1:15:19<1:49:17,  1.72it/s] 36%|███▌      | 6270/17525 [1:15:19<1:48:54,  1.72it/s]                                                        {'loss': 0.6277, 'grad_norm': 10.226578712463379, 'learning_rate': 1.4353038083600453e-05, 'epoch': 8.94}
 36%|███▌      | 6270/17525 [1:15:19<1:48:54,  1.72it/s] 36%|███▌      | 6271/17525 [1:15:20<1:57:13,  1.60it/s] 36%|███▌      | 6272/17525 [1:15:21<1:54:45,  1.63it/s] 36%|███▌      | 6273/17525 [1:15:21<1:52:56,  1.66it/s] 36%|███▌      | 6274/17525 [1:15:22<1:51:21,  1.68it/s] 36%|███▌      | 6275/17525 [1:15:23<1:50:27,  1.70it/s] 36%|███▌      | 6276/17525 [1:15:23<1:50:04,  1.70it/s] 36%|███▌      | 6277/17525 [1:15:24<1:50:12,  1.70it/s] 36%|███▌      | 6278/17525 [1:15:24<1:49:40,  1.71it/s] 36%|███▌      | 6279/17525 [1:15:25<1:49:32,  1.71it/s] 36%|███▌      | 6280/17525 [1:15:26<2:09:46,  1.44it/s]                                                        {'loss': 0.6026, 'grad_norm': 11.472738265991211, 'learning_rate': 1.4336873844574266e-05, 'epoch': 8.96}
 36%|███▌      | 6280/17525 [1:15:26<2:09:46,  1.44it/s] 36%|███▌      | 6281/17525 [1:15:26<2:03:25,  1.52it/s] 36%|███▌      | 6282/17525 [1:15:27<1:58:52,  1.58it/s] 36%|███▌      | 6283/17525 [1:15:28<1:55:48,  1.62it/s] 36%|███▌      | 6284/17525 [1:15:28<1:53:23,  1.65it/s] 36%|███▌      | 6285/17525 [1:15:29<1:51:46,  1.68it/s] 36%|███▌      | 6286/17525 [1:15:29<1:50:51,  1.69it/s] 36%|███▌      | 6287/17525 [1:15:30<1:50:05,  1.70it/s] 36%|███▌      | 6288/17525 [1:15:30<1:49:27,  1.71it/s] 36%|███▌      | 6289/17525 [1:15:31<1:48:59,  1.72it/s] 36%|███▌      | 6290/17525 [1:15:32<1:48:46,  1.72it/s]                                                        {'loss': 0.4876, 'grad_norm': 8.291390419006348, 'learning_rate': 1.4320695636970385e-05, 'epoch': 8.97}
 36%|███▌      | 6290/17525 [1:15:32<1:48:46,  1.72it/s] 36%|███▌      | 6291/17525 [1:15:32<1:48:55,  1.72it/s] 36%|███▌      | 6292/17525 [1:15:33<1:48:35,  1.72it/s] 36%|███▌      | 6293/17525 [1:15:33<1:48:26,  1.73it/s] 36%|███▌      | 6294/17525 [1:15:34<1:48:25,  1.73it/s] 36%|███▌      | 6295/17525 [1:15:34<1:48:24,  1.73it/s] 36%|███▌      | 6296/17525 [1:15:35<1:48:22,  1.73it/s] 36%|███▌      | 6297/17525 [1:15:36<1:48:20,  1.73it/s] 36%|███▌      | 6298/17525 [1:15:36<1:48:14,  1.73it/s] 36%|███▌      | 6299/17525 [1:15:37<1:48:22,  1.73it/s] 36%|███▌      | 6300/17525 [1:15:37<1:48:20,  1.73it/s]                                                        {'loss': 0.6082, 'grad_norm': 6.913399696350098, 'learning_rate': 1.4304503512896979e-05, 'epoch': 8.99}
 36%|███▌      | 6300/17525 [1:15:37<1:48:20,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:18:59,247 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:18:59,247 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:18:59,247 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.8950125575065613, 'eval_runtime': 4.5973, 'eval_samples_per_second': 96.36, 'eval_steps_per_second': 4.133, 'epoch': 8.99}
 36%|███▌      | 6300/17525 [1:15:42<1:48:20,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:19:03,894 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a6d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 93b5b2b8-94b3-4291-b05d-055577b4d897)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:19:13,951 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:19:13,954 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 36%|███▌      | 6301/17525 [1:15:53<15:41:34,  5.03s/it] 36%|███▌      | 6302/17525 [1:15:53<11:31:25,  3.70s/it] 36%|███▌      | 6303/17525 [1:15:54<8:36:17,  2.76s/it]  36%|███▌      | 6304/17525 [1:15:55<6:33:27,  2.10s/it] 36%|███▌      | 6305/17525 [1:15:55<5:08:09,  1.65s/it] 36%|███▌      | 6306/17525 [1:15:56<4:08:21,  1.33s/it] 36%|███▌      | 6307/17525 [1:15:57<4:00:41,  1.29s/it] 36%|███▌      | 6308/17525 [1:15:57<3:20:49,  1.07s/it] 36%|███▌      | 6309/17525 [1:15:58<2:53:06,  1.08it/s] 36%|███▌      | 6310/17525 [1:15:59<2:33:42,  1.22it/s]                                                        {'loss': 0.5737, 'grad_norm': 19.366531372070312, 'learning_rate': 1.4288297524507033e-05, 'epoch': 9.0}
 36%|███▌      | 6310/17525 [1:15:59<2:33:42,  1.22it/s] 36%|███▌      | 6311/17525 [1:15:59<2:20:31,  1.33it/s] 36%|███▌      | 6312/17525 [1:16:00<2:10:30,  1.43it/s] 36%|███▌      | 6313/17525 [1:16:00<2:03:54,  1.51it/s] 36%|███▌      | 6314/17525 [1:16:01<1:59:21,  1.57it/s] 36%|███▌      | 6315/17525 [1:16:02<1:56:43,  1.60it/s] 36%|███▌      | 6316/17525 [1:16:02<1:55:09,  1.62it/s] 36%|███▌      | 6317/17525 [1:16:03<1:53:02,  1.65it/s] 36%|███▌      | 6318/17525 [1:16:03<1:53:29,  1.65it/s] 36%|███▌      | 6319/17525 [1:16:04<1:51:50,  1.67it/s] 36%|███▌      | 6320/17525 [1:16:04<1:50:56,  1.68it/s]                                                        {'loss': 0.5045, 'grad_norm': 9.023717880249023, 'learning_rate': 1.4272077723998199e-05, 'epoch': 9.02}
 36%|███▌      | 6320/17525 [1:16:04<1:50:56,  1.68it/s] 36%|███▌      | 6321/17525 [1:16:05<1:50:23,  1.69it/s] 36%|███▌      | 6322/17525 [1:16:06<1:49:41,  1.70it/s] 36%|███▌      | 6323/17525 [1:16:06<1:49:40,  1.70it/s] 36%|███▌      | 6324/17525 [1:16:07<1:49:12,  1.71it/s] 36%|███▌      | 6325/17525 [1:16:07<1:48:48,  1.72it/s] 36%|███▌      | 6326/17525 [1:16:08<1:48:24,  1.72it/s] 36%|███▌      | 6327/17525 [1:16:09<1:48:00,  1.73it/s] 36%|███▌      | 6328/17525 [1:16:09<1:47:47,  1.73it/s] 36%|███▌      | 6329/17525 [1:16:10<1:47:58,  1.73it/s] 36%|███▌      | 6330/17525 [1:16:10<1:47:48,  1.73it/s]                                                        {'loss': 0.505, 'grad_norm': 19.125810623168945, 'learning_rate': 1.4255844163612608e-05, 'epoch': 9.03}
 36%|███▌      | 6330/17525 [1:16:10<1:47:48,  1.73it/s] 36%|███▌      | 6331/17525 [1:16:11<1:48:03,  1.73it/s] 36%|███▌      | 6332/17525 [1:16:11<1:47:59,  1.73it/s] 36%|███▌      | 6333/17525 [1:16:12<1:48:02,  1.73it/s] 36%|███▌      | 6334/17525 [1:16:13<1:48:02,  1.73it/s] 36%|███▌      | 6335/17525 [1:16:13<1:47:57,  1.73it/s] 36%|███▌      | 6336/17525 [1:16:14<1:48:04,  1.73it/s] 36%|███▌      | 6337/17525 [1:16:14<1:48:07,  1.72it/s] 36%|███▌      | 6338/17525 [1:16:15<1:48:36,  1.72it/s] 36%|███▌      | 6339/17525 [1:16:15<1:48:28,  1.72it/s] 36%|███▌      | 6340/17525 [1:16:16<1:48:16,  1.72it/s]                                                        {'loss': 0.5478, 'grad_norm': 8.659717559814453, 'learning_rate': 1.4239596895636713e-05, 'epoch': 9.04}
 36%|███▌      | 6340/17525 [1:16:16<1:48:16,  1.72it/s] 36%|███▌      | 6341/17525 [1:16:17<1:48:03,  1.72it/s] 36%|███▌      | 6342/17525 [1:16:17<1:47:56,  1.73it/s] 36%|███▌      | 6343/17525 [1:16:18<1:47:53,  1.73it/s] 36%|███▌      | 6344/17525 [1:16:18<1:47:54,  1.73it/s] 36%|███▌      | 6345/17525 [1:16:19<1:47:52,  1.73it/s] 36%|███▌      | 6346/17525 [1:16:20<1:47:54,  1.73it/s] 36%|███▌      | 6347/17525 [1:16:20<1:47:39,  1.73it/s] 36%|███▌      | 6348/17525 [1:16:21<1:47:50,  1.73it/s] 36%|███▌      | 6349/17525 [1:16:21<1:47:39,  1.73it/s] 36%|███▌      | 6350/17525 [1:16:22<1:47:35,  1.73it/s]                                                        {'loss': 0.5798, 'grad_norm': 14.272029876708984, 'learning_rate': 1.4223335972401122e-05, 'epoch': 9.06}
 36%|███▌      | 6350/17525 [1:16:22<1:47:35,  1.73it/s] 36%|███▌      | 6351/17525 [1:16:22<1:47:37,  1.73it/s] 36%|███▌      | 6352/17525 [1:16:23<1:47:26,  1.73it/s] 36%|███▋      | 6353/17525 [1:16:24<1:47:29,  1.73it/s] 36%|███▋      | 6354/17525 [1:16:24<1:47:57,  1.72it/s] 36%|███▋      | 6355/17525 [1:16:25<1:49:42,  1.70it/s] 36%|███▋      | 6356/17525 [1:16:25<1:49:05,  1.71it/s] 36%|███▋      | 6357/17525 [1:16:26<1:48:41,  1.71it/s] 36%|███▋      | 6358/17525 [1:16:27<1:48:27,  1.72it/s] 36%|███▋      | 6359/17525 [1:16:27<1:47:57,  1.72it/s] 36%|███▋      | 6360/17525 [1:16:28<1:48:04,  1.72it/s]                                                        {'loss': 0.5897, 'grad_norm': 17.648847579956055, 'learning_rate': 1.4207061446280415e-05, 'epoch': 9.07}
 36%|███▋      | 6360/17525 [1:16:28<1:48:04,  1.72it/s] 36%|███▋      | 6361/17525 [1:16:28<1:48:06,  1.72it/s] 36%|███▋      | 6362/17525 [1:16:29<1:47:42,  1.73it/s] 36%|███▋      | 6363/17525 [1:16:29<1:47:39,  1.73it/s] 36%|███▋      | 6364/17525 [1:16:30<1:47:23,  1.73it/s] 36%|███▋      | 6365/17525 [1:16:31<1:49:33,  1.70it/s] 36%|███▋      | 6366/17525 [1:16:31<1:49:05,  1.70it/s] 36%|███▋      | 6367/17525 [1:16:32<1:48:26,  1.71it/s] 36%|███▋      | 6368/17525 [1:16:32<1:48:09,  1.72it/s] 36%|███▋      | 6369/17525 [1:16:33<1:48:09,  1.72it/s] 36%|███▋      | 6370/17525 [1:16:33<1:47:49,  1.72it/s]                                                        {'loss': 0.5392, 'grad_norm': 6.2433929443359375, 'learning_rate': 1.4190773369692992e-05, 'epoch': 9.09}
 36%|███▋      | 6370/17525 [1:16:33<1:47:49,  1.72it/s] 36%|███▋      | 6371/17525 [1:16:34<1:47:36,  1.73it/s] 36%|███▋      | 6372/17525 [1:16:35<1:47:33,  1.73it/s] 36%|███▋      | 6373/17525 [1:16:35<1:47:38,  1.73it/s] 36%|███▋      | 6374/17525 [1:16:36<1:47:44,  1.73it/s] 36%|███▋      | 6375/17525 [1:16:36<1:47:46,  1.72it/s] 36%|███▋      | 6376/17525 [1:16:37<1:47:32,  1.73it/s] 36%|███▋      | 6377/17525 [1:16:38<1:47:25,  1.73it/s] 36%|███▋      | 6378/17525 [1:16:38<1:47:17,  1.73it/s] 36%|███▋      | 6379/17525 [1:16:39<1:47:13,  1.73it/s] 36%|███▋      | 6380/17525 [1:16:39<1:47:11,  1.73it/s]                                                        {'loss': 0.5119, 'grad_norm': 12.456335067749023, 'learning_rate': 1.4174471795100897e-05, 'epoch': 9.1}
 36%|███▋      | 6380/17525 [1:16:39<1:47:11,  1.73it/s] 36%|███▋      | 6381/17525 [1:16:40<1:55:04,  1.61it/s] 36%|███▋      | 6382/17525 [1:16:41<1:52:31,  1.65it/s] 36%|███▋      | 6383/17525 [1:16:41<1:51:04,  1.67it/s] 36%|███▋      | 6384/17525 [1:16:42<2:09:15,  1.44it/s] 36%|███▋      | 6385/17525 [1:16:43<2:02:51,  1.51it/s] 36%|███▋      | 6386/17525 [1:16:43<1:58:07,  1.57it/s] 36%|███▋      | 6387/17525 [1:16:44<1:55:06,  1.61it/s] 36%|███▋      | 6388/17525 [1:16:44<1:53:02,  1.64it/s] 36%|███▋      | 6389/17525 [1:16:45<1:59:10,  1.56it/s] 36%|███▋      | 6390/17525 [1:16:46<1:55:48,  1.60it/s]                                                        {'loss': 0.4754, 'grad_norm': 6.483767986297607, 'learning_rate': 1.4158156775009648e-05, 'epoch': 9.12}
 36%|███▋      | 6390/17525 [1:16:46<1:55:48,  1.60it/s] 36%|███▋      | 6391/17525 [1:16:46<1:53:40,  1.63it/s] 36%|███▋      | 6392/17525 [1:16:47<1:51:49,  1.66it/s] 36%|███▋      | 6393/17525 [1:16:47<1:50:22,  1.68it/s] 36%|███▋      | 6394/17525 [1:16:48<1:49:28,  1.69it/s] 36%|███▋      | 6395/17525 [1:16:49<1:48:53,  1.70it/s] 36%|███▋      | 6396/17525 [1:16:49<1:50:22,  1.68it/s] 37%|███▋      | 6397/17525 [1:16:50<1:49:21,  1.70it/s] 37%|███▋      | 6398/17525 [1:16:50<1:48:55,  1.70it/s] 37%|███▋      | 6399/17525 [1:16:51<1:48:32,  1.71it/s] 37%|███▋      | 6400/17525 [1:16:52<1:48:02,  1.72it/s]                                                        {'loss': 0.6618, 'grad_norm': 19.7570858001709, 'learning_rate': 1.4141828361968069e-05, 'epoch': 9.13}
 37%|███▋      | 6400/17525 [1:16:52<1:48:02,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:20:13,408 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:20:13,408 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:20:13,408 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.17it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9077568054199219, 'eval_runtime': 4.605, 'eval_samples_per_second': 96.199, 'eval_steps_per_second': 4.126, 'epoch': 9.13}
 37%|███▋      | 6400/17525 [1:16:56<1:48:02,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 37%|███▋      | 6401/17525 [1:16:57<6:04:14,  1.96s/it] 37%|███▋      | 6402/17525 [1:16:57<4:48:09,  1.55s/it] 37%|███▋      | 6403/17525 [1:16:58<3:54:06,  1.26s/it] 37%|███▋      | 6404/17525 [1:16:58<3:16:24,  1.06s/it] 37%|███▋      | 6405/17525 [1:16:59<2:49:59,  1.09it/s] 37%|███▋      | 6406/17525 [1:17:00<2:31:31,  1.22it/s] 37%|███▋      | 6407/17525 [1:17:00<2:18:17,  1.34it/s] 37%|███▋      | 6408/17525 [1:17:01<2:09:00,  1.44it/s] 37%|███▋      | 6409/17525 [1:17:02<2:47:05,  1.11it/s] 37%|███▋      | 6410/17525 [1:17:03<2:28:52,  1.24it/s]                                                        {'loss': 0.6035, 'grad_norm': 6.20851469039917, 'learning_rate': 1.4125486608568126e-05, 'epoch': 9.14}
 37%|███▋      | 6410/17525 [1:17:03<2:28:52,  1.24it/s] 37%|███▋      | 6411/17525 [1:17:03<2:16:27,  1.36it/s] 37%|███▋      | 6412/17525 [1:17:04<2:07:36,  1.45it/s] 37%|███▋      | 6413/17525 [1:17:04<2:01:43,  1.52it/s] 37%|███▋      | 6414/17525 [1:17:05<1:57:16,  1.58it/s] 37%|███▋      | 6415/17525 [1:17:06<1:54:19,  1.62it/s] 37%|███▋      | 6416/17525 [1:17:06<1:52:42,  1.64it/s] 37%|███▋      | 6417/17525 [1:17:07<1:51:11,  1.66it/s] 37%|███▋      | 6418/17525 [1:17:07<1:50:02,  1.68it/s] 37%|███▋      | 6419/17525 [1:17:08<1:49:15,  1.69it/s] 37%|███▋      | 6420/17525 [1:17:09<1:48:37,  1.70it/s]                                                        {'loss': 0.4964, 'grad_norm': 15.837336540222168, 'learning_rate': 1.4109131567444746e-05, 'epoch': 9.16}
 37%|███▋      | 6420/17525 [1:17:09<1:48:37,  1.70it/s] 37%|███▋      | 6421/17525 [1:17:09<1:48:22,  1.71it/s] 37%|███▋      | 6422/17525 [1:17:10<1:47:48,  1.72it/s] 37%|███▋      | 6423/17525 [1:17:10<1:47:46,  1.72it/s] 37%|███▋      | 6424/17525 [1:17:11<1:47:33,  1.72it/s] 37%|███▋      | 6425/17525 [1:17:11<1:47:37,  1.72it/s] 37%|███▋      | 6426/17525 [1:17:12<1:47:17,  1.72it/s] 37%|███▋      | 6427/17525 [1:17:13<1:47:16,  1.72it/s] 37%|███▋      | 6428/17525 [1:17:13<1:47:18,  1.72it/s] 37%|███▋      | 6429/17525 [1:17:14<1:47:13,  1.72it/s] 37%|███▋      | 6430/17525 [1:17:14<1:47:24,  1.72it/s]                                                        {'loss': 0.5243, 'grad_norm': 11.17184066772461, 'learning_rate': 1.409276329127566e-05, 'epoch': 9.17}
 37%|███▋      | 6430/17525 [1:17:14<1:47:24,  1.72it/s] 37%|███▋      | 6431/17525 [1:17:15<1:48:13,  1.71it/s] 37%|███▋      | 6432/17525 [1:17:16<1:48:18,  1.71it/s] 37%|███▋      | 6433/17525 [1:17:16<1:47:47,  1.71it/s] 37%|███▋      | 6434/17525 [1:17:17<2:07:22,  1.45it/s] 37%|███▋      | 6435/17525 [1:17:18<2:03:33,  1.50it/s] 37%|███▋      | 6436/17525 [1:17:18<1:58:35,  1.56it/s] 37%|███▋      | 6437/17525 [1:17:19<1:55:24,  1.60it/s] 37%|███▋      | 6438/17525 [1:17:19<1:53:00,  1.64it/s] 37%|███▋      | 6439/17525 [1:17:20<1:50:55,  1.67it/s] 37%|███▋      | 6440/17525 [1:17:21<1:49:52,  1.68it/s]                                                        {'loss': 0.4897, 'grad_norm': 14.313541412353516, 'learning_rate': 1.4076381832781222e-05, 'epoch': 9.19}
 37%|███▋      | 6440/17525 [1:17:21<1:49:52,  1.68it/s] 37%|███▋      | 6441/17525 [1:17:21<1:49:23,  1.69it/s] 37%|███▋      | 6442/17525 [1:17:22<1:48:42,  1.70it/s] 37%|███▋      | 6443/17525 [1:17:22<1:47:59,  1.71it/s] 37%|███▋      | 6444/17525 [1:17:23<1:47:47,  1.71it/s] 37%|███▋      | 6445/17525 [1:17:23<1:47:38,  1.72it/s] 37%|███▋      | 6446/17525 [1:17:25<2:13:27,  1.38it/s] 37%|███▋      | 6447/17525 [1:17:25<2:05:22,  1.47it/s] 37%|███▋      | 6448/17525 [1:17:26<1:59:43,  1.54it/s] 37%|███▋      | 6449/17525 [1:17:26<1:55:46,  1.59it/s] 37%|███▋      | 6450/17525 [1:17:27<1:53:58,  1.62it/s]                                                        {'loss': 0.5061, 'grad_norm': 9.902589797973633, 'learning_rate': 1.4059987244724251e-05, 'epoch': 9.2}
 37%|███▋      | 6450/17525 [1:17:27<1:53:58,  1.62it/s][INFO|trainer.py:3203] 2024-06-25 03:20:48,754 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a45990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7adbf564-5d2c-47e9-8d1c-3d96c1277f24)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:20:58,817 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:20:58,819 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 37%|███▋      | 6451/17525 [1:17:38<11:16:34,  3.67s/it] 37%|███▋      | 6452/17525 [1:17:38<8:25:38,  2.74s/it]  37%|███▋      | 6453/17525 [1:17:39<6:25:39,  2.09s/it] 37%|███▋      | 6454/17525 [1:17:39<5:01:51,  1.64s/it] 37%|███▋      | 6455/17525 [1:17:40<4:02:59,  1.32s/it] 37%|███▋      | 6456/17525 [1:17:41<3:23:00,  1.10s/it] 37%|███▋      | 6457/17525 [1:17:41<2:54:07,  1.06it/s] 37%|███▋      | 6458/17525 [1:17:42<2:33:43,  1.20it/s] 37%|███▋      | 6459/17525 [1:17:42<2:19:44,  1.32it/s] 37%|███▋      | 6460/17525 [1:17:43<2:09:53,  1.42it/s]                                                        {'loss': 0.4159, 'grad_norm': 4.903430461883545, 'learning_rate': 1.404357957990985e-05, 'epoch': 9.22}
 37%|███▋      | 6460/17525 [1:17:43<2:09:53,  1.42it/s] 37%|███▋      | 6461/17525 [1:17:43<2:02:51,  1.50it/s] 37%|███▋      | 6462/17525 [1:17:44<2:17:46,  1.34it/s] 37%|███▋      | 6463/17525 [1:17:45<2:08:28,  1.44it/s] 37%|███▋      | 6464/17525 [1:17:46<2:01:49,  1.51it/s] 37%|███▋      | 6465/17525 [1:17:46<1:56:54,  1.58it/s] 37%|███▋      | 6466/17525 [1:17:47<1:53:43,  1.62it/s] 37%|███▋      | 6467/17525 [1:17:47<1:51:24,  1.65it/s] 37%|███▋      | 6468/17525 [1:17:48<1:49:58,  1.68it/s] 37%|███▋      | 6469/17525 [1:17:48<1:48:45,  1.69it/s] 37%|███▋      | 6470/17525 [1:17:49<1:48:05,  1.70it/s]                                                        {'loss': 0.4623, 'grad_norm': 12.409546852111816, 'learning_rate': 1.4027158891185241e-05, 'epoch': 9.23}
 37%|███▋      | 6470/17525 [1:17:49<1:48:05,  1.70it/s] 37%|███▋      | 6471/17525 [1:17:50<1:47:35,  1.71it/s] 37%|███▋      | 6472/17525 [1:17:50<1:48:07,  1.70it/s] 37%|███▋      | 6473/17525 [1:17:51<1:47:46,  1.71it/s] 37%|███▋      | 6474/17525 [1:17:51<1:47:28,  1.71it/s] 37%|███▋      | 6475/17525 [1:17:52<1:47:00,  1.72it/s] 37%|███▋      | 6476/17525 [1:17:52<1:46:38,  1.73it/s] 37%|███▋      | 6477/17525 [1:17:53<1:46:13,  1.73it/s] 37%|███▋      | 6478/17525 [1:17:54<1:46:11,  1.73it/s] 37%|███▋      | 6479/17525 [1:17:54<1:46:09,  1.73it/s] 37%|███▋      | 6480/17525 [1:17:55<1:46:15,  1.73it/s]                                                        {'loss': 0.4741, 'grad_norm': 10.82909870147705, 'learning_rate': 1.40107252314396e-05, 'epoch': 9.24}
 37%|███▋      | 6480/17525 [1:17:55<1:46:15,  1.73it/s] 37%|███▋      | 6481/17525 [1:17:55<1:46:22,  1.73it/s] 37%|███▋      | 6482/17525 [1:17:56<1:46:21,  1.73it/s] 37%|███▋      | 6483/17525 [1:17:56<1:46:20,  1.73it/s] 37%|███▋      | 6484/17525 [1:17:57<1:46:23,  1.73it/s] 37%|███▋      | 6485/17525 [1:17:58<1:46:20,  1.73it/s] 37%|███▋      | 6486/17525 [1:17:58<1:46:18,  1.73it/s] 37%|███▋      | 6487/17525 [1:17:59<1:46:19,  1.73it/s] 37%|███▋      | 6488/17525 [1:17:59<1:46:21,  1.73it/s] 37%|███▋      | 6489/17525 [1:18:00<1:46:11,  1.73it/s] 37%|███▋      | 6490/17525 [1:18:01<1:46:12,  1.73it/s]                                                        {'loss': 0.5871, 'grad_norm': 18.947227478027344, 'learning_rate': 1.3994278653603872e-05, 'epoch': 9.26}
 37%|███▋      | 6490/17525 [1:18:01<1:46:12,  1.73it/s] 37%|███▋      | 6491/17525 [1:18:01<1:46:04,  1.73it/s] 37%|███▋      | 6492/17525 [1:18:02<1:46:03,  1.73it/s] 37%|███▋      | 6493/17525 [1:18:02<1:45:48,  1.74it/s] 37%|███▋      | 6494/17525 [1:18:03<1:47:25,  1.71it/s] 37%|███▋      | 6495/17525 [1:18:03<1:46:54,  1.72it/s] 37%|███▋      | 6496/17525 [1:18:04<1:46:42,  1.72it/s] 37%|███▋      | 6497/17525 [1:18:05<1:47:21,  1.71it/s] 37%|███▋      | 6498/17525 [1:18:05<1:47:01,  1.72it/s] 37%|███▋      | 6499/17525 [1:18:06<1:46:32,  1.72it/s] 37%|███▋      | 6500/17525 [1:18:06<1:46:10,  1.73it/s]                                                        {'loss': 0.5035, 'grad_norm': 10.588828086853027, 'learning_rate': 1.397781921065062e-05, 'epoch': 9.27}
 37%|███▋      | 6500/17525 [1:18:06<1:46:10,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:21:28,236 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:21:28,236 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:21:28,236 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9202320575714111, 'eval_runtime': 4.5982, 'eval_samples_per_second': 96.343, 'eval_steps_per_second': 4.132, 'epoch': 9.27}
 37%|███▋      | 6500/17525 [1:18:11<1:46:10,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 37%|███▋      | 6501/17525 [1:18:12<5:59:59,  1.96s/it] 37%|███▋      | 6502/17525 [1:18:13<5:19:09,  1.74s/it] 37%|███▋      | 6503/17525 [1:18:13<4:15:06,  1.39s/it] 37%|███▋      | 6504/17525 [1:18:14<3:30:33,  1.15s/it] 37%|███▋      | 6505/17525 [1:18:14<2:59:23,  1.02it/s] 37%|███▋      | 6506/17525 [1:18:15<2:37:37,  1.17it/s] 37%|███▋      | 6507/17525 [1:18:16<2:22:25,  1.29it/s] 37%|███▋      | 6508/17525 [1:18:16<2:11:35,  1.40it/s] 37%|███▋      | 6509/17525 [1:18:17<2:04:09,  1.48it/s] 37%|███▋      | 6510/17525 [1:18:17<2:00:06,  1.53it/s]                                                        {'loss': 0.4696, 'grad_norm': 6.217639446258545, 'learning_rate': 1.3961346955593835e-05, 'epoch': 9.29}
 37%|███▋      | 6510/17525 [1:18:17<2:00:06,  1.53it/s] 37%|███▋      | 6511/17525 [1:18:18<1:55:59,  1.58it/s] 37%|███▋      | 6512/17525 [1:18:19<1:52:50,  1.63it/s] 37%|███▋      | 6513/17525 [1:18:19<1:50:54,  1.65it/s] 37%|███▋      | 6514/17525 [1:18:20<1:49:23,  1.68it/s] 37%|███▋      | 6515/17525 [1:18:21<2:30:47,  1.22it/s] 37%|███▋      | 6516/17525 [1:18:22<2:17:18,  1.34it/s] 37%|███▋      | 6517/17525 [1:18:22<2:07:51,  1.43it/s] 37%|███▋      | 6518/17525 [1:18:23<2:01:21,  1.51it/s] 37%|███▋      | 6519/17525 [1:18:23<1:56:51,  1.57it/s] 37%|███▋      | 6520/17525 [1:18:24<1:53:47,  1.61it/s]                                                        {'loss': 0.4835, 'grad_norm': 6.626623630523682, 'learning_rate': 1.3944861941488777e-05, 'epoch': 9.3}
 37%|███▋      | 6520/17525 [1:18:24<1:53:47,  1.61it/s] 37%|███▋      | 6521/17525 [1:18:25<1:51:30,  1.64it/s] 37%|███▋      | 6522/17525 [1:18:25<1:49:57,  1.67it/s] 37%|███▋      | 6523/17525 [1:18:26<1:48:45,  1.69it/s] 37%|███▋      | 6524/17525 [1:18:26<1:47:51,  1.70it/s] 37%|███▋      | 6525/17525 [1:18:27<1:47:08,  1.71it/s] 37%|███▋      | 6526/17525 [1:18:27<1:46:51,  1.72it/s] 37%|███▋      | 6527/17525 [1:18:28<1:46:30,  1.72it/s] 37%|███▋      | 6528/17525 [1:18:29<1:46:08,  1.73it/s] 37%|███▋      | 6529/17525 [1:18:29<1:45:57,  1.73it/s] 37%|███▋      | 6530/17525 [1:18:30<1:46:16,  1.72it/s]                                                        {'loss': 0.425, 'grad_norm': 11.571187973022461, 'learning_rate': 1.3928364221431807e-05, 'epoch': 9.32}
 37%|███▋      | 6530/17525 [1:18:30<1:46:16,  1.72it/s] 37%|███▋      | 6531/17525 [1:18:30<1:46:12,  1.73it/s] 37%|███▋      | 6532/17525 [1:18:31<1:45:59,  1.73it/s] 37%|███▋      | 6533/17525 [1:18:31<1:45:52,  1.73it/s] 37%|███▋      | 6534/17525 [1:18:32<1:45:49,  1.73it/s] 37%|███▋      | 6535/17525 [1:18:33<1:45:53,  1.73it/s] 37%|███▋      | 6536/17525 [1:18:33<1:45:40,  1.73it/s] 37%|███▋      | 6537/17525 [1:18:34<1:45:53,  1.73it/s] 37%|███▋      | 6538/17525 [1:18:34<1:45:38,  1.73it/s] 37%|███▋      | 6539/17525 [1:18:35<1:45:35,  1.73it/s] 37%|███▋      | 6540/17525 [1:18:36<1:45:40,  1.73it/s]                                                        {'loss': 0.4328, 'grad_norm': 5.811758518218994, 'learning_rate': 1.3911853848560206e-05, 'epoch': 9.33}
 37%|███▋      | 6540/17525 [1:18:36<1:45:40,  1.73it/s] 37%|███▋      | 6541/17525 [1:18:36<1:45:37,  1.73it/s] 37%|███▋      | 6542/17525 [1:18:37<1:45:37,  1.73it/s] 37%|███▋      | 6543/17525 [1:18:37<1:45:25,  1.74it/s] 37%|███▋      | 6544/17525 [1:18:38<1:45:24,  1.74it/s] 37%|███▋      | 6545/17525 [1:18:38<1:45:35,  1.73it/s] 37%|███▋      | 6546/17525 [1:18:39<1:45:34,  1.73it/s] 37%|███▋      | 6547/17525 [1:18:40<1:45:20,  1.74it/s] 37%|███▋      | 6548/17525 [1:18:40<1:45:36,  1.73it/s] 37%|███▋      | 6549/17525 [1:18:41<1:45:20,  1.74it/s] 37%|███▋      | 6550/17525 [1:18:41<1:44:58,  1.74it/s]                                                        {'loss': 0.4304, 'grad_norm': 14.99660587310791, 'learning_rate': 1.3895330876052002e-05, 'epoch': 9.34}
 37%|███▋      | 6550/17525 [1:18:41<1:44:58,  1.74it/s] 37%|███▋      | 6551/17525 [1:18:42<1:45:13,  1.74it/s] 37%|███▋      | 6552/17525 [1:18:42<1:45:09,  1.74it/s] 37%|███▋      | 6553/17525 [1:18:43<1:45:16,  1.74it/s] 37%|███▋      | 6554/17525 [1:18:44<1:45:09,  1.74it/s] 37%|███▋      | 6555/17525 [1:18:44<1:45:06,  1.74it/s] 37%|███▋      | 6556/17525 [1:18:45<1:45:25,  1.73it/s] 37%|███▋      | 6557/17525 [1:18:45<1:45:15,  1.74it/s] 37%|███▋      | 6558/17525 [1:18:46<1:45:11,  1.74it/s] 37%|███▋      | 6559/17525 [1:18:46<1:45:23,  1.73it/s] 37%|███▋      | 6560/17525 [1:18:47<1:46:47,  1.71it/s]                                                        {'loss': 0.5552, 'grad_norm': 4.657138347625732, 'learning_rate': 1.3878795357125819e-05, 'epoch': 9.36}
 37%|███▋      | 6560/17525 [1:18:47<1:46:47,  1.71it/s] 37%|███▋      | 6561/17525 [1:18:48<1:46:36,  1.71it/s] 37%|███▋      | 6562/17525 [1:18:48<1:46:09,  1.72it/s] 37%|███▋      | 6563/17525 [1:18:49<1:45:58,  1.72it/s] 37%|███▋      | 6564/17525 [1:18:50<2:05:19,  1.46it/s] 37%|███▋      | 6565/17525 [1:18:50<1:59:19,  1.53it/s] 37%|███▋      | 6566/17525 [1:18:51<1:55:08,  1.59it/s] 37%|███▋      | 6567/17525 [1:18:51<1:51:48,  1.63it/s] 37%|███▋      | 6568/17525 [1:18:52<1:49:41,  1.66it/s] 37%|███▋      | 6569/17525 [1:18:53<1:48:21,  1.69it/s] 37%|███▋      | 6570/17525 [1:18:53<1:47:09,  1.70it/s]                                                        {'loss': 0.5224, 'grad_norm': 5.053493022918701, 'learning_rate': 1.3862247345040678e-05, 'epoch': 9.37}
 37%|███▋      | 6570/17525 [1:18:53<1:47:09,  1.70it/s] 37%|███▋      | 6571/17525 [1:18:54<1:46:33,  1.71it/s] 38%|███▊      | 6572/17525 [1:18:54<1:47:30,  1.70it/s] 38%|███▊      | 6573/17525 [1:18:55<1:46:41,  1.71it/s] 38%|███▊      | 6574/17525 [1:18:56<1:46:18,  1.72it/s] 38%|███▊      | 6575/17525 [1:18:56<1:46:04,  1.72it/s] 38%|███▊      | 6576/17525 [1:18:57<1:45:35,  1.73it/s] 38%|███▊      | 6577/17525 [1:18:57<1:45:41,  1.73it/s] 38%|███▊      | 6578/17525 [1:18:58<1:45:33,  1.73it/s] 38%|███▊      | 6579/17525 [1:18:58<1:45:42,  1.73it/s] 38%|███▊      | 6580/17525 [1:18:59<1:45:51,  1.72it/s]                                                        {'loss': 0.5156, 'grad_norm': 10.311708450317383, 'learning_rate': 1.384568689309585e-05, 'epoch': 9.39}
 38%|███▊      | 6580/17525 [1:18:59<1:45:51,  1.72it/s] 38%|███▊      | 6581/17525 [1:19:00<1:45:53,  1.72it/s] 38%|███▊      | 6582/17525 [1:19:00<1:45:42,  1.73it/s] 38%|███▊      | 6583/17525 [1:19:01<2:28:36,  1.23it/s] 38%|███▊      | 6584/17525 [1:19:02<2:15:48,  1.34it/s] 38%|███▊      | 6585/17525 [1:19:03<2:06:28,  1.44it/s] 38%|███▊      | 6586/17525 [1:19:03<1:59:54,  1.52it/s] 38%|███▊      | 6587/17525 [1:19:04<1:55:20,  1.58it/s] 38%|███▊      | 6588/17525 [1:19:04<1:52:05,  1.63it/s] 38%|███▊      | 6589/17525 [1:19:05<1:50:23,  1.65it/s] 38%|███▊      | 6590/17525 [1:19:06<1:48:56,  1.67it/s]                                                        {'loss': 0.5459, 'grad_norm': 10.285597801208496, 'learning_rate': 1.3829114054630663e-05, 'epoch': 9.4}
 38%|███▊      | 6590/17525 [1:19:06<1:48:56,  1.67it/s] 38%|███▊      | 6591/17525 [1:19:07<2:11:01,  1.39it/s] 38%|███▊      | 6592/17525 [1:19:07<2:03:14,  1.48it/s] 38%|███▊      | 6593/17525 [1:19:08<1:58:03,  1.54it/s] 38%|███▊      | 6594/17525 [1:19:08<1:54:30,  1.59it/s] 38%|███▊      | 6595/17525 [1:19:09<1:51:48,  1.63it/s] 38%|███▊      | 6596/17525 [1:19:09<1:49:48,  1.66it/s] 38%|███▊      | 6597/17525 [1:19:10<1:48:22,  1.68it/s] 38%|███▊      | 6598/17525 [1:19:11<1:47:27,  1.69it/s] 38%|███▊      | 6599/17525 [1:19:11<1:46:32,  1.71it/s] 38%|███▊      | 6600/17525 [1:19:12<1:46:06,  1.72it/s]                                                        {'loss': 0.4988, 'grad_norm': 11.144245147705078, 'learning_rate': 1.3812528883024352e-05, 'epoch': 9.42}
 38%|███▊      | 6600/17525 [1:19:12<1:46:06,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:22:33,640 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:22:33,640 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:22:33,640 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.925553560256958, 'eval_runtime': 4.6062, 'eval_samples_per_second': 96.174, 'eval_steps_per_second': 4.125, 'epoch': 9.42}
 38%|███▊      | 6600/17525 [1:19:16<1:46:06,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:22:38,249 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: fedad099-4ee4-454b-97a1-2d05677f548f)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:22:48,307 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:22:48,309 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 38%|███▊      | 6601/17525 [1:19:27<15:14:35,  5.02s/it] 38%|███▊      | 6602/17525 [1:19:28<11:11:41,  3.69s/it] 38%|███▊      | 6603/17525 [1:19:28<8:21:50,  2.76s/it]  38%|███▊      | 6604/17525 [1:19:29<6:42:34,  2.21s/it] 38%|███▊      | 6605/17525 [1:19:30<5:13:24,  1.72s/it] 38%|███▊      | 6606/17525 [1:19:30<4:10:54,  1.38s/it] 38%|███▊      | 6607/17525 [1:19:31<3:26:54,  1.14s/it] 38%|███▊      | 6608/17525 [1:19:32<2:56:08,  1.03it/s] 38%|███▊      | 6609/17525 [1:19:32<2:35:02,  1.17it/s] 38%|███▊      | 6610/17525 [1:19:33<2:20:23,  1.30it/s]                                                        {'loss': 0.565, 'grad_norm': 11.32159423828125, 'learning_rate': 1.3795931431695865e-05, 'epoch': 9.43}
 38%|███▊      | 6610/17525 [1:19:33<2:20:23,  1.30it/s] 38%|███▊      | 6611/17525 [1:19:33<2:09:59,  1.40it/s] 38%|███▊      | 6612/17525 [1:19:34<2:02:34,  1.48it/s] 38%|███▊      | 6613/17525 [1:19:34<1:57:35,  1.55it/s] 38%|███▊      | 6614/17525 [1:19:35<1:53:53,  1.60it/s] 38%|███▊      | 6615/17525 [1:19:36<1:51:12,  1.63it/s] 38%|███▊      | 6616/17525 [1:19:36<1:49:21,  1.66it/s] 38%|███▊      | 6617/17525 [1:19:37<1:48:10,  1.68it/s] 38%|███▊      | 6618/17525 [1:19:37<1:47:01,  1.70it/s] 38%|███▊      | 6619/17525 [1:19:38<1:46:27,  1.71it/s] 38%|███▊      | 6620/17525 [1:19:38<1:45:55,  1.72it/s]                                                        {'loss': 0.5071, 'grad_norm': 16.70543098449707, 'learning_rate': 1.3779321754103707e-05, 'epoch': 9.44}
 38%|███▊      | 6620/17525 [1:19:38<1:45:55,  1.72it/s] 38%|███▊      | 6621/17525 [1:19:39<1:45:32,  1.72it/s] 38%|███▊      | 6622/17525 [1:19:40<1:45:11,  1.73it/s] 38%|███▊      | 6623/17525 [1:19:40<1:44:53,  1.73it/s] 38%|███▊      | 6624/17525 [1:19:41<1:44:38,  1.74it/s] 38%|███▊      | 6625/17525 [1:19:41<1:44:39,  1.74it/s] 38%|███▊      | 6626/17525 [1:19:42<1:44:25,  1.74it/s] 38%|███▊      | 6627/17525 [1:19:43<1:44:31,  1.74it/s] 38%|███▊      | 6628/17525 [1:19:43<1:44:32,  1.74it/s] 38%|███▊      | 6629/17525 [1:19:44<1:45:49,  1.72it/s] 38%|███▊      | 6630/17525 [1:19:44<1:46:52,  1.70it/s]                                                        {'loss': 0.5851, 'grad_norm': 19.88191795349121, 'learning_rate': 1.3762699903745764e-05, 'epoch': 9.46}
 38%|███▊      | 6630/17525 [1:19:44<1:46:52,  1.70it/s] 38%|███▊      | 6631/17525 [1:19:45<1:46:15,  1.71it/s] 38%|███▊      | 6632/17525 [1:19:45<1:46:09,  1.71it/s] 38%|███▊      | 6633/17525 [1:19:46<1:45:44,  1.72it/s] 38%|███▊      | 6634/17525 [1:19:47<1:45:12,  1.73it/s] 38%|███▊      | 6635/17525 [1:19:47<1:45:12,  1.73it/s] 38%|███▊      | 6636/17525 [1:19:48<1:45:17,  1.72it/s] 38%|███▊      | 6637/17525 [1:19:48<1:44:52,  1.73it/s] 38%|███▊      | 6638/17525 [1:19:49<1:44:50,  1.73it/s] 38%|███▊      | 6639/17525 [1:19:49<1:44:48,  1.73it/s] 38%|███▊      | 6640/17525 [1:19:50<1:44:40,  1.73it/s]                                                        {'loss': 0.5487, 'grad_norm': 8.612414360046387, 'learning_rate': 1.3746065934159123e-05, 'epoch': 9.47}
 38%|███▊      | 6640/17525 [1:19:50<1:44:40,  1.73it/s] 38%|███▊      | 6641/17525 [1:19:51<1:44:47,  1.73it/s] 38%|███▊      | 6642/17525 [1:19:51<1:51:57,  1.62it/s] 38%|███▊      | 6643/17525 [1:19:52<1:50:04,  1.65it/s] 38%|███▊      | 6644/17525 [1:19:53<1:48:48,  1.67it/s] 38%|███▊      | 6645/17525 [1:19:53<1:47:44,  1.68it/s] 38%|███▊      | 6646/17525 [1:19:54<1:46:44,  1.70it/s] 38%|███▊      | 6647/17525 [1:19:54<1:45:51,  1.71it/s] 38%|███▊      | 6648/17525 [1:19:55<1:45:15,  1.72it/s] 38%|███▊      | 6649/17525 [1:19:56<2:08:40,  1.41it/s] 38%|███▊      | 6650/17525 [1:19:56<2:01:26,  1.49it/s]                                                        {'loss': 0.5504, 'grad_norm': 10.483593940734863, 'learning_rate': 1.3729419898919912e-05, 'epoch': 9.49}
 38%|███▊      | 6650/17525 [1:19:56<2:01:26,  1.49it/s] 38%|███▊      | 6651/17525 [1:19:57<1:56:33,  1.55it/s] 38%|███▊      | 6652/17525 [1:19:58<1:53:02,  1.60it/s] 38%|███▊      | 6653/17525 [1:19:58<1:50:14,  1.64it/s] 38%|███▊      | 6654/17525 [1:19:59<1:48:25,  1.67it/s] 38%|███▊      | 6655/17525 [1:19:59<1:47:18,  1.69it/s] 38%|███▊      | 6656/17525 [1:20:00<1:46:34,  1.70it/s] 38%|███▊      | 6657/17525 [1:20:00<1:45:45,  1.71it/s] 38%|███▊      | 6658/17525 [1:20:01<1:45:11,  1.72it/s] 38%|███▊      | 6659/17525 [1:20:02<1:45:34,  1.72it/s] 38%|███▊      | 6660/17525 [1:20:02<1:45:06,  1.72it/s]                                                        {'loss': 0.4435, 'grad_norm': 7.988527774810791, 'learning_rate': 1.3712761851643116e-05, 'epoch': 9.5}
 38%|███▊      | 6660/17525 [1:20:02<1:45:06,  1.72it/s] 38%|███▊      | 6661/17525 [1:20:03<2:01:45,  1.49it/s] 38%|███▊      | 6662/17525 [1:20:04<1:56:34,  1.55it/s] 38%|███▊      | 6663/17525 [1:20:04<1:53:07,  1.60it/s] 38%|███▊      | 6664/17525 [1:20:05<1:50:44,  1.63it/s] 38%|███▊      | 6665/17525 [1:20:05<1:48:55,  1.66it/s] 38%|███▊      | 6666/17525 [1:20:06<1:47:41,  1.68it/s] 38%|███▊      | 6667/17525 [1:20:07<1:47:58,  1.68it/s] 38%|███▊      | 6668/17525 [1:20:07<1:47:44,  1.68it/s] 38%|███▊      | 6669/17525 [1:20:08<1:46:57,  1.69it/s] 38%|███▊      | 6670/17525 [1:20:08<1:46:26,  1.70it/s]                                                        {'loss': 0.4782, 'grad_norm': 8.666902542114258, 'learning_rate': 1.3696091845982413e-05, 'epoch': 9.51}
 38%|███▊      | 6670/17525 [1:20:08<1:46:26,  1.70it/s] 38%|███▊      | 6671/17525 [1:20:09<1:45:42,  1.71it/s] 38%|███▊      | 6672/17525 [1:20:09<1:45:12,  1.72it/s] 38%|███▊      | 6673/17525 [1:20:10<1:44:59,  1.72it/s] 38%|███▊      | 6674/17525 [1:20:11<1:44:40,  1.73it/s] 38%|███▊      | 6675/17525 [1:20:11<1:44:30,  1.73it/s] 38%|███▊      | 6676/17525 [1:20:12<1:44:27,  1.73it/s] 38%|███▊      | 6677/17525 [1:20:12<1:44:18,  1.73it/s] 38%|███▊      | 6678/17525 [1:20:13<1:44:12,  1.73it/s] 38%|███▊      | 6679/17525 [1:20:13<1:44:11,  1.73it/s] 38%|███▊      | 6680/17525 [1:20:14<1:44:13,  1.73it/s]                                                        {'loss': 0.5449, 'grad_norm': 10.77098560333252, 'learning_rate': 1.367940993563e-05, 'epoch': 9.53}
 38%|███▊      | 6680/17525 [1:20:14<1:44:13,  1.73it/s] 38%|███▊      | 6681/17525 [1:20:15<1:44:27,  1.73it/s] 38%|███▊      | 6682/17525 [1:20:15<1:44:11,  1.73it/s] 38%|███▊      | 6683/17525 [1:20:16<1:44:13,  1.73it/s] 38%|███▊      | 6684/17525 [1:20:16<1:43:59,  1.74it/s] 38%|███▊      | 6685/17525 [1:20:17<1:43:59,  1.74it/s] 38%|███▊      | 6686/17525 [1:20:18<1:45:45,  1.71it/s] 38%|███▊      | 6687/17525 [1:20:18<1:52:54,  1.60it/s] 38%|███▊      | 6688/17525 [1:20:19<1:50:10,  1.64it/s] 38%|███▊      | 6689/17525 [1:20:19<1:48:10,  1.67it/s] 38%|███▊      | 6690/17525 [1:20:20<1:46:48,  1.69it/s]                                                        {'loss': 0.5347, 'grad_norm': 28.101158142089844, 'learning_rate': 1.3662716174316407e-05, 'epoch': 9.54}
 38%|███▊      | 6690/17525 [1:20:20<1:46:48,  1.69it/s] 38%|███▊      | 6691/17525 [1:20:21<1:46:18,  1.70it/s] 38%|███▊      | 6692/17525 [1:20:21<1:45:45,  1.71it/s] 38%|███▊      | 6693/17525 [1:20:22<2:04:04,  1.45it/s] 38%|███▊      | 6694/17525 [1:20:23<1:58:04,  1.53it/s] 38%|███▊      | 6695/17525 [1:20:23<1:53:54,  1.58it/s] 38%|███▊      | 6696/17525 [1:20:24<1:51:09,  1.62it/s] 38%|███▊      | 6697/17525 [1:20:24<1:49:21,  1.65it/s] 38%|███▊      | 6698/17525 [1:20:25<1:47:50,  1.67it/s] 38%|███▊      | 6699/17525 [1:20:26<1:46:41,  1.69it/s] 38%|███▊      | 6700/17525 [1:20:26<1:46:08,  1.70it/s]                                                        {'loss': 0.5067, 'grad_norm': 8.742234230041504, 'learning_rate': 1.3646010615810346e-05, 'epoch': 9.56}
 38%|███▊      | 6700/17525 [1:20:26<1:46:08,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 03:23:48,037 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:23:48,037 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:23:48,037 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.74it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.82it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.37it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.61it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9264259934425354, 'eval_runtime': 4.6064, 'eval_samples_per_second': 96.17, 'eval_steps_per_second': 4.125, 'epoch': 9.56}
 38%|███▊      | 6700/17525 [1:20:31<1:46:08,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 38%|███▊      | 6701/17525 [1:20:31<5:55:19,  1.97s/it] 38%|███▊      | 6702/17525 [1:20:32<4:40:05,  1.55s/it] 38%|███▊      | 6703/17525 [1:20:32<3:47:43,  1.26s/it] 38%|███▊      | 6704/17525 [1:20:33<3:10:39,  1.06s/it] 38%|███▊      | 6705/17525 [1:20:34<2:44:47,  1.09it/s] 38%|███▊      | 6706/17525 [1:20:34<2:26:40,  1.23it/s] 38%|███▊      | 6707/17525 [1:20:35<2:13:44,  1.35it/s] 38%|███▊      | 6708/17525 [1:20:35<2:05:03,  1.44it/s] 38%|███▊      | 6709/17525 [1:20:36<1:58:47,  1.52it/s] 38%|███▊      | 6710/17525 [1:20:37<1:54:20,  1.58it/s]                                                        {'loss': 0.4921, 'grad_norm': 8.647035598754883, 'learning_rate': 1.362929331391852e-05, 'epoch': 9.57}
 38%|███▊      | 6710/17525 [1:20:37<1:54:20,  1.58it/s] 38%|███▊      | 6711/17525 [1:20:37<1:51:26,  1.62it/s] 38%|███▊      | 6712/17525 [1:20:38<1:49:13,  1.65it/s] 38%|███▊      | 6713/17525 [1:20:38<1:47:39,  1.67it/s] 38%|███▊      | 6714/17525 [1:20:39<2:06:13,  1.43it/s] 38%|███▊      | 6715/17525 [1:20:40<1:59:33,  1.51it/s] 38%|███▊      | 6716/17525 [1:20:40<1:54:47,  1.57it/s] 38%|███▊      | 6717/17525 [1:20:41<1:51:35,  1.61it/s] 38%|███▊      | 6718/17525 [1:20:42<1:49:10,  1.65it/s] 38%|███▊      | 6719/17525 [1:20:42<1:47:35,  1.67it/s] 38%|███▊      | 6720/17525 [1:20:43<1:46:18,  1.69it/s]                                                        {'loss': 0.394, 'grad_norm': 17.68406867980957, 'learning_rate': 1.3612564322485464e-05, 'epoch': 9.59}
 38%|███▊      | 6720/17525 [1:20:43<1:46:18,  1.69it/s] 38%|███▊      | 6721/17525 [1:20:43<1:45:42,  1.70it/s] 38%|███▊      | 6722/17525 [1:20:44<1:45:11,  1.71it/s] 38%|███▊      | 6723/17525 [1:20:44<1:44:43,  1.72it/s] 38%|███▊      | 6724/17525 [1:20:45<1:44:40,  1.72it/s] 38%|███▊      | 6725/17525 [1:20:46<1:44:19,  1.73it/s] 38%|███▊      | 6726/17525 [1:20:46<1:43:57,  1.73it/s] 38%|███▊      | 6727/17525 [1:20:47<1:44:36,  1.72it/s] 38%|███▊      | 6728/17525 [1:20:48<2:01:44,  1.48it/s] 38%|███▊      | 6729/17525 [1:20:48<1:56:09,  1.55it/s] 38%|███▊      | 6730/17525 [1:20:49<1:52:38,  1.60it/s]                                                        {'loss': 0.5253, 'grad_norm': 13.817681312561035, 'learning_rate': 1.3595823695393352e-05, 'epoch': 9.6}
 38%|███▊      | 6730/17525 [1:20:49<1:52:38,  1.60it/s] 38%|███▊      | 6731/17525 [1:20:49<1:50:15,  1.63it/s] 38%|███▊      | 6732/17525 [1:20:50<1:48:02,  1.67it/s] 38%|███▊      | 6733/17525 [1:20:51<1:46:45,  1.68it/s] 38%|███▊      | 6734/17525 [1:20:51<1:46:59,  1.68it/s] 38%|███▊      | 6735/17525 [1:20:52<1:46:01,  1.70it/s] 38%|███▊      | 6736/17525 [1:20:52<1:45:19,  1.71it/s] 38%|███▊      | 6737/17525 [1:20:53<1:44:38,  1.72it/s] 38%|███▊      | 6738/17525 [1:20:54<2:06:57,  1.42it/s] 38%|███▊      | 6739/17525 [1:20:54<1:59:46,  1.50it/s] 38%|███▊      | 6740/17525 [1:20:55<1:54:55,  1.56it/s]                                                        {'loss': 0.5105, 'grad_norm': 16.243749618530273, 'learning_rate': 1.3579071486561843e-05, 'epoch': 9.61}
 38%|███▊      | 6740/17525 [1:20:55<1:54:55,  1.56it/s] 38%|███▊      | 6741/17525 [1:20:56<1:51:23,  1.61it/s] 38%|███▊      | 6742/17525 [1:20:56<1:50:31,  1.63it/s] 38%|███▊      | 6743/17525 [1:20:57<1:48:28,  1.66it/s] 38%|███▊      | 6744/17525 [1:20:57<1:46:51,  1.68it/s] 38%|███▊      | 6745/17525 [1:20:58<1:45:47,  1.70it/s] 38%|███▊      | 6746/17525 [1:20:58<1:44:54,  1.71it/s] 38%|███▊      | 6747/17525 [1:20:59<1:44:51,  1.71it/s] 39%|███▊      | 6748/17525 [1:21:00<1:44:46,  1.71it/s] 39%|███▊      | 6749/17525 [1:21:01<2:09:37,  1.39it/s] 39%|███▊      | 6750/17525 [1:21:01<2:02:10,  1.47it/s]                                                        {'loss': 0.499, 'grad_norm': 19.334890365600586, 'learning_rate': 1.3562307749947896e-05, 'epoch': 9.63}
 39%|███▊      | 6750/17525 [1:21:01<2:02:10,  1.47it/s][INFO|trainer.py:3203] 2024-06-25 03:24:23,154 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: b13fec8e-5061-4fa2-bf95-2c0d162f5d58)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:24:33,210 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:24:33,213 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 39%|███▊      | 6751/17525 [1:21:12<11:05:27,  3.71s/it] 39%|███▊      | 6752/17525 [1:21:13<8:16:56,  2.77s/it]  39%|███▊      | 6753/17525 [1:21:13<6:18:54,  2.11s/it] 39%|███▊      | 6754/17525 [1:21:14<4:56:15,  1.65s/it] 39%|███▊      | 6755/17525 [1:21:14<3:58:27,  1.33s/it] 39%|███▊      | 6756/17525 [1:21:15<3:17:54,  1.10s/it] 39%|███▊      | 6757/17525 [1:21:15<2:49:22,  1.06it/s] 39%|███▊      | 6758/17525 [1:21:16<2:29:42,  1.20it/s] 39%|███▊      | 6759/17525 [1:21:17<2:15:44,  1.32it/s] 39%|███▊      | 6760/17525 [1:21:17<2:06:12,  1.42it/s]                                                        {'loss': 0.4104, 'grad_norm': 12.224520683288574, 'learning_rate': 1.3545532539545603e-05, 'epoch': 9.64}
 39%|███▊      | 6760/17525 [1:21:17<2:06:12,  1.42it/s] 39%|███▊      | 6761/17525 [1:21:18<1:59:25,  1.50it/s] 39%|███▊      | 6762/17525 [1:21:18<1:54:34,  1.57it/s] 39%|███▊      | 6763/17525 [1:21:19<1:51:28,  1.61it/s] 39%|███▊      | 6764/17525 [1:21:20<1:59:48,  1.50it/s] 39%|███▊      | 6765/17525 [1:21:20<1:54:58,  1.56it/s] 39%|███▊      | 6766/17525 [1:21:21<1:51:27,  1.61it/s] 39%|███▊      | 6767/17525 [1:21:21<1:48:52,  1.65it/s] 39%|███▊      | 6768/17525 [1:21:22<1:47:07,  1.67it/s] 39%|███▊      | 6769/17525 [1:21:23<1:45:45,  1.69it/s] 39%|███▊      | 6770/17525 [1:21:23<1:44:52,  1.71it/s]                                                        {'loss': 0.5207, 'grad_norm': 16.02351188659668, 'learning_rate': 1.352874590938601e-05, 'epoch': 9.66}
 39%|███▊      | 6770/17525 [1:21:23<1:44:52,  1.71it/s] 39%|███▊      | 6771/17525 [1:21:24<1:45:15,  1.70it/s] 39%|███▊      | 6772/17525 [1:21:24<1:44:41,  1.71it/s] 39%|███▊      | 6773/17525 [1:21:25<1:44:13,  1.72it/s] 39%|███▊      | 6774/17525 [1:21:25<1:43:56,  1.72it/s] 39%|███▊      | 6775/17525 [1:21:26<1:44:02,  1.72it/s] 39%|███▊      | 6776/17525 [1:21:27<1:44:07,  1.72it/s] 39%|███▊      | 6777/17525 [1:21:27<1:44:21,  1.72it/s] 39%|███▊      | 6778/17525 [1:21:28<1:44:03,  1.72it/s] 39%|███▊      | 6779/17525 [1:21:28<1:43:52,  1.72it/s] 39%|███▊      | 6780/17525 [1:21:29<1:43:45,  1.73it/s]                                                        {'loss': 0.5044, 'grad_norm': 12.111274719238281, 'learning_rate': 1.3511947913536942e-05, 'epoch': 9.67}
 39%|███▊      | 6780/17525 [1:21:29<1:43:45,  1.73it/s] 39%|███▊      | 6781/17525 [1:21:30<1:44:08,  1.72it/s] 39%|███▊      | 6782/17525 [1:21:30<1:44:09,  1.72it/s] 39%|███▊      | 6783/17525 [1:21:31<1:44:03,  1.72it/s] 39%|███▊      | 6784/17525 [1:21:31<1:44:06,  1.72it/s] 39%|███▊      | 6785/17525 [1:21:32<1:44:09,  1.72it/s] 39%|███▊      | 6786/17525 [1:21:32<1:43:47,  1.72it/s] 39%|███▊      | 6787/17525 [1:21:33<1:43:37,  1.73it/s] 39%|███▊      | 6788/17525 [1:21:34<2:25:35,  1.23it/s] 39%|███▊      | 6789/17525 [1:21:35<2:12:33,  1.35it/s] 39%|███▊      | 6790/17525 [1:21:36<2:03:49,  1.44it/s]                                                        {'loss': 0.4771, 'grad_norm': 21.99998664855957, 'learning_rate': 1.3495138606102836e-05, 'epoch': 9.69}
 39%|███▊      | 6790/17525 [1:21:36<2:03:49,  1.44it/s] 39%|███▉      | 6791/17525 [1:21:36<1:57:50,  1.52it/s] 39%|███▉      | 6792/17525 [1:21:37<1:54:18,  1.56it/s] 39%|███▉      | 6793/17525 [1:21:37<1:50:51,  1.61it/s] 39%|███▉      | 6794/17525 [1:21:38<1:48:22,  1.65it/s] 39%|███▉      | 6795/17525 [1:21:38<1:46:31,  1.68it/s] 39%|███▉      | 6796/17525 [1:21:39<1:45:22,  1.70it/s] 39%|███▉      | 6797/17525 [1:21:40<1:44:39,  1.71it/s] 39%|███▉      | 6798/17525 [1:21:40<1:44:09,  1.72it/s] 39%|███▉      | 6799/17525 [1:21:41<1:43:45,  1.72it/s] 39%|███▉      | 6800/17525 [1:21:41<1:43:22,  1.73it/s]                                                        {'loss': 0.4728, 'grad_norm': 7.9785027503967285, 'learning_rate': 1.347831804122456e-05, 'epoch': 9.7}
 39%|███▉      | 6800/17525 [1:21:41<1:43:22,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:25:03,224 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:25:03,224 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:25:03,224 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.61it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.76it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.84it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.921754777431488, 'eval_runtime': 4.5904, 'eval_samples_per_second': 96.505, 'eval_steps_per_second': 4.139, 'epoch': 9.7}
 39%|███▉      | 6800/17525 [1:21:46<1:43:22,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 39%|███▉      | 6801/17525 [1:21:47<5:50:28,  1.96s/it] 39%|███▉      | 6802/17525 [1:21:47<4:36:10,  1.55s/it] 39%|███▉      | 6803/17525 [1:21:48<3:44:04,  1.25s/it] 39%|███▉      | 6804/17525 [1:21:48<3:07:38,  1.05s/it] 39%|███▉      | 6805/17525 [1:21:49<2:42:23,  1.10it/s] 39%|███▉      | 6806/17525 [1:21:49<2:24:43,  1.23it/s] 39%|███▉      | 6807/17525 [1:21:50<2:12:08,  1.35it/s] 39%|███▉      | 6808/17525 [1:21:51<2:04:24,  1.44it/s] 39%|███▉      | 6809/17525 [1:21:51<2:08:55,  1.39it/s] 39%|███▉      | 6810/17525 [1:21:52<2:01:18,  1.47it/s]                                                        {'loss': 0.4844, 'grad_norm': 12.15345573425293, 'learning_rate': 1.3461486273079243e-05, 'epoch': 9.71}
 39%|███▉      | 6810/17525 [1:21:52<2:01:18,  1.47it/s] 39%|███▉      | 6811/17525 [1:21:53<2:03:50,  1.44it/s] 39%|███▉      | 6812/17525 [1:21:53<1:57:39,  1.52it/s] 39%|███▉      | 6813/17525 [1:21:54<1:53:21,  1.57it/s] 39%|███▉      | 6814/17525 [1:21:54<1:51:56,  1.59it/s] 39%|███▉      | 6815/17525 [1:21:55<1:49:37,  1.63it/s] 39%|███▉      | 6816/17525 [1:21:56<1:47:59,  1.65it/s] 39%|███▉      | 6817/17525 [1:21:56<1:46:37,  1.67it/s] 39%|███▉      | 6818/17525 [1:21:57<1:45:41,  1.69it/s] 39%|███▉      | 6819/17525 [1:21:59<3:36:03,  1.21s/it] 39%|███▉      | 6820/17525 [1:22:00<3:03:16,  1.03s/it]                                                        {'loss': 0.5553, 'grad_norm': 11.244388580322266, 'learning_rate': 1.3444643355880098e-05, 'epoch': 9.73}
 39%|███▉      | 6820/17525 [1:22:00<3:03:16,  1.03s/it] 39%|███▉      | 6821/17525 [1:22:01<2:57:20,  1.01it/s] 39%|███▉      | 6822/17525 [1:22:02<2:36:01,  1.14it/s] 39%|███▉      | 6823/17525 [1:22:02<2:20:32,  1.27it/s] 39%|███▉      | 6824/17525 [1:22:03<2:09:24,  1.38it/s] 39%|███▉      | 6825/17525 [1:22:03<2:01:43,  1.46it/s] 39%|███▉      | 6826/17525 [1:22:04<1:56:41,  1.53it/s] 39%|███▉      | 6827/17525 [1:22:05<2:12:03,  1.35it/s] 39%|███▉      | 6828/17525 [1:22:05<2:03:54,  1.44it/s] 39%|███▉      | 6829/17525 [1:22:06<1:58:03,  1.51it/s] 39%|███▉      | 6830/17525 [1:22:07<1:54:04,  1.56it/s]                                                        {'loss': 0.4435, 'grad_norm': 8.466879844665527, 'learning_rate': 1.3427789343876242e-05, 'epoch': 9.74}
 39%|███▉      | 6830/17525 [1:22:07<1:54:04,  1.56it/s] 39%|███▉      | 6831/17525 [1:22:07<1:51:29,  1.60it/s] 39%|███▉      | 6832/17525 [1:22:08<1:49:22,  1.63it/s] 39%|███▉      | 6833/17525 [1:22:08<1:47:36,  1.66it/s] 39%|███▉      | 6834/17525 [1:22:09<1:46:28,  1.67it/s] 39%|███▉      | 6835/17525 [1:22:09<1:45:44,  1.68it/s] 39%|███▉      | 6836/17525 [1:22:10<1:54:42,  1.55it/s] 39%|███▉      | 6837/17525 [1:22:11<1:51:27,  1.60it/s] 39%|███▉      | 6838/17525 [1:22:11<1:49:05,  1.63it/s] 39%|███▉      | 6839/17525 [1:22:12<1:47:28,  1.66it/s] 39%|███▉      | 6840/17525 [1:22:13<1:46:27,  1.67it/s]                                                        {'loss': 0.5852, 'grad_norm': 12.50992202758789, 'learning_rate': 1.3410924291352537e-05, 'epoch': 9.76}
 39%|███▉      | 6840/17525 [1:22:13<1:46:27,  1.67it/s] 39%|███▉      | 6841/17525 [1:22:13<1:46:01,  1.68it/s] 39%|███▉      | 6842/17525 [1:22:14<1:45:35,  1.69it/s] 39%|███▉      | 6843/17525 [1:22:14<1:45:09,  1.69it/s] 39%|███▉      | 6844/17525 [1:22:15<1:45:05,  1.69it/s] 39%|███▉      | 6845/17525 [1:22:16<1:44:44,  1.70it/s] 39%|███▉      | 6846/17525 [1:22:16<1:44:24,  1.70it/s] 39%|███▉      | 6847/17525 [1:22:17<1:44:23,  1.70it/s] 39%|███▉      | 6848/17525 [1:22:17<1:44:11,  1.71it/s] 39%|███▉      | 6849/17525 [1:22:18<1:44:28,  1.70it/s] 39%|███▉      | 6850/17525 [1:22:18<1:44:04,  1.71it/s]                                                        {'loss': 0.5285, 'grad_norm': 13.07665729522705, 'learning_rate': 1.33940482526294e-05, 'epoch': 9.77}
 39%|███▉      | 6850/17525 [1:22:18<1:44:04,  1.71it/s] 39%|███▉      | 6851/17525 [1:22:19<1:44:10,  1.71it/s] 39%|███▉      | 6852/17525 [1:22:20<2:02:43,  1.45it/s] 39%|███▉      | 6853/17525 [1:22:21<1:57:16,  1.52it/s] 39%|███▉      | 6854/17525 [1:22:21<1:52:57,  1.57it/s] 39%|███▉      | 6855/17525 [1:22:22<1:50:09,  1.61it/s] 39%|███▉      | 6856/17525 [1:22:22<1:47:55,  1.65it/s] 39%|███▉      | 6857/17525 [1:22:23<1:46:20,  1.67it/s] 39%|███▉      | 6858/17525 [1:22:23<1:45:35,  1.68it/s] 39%|███▉      | 6859/17525 [1:22:24<2:07:26,  1.39it/s] 39%|███▉      | 6860/17525 [1:22:25<2:00:07,  1.48it/s]                                                        {'loss': 0.5058, 'grad_norm': 7.634036540985107, 'learning_rate': 1.3377161282062625e-05, 'epoch': 9.79}
 39%|███▉      | 6860/17525 [1:22:25<2:00:07,  1.48it/s] 39%|███▉      | 6861/17525 [1:22:26<1:55:14,  1.54it/s] 39%|███▉      | 6862/17525 [1:22:26<1:51:33,  1.59it/s] 39%|███▉      | 6863/17525 [1:22:27<1:49:04,  1.63it/s] 39%|███▉      | 6864/17525 [1:22:27<1:47:37,  1.65it/s] 39%|███▉      | 6865/17525 [1:22:28<1:46:27,  1.67it/s] 39%|███▉      | 6866/17525 [1:22:29<1:46:55,  1.66it/s] 39%|███▉      | 6867/17525 [1:22:29<1:45:49,  1.68it/s] 39%|███▉      | 6868/17525 [1:22:30<1:44:58,  1.69it/s] 39%|███▉      | 6869/17525 [1:22:30<1:44:13,  1.70it/s] 39%|███▉      | 6870/17525 [1:22:31<1:44:09,  1.70it/s]                                                        {'loss': 0.5123, 'grad_norm': 10.011777877807617, 'learning_rate': 1.3360263434043237e-05, 'epoch': 9.8}
 39%|███▉      | 6870/17525 [1:22:31<1:44:09,  1.70it/s] 39%|███▉      | 6871/17525 [1:22:31<1:43:53,  1.71it/s] 39%|███▉      | 6872/17525 [1:22:32<1:43:39,  1.71it/s] 39%|███▉      | 6873/17525 [1:22:33<1:43:28,  1.72it/s] 39%|███▉      | 6874/17525 [1:22:33<1:43:38,  1.71it/s] 39%|███▉      | 6875/17525 [1:22:34<1:43:24,  1.72it/s] 39%|███▉      | 6876/17525 [1:22:34<1:43:25,  1.72it/s] 39%|███▉      | 6877/17525 [1:22:35<1:43:13,  1.72it/s] 39%|███▉      | 6878/17525 [1:22:36<1:43:49,  1.71it/s] 39%|███▉      | 6879/17525 [1:22:36<1:43:41,  1.71it/s] 39%|███▉      | 6880/17525 [1:22:37<1:43:52,  1.71it/s]                                                        {'loss': 0.5159, 'grad_norm': 12.847504615783691, 'learning_rate': 1.3343354762997276e-05, 'epoch': 9.81}
 39%|███▉      | 6880/17525 [1:22:37<1:43:52,  1.71it/s] 39%|███▉      | 6881/17525 [1:22:37<1:44:02,  1.71it/s] 39%|███▉      | 6882/17525 [1:22:38<1:53:42,  1.56it/s] 39%|███▉      | 6883/17525 [1:22:39<1:50:32,  1.60it/s] 39%|███▉      | 6884/17525 [1:22:39<1:48:18,  1.64it/s] 39%|███▉      | 6885/17525 [1:22:40<1:46:48,  1.66it/s] 39%|███▉      | 6886/17525 [1:22:40<1:45:38,  1.68it/s] 39%|███▉      | 6887/17525 [1:22:41<1:44:52,  1.69it/s] 39%|███▉      | 6888/17525 [1:22:42<1:44:19,  1.70it/s] 39%|███▉      | 6889/17525 [1:22:42<1:43:53,  1.71it/s] 39%|███▉      | 6890/17525 [1:22:43<1:43:45,  1.71it/s]                                                        {'loss': 0.6677, 'grad_norm': 11.096224784851074, 'learning_rate': 1.3326435323385652e-05, 'epoch': 9.83}
 39%|███▉      | 6890/17525 [1:22:43<1:43:45,  1.71it/s] 39%|███▉      | 6891/17525 [1:22:43<1:43:38,  1.71it/s] 39%|███▉      | 6892/17525 [1:22:44<1:43:22,  1.71it/s] 39%|███▉      | 6893/17525 [1:22:44<1:43:29,  1.71it/s] 39%|███▉      | 6894/17525 [1:22:45<1:43:16,  1.72it/s] 39%|███▉      | 6895/17525 [1:22:46<1:43:06,  1.72it/s] 39%|███▉      | 6896/17525 [1:22:46<1:42:47,  1.72it/s] 39%|███▉      | 6897/17525 [1:22:47<1:42:36,  1.73it/s] 39%|███▉      | 6898/17525 [1:22:47<1:42:59,  1.72it/s] 39%|███▉      | 6899/17525 [1:22:48<1:42:52,  1.72it/s] 39%|███▉      | 6900/17525 [1:22:49<1:42:41,  1.72it/s]                                                        {'loss': 0.5376, 'grad_norm': 21.54180908203125, 'learning_rate': 1.3309505169703956e-05, 'epoch': 9.84}
 39%|███▉      | 6900/17525 [1:22:49<1:42:41,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:26:11,414 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:26:11,415 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:26:11,415 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.17it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.58it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A                                                        
                                               [A{'eval_loss': 0.9210451245307922, 'eval_runtime': 4.6134, 'eval_samples_per_second': 96.025, 'eval_steps_per_second': 4.118, 'epoch': 9.84}
 39%|███▉      | 6900/17525 [1:22:54<1:42:41,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:26:16,032 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79ad990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 3bd87d63-571d-4bc7-9a34-83ab56215f63)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:26:26,137 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:26:26,141 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-6900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 39%|███▉      | 6901/17525 [1:23:05<15:47:50,  5.35s/it] 39%|███▉      | 6902/17525 [1:23:06<11:43:45,  3.97s/it] 39%|███▉      | 6903/17525 [1:23:06<8:44:45,  2.96s/it]  39%|███▉      | 6904/17525 [1:23:07<6:38:47,  2.25s/it] 39%|███▉      | 6905/17525 [1:23:08<5:10:28,  1.75s/it] 39%|███▉      | 6906/17525 [1:23:08<4:08:38,  1.40s/it] 39%|███▉      | 6907/17525 [1:23:09<3:25:36,  1.16s/it] 39%|███▉      | 6908/17525 [1:23:09<2:54:59,  1.01it/s] 39%|███▉      | 6909/17525 [1:23:10<2:34:41,  1.14it/s] 39%|███▉      | 6910/17525 [1:23:11<2:20:13,  1.26it/s]                                                        {'loss': 0.5198, 'grad_norm': 8.668615341186523, 'learning_rate': 1.329256435648229e-05, 'epoch': 9.86}
 39%|███▉      | 6910/17525 [1:23:11<2:20:13,  1.26it/s] 39%|███▉      | 6911/17525 [1:23:11<2:09:35,  1.37it/s] 39%|███▉      | 6912/17525 [1:23:12<2:02:45,  1.44it/s] 39%|███▉      | 6913/17525 [1:23:13<2:53:02,  1.02it/s] 39%|███▉      | 6914/17525 [1:23:14<2:32:31,  1.16it/s] 39%|███▉      | 6915/17525 [1:23:15<2:17:54,  1.28it/s] 39%|███▉      | 6916/17525 [1:23:15<2:07:46,  1.38it/s] 39%|███▉      | 6917/17525 [1:23:16<2:00:32,  1.47it/s] 39%|███▉      | 6918/17525 [1:23:16<1:55:25,  1.53it/s] 39%|███▉      | 6919/17525 [1:23:17<1:52:17,  1.57it/s] 39%|███▉      | 6920/17525 [1:23:18<1:50:00,  1.61it/s]                                                        {'loss': 0.4683, 'grad_norm': 17.630403518676758, 'learning_rate': 1.3275612938285086e-05, 'epoch': 9.87}
 39%|███▉      | 6920/17525 [1:23:18<1:50:00,  1.61it/s] 39%|███▉      | 6921/17525 [1:23:18<1:48:34,  1.63it/s] 39%|███▉      | 6922/17525 [1:23:19<1:47:28,  1.64it/s] 40%|███▉      | 6923/17525 [1:23:19<1:46:38,  1.66it/s] 40%|███▉      | 6924/17525 [1:23:20<1:45:53,  1.67it/s] 40%|███▉      | 6925/17525 [1:23:20<1:45:45,  1.67it/s] 40%|███▉      | 6926/17525 [1:23:21<1:45:32,  1.67it/s] 40%|███▉      | 6927/17525 [1:23:22<1:45:31,  1.67it/s] 40%|███▉      | 6928/17525 [1:23:22<1:45:00,  1.68it/s] 40%|███▉      | 6929/17525 [1:23:23<1:52:30,  1.57it/s] 40%|███▉      | 6930/17525 [1:23:24<1:50:17,  1.60it/s]                                                        {'loss': 0.5191, 'grad_norm': 7.489745140075684, 'learning_rate': 1.3258650969710934e-05, 'epoch': 9.89}
 40%|███▉      | 6930/17525 [1:23:24<1:50:17,  1.60it/s] 40%|███▉      | 6931/17525 [1:23:24<1:48:29,  1.63it/s] 40%|███▉      | 6932/17525 [1:23:25<1:47:02,  1.65it/s] 40%|███▉      | 6933/17525 [1:23:25<1:46:16,  1.66it/s] 40%|███▉      | 6934/17525 [1:23:26<1:45:24,  1.67it/s] 40%|███▉      | 6935/17525 [1:23:28<2:39:55,  1.10it/s] 40%|███▉      | 6936/17525 [1:23:28<2:22:57,  1.23it/s] 40%|███▉      | 6937/17525 [1:23:29<2:10:54,  1.35it/s] 40%|███▉      | 6938/17525 [1:23:29<2:03:39,  1.43it/s] 40%|███▉      | 6939/17525 [1:23:30<1:57:25,  1.50it/s] 40%|███▉      | 6940/17525 [1:23:31<1:52:55,  1.56it/s]                                                        {'loss': 0.5393, 'grad_norm': 10.78317928314209, 'learning_rate': 1.324167850539241e-05, 'epoch': 9.9}
 40%|███▉      | 6940/17525 [1:23:31<1:52:55,  1.56it/s] 40%|███▉      | 6941/17525 [1:23:31<1:49:53,  1.61it/s] 40%|███▉      | 6942/17525 [1:23:32<1:47:39,  1.64it/s] 40%|███▉      | 6943/17525 [1:23:32<1:46:20,  1.66it/s] 40%|███▉      | 6944/17525 [1:23:33<1:45:05,  1.68it/s] 40%|███▉      | 6945/17525 [1:23:33<1:44:41,  1.68it/s] 40%|███▉      | 6946/17525 [1:23:34<1:43:57,  1.70it/s] 40%|███▉      | 6947/17525 [1:23:35<1:43:35,  1.70it/s] 40%|███▉      | 6948/17525 [1:23:35<1:50:32,  1.59it/s] 40%|███▉      | 6949/17525 [1:23:36<1:48:17,  1.63it/s] 40%|███▉      | 6950/17525 [1:23:36<1:46:22,  1.66it/s]                                                        {'loss': 0.5181, 'grad_norm': 7.472164154052734, 'learning_rate': 1.3224695599995888e-05, 'epoch': 9.91}
 40%|███▉      | 6950/17525 [1:23:36<1:46:22,  1.66it/s] 40%|███▉      | 6951/17525 [1:23:37<1:45:28,  1.67it/s] 40%|███▉      | 6952/17525 [1:23:38<1:44:58,  1.68it/s] 40%|███▉      | 6953/17525 [1:23:38<1:44:11,  1.69it/s] 40%|███▉      | 6954/17525 [1:23:39<1:43:47,  1.70it/s] 40%|███▉      | 6955/17525 [1:23:39<1:43:41,  1.70it/s] 40%|███▉      | 6956/17525 [1:23:40<1:43:21,  1.70it/s] 40%|███▉      | 6957/17525 [1:23:41<1:43:16,  1.71it/s] 40%|███▉      | 6958/17525 [1:23:41<1:43:06,  1.71it/s] 40%|███▉      | 6959/17525 [1:23:42<1:43:02,  1.71it/s] 40%|███▉      | 6960/17525 [1:23:42<1:42:56,  1.71it/s]                                                        {'loss': 0.4813, 'grad_norm': 14.190376281738281, 'learning_rate': 1.3207702308221386e-05, 'epoch': 9.93}
 40%|███▉      | 6960/17525 [1:23:42<1:42:56,  1.71it/s] 40%|███▉      | 6961/17525 [1:23:43<1:43:17,  1.70it/s] 40%|███▉      | 6962/17525 [1:23:43<1:43:10,  1.71it/s] 40%|███▉      | 6963/17525 [1:23:44<2:01:59,  1.44it/s] 40%|███▉      | 6964/17525 [1:23:45<1:57:04,  1.50it/s] 40%|███▉      | 6965/17525 [1:23:46<1:52:39,  1.56it/s] 40%|███▉      | 6966/17525 [1:23:46<1:49:24,  1.61it/s] 40%|███▉      | 6967/17525 [1:23:47<1:47:10,  1.64it/s] 40%|███▉      | 6968/17525 [1:23:47<1:46:23,  1.65it/s] 40%|███▉      | 6969/17525 [1:23:48<1:45:39,  1.67it/s] 40%|███▉      | 6970/17525 [1:23:49<1:45:04,  1.67it/s]                                                        {'loss': 0.4562, 'grad_norm': 39.03765106201172, 'learning_rate': 1.3190698684802355e-05, 'epoch': 9.94}
 40%|███▉      | 6970/17525 [1:23:49<1:45:04,  1.67it/s] 40%|███▉      | 6971/17525 [1:23:49<1:45:19,  1.67it/s] 40%|███▉      | 6972/17525 [1:23:50<1:44:54,  1.68it/s] 40%|███▉      | 6973/17525 [1:23:50<1:44:38,  1.68it/s] 40%|███▉      | 6974/17525 [1:23:51<1:44:07,  1.69it/s] 40%|███▉      | 6975/17525 [1:23:52<1:43:43,  1.70it/s] 40%|███▉      | 6976/17525 [1:23:52<1:43:15,  1.70it/s] 40%|███▉      | 6977/17525 [1:23:53<1:43:00,  1.71it/s] 40%|███▉      | 6978/17525 [1:23:53<1:42:38,  1.71it/s] 40%|███▉      | 6979/17525 [1:23:54<1:42:33,  1.71it/s] 40%|███▉      | 6980/17525 [1:23:54<1:42:35,  1.71it/s]                                                        {'loss': 0.488, 'grad_norm': 7.515273094177246, 'learning_rate': 1.3173684784505536e-05, 'epoch': 9.96}
 40%|███▉      | 6980/17525 [1:23:54<1:42:35,  1.71it/s] 40%|███▉      | 6981/17525 [1:23:55<1:42:24,  1.72it/s] 40%|███▉      | 6982/17525 [1:23:56<1:42:20,  1.72it/s] 40%|███▉      | 6983/17525 [1:23:56<1:42:09,  1.72it/s] 40%|███▉      | 6984/17525 [1:23:57<1:42:18,  1.72it/s] 40%|███▉      | 6985/17525 [1:23:57<1:42:05,  1.72it/s] 40%|███▉      | 6986/17525 [1:23:58<1:42:24,  1.72it/s] 40%|███▉      | 6987/17525 [1:23:58<1:42:27,  1.71it/s] 40%|███▉      | 6988/17525 [1:23:59<1:42:35,  1.71it/s] 40%|███▉      | 6989/17525 [1:24:00<1:42:27,  1.71it/s] 40%|███▉      | 6990/17525 [1:24:00<1:42:20,  1.72it/s]                                                        {'loss': 0.4404, 'grad_norm': 9.502337455749512, 'learning_rate': 1.3156660662130769e-05, 'epoch': 9.97}
 40%|███▉      | 6990/17525 [1:24:00<1:42:20,  1.72it/s] 40%|███▉      | 6991/17525 [1:24:01<1:42:31,  1.71it/s] 40%|███▉      | 6992/17525 [1:24:01<1:42:33,  1.71it/s] 40%|███▉      | 6993/17525 [1:24:02<1:42:23,  1.71it/s] 40%|███▉      | 6994/17525 [1:24:03<1:42:17,  1.72it/s] 40%|███▉      | 6995/17525 [1:24:03<1:42:15,  1.72it/s] 40%|███▉      | 6996/17525 [1:24:04<1:42:21,  1.71it/s] 40%|███▉      | 6997/17525 [1:24:04<1:42:19,  1.71it/s] 40%|███▉      | 6998/17525 [1:24:05<1:42:09,  1.72it/s] 40%|███▉      | 6999/17525 [1:24:06<1:42:58,  1.70it/s] 40%|███▉      | 7000/17525 [1:24:06<1:42:35,  1.71it/s]                                                        {'loss': 0.502, 'grad_norm': 15.085158348083496, 'learning_rate': 1.3139626372510814e-05, 'epoch': 9.99}
 40%|███▉      | 7000/17525 [1:24:06<1:42:35,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 03:27:27,984 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:27:27,984 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:27:27,984 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.32it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.56it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.67it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.72it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.80it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.18it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                        
                                               [A{'eval_loss': 0.9287936687469482, 'eval_runtime': 4.616, 'eval_samples_per_second': 95.97, 'eval_steps_per_second': 4.116, 'epoch': 9.99}
 40%|███▉      | 7000/17525 [1:24:11<1:42:35,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 40%|███▉      | 7001/17525 [1:24:11<5:46:10,  1.97s/it] 40%|███▉      | 7002/17525 [1:24:12<4:33:34,  1.56s/it] 40%|███▉      | 7003/17525 [1:24:12<3:42:57,  1.27s/it] 40%|███▉      | 7004/17525 [1:24:14<3:39:28,  1.25s/it] 40%|███▉      | 7005/17525 [1:24:14<3:05:16,  1.06s/it] 40%|███▉      | 7006/17525 [1:24:15<2:40:51,  1.09it/s] 40%|███▉      | 7007/17525 [1:24:15<2:23:51,  1.22it/s] 40%|███▉      | 7008/17525 [1:24:16<2:30:52,  1.16it/s] 40%|███▉      | 7009/17525 [1:24:17<2:17:04,  1.28it/s] 40%|████      | 7010/17525 [1:24:18<2:06:45,  1.38it/s]                                                        {'loss': 0.4842, 'grad_norm': 18.005985260009766, 'learning_rate': 1.3122581970511188e-05, 'epoch': 10.0}
 40%|████      | 7010/17525 [1:24:18<2:06:45,  1.38it/s] 40%|████      | 7011/17525 [1:24:18<1:59:51,  1.46it/s] 40%|████      | 7012/17525 [1:24:19<1:54:46,  1.53it/s] 40%|████      | 7013/17525 [1:24:20<1:57:25,  1.49it/s] 40%|████      | 7014/17525 [1:24:20<1:53:53,  1.54it/s] 40%|████      | 7015/17525 [1:24:21<1:50:41,  1.58it/s] 40%|████      | 7016/17525 [1:24:21<1:48:38,  1.61it/s] 40%|████      | 7017/17525 [1:24:22<1:46:50,  1.64it/s] 40%|████      | 7018/17525 [1:24:22<1:45:26,  1.66it/s] 40%|████      | 7019/17525 [1:24:23<1:44:36,  1.67it/s] 40%|████      | 7020/17525 [1:24:24<1:44:06,  1.68it/s]                                                        {'loss': 0.3851, 'grad_norm': 7.509927272796631, 'learning_rate': 1.3105527511029967e-05, 'epoch': 10.01}
 40%|████      | 7020/17525 [1:24:24<1:44:06,  1.68it/s] 40%|████      | 7021/17525 [1:24:24<1:43:44,  1.69it/s] 40%|████      | 7022/17525 [1:24:25<1:43:30,  1.69it/s] 40%|████      | 7023/17525 [1:24:25<1:43:17,  1.69it/s] 40%|████      | 7024/17525 [1:24:26<1:43:17,  1.69it/s] 40%|████      | 7025/17525 [1:24:27<1:43:00,  1.70it/s] 40%|████      | 7026/17525 [1:24:27<1:42:43,  1.70it/s] 40%|████      | 7027/17525 [1:24:28<1:44:07,  1.68it/s] 40%|████      | 7028/17525 [1:24:28<1:43:47,  1.69it/s] 40%|████      | 7029/17525 [1:24:29<1:43:22,  1.69it/s] 40%|████      | 7030/17525 [1:24:30<1:42:59,  1.70it/s]                                                        {'loss': 0.4707, 'grad_norm': 19.8839054107666, 'learning_rate': 1.3088463048997626e-05, 'epoch': 10.03}
 40%|████      | 7030/17525 [1:24:30<1:42:59,  1.70it/s] 40%|████      | 7031/17525 [1:24:30<1:42:53,  1.70it/s] 40%|████      | 7032/17525 [1:24:31<1:42:48,  1.70it/s] 40%|████      | 7033/17525 [1:24:32<2:23:44,  1.22it/s] 40%|████      | 7034/17525 [1:24:33<2:11:16,  1.33it/s] 40%|████      | 7035/17525 [1:24:33<2:02:42,  1.42it/s] 40%|████      | 7036/17525 [1:24:34<1:56:44,  1.50it/s] 40%|████      | 7037/17525 [1:24:34<1:52:25,  1.55it/s] 40%|████      | 7038/17525 [1:24:35<1:49:41,  1.59it/s] 40%|████      | 7039/17525 [1:24:36<1:47:57,  1.62it/s] 40%|████      | 7040/17525 [1:24:36<1:46:12,  1.65it/s]                                                        {'loss': 0.434, 'grad_norm': 14.134944915771484, 'learning_rate': 1.3071388639376861e-05, 'epoch': 10.04}
 40%|████      | 7040/17525 [1:24:36<1:46:12,  1.65it/s] 40%|████      | 7041/17525 [1:24:37<1:45:41,  1.65it/s] 40%|████      | 7042/17525 [1:24:38<2:03:06,  1.42it/s] 40%|████      | 7043/17525 [1:24:38<1:57:04,  1.49it/s] 40%|████      | 7044/17525 [1:24:39<1:53:14,  1.54it/s] 40%|████      | 7045/17525 [1:24:40<1:50:18,  1.58it/s] 40%|████      | 7046/17525 [1:24:40<1:47:52,  1.62it/s] 40%|████      | 7047/17525 [1:24:41<1:46:02,  1.65it/s] 40%|████      | 7048/17525 [1:24:41<1:45:05,  1.66it/s] 40%|████      | 7049/17525 [1:24:42<1:44:14,  1.68it/s] 40%|████      | 7050/17525 [1:24:42<1:43:34,  1.69it/s]                                                        {'loss': 0.556, 'grad_norm': 30.949302673339844, 'learning_rate': 1.3054304337162404e-05, 'epoch': 10.06}
 40%|████      | 7050/17525 [1:24:42<1:43:34,  1.69it/s][INFO|trainer.py:3203] 2024-06-25 03:28:04,338 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a79ad990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7fc685a1-3741-4616-92df-bb7e1039af7e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:28:14,397 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:28:14,399 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 40%|████      | 7051/17525 [1:24:53<10:37:47,  3.65s/it] 40%|████      | 7052/17525 [1:24:54<7:57:04,  2.73s/it]  40%|████      | 7053/17525 [1:24:54<6:04:48,  2.09s/it] 40%|████      | 7054/17525 [1:24:55<4:46:14,  1.64s/it] 40%|████      | 7055/17525 [1:24:56<3:51:01,  1.32s/it] 40%|████      | 7056/17525 [1:24:56<3:12:28,  1.10s/it] 40%|████      | 7057/17525 [1:24:57<2:45:34,  1.05it/s] 40%|████      | 7058/17525 [1:24:57<2:26:21,  1.19it/s] 40%|████      | 7059/17525 [1:24:58<2:13:51,  1.30it/s] 40%|████      | 7060/17525 [1:24:59<2:04:32,  1.40it/s]                                                        {'loss': 0.4037, 'grad_norm': 4.190235614776611, 'learning_rate': 1.3037210197380849e-05, 'epoch': 10.07}
 40%|████      | 7060/17525 [1:24:59<2:04:32,  1.40it/s] 40%|████      | 7061/17525 [1:24:59<1:58:57,  1.47it/s] 40%|████      | 7062/17525 [1:25:00<1:54:22,  1.52it/s] 40%|████      | 7063/17525 [1:25:01<2:00:19,  1.45it/s] 40%|████      | 7064/17525 [1:25:01<1:56:04,  1.50it/s] 40%|████      | 7065/17525 [1:25:02<1:54:04,  1.53it/s] 40%|████      | 7066/17525 [1:25:02<1:51:47,  1.56it/s] 40%|████      | 7067/17525 [1:25:03<1:49:31,  1.59it/s] 40%|████      | 7068/17525 [1:25:04<1:47:57,  1.61it/s] 40%|████      | 7069/17525 [1:25:04<1:48:07,  1.61it/s] 40%|████      | 7070/17525 [1:25:05<1:47:38,  1.62it/s]                                                        {'loss': 0.4339, 'grad_norm': 18.47751808166504, 'learning_rate': 1.3020106275090478e-05, 'epoch': 10.09}
 40%|████      | 7070/17525 [1:25:05<1:47:38,  1.62it/s] 40%|████      | 7071/17525 [1:25:06<2:08:25,  1.36it/s] 40%|████      | 7072/17525 [1:25:06<2:01:11,  1.44it/s] 40%|████      | 7073/17525 [1:25:07<1:55:57,  1.50it/s] 40%|████      | 7074/17525 [1:25:08<1:53:11,  1.54it/s] 40%|████      | 7075/17525 [1:25:08<1:51:57,  1.56it/s] 40%|████      | 7076/17525 [1:25:09<2:21:57,  1.23it/s] 40%|████      | 7077/17525 [1:25:10<2:11:29,  1.32it/s] 40%|████      | 7078/17525 [1:25:11<2:03:21,  1.41it/s] 40%|████      | 7079/17525 [1:25:11<1:58:41,  1.47it/s] 40%|████      | 7080/17525 [1:25:12<1:55:01,  1.51it/s]                                                        {'loss': 0.5491, 'grad_norm': 10.130693435668945, 'learning_rate': 1.3002992625381081e-05, 'epoch': 10.1}
 40%|████      | 7080/17525 [1:25:12<1:55:01,  1.51it/s] 40%|████      | 7081/17525 [1:25:13<1:52:41,  1.54it/s] 40%|████      | 7082/17525 [1:25:13<1:52:43,  1.54it/s] 40%|████      | 7083/17525 [1:25:14<1:50:25,  1.58it/s] 40%|████      | 7084/17525 [1:25:14<1:48:15,  1.61it/s] 40%|████      | 7085/17525 [1:25:15<1:46:45,  1.63it/s] 40%|████      | 7086/17525 [1:25:16<1:45:53,  1.64it/s] 40%|████      | 7087/17525 [1:25:16<1:45:01,  1.66it/s] 40%|████      | 7088/17525 [1:25:17<1:44:20,  1.67it/s] 40%|████      | 7089/17525 [1:25:17<1:43:59,  1.67it/s] 40%|████      | 7090/17525 [1:25:18<1:44:11,  1.67it/s]                                                        {'loss': 0.539, 'grad_norm': 17.3286190032959, 'learning_rate': 1.2985869303373777e-05, 'epoch': 10.11}
 40%|████      | 7090/17525 [1:25:18<1:44:11,  1.67it/s] 40%|████      | 7091/17525 [1:25:19<1:43:56,  1.67it/s] 40%|████      | 7092/17525 [1:25:19<1:43:31,  1.68it/s] 40%|████      | 7093/17525 [1:25:20<1:43:57,  1.67it/s] 40%|████      | 7094/17525 [1:25:20<1:43:42,  1.68it/s] 40%|████      | 7095/17525 [1:25:21<1:43:19,  1.68it/s] 40%|████      | 7096/17525 [1:25:21<1:43:00,  1.69it/s] 40%|████      | 7097/17525 [1:25:22<1:42:52,  1.69it/s] 41%|████      | 7098/17525 [1:25:23<1:42:38,  1.69it/s] 41%|████      | 7099/17525 [1:25:23<1:42:19,  1.70it/s] 41%|████      | 7100/17525 [1:25:24<1:42:42,  1.69it/s]                                                        {'loss': 0.6084, 'grad_norm': 14.658620834350586, 'learning_rate': 1.2968736364220842e-05, 'epoch': 10.13}
 41%|████      | 7100/17525 [1:25:24<1:42:42,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 03:28:45,745 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:28:45,746 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:28:45,746 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.75it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.31it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.54it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.78it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.24it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.51it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.57it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.65it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.75it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.84it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.01it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.12it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.17it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.71it/s][A                                                        
                                               [A{'eval_loss': 0.9467118978500366, 'eval_runtime': 4.6521, 'eval_samples_per_second': 95.225, 'eval_steps_per_second': 4.084, 'epoch': 10.13}
 41%|████      | 7100/17525 [1:25:29<1:42:42,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.71it/s][A
                                               [A 41%|████      | 7101/17525 [1:25:29<5:46:00,  1.99s/it] 41%|████      | 7102/17525 [1:25:30<4:33:44,  1.58s/it] 41%|████      | 7103/17525 [1:25:30<3:43:04,  1.28s/it] 41%|████      | 7104/17525 [1:25:31<3:08:48,  1.09s/it] 41%|████      | 7105/17525 [1:25:32<2:44:04,  1.06it/s] 41%|████      | 7106/17525 [1:25:32<2:27:15,  1.18it/s] 41%|████      | 7107/17525 [1:25:33<2:14:54,  1.29it/s] 41%|████      | 7108/17525 [1:25:33<2:05:25,  1.38it/s] 41%|████      | 7109/17525 [1:25:34<1:58:45,  1.46it/s] 41%|████      | 7110/17525 [1:25:35<1:54:04,  1.52it/s]                                                        {'loss': 0.4473, 'grad_norm': 29.71181297302246, 'learning_rate': 1.2951593863105525e-05, 'epoch': 10.14}
 41%|████      | 7110/17525 [1:25:35<1:54:04,  1.52it/s] 41%|████      | 7111/17525 [1:25:35<1:51:02,  1.56it/s] 41%|████      | 7112/17525 [1:25:36<1:48:10,  1.60it/s] 41%|████      | 7113/17525 [1:25:36<1:46:23,  1.63it/s] 41%|████      | 7114/17525 [1:25:37<1:45:23,  1.65it/s] 41%|████      | 7115/17525 [1:25:38<2:15:24,  1.28it/s] 41%|████      | 7116/17525 [1:25:39<2:05:11,  1.39it/s] 41%|████      | 7117/17525 [1:25:39<1:58:25,  1.46it/s] 41%|████      | 7118/17525 [1:25:40<1:54:17,  1.52it/s] 41%|████      | 7119/17525 [1:25:40<1:50:38,  1.57it/s] 41%|████      | 7120/17525 [1:25:41<1:47:55,  1.61it/s]                                                        {'loss': 0.5223, 'grad_norm': 10.658662796020508, 'learning_rate': 1.293444185524187e-05, 'epoch': 10.16}
 41%|████      | 7120/17525 [1:25:41<1:47:55,  1.61it/s] 41%|████      | 7121/17525 [1:25:42<1:46:22,  1.63it/s] 41%|████      | 7122/17525 [1:25:42<1:45:15,  1.65it/s] 41%|████      | 7123/17525 [1:25:43<1:45:18,  1.65it/s] 41%|████      | 7124/17525 [1:25:43<1:44:19,  1.66it/s] 41%|████      | 7125/17525 [1:25:44<1:43:40,  1.67it/s] 41%|████      | 7126/17525 [1:25:45<1:43:18,  1.68it/s] 41%|████      | 7127/17525 [1:25:45<1:43:39,  1.67it/s] 41%|████      | 7128/17525 [1:25:46<1:44:48,  1.65it/s] 41%|████      | 7129/17525 [1:25:46<1:45:20,  1.64it/s] 41%|████      | 7130/17525 [1:25:47<1:45:15,  1.65it/s]                                                        {'loss': 0.4356, 'grad_norm': 7.93001127243042, 'learning_rate': 1.2917280395874549e-05, 'epoch': 10.17}
 41%|████      | 7130/17525 [1:25:47<1:45:15,  1.65it/s] 41%|████      | 7131/17525 [1:25:48<2:02:31,  1.41it/s] 41%|████      | 7132/17525 [1:25:49<1:57:57,  1.47it/s] 41%|████      | 7133/17525 [1:25:49<1:53:25,  1.53it/s] 41%|████      | 7134/17525 [1:25:50<1:50:38,  1.57it/s] 41%|████      | 7135/17525 [1:25:50<1:47:58,  1.60it/s] 41%|████      | 7136/17525 [1:25:51<1:46:14,  1.63it/s] 41%|████      | 7137/17525 [1:25:52<1:45:05,  1.65it/s] 41%|████      | 7138/17525 [1:25:52<1:45:11,  1.65it/s] 41%|████      | 7139/17525 [1:25:53<1:44:34,  1.66it/s] 41%|████      | 7140/17525 [1:25:53<1:43:53,  1.67it/s]                                                        {'loss': 0.4476, 'grad_norm': 10.131985664367676, 'learning_rate': 1.2900109540278671e-05, 'epoch': 10.19}
 41%|████      | 7140/17525 [1:25:53<1:43:53,  1.67it/s] 41%|████      | 7141/17525 [1:25:54<1:44:11,  1.66it/s] 41%|████      | 7142/17525 [1:25:55<2:08:08,  1.35it/s] 41%|████      | 7143/17525 [1:25:56<2:00:29,  1.44it/s] 41%|████      | 7144/17525 [1:25:56<1:55:39,  1.50it/s] 41%|████      | 7145/17525 [1:25:57<1:51:35,  1.55it/s] 41%|████      | 7146/17525 [1:25:57<1:48:53,  1.59it/s] 41%|████      | 7147/17525 [1:25:58<1:47:09,  1.61it/s] 41%|████      | 7148/17525 [1:25:59<1:46:32,  1.62it/s] 41%|████      | 7149/17525 [1:25:59<1:46:57,  1.62it/s] 41%|████      | 7150/17525 [1:26:00<1:46:18,  1.63it/s]                                                        {'loss': 0.4552, 'grad_norm': 10.403264045715332, 'learning_rate': 1.288292934375961e-05, 'epoch': 10.2}
 41%|████      | 7150/17525 [1:26:00<1:46:18,  1.63it/s] 41%|████      | 7151/17525 [1:26:01<1:46:16,  1.63it/s] 41%|████      | 7152/17525 [1:26:01<1:45:08,  1.64it/s] 41%|████      | 7153/17525 [1:26:02<1:44:12,  1.66it/s] 41%|████      | 7154/17525 [1:26:02<1:43:38,  1.67it/s] 41%|████      | 7155/17525 [1:26:03<1:42:59,  1.68it/s] 41%|████      | 7156/17525 [1:26:03<1:42:37,  1.68it/s] 41%|████      | 7157/17525 [1:26:04<1:42:18,  1.69it/s] 41%|████      | 7158/17525 [1:26:05<1:42:31,  1.69it/s] 41%|████      | 7159/17525 [1:26:05<1:42:55,  1.68it/s] 41%|████      | 7160/17525 [1:26:06<1:42:28,  1.69it/s]                                                        {'loss': 0.5003, 'grad_norm': 13.007854461669922, 'learning_rate': 1.2865739861652824e-05, 'epoch': 10.21}
 41%|████      | 7160/17525 [1:26:06<1:42:28,  1.69it/s] 41%|████      | 7161/17525 [1:26:06<1:42:23,  1.69it/s] 41%|████      | 7162/17525 [1:26:07<1:42:11,  1.69it/s] 41%|████      | 7163/17525 [1:26:08<1:41:52,  1.70it/s] 41%|████      | 7164/17525 [1:26:08<1:41:43,  1.70it/s] 41%|████      | 7165/17525 [1:26:09<1:41:26,  1.70it/s] 41%|████      | 7166/17525 [1:26:09<1:41:26,  1.70it/s] 41%|████      | 7167/17525 [1:26:10<1:41:33,  1.70it/s] 41%|████      | 7168/17525 [1:26:11<1:41:35,  1.70it/s] 41%|████      | 7169/17525 [1:26:11<1:41:42,  1.70it/s] 41%|████      | 7170/17525 [1:26:12<1:41:47,  1.70it/s]                                                        {'loss': 0.5013, 'grad_norm': 13.870424270629883, 'learning_rate': 1.2848541149323683e-05, 'epoch': 10.23}
 41%|████      | 7170/17525 [1:26:12<1:41:47,  1.70it/s] 41%|████      | 7171/17525 [1:26:12<1:42:43,  1.68it/s] 41%|████      | 7172/17525 [1:26:13<1:42:15,  1.69it/s] 41%|████      | 7173/17525 [1:26:14<1:42:13,  1.69it/s] 41%|████      | 7174/17525 [1:26:14<1:42:06,  1.69it/s] 41%|████      | 7175/17525 [1:26:15<1:41:59,  1.69it/s] 41%|████      | 7176/17525 [1:26:15<1:51:42,  1.54it/s] 41%|████      | 7177/17525 [1:26:16<1:49:03,  1.58it/s] 41%|████      | 7178/17525 [1:26:17<1:47:03,  1.61it/s] 41%|████      | 7179/17525 [1:26:17<1:45:34,  1.63it/s] 41%|████      | 7180/17525 [1:26:18<1:44:49,  1.64it/s]                                                        {'loss': 0.4413, 'grad_norm': 18.673933029174805, 'learning_rate': 1.2831333262167286e-05, 'epoch': 10.24}
 41%|████      | 7180/17525 [1:26:18<1:44:49,  1.64it/s] 41%|████      | 7181/17525 [1:26:18<1:45:27,  1.63it/s] 41%|████      | 7182/17525 [1:26:19<1:44:37,  1.65it/s] 41%|████      | 7183/17525 [1:26:20<1:44:00,  1.66it/s] 41%|████      | 7184/17525 [1:26:20<1:43:39,  1.66it/s] 41%|████      | 7185/17525 [1:26:21<1:42:46,  1.68it/s] 41%|████      | 7186/17525 [1:26:21<1:42:19,  1.68it/s] 41%|████      | 7187/17525 [1:26:22<1:41:57,  1.69it/s] 41%|████      | 7188/17525 [1:26:23<1:41:43,  1.69it/s] 41%|████      | 7189/17525 [1:26:23<1:41:36,  1.70it/s] 41%|████      | 7190/17525 [1:26:24<1:41:39,  1.69it/s]                                                        {'loss': 0.457, 'grad_norm': 9.575911521911621, 'learning_rate': 1.281411625560828e-05, 'epoch': 10.26}
 41%|████      | 7190/17525 [1:26:24<1:41:39,  1.69it/s] 41%|████      | 7191/17525 [1:26:24<1:41:45,  1.69it/s] 41%|████      | 7192/17525 [1:26:25<1:41:57,  1.69it/s] 41%|████      | 7193/17525 [1:26:26<1:41:53,  1.69it/s] 41%|████      | 7194/17525 [1:26:26<1:41:39,  1.69it/s] 41%|████      | 7195/17525 [1:26:27<1:41:29,  1.70it/s] 41%|████      | 7196/17525 [1:26:27<1:41:35,  1.69it/s] 41%|████      | 7197/17525 [1:26:28<1:41:41,  1.69it/s] 41%|████      | 7198/17525 [1:26:29<1:41:46,  1.69it/s] 41%|████      | 7199/17525 [1:26:29<1:41:43,  1.69it/s] 41%|████      | 7200/17525 [1:26:30<1:41:30,  1.70it/s]                                                        {'loss': 0.5809, 'grad_norm': 11.162367820739746, 'learning_rate': 1.2796890185100686e-05, 'epoch': 10.27}
 41%|████      | 7200/17525 [1:26:30<1:41:30,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 03:29:51,587 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:29:51,587 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:29:51,587 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.86it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9550700783729553, 'eval_runtime': 4.6032, 'eval_samples_per_second': 96.237, 'eval_steps_per_second': 4.128, 'epoch': 10.27}
 41%|████      | 7200/17525 [1:26:34<1:41:30,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:29:56,194 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a6d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 51dab4ef-33a0-47ac-a16a-ff5da3c3dfba)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:30:06,254 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:30:06,256 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 41%|████      | 7201/17525 [1:26:45<14:41:21,  5.12s/it] 41%|████      | 7202/17525 [1:26:46<10:47:15,  3.76s/it] 41%|████      | 7203/17525 [1:26:47<8:22:00,  2.92s/it]  41%|████      | 7204/17525 [1:26:48<6:22:47,  2.23s/it] 41%|████      | 7205/17525 [1:26:48<4:58:22,  1.73s/it] 41%|████      | 7206/17525 [1:26:49<3:59:14,  1.39s/it] 41%|████      | 7207/17525 [1:26:49<3:17:58,  1.15s/it] 41%|████      | 7208/17525 [1:26:50<2:48:46,  1.02it/s] 41%|████      | 7209/17525 [1:26:50<2:28:50,  1.16it/s] 41%|████      | 7210/17525 [1:26:51<2:15:13,  1.27it/s]                                                        {'loss': 0.4917, 'grad_norm': 7.275755405426025, 'learning_rate': 1.2779655106127717e-05, 'epoch': 10.29}
 41%|████      | 7210/17525 [1:26:51<2:15:13,  1.27it/s] 41%|████      | 7211/17525 [1:26:52<2:05:38,  1.37it/s] 41%|████      | 7212/17525 [1:26:52<1:58:10,  1.45it/s] 41%|████      | 7213/17525 [1:26:53<1:53:18,  1.52it/s] 41%|████      | 7214/17525 [1:26:53<1:49:32,  1.57it/s] 41%|████      | 7215/17525 [1:26:54<1:46:58,  1.61it/s] 41%|████      | 7216/17525 [1:26:55<1:46:20,  1.62it/s] 41%|████      | 7217/17525 [1:26:55<1:45:05,  1.63it/s] 41%|████      | 7218/17525 [1:26:57<2:24:55,  1.19it/s] 41%|████      | 7219/17525 [1:26:57<2:12:54,  1.29it/s] 41%|████      | 7220/17525 [1:26:58<2:03:50,  1.39it/s]                                                        {'loss': 0.4669, 'grad_norm': 17.216449737548828, 'learning_rate': 1.2762411074201606e-05, 'epoch': 10.3}
 41%|████      | 7220/17525 [1:26:58<2:03:50,  1.39it/s] 41%|████      | 7221/17525 [1:26:58<1:57:00,  1.47it/s] 41%|████      | 7222/17525 [1:26:59<1:52:01,  1.53it/s] 41%|████      | 7223/17525 [1:27:00<1:48:22,  1.58it/s] 41%|████      | 7224/17525 [1:27:00<1:45:48,  1.62it/s] 41%|████      | 7225/17525 [1:27:01<1:44:18,  1.65it/s] 41%|████      | 7226/17525 [1:27:01<1:42:54,  1.67it/s] 41%|████      | 7227/17525 [1:27:02<2:00:07,  1.43it/s] 41%|████      | 7228/17525 [1:27:03<1:54:07,  1.50it/s] 41%|████      | 7229/17525 [1:27:03<1:49:52,  1.56it/s] 41%|████▏     | 7230/17525 [1:27:04<1:47:09,  1.60it/s]                                                        {'loss': 0.3777, 'grad_norm': 27.0595760345459, 'learning_rate': 1.2745158144863422e-05, 'epoch': 10.31}
 41%|████▏     | 7230/17525 [1:27:04<1:47:09,  1.60it/s] 41%|████▏     | 7231/17525 [1:27:05<1:45:11,  1.63it/s] 41%|████▏     | 7232/17525 [1:27:05<1:43:36,  1.66it/s] 41%|████▏     | 7233/17525 [1:27:06<1:42:29,  1.67it/s] 41%|████▏     | 7234/17525 [1:27:06<1:41:36,  1.69it/s] 41%|████▏     | 7235/17525 [1:27:07<1:41:06,  1.70it/s] 41%|████▏     | 7236/17525 [1:27:08<1:40:56,  1.70it/s] 41%|████▏     | 7237/17525 [1:27:09<2:02:43,  1.40it/s] 41%|████▏     | 7238/17525 [1:27:09<1:57:33,  1.46it/s] 41%|████▏     | 7239/17525 [1:27:10<1:53:28,  1.51it/s] 41%|████▏     | 7240/17525 [1:27:11<2:10:39,  1.31it/s]                                                        {'loss': 0.454, 'grad_norm': 5.155299186706543, 'learning_rate': 1.2727896373682884e-05, 'epoch': 10.33}
 41%|████▏     | 7240/17525 [1:27:11<2:10:39,  1.31it/s] 41%|████▏     | 7241/17525 [1:27:11<2:02:23,  1.40it/s] 41%|████▏     | 7242/17525 [1:27:12<1:55:40,  1.48it/s] 41%|████▏     | 7243/17525 [1:27:13<1:51:23,  1.54it/s] 41%|████▏     | 7244/17525 [1:27:13<1:48:10,  1.58it/s] 41%|████▏     | 7245/17525 [1:27:14<1:45:52,  1.62it/s] 41%|████▏     | 7246/17525 [1:27:14<1:44:04,  1.65it/s] 41%|████▏     | 7247/17525 [1:27:15<1:42:41,  1.67it/s] 41%|████▏     | 7248/17525 [1:27:16<1:58:06,  1.45it/s] 41%|████▏     | 7249/17525 [1:27:16<1:54:21,  1.50it/s] 41%|████▏     | 7250/17525 [1:27:17<1:50:01,  1.56it/s]                                                        {'loss': 0.5115, 'grad_norm': 15.751672744750977, 'learning_rate': 1.2710625816258197e-05, 'epoch': 10.34}
 41%|████▏     | 7250/17525 [1:27:17<1:50:01,  1.56it/s] 41%|████▏     | 7251/17525 [1:27:18<1:47:12,  1.60it/s] 41%|████▏     | 7252/17525 [1:27:18<1:45:06,  1.63it/s] 41%|████▏     | 7253/17525 [1:27:19<1:43:30,  1.65it/s] 41%|████▏     | 7254/17525 [1:27:19<1:42:17,  1.67it/s] 41%|████▏     | 7255/17525 [1:27:20<1:41:35,  1.68it/s] 41%|████▏     | 7256/17525 [1:27:20<1:41:02,  1.69it/s] 41%|████▏     | 7257/17525 [1:27:21<1:40:57,  1.70it/s] 41%|████▏     | 7258/17525 [1:27:22<1:40:42,  1.70it/s] 41%|████▏     | 7259/17525 [1:27:22<1:40:22,  1.70it/s] 41%|████▏     | 7260/17525 [1:27:23<1:40:29,  1.70it/s]                                                        {'loss': 0.4693, 'grad_norm': 26.089242935180664, 'learning_rate': 1.2693346528215863e-05, 'epoch': 10.36}
 41%|████▏     | 7260/17525 [1:27:23<1:40:29,  1.70it/s] 41%|████▏     | 7261/17525 [1:27:23<1:40:36,  1.70it/s] 41%|████▏     | 7262/17525 [1:27:24<1:41:24,  1.69it/s] 41%|████▏     | 7263/17525 [1:27:25<1:41:29,  1.69it/s] 41%|████▏     | 7264/17525 [1:27:25<1:41:41,  1.68it/s] 41%|████▏     | 7265/17525 [1:27:26<1:41:47,  1.68it/s] 41%|████▏     | 7266/17525 [1:27:26<1:41:27,  1.69it/s] 41%|████▏     | 7267/17525 [1:27:27<1:41:05,  1.69it/s] 41%|████▏     | 7268/17525 [1:27:28<1:40:46,  1.70it/s] 41%|████▏     | 7269/17525 [1:27:28<1:40:28,  1.70it/s] 41%|████▏     | 7270/17525 [1:27:29<1:40:02,  1.71it/s]                                                        {'loss': 0.4806, 'grad_norm': 7.071141719818115, 'learning_rate': 1.2676058565210507e-05, 'epoch': 10.37}
 41%|████▏     | 7270/17525 [1:27:29<1:40:02,  1.71it/s] 41%|████▏     | 7271/17525 [1:27:29<1:39:59,  1.71it/s] 41%|████▏     | 7272/17525 [1:27:30<1:39:50,  1.71it/s] 42%|████▏     | 7273/17525 [1:27:30<1:39:58,  1.71it/s] 42%|████▏     | 7274/17525 [1:27:31<1:39:56,  1.71it/s] 42%|████▏     | 7275/17525 [1:27:32<1:39:53,  1.71it/s] 42%|████▏     | 7276/17525 [1:27:32<1:39:41,  1.71it/s] 42%|████▏     | 7277/17525 [1:27:33<1:39:37,  1.71it/s] 42%|████▏     | 7278/17525 [1:27:33<1:39:33,  1.72it/s] 42%|████▏     | 7279/17525 [1:27:34<1:39:50,  1.71it/s] 42%|████▏     | 7280/17525 [1:27:35<1:39:58,  1.71it/s]                                                        {'loss': 0.4786, 'grad_norm': 13.34291934967041, 'learning_rate': 1.2658761982924693e-05, 'epoch': 10.39}
 42%|████▏     | 7280/17525 [1:27:35<1:39:58,  1.71it/s] 42%|████▏     | 7281/17525 [1:27:35<1:40:34,  1.70it/s] 42%|████▏     | 7282/17525 [1:27:36<1:58:20,  1.44it/s] 42%|████▏     | 7283/17525 [1:27:37<1:52:55,  1.51it/s] 42%|████▏     | 7284/17525 [1:27:37<1:48:56,  1.57it/s] 42%|████▏     | 7285/17525 [1:27:38<1:46:07,  1.61it/s] 42%|████▏     | 7286/17525 [1:27:38<1:44:51,  1.63it/s] 42%|████▏     | 7287/17525 [1:27:39<1:43:57,  1.64it/s] 42%|████▏     | 7288/17525 [1:27:40<1:42:32,  1.66it/s] 42%|████▏     | 7289/17525 [1:27:40<1:41:37,  1.68it/s] 42%|████▏     | 7290/17525 [1:27:41<1:40:59,  1.69it/s]                                                        {'loss': 0.513, 'grad_norm': 16.679176330566406, 'learning_rate': 1.2641456837068742e-05, 'epoch': 10.4}
 42%|████▏     | 7290/17525 [1:27:41<1:40:59,  1.69it/s] 42%|████▏     | 7291/17525 [1:27:41<1:40:29,  1.70it/s] 42%|████▏     | 7292/17525 [1:27:42<1:39:54,  1.71it/s] 42%|████▏     | 7293/17525 [1:27:43<1:40:01,  1.70it/s] 42%|████▏     | 7294/17525 [1:27:43<1:40:02,  1.70it/s] 42%|████▏     | 7295/17525 [1:27:44<1:40:01,  1.70it/s] 42%|████▏     | 7296/17525 [1:27:44<1:40:04,  1.70it/s] 42%|████▏     | 7297/17525 [1:27:45<1:40:01,  1.70it/s] 42%|████▏     | 7298/17525 [1:27:45<1:39:45,  1.71it/s] 42%|████▏     | 7299/17525 [1:27:46<1:40:13,  1.70it/s] 42%|████▏     | 7300/17525 [1:27:47<1:40:01,  1.70it/s]                                                        {'loss': 0.4646, 'grad_norm': 24.617122650146484, 'learning_rate': 1.2624143183380566e-05, 'epoch': 10.41}
 42%|████▏     | 7300/17525 [1:27:47<1:40:01,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 03:31:08,566 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:31:08,567 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:31:08,567 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.72it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9341464042663574, 'eval_runtime': 4.6014, 'eval_samples_per_second': 96.276, 'eval_steps_per_second': 4.129, 'epoch': 10.41}
 42%|████▏     | 7300/17525 [1:27:51<1:40:01,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 42%|████▏     | 7301/17525 [1:27:52<5:36:13,  1.97s/it] 42%|████▏     | 7302/17525 [1:27:52<4:25:40,  1.56s/it] 42%|████▏     | 7303/17525 [1:27:53<3:36:05,  1.27s/it] 42%|████▏     | 7304/17525 [1:27:54<3:01:30,  1.07s/it] 42%|████▏     | 7305/17525 [1:27:54<2:37:01,  1.08it/s] 42%|████▏     | 7306/17525 [1:27:55<2:19:48,  1.22it/s] 42%|████▏     | 7307/17525 [1:27:55<2:07:56,  1.33it/s] 42%|████▏     | 7308/17525 [1:27:56<1:59:50,  1.42it/s] 42%|████▏     | 7309/17525 [1:27:57<1:53:57,  1.49it/s] 42%|████▏     | 7310/17525 [1:27:57<1:49:49,  1.55it/s]                                                        {'loss': 0.5098, 'grad_norm': 12.259984016418457, 'learning_rate': 1.260682107762547e-05, 'epoch': 10.43}
 42%|████▏     | 7310/17525 [1:27:57<1:49:49,  1.55it/s] 42%|████▏     | 7311/17525 [1:27:58<1:47:14,  1.59it/s] 42%|████▏     | 7312/17525 [1:27:58<1:45:00,  1.62it/s] 42%|████▏     | 7313/17525 [1:27:59<1:43:26,  1.65it/s] 42%|████▏     | 7314/17525 [1:28:00<1:42:15,  1.66it/s] 42%|████▏     | 7315/17525 [1:28:00<1:41:30,  1.68it/s] 42%|████▏     | 7316/17525 [1:28:01<1:40:50,  1.69it/s] 42%|████▏     | 7317/17525 [1:28:01<1:40:33,  1.69it/s] 42%|████▏     | 7318/17525 [1:28:02<1:40:09,  1.70it/s] 42%|████▏     | 7319/17525 [1:28:02<1:40:00,  1.70it/s] 42%|████▏     | 7320/17525 [1:28:03<1:39:52,  1.70it/s]                                                        {'loss': 0.3769, 'grad_norm': 11.583709716796875, 'learning_rate': 1.2589490575595998e-05, 'epoch': 10.44}
 42%|████▏     | 7320/17525 [1:28:03<1:39:52,  1.70it/s] 42%|████▏     | 7321/17525 [1:28:04<1:39:43,  1.71it/s] 42%|████▏     | 7322/17525 [1:28:04<1:39:41,  1.71it/s] 42%|████▏     | 7323/17525 [1:28:05<1:39:42,  1.71it/s] 42%|████▏     | 7324/17525 [1:28:05<1:39:35,  1.71it/s] 42%|████▏     | 7325/17525 [1:28:06<1:39:41,  1.71it/s] 42%|████▏     | 7326/17525 [1:28:07<1:39:45,  1.70it/s] 42%|████▏     | 7327/17525 [1:28:07<1:40:05,  1.70it/s] 42%|████▏     | 7328/17525 [1:28:08<1:40:04,  1.70it/s] 42%|████▏     | 7329/17525 [1:28:08<1:40:27,  1.69it/s] 42%|████▏     | 7330/17525 [1:28:09<1:40:18,  1.69it/s]                                                        {'loss': 0.5149, 'grad_norm': 19.25716209411621, 'learning_rate': 1.2572151733111718e-05, 'epoch': 10.46}
 42%|████▏     | 7330/17525 [1:28:09<1:40:18,  1.69it/s] 42%|████▏     | 7331/17525 [1:28:10<1:48:57,  1.56it/s] 42%|████▏     | 7332/17525 [1:28:10<1:46:40,  1.59it/s] 42%|████▏     | 7333/17525 [1:28:11<1:45:01,  1.62it/s] 42%|████▏     | 7334/17525 [1:28:11<1:43:40,  1.64it/s] 42%|████▏     | 7335/17525 [1:28:12<1:43:42,  1.64it/s] 42%|████▏     | 7336/17525 [1:28:13<1:42:57,  1.65it/s] 42%|████▏     | 7337/17525 [1:28:13<1:42:07,  1.66it/s] 42%|████▏     | 7338/17525 [1:28:14<1:42:25,  1.66it/s] 42%|████▏     | 7339/17525 [1:28:14<1:41:41,  1.67it/s] 42%|████▏     | 7340/17525 [1:28:15<1:41:16,  1.68it/s]                                                        {'loss': 0.4929, 'grad_norm': 107.32926940917969, 'learning_rate': 1.2554804606019073e-05, 'epoch': 10.47}
 42%|████▏     | 7340/17525 [1:28:15<1:41:16,  1.68it/s] 42%|████▏     | 7341/17525 [1:28:16<1:40:58,  1.68it/s] 42%|████▏     | 7342/17525 [1:28:16<1:40:37,  1.69it/s] 42%|████▏     | 7343/17525 [1:28:17<1:40:28,  1.69it/s] 42%|████▏     | 7344/17525 [1:28:17<1:40:15,  1.69it/s] 42%|████▏     | 7345/17525 [1:28:18<1:40:16,  1.69it/s] 42%|████▏     | 7346/17525 [1:28:19<1:40:19,  1.69it/s] 42%|████▏     | 7347/17525 [1:28:19<1:40:14,  1.69it/s] 42%|████▏     | 7348/17525 [1:28:20<1:40:04,  1.69it/s] 42%|████▏     | 7349/17525 [1:28:20<1:40:04,  1.69it/s] 42%|████▏     | 7350/17525 [1:28:21<1:40:59,  1.68it/s]                                                        {'loss': 0.5077, 'grad_norm': 14.453516960144043, 'learning_rate': 1.253744925019119e-05, 'epoch': 10.49}
 42%|████▏     | 7350/17525 [1:28:21<1:40:59,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 03:31:42,877 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7ad5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6be223c1-9a95-4f1c-ae23-2e56320d402d)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:31:52,940 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:31:52,942 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 42%|████▏     | 7351/17525 [1:28:32<10:19:56,  3.66s/it] 42%|████▏     | 7352/17525 [1:28:32<7:43:43,  2.74s/it]  42%|████▏     | 7353/17525 [1:28:33<5:54:23,  2.09s/it] 42%|████▏     | 7354/17525 [1:28:34<4:37:34,  1.64s/it] 42%|████▏     | 7355/17525 [1:28:34<3:43:47,  1.32s/it] 42%|████▏     | 7356/17525 [1:28:35<3:06:08,  1.10s/it] 42%|████▏     | 7357/17525 [1:28:35<2:39:51,  1.06it/s] 42%|████▏     | 7358/17525 [1:28:36<2:21:24,  1.20it/s] 42%|████▏     | 7359/17525 [1:28:36<2:08:25,  1.32it/s] 42%|████▏     | 7360/17525 [1:28:37<1:59:25,  1.42it/s]                                                        {'loss': 0.4652, 'grad_norm': 8.738386154174805, 'learning_rate': 1.2520085721527696e-05, 'epoch': 10.5}
 42%|████▏     | 7360/17525 [1:28:37<1:59:25,  1.42it/s] 42%|████▏     | 7361/17525 [1:28:38<2:11:37,  1.29it/s] 42%|████▏     | 7362/17525 [1:28:39<2:01:38,  1.39it/s] 42%|████▏     | 7363/17525 [1:28:39<1:54:40,  1.48it/s] 42%|████▏     | 7364/17525 [1:28:40<1:49:47,  1.54it/s] 42%|████▏     | 7365/17525 [1:28:40<1:47:13,  1.58it/s] 42%|████▏     | 7366/17525 [1:28:41<1:44:48,  1.62it/s] 42%|████▏     | 7367/17525 [1:28:41<1:42:44,  1.65it/s] 42%|████▏     | 7368/17525 [1:28:42<1:41:45,  1.66it/s] 42%|████▏     | 7369/17525 [1:28:43<1:41:20,  1.67it/s] 42%|████▏     | 7370/17525 [1:28:43<1:40:10,  1.69it/s]                                                        {'loss': 0.3967, 'grad_norm': 10.115437507629395, 'learning_rate': 1.2502714075954538e-05, 'epoch': 10.51}
 42%|████▏     | 7370/17525 [1:28:43<1:40:10,  1.69it/s] 42%|████▏     | 7371/17525 [1:28:44<1:39:41,  1.70it/s] 42%|████▏     | 7372/17525 [1:28:44<1:39:02,  1.71it/s] 42%|████▏     | 7373/17525 [1:28:45<1:55:27,  1.47it/s] 42%|████▏     | 7374/17525 [1:28:46<1:50:01,  1.54it/s] 42%|████▏     | 7375/17525 [1:28:46<1:46:25,  1.59it/s] 42%|████▏     | 7376/17525 [1:28:47<1:43:44,  1.63it/s] 42%|████▏     | 7377/17525 [1:28:48<1:41:36,  1.66it/s] 42%|████▏     | 7378/17525 [1:28:48<1:40:18,  1.69it/s] 42%|████▏     | 7379/17525 [1:28:49<1:39:17,  1.70it/s] 42%|████▏     | 7380/17525 [1:28:49<1:38:36,  1.71it/s]                                                        {'loss': 0.4914, 'grad_norm': 6.020747184753418, 'learning_rate': 1.2485334369423823e-05, 'epoch': 10.53}
 42%|████▏     | 7380/17525 [1:28:49<1:38:36,  1.71it/s] 42%|████▏     | 7381/17525 [1:28:50<1:48:22,  1.56it/s] 42%|████▏     | 7382/17525 [1:28:51<1:45:01,  1.61it/s] 42%|████▏     | 7383/17525 [1:28:51<1:42:45,  1.64it/s] 42%|████▏     | 7384/17525 [1:28:52<1:41:12,  1.67it/s] 42%|████▏     | 7385/17525 [1:28:53<1:58:22,  1.43it/s] 42%|████▏     | 7386/17525 [1:28:53<1:51:57,  1.51it/s] 42%|████▏     | 7387/17525 [1:28:54<1:47:26,  1.57it/s] 42%|████▏     | 7388/17525 [1:28:54<1:44:13,  1.62it/s] 42%|████▏     | 7389/17525 [1:28:55<1:42:05,  1.65it/s] 42%|████▏     | 7390/17525 [1:28:56<1:41:03,  1.67it/s]                                                        {'loss': 0.499, 'grad_norm': 7.298431873321533, 'learning_rate': 1.24679466579136e-05, 'epoch': 10.54}
 42%|████▏     | 7390/17525 [1:28:56<1:41:03,  1.67it/s] 42%|████▏     | 7391/17525 [1:28:56<1:40:10,  1.69it/s] 42%|████▏     | 7392/17525 [1:28:57<1:39:24,  1.70it/s] 42%|████▏     | 7393/17525 [1:28:57<1:39:16,  1.70it/s] 42%|████▏     | 7394/17525 [1:28:58<1:39:30,  1.70it/s] 42%|████▏     | 7395/17525 [1:28:59<1:40:09,  1.69it/s] 42%|████▏     | 7396/17525 [1:28:59<1:39:03,  1.70it/s] 42%|████▏     | 7397/17525 [1:29:00<1:38:56,  1.71it/s] 42%|████▏     | 7398/17525 [1:29:00<1:39:43,  1.69it/s] 42%|████▏     | 7399/17525 [1:29:01<1:38:50,  1.71it/s] 42%|████▏     | 7400/17525 [1:29:01<1:38:37,  1.71it/s]                                                        {'loss': 0.4099, 'grad_norm': 35.80080795288086, 'learning_rate': 1.2450550997427715e-05, 'epoch': 10.56}
 42%|████▏     | 7400/17525 [1:29:01<1:38:37,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 03:32:23,389 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:32:23,390 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:32:23,390 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9423083066940308, 'eval_runtime': 4.5931, 'eval_samples_per_second': 96.45, 'eval_steps_per_second': 4.137, 'epoch': 10.56}
 42%|████▏     | 7400/17525 [1:29:06<1:38:37,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 42%|████▏     | 7401/17525 [1:29:07<5:31:22,  1.96s/it] 42%|████▏     | 7402/17525 [1:29:07<4:20:51,  1.55s/it] 42%|████▏     | 7403/17525 [1:29:08<3:31:51,  1.26s/it] 42%|████▏     | 7404/17525 [1:29:08<2:57:23,  1.05s/it] 42%|████▏     | 7405/17525 [1:29:09<2:34:36,  1.09it/s] 42%|████▏     | 7406/17525 [1:29:10<2:17:21,  1.23it/s] 42%|████▏     | 7407/17525 [1:29:10<2:05:02,  1.35it/s] 42%|████▏     | 7408/17525 [1:29:11<1:56:47,  1.44it/s] 42%|████▏     | 7409/17525 [1:29:11<1:51:42,  1.51it/s] 42%|████▏     | 7410/17525 [1:29:12<1:47:11,  1.57it/s]                                                        {'loss': 0.479, 'grad_norm': 9.802257537841797, 'learning_rate': 1.2433147443995614e-05, 'epoch': 10.57}
 42%|████▏     | 7410/17525 [1:29:12<1:47:11,  1.57it/s] 42%|████▏     | 7411/17525 [1:29:12<1:45:15,  1.60it/s] 42%|████▏     | 7412/17525 [1:29:13<1:42:50,  1.64it/s] 42%|████▏     | 7413/17525 [1:29:14<1:41:14,  1.66it/s] 42%|████▏     | 7414/17525 [1:29:14<1:40:02,  1.68it/s] 42%|████▏     | 7415/17525 [1:29:15<1:40:02,  1.68it/s] 42%|████▏     | 7416/17525 [1:29:15<1:39:02,  1.70it/s] 42%|████▏     | 7417/17525 [1:29:16<1:38:25,  1.71it/s] 42%|████▏     | 7418/17525 [1:29:17<1:37:42,  1.72it/s] 42%|████▏     | 7419/17525 [1:29:17<1:37:15,  1.73it/s] 42%|████▏     | 7420/17525 [1:29:18<1:36:56,  1.74it/s]                                                        {'loss': 0.5212, 'grad_norm': 9.964408874511719, 'learning_rate': 1.2415736053672162e-05, 'epoch': 10.58}
 42%|████▏     | 7420/17525 [1:29:18<1:36:56,  1.74it/s] 42%|████▏     | 7421/17525 [1:29:18<1:36:52,  1.74it/s] 42%|████▏     | 7422/17525 [1:29:19<1:36:43,  1.74it/s] 42%|████▏     | 7423/17525 [1:29:19<1:36:36,  1.74it/s] 42%|████▏     | 7424/17525 [1:29:20<1:36:25,  1.75it/s] 42%|████▏     | 7425/17525 [1:29:21<1:36:26,  1.75it/s] 42%|████▏     | 7426/17525 [1:29:21<1:36:49,  1.74it/s] 42%|████▏     | 7427/17525 [1:29:22<1:37:08,  1.73it/s] 42%|████▏     | 7428/17525 [1:29:22<1:37:20,  1.73it/s] 42%|████▏     | 7429/17525 [1:29:23<1:37:27,  1.73it/s] 42%|████▏     | 7430/17525 [1:29:23<1:37:04,  1.73it/s]                                                        {'loss': 0.435, 'grad_norm': 6.585258960723877, 'learning_rate': 1.2398316882537475e-05, 'epoch': 10.6}
 42%|████▏     | 7430/17525 [1:29:23<1:37:04,  1.73it/s] 42%|████▏     | 7431/17525 [1:29:24<1:36:49,  1.74it/s] 42%|████▏     | 7432/17525 [1:29:25<1:36:39,  1.74it/s] 42%|████▏     | 7433/17525 [1:29:25<1:36:43,  1.74it/s] 42%|████▏     | 7434/17525 [1:29:26<1:36:32,  1.74it/s] 42%|████▏     | 7435/17525 [1:29:26<1:37:11,  1.73it/s] 42%|████▏     | 7436/17525 [1:29:27<1:36:50,  1.74it/s] 42%|████▏     | 7437/17525 [1:29:27<1:36:35,  1.74it/s] 42%|████▏     | 7438/17525 [1:29:28<1:36:31,  1.74it/s] 42%|████▏     | 7439/17525 [1:29:29<1:36:27,  1.74it/s] 42%|████▏     | 7440/17525 [1:29:30<2:00:47,  1.39it/s]                                                        {'loss': 0.4792, 'grad_norm': 13.267147064208984, 'learning_rate': 1.2380889986696714e-05, 'epoch': 10.61}
 42%|████▏     | 7440/17525 [1:29:30<2:00:47,  1.39it/s] 42%|████▏     | 7441/17525 [1:29:30<1:53:23,  1.48it/s] 42%|████▏     | 7442/17525 [1:29:31<1:48:10,  1.55it/s] 42%|████▏     | 7443/17525 [1:29:31<1:44:36,  1.61it/s] 42%|████▏     | 7444/17525 [1:29:32<1:42:14,  1.64it/s] 42%|████▏     | 7445/17525 [1:29:33<1:41:08,  1.66it/s] 42%|████▏     | 7446/17525 [1:29:33<1:39:37,  1.69it/s] 42%|████▏     | 7447/17525 [1:29:34<1:38:21,  1.71it/s] 42%|████▏     | 7448/17525 [1:29:34<1:37:33,  1.72it/s] 43%|████▎     | 7449/17525 [1:29:35<1:37:19,  1.73it/s] 43%|████▎     | 7450/17525 [1:29:35<1:37:11,  1.73it/s]                                                        {'loss': 0.4484, 'grad_norm': 6.8082685470581055, 'learning_rate': 1.2363455422279932e-05, 'epoch': 10.63}
 43%|████▎     | 7450/17525 [1:29:35<1:37:11,  1.73it/s] 43%|████▎     | 7451/17525 [1:29:36<1:36:45,  1.74it/s] 43%|████▎     | 7452/17525 [1:29:37<1:36:31,  1.74it/s] 43%|████▎     | 7453/17525 [1:29:37<1:36:34,  1.74it/s] 43%|████▎     | 7454/17525 [1:29:38<1:36:22,  1.74it/s] 43%|████▎     | 7455/17525 [1:29:38<1:38:12,  1.71it/s] 43%|████▎     | 7456/17525 [1:29:39<1:37:36,  1.72it/s] 43%|████▎     | 7457/17525 [1:29:39<1:36:59,  1.73it/s] 43%|████▎     | 7458/17525 [1:29:40<1:36:40,  1.74it/s] 43%|████▎     | 7459/17525 [1:29:41<1:36:16,  1.74it/s] 43%|████▎     | 7460/17525 [1:29:41<1:35:49,  1.75it/s]                                                        {'loss': 0.4824, 'grad_norm': 9.050300598144531, 'learning_rate': 1.2346013245441885e-05, 'epoch': 10.64}
 43%|████▎     | 7460/17525 [1:29:41<1:35:49,  1.75it/s] 43%|████▎     | 7461/17525 [1:29:42<1:36:08,  1.74it/s] 43%|████▎     | 7462/17525 [1:29:42<1:36:04,  1.75it/s] 43%|████▎     | 7463/17525 [1:29:43<1:36:01,  1.75it/s] 43%|████▎     | 7464/17525 [1:29:43<1:35:58,  1.75it/s] 43%|████▎     | 7465/17525 [1:29:44<1:35:57,  1.75it/s] 43%|████▎     | 7466/17525 [1:29:45<1:35:55,  1.75it/s] 43%|████▎     | 7467/17525 [1:29:45<1:35:53,  1.75it/s] 43%|████▎     | 7468/17525 [1:29:46<1:35:34,  1.75it/s] 43%|████▎     | 7469/17525 [1:29:46<1:35:25,  1.76it/s] 43%|████▎     | 7470/17525 [1:29:47<1:44:58,  1.60it/s]                                                        {'loss': 0.5459, 'grad_norm': 11.418045043945312, 'learning_rate': 1.232856351236184e-05, 'epoch': 10.66}
 43%|████▎     | 7470/17525 [1:29:47<1:44:58,  1.60it/s] 43%|████▎     | 7471/17525 [1:29:48<1:42:27,  1.64it/s] 43%|████▎     | 7472/17525 [1:29:48<1:40:27,  1.67it/s] 43%|████▎     | 7473/17525 [1:29:49<1:46:41,  1.57it/s] 43%|████▎     | 7474/17525 [1:29:50<1:43:15,  1.62it/s] 43%|████▎     | 7475/17525 [1:29:50<1:40:51,  1.66it/s] 43%|████▎     | 7476/17525 [1:29:51<1:39:18,  1.69it/s] 43%|████▎     | 7477/17525 [1:29:51<1:38:15,  1.70it/s] 43%|████▎     | 7478/17525 [1:29:52<1:37:18,  1.72it/s] 43%|████▎     | 7479/17525 [1:29:52<1:36:37,  1.73it/s] 43%|████▎     | 7480/17525 [1:29:53<1:36:06,  1.74it/s]                                                        {'loss': 0.5251, 'grad_norm': 12.0248441696167, 'learning_rate': 1.23111062792434e-05, 'epoch': 10.67}
 43%|████▎     | 7480/17525 [1:29:53<1:36:06,  1.74it/s] 43%|████▎     | 7481/17525 [1:29:53<1:36:05,  1.74it/s] 43%|████▎     | 7482/17525 [1:29:54<1:35:52,  1.75it/s] 43%|████▎     | 7483/17525 [1:29:55<1:35:37,  1.75it/s] 43%|████▎     | 7484/17525 [1:29:55<1:35:23,  1.75it/s] 43%|████▎     | 7485/17525 [1:29:56<1:35:25,  1.75it/s] 43%|████▎     | 7486/17525 [1:29:56<1:43:05,  1.62it/s] 43%|████▎     | 7487/17525 [1:29:57<1:41:00,  1.66it/s] 43%|████▎     | 7488/17525 [1:29:58<2:01:10,  1.38it/s] 43%|████▎     | 7489/17525 [1:29:59<1:54:43,  1.46it/s] 43%|████▎     | 7490/17525 [1:29:59<1:48:51,  1.54it/s]                                                        {'loss': 0.474, 'grad_norm': 4.852339267730713, 'learning_rate': 1.2293641602314328e-05, 'epoch': 10.68}
 43%|████▎     | 7490/17525 [1:29:59<1:48:51,  1.54it/s] 43%|████▎     | 7491/17525 [1:30:00<1:46:23,  1.57it/s] 43%|████▎     | 7492/17525 [1:30:00<1:42:57,  1.62it/s] 43%|████▎     | 7493/17525 [1:30:01<1:40:33,  1.66it/s] 43%|████▎     | 7494/17525 [1:30:02<1:39:26,  1.68it/s] 43%|████▎     | 7495/17525 [1:30:02<1:38:11,  1.70it/s] 43%|████▎     | 7496/17525 [1:30:03<1:37:22,  1.72it/s] 43%|████▎     | 7497/17525 [1:30:03<1:36:41,  1.73it/s] 43%|████▎     | 7498/17525 [1:30:04<1:36:13,  1.74it/s] 43%|████▎     | 7499/17525 [1:30:04<1:35:54,  1.74it/s] 43%|████▎     | 7500/17525 [1:30:05<1:36:24,  1.73it/s]                                                        {'loss': 0.4617, 'grad_norm': 9.343945503234863, 'learning_rate': 1.2276169537826366e-05, 'epoch': 10.7}
 43%|████▎     | 7500/17525 [1:30:05<1:36:24,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:33:26,884 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:33:26,884 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:33:26,884 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.11it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.17it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                        
                                               [A{'eval_loss': 0.9398716688156128, 'eval_runtime': 4.6156, 'eval_samples_per_second': 95.979, 'eval_steps_per_second': 4.116, 'epoch': 10.7}
 43%|████▎     | 7500/17525 [1:30:10<1:36:24,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:33:31,506 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7abd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a66eb7a5-1d1b-47a4-8308-ee8096578bf5)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:33:41,610 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:33:41,612 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 43%|████▎     | 7501/17525 [1:30:20<14:02:00,  5.04s/it] 43%|████▎     | 7502/17525 [1:30:21<10:18:38,  3.70s/it] 43%|████▎     | 7503/17525 [1:30:22<7:43:57,  2.78s/it]  43%|████▎     | 7504/17525 [1:30:22<5:53:56,  2.12s/it] 43%|████▎     | 7505/17525 [1:30:23<4:37:27,  1.66s/it] 43%|████▎     | 7506/17525 [1:30:23<3:43:29,  1.34s/it] 43%|████▎     | 7507/17525 [1:30:24<3:05:45,  1.11s/it] 43%|████▎     | 7508/17525 [1:30:25<2:39:04,  1.05it/s] 43%|████▎     | 7509/17525 [1:30:25<2:20:39,  1.19it/s] 43%|████▎     | 7510/17525 [1:30:26<2:09:13,  1.29it/s]                                                        {'loss': 0.5442, 'grad_norm': 12.847272872924805, 'learning_rate': 1.2258690142055048e-05, 'epoch': 10.71}
 43%|████▎     | 7510/17525 [1:30:26<2:09:13,  1.29it/s] 43%|████▎     | 7511/17525 [1:30:26<2:00:32,  1.38it/s] 43%|████▎     | 7512/17525 [1:30:27<1:53:14,  1.47it/s] 43%|████▎     | 7513/17525 [1:30:28<1:48:06,  1.54it/s] 43%|████▎     | 7514/17525 [1:30:28<1:44:42,  1.59it/s] 43%|████▎     | 7515/17525 [1:30:29<1:42:51,  1.62it/s] 43%|████▎     | 7516/17525 [1:30:29<1:41:16,  1.65it/s] 43%|████▎     | 7517/17525 [1:30:30<1:40:44,  1.66it/s] 43%|████▎     | 7518/17525 [1:30:30<1:39:21,  1.68it/s] 43%|████▎     | 7519/17525 [1:30:31<1:38:18,  1.70it/s] 43%|████▎     | 7520/17525 [1:30:32<1:37:46,  1.71it/s]                                                        {'loss': 0.5531, 'grad_norm': 10.149731636047363, 'learning_rate': 1.224120347129952e-05, 'epoch': 10.73}
 43%|████▎     | 7520/17525 [1:30:32<1:37:46,  1.71it/s] 43%|████▎     | 7521/17525 [1:30:32<1:37:51,  1.70it/s] 43%|████▎     | 7522/17525 [1:30:33<1:37:42,  1.71it/s] 43%|████▎     | 7523/17525 [1:30:33<1:37:50,  1.70it/s] 43%|████▎     | 7524/17525 [1:30:34<1:37:14,  1.71it/s] 43%|████▎     | 7525/17525 [1:30:35<1:36:56,  1.72it/s] 43%|████▎     | 7526/17525 [1:30:35<1:46:17,  1.57it/s] 43%|████▎     | 7527/17525 [1:30:36<1:43:47,  1.61it/s] 43%|████▎     | 7528/17525 [1:30:36<1:41:43,  1.64it/s] 43%|████▎     | 7529/17525 [1:30:37<1:40:09,  1.66it/s] 43%|████▎     | 7530/17525 [1:30:38<1:47:14,  1.55it/s]                                                        {'loss': 0.4409, 'grad_norm': 10.825153350830078, 'learning_rate': 1.2223709581882362e-05, 'epoch': 10.74}
 43%|████▎     | 7530/17525 [1:30:38<1:47:14,  1.55it/s] 43%|████▎     | 7531/17525 [1:30:38<1:44:13,  1.60it/s] 43%|████▎     | 7532/17525 [1:30:39<1:42:16,  1.63it/s] 43%|████▎     | 7533/17525 [1:30:40<1:40:37,  1.65it/s] 43%|████▎     | 7534/17525 [1:30:40<1:39:31,  1.67it/s] 43%|████▎     | 7535/17525 [1:30:41<1:38:22,  1.69it/s] 43%|████▎     | 7536/17525 [1:30:42<2:16:24,  1.22it/s] 43%|████▎     | 7537/17525 [1:30:43<2:05:02,  1.33it/s] 43%|████▎     | 7538/17525 [1:30:43<1:56:36,  1.43it/s] 43%|████▎     | 7539/17525 [1:30:44<1:50:22,  1.51it/s] 43%|████▎     | 7540/17525 [1:30:44<1:47:08,  1.55it/s]                                                        {'loss': 0.5785, 'grad_norm': 7.30893611907959, 'learning_rate': 1.2206208530149401e-05, 'epoch': 10.76}
 43%|████▎     | 7540/17525 [1:30:44<1:47:08,  1.55it/s] 43%|████▎     | 7541/17525 [1:30:45<1:43:45,  1.60it/s] 43%|████▎     | 7542/17525 [1:30:46<1:41:28,  1.64it/s] 43%|████▎     | 7543/17525 [1:30:46<1:40:21,  1.66it/s] 43%|████▎     | 7544/17525 [1:30:48<2:30:12,  1.11it/s] 43%|████▎     | 7545/17525 [1:30:48<2:14:04,  1.24it/s] 43%|████▎     | 7546/17525 [1:30:49<2:02:54,  1.35it/s] 43%|████▎     | 7547/17525 [1:30:49<1:54:55,  1.45it/s] 43%|████▎     | 7548/17525 [1:30:50<1:49:34,  1.52it/s] 43%|████▎     | 7549/17525 [1:30:51<1:45:36,  1.57it/s] 43%|████▎     | 7550/17525 [1:30:51<1:42:44,  1.62it/s]                                                        {'loss': 0.4365, 'grad_norm': 12.153482437133789, 'learning_rate': 1.2188700372469537e-05, 'epoch': 10.77}
 43%|████▎     | 7550/17525 [1:30:51<1:42:44,  1.62it/s] 43%|████▎     | 7551/17525 [1:30:52<1:40:55,  1.65it/s] 43%|████▎     | 7552/17525 [1:30:52<1:39:26,  1.67it/s] 43%|████▎     | 7553/17525 [1:30:53<1:38:27,  1.69it/s] 43%|████▎     | 7554/17525 [1:30:54<1:37:40,  1.70it/s] 43%|████▎     | 7555/17525 [1:30:54<1:37:03,  1.71it/s] 43%|████▎     | 7556/17525 [1:30:55<1:36:43,  1.72it/s] 43%|████▎     | 7557/17525 [1:30:55<1:36:31,  1.72it/s] 43%|████▎     | 7558/17525 [1:30:56<1:36:10,  1.73it/s] 43%|████▎     | 7559/17525 [1:30:56<1:35:45,  1.73it/s] 43%|████▎     | 7560/17525 [1:30:57<1:36:01,  1.73it/s]                                                        {'loss': 0.5206, 'grad_norm': 14.513120651245117, 'learning_rate': 1.2171185165234558e-05, 'epoch': 10.78}
 43%|████▎     | 7560/17525 [1:30:57<1:36:01,  1.73it/s] 43%|████▎     | 7561/17525 [1:30:58<1:43:06,  1.61it/s] 43%|████▎     | 7562/17525 [1:30:58<1:40:54,  1.65it/s] 43%|████▎     | 7563/17525 [1:30:59<1:39:43,  1.66it/s] 43%|████▎     | 7564/17525 [1:30:59<1:38:34,  1.68it/s] 43%|████▎     | 7565/17525 [1:31:00<1:44:20,  1.59it/s] 43%|████▎     | 7566/17525 [1:31:01<1:42:01,  1.63it/s] 43%|████▎     | 7567/17525 [1:31:01<1:40:26,  1.65it/s] 43%|████▎     | 7568/17525 [1:31:02<1:56:48,  1.42it/s] 43%|████▎     | 7569/17525 [1:31:03<1:50:36,  1.50it/s] 43%|████▎     | 7570/17525 [1:31:03<1:45:57,  1.57it/s]                                                        {'loss': 0.4996, 'grad_norm': 13.990126609802246, 'learning_rate': 1.2153662964858952e-05, 'epoch': 10.8}
 43%|████▎     | 7570/17525 [1:31:03<1:45:57,  1.57it/s] 43%|████▎     | 7571/17525 [1:31:04<2:00:23,  1.38it/s] 43%|████▎     | 7572/17525 [1:31:05<1:52:58,  1.47it/s] 43%|████▎     | 7573/17525 [1:31:06<1:48:00,  1.54it/s] 43%|████▎     | 7574/17525 [1:31:06<1:44:27,  1.59it/s] 43%|████▎     | 7575/17525 [1:31:07<1:41:53,  1.63it/s] 43%|████▎     | 7576/17525 [1:31:07<1:40:08,  1.66it/s] 43%|████▎     | 7577/17525 [1:31:08<1:38:59,  1.67it/s] 43%|████▎     | 7578/17525 [1:31:08<1:38:06,  1.69it/s] 43%|████▎     | 7579/17525 [1:31:09<1:37:27,  1.70it/s] 43%|████▎     | 7580/17525 [1:31:10<1:36:51,  1.71it/s]                                                        {'loss': 0.5045, 'grad_norm': 14.860081672668457, 'learning_rate': 1.2136133827779735e-05, 'epoch': 10.81}
 43%|████▎     | 7580/17525 [1:31:10<1:36:51,  1.71it/s] 43%|████▎     | 7581/17525 [1:31:10<1:36:32,  1.72it/s] 43%|████▎     | 7582/17525 [1:31:11<1:36:11,  1.72it/s] 43%|████▎     | 7583/17525 [1:31:11<1:35:55,  1.73it/s] 43%|████▎     | 7584/17525 [1:31:12<1:35:57,  1.73it/s] 43%|████▎     | 7585/17525 [1:31:12<1:35:43,  1.73it/s] 43%|████▎     | 7586/17525 [1:31:13<1:35:31,  1.73it/s] 43%|████▎     | 7587/17525 [1:31:14<1:35:20,  1.74it/s] 43%|████▎     | 7588/17525 [1:31:14<1:35:21,  1.74it/s] 43%|████▎     | 7589/17525 [1:31:15<1:35:11,  1.74it/s] 43%|████▎     | 7590/17525 [1:31:15<1:35:14,  1.74it/s]                                                        {'loss': 0.4975, 'grad_norm': 7.674615859985352, 'learning_rate': 1.2118597810456267e-05, 'epoch': 10.83}
 43%|████▎     | 7590/17525 [1:31:15<1:35:14,  1.74it/s] 43%|████▎     | 7591/17525 [1:31:16<1:35:20,  1.74it/s] 43%|████▎     | 7592/17525 [1:31:16<1:35:18,  1.74it/s] 43%|████▎     | 7593/17525 [1:31:17<1:35:17,  1.74it/s] 43%|████▎     | 7594/17525 [1:31:18<1:35:00,  1.74it/s] 43%|████▎     | 7595/17525 [1:31:18<1:35:04,  1.74it/s] 43%|████▎     | 7596/17525 [1:31:19<1:34:59,  1.74it/s] 43%|████▎     | 7597/17525 [1:31:19<1:35:04,  1.74it/s] 43%|████▎     | 7598/17525 [1:31:20<1:35:13,  1.74it/s] 43%|████▎     | 7599/17525 [1:31:20<1:35:10,  1.74it/s] 43%|████▎     | 7600/17525 [1:31:21<1:35:03,  1.74it/s]                                                        {'loss': 0.5335, 'grad_norm': 6.280383110046387, 'learning_rate': 1.2101054969370068e-05, 'epoch': 10.84}
 43%|████▎     | 7600/17525 [1:31:21<1:35:03,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 03:34:42,955 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:34:42,955 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:34:42,955 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.76it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9467781186103821, 'eval_runtime': 4.6063, 'eval_samples_per_second': 96.173, 'eval_steps_per_second': 4.125, 'epoch': 10.84}
 43%|████▎     | 7600/17525 [1:31:26<1:35:03,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 43%|████▎     | 7601/17525 [1:31:26<5:24:24,  1.96s/it] 43%|████▎     | 7602/17525 [1:31:27<4:15:33,  1.55s/it] 43%|████▎     | 7603/17525 [1:31:27<3:27:27,  1.25s/it] 43%|████▎     | 7604/17525 [1:31:28<2:53:59,  1.05s/it] 43%|████▎     | 7605/17525 [1:31:29<2:30:12,  1.10it/s] 43%|████▎     | 7606/17525 [1:31:29<2:13:40,  1.24it/s] 43%|████▎     | 7607/17525 [1:31:30<2:02:12,  1.35it/s] 43%|████▎     | 7608/17525 [1:31:30<1:54:03,  1.45it/s] 43%|████▎     | 7609/17525 [1:31:31<1:48:29,  1.52it/s] 43%|████▎     | 7610/17525 [1:31:31<1:44:36,  1.58it/s]                                                        {'loss': 0.4439, 'grad_norm': 16.281312942504883, 'learning_rate': 1.2083505361024628e-05, 'epoch': 10.86}
 43%|████▎     | 7610/17525 [1:31:31<1:44:36,  1.58it/s] 43%|████▎     | 7611/17525 [1:31:32<1:42:00,  1.62it/s] 43%|████▎     | 7612/17525 [1:31:33<1:39:56,  1.65it/s] 43%|████▎     | 7613/17525 [1:31:33<1:38:29,  1.68it/s] 43%|████▎     | 7614/17525 [1:31:34<1:37:32,  1.69it/s] 43%|████▎     | 7615/17525 [1:31:34<1:36:40,  1.71it/s] 43%|████▎     | 7616/17525 [1:31:35<1:36:12,  1.72it/s] 43%|████▎     | 7617/17525 [1:31:35<1:35:58,  1.72it/s] 43%|████▎     | 7618/17525 [1:31:36<1:35:50,  1.72it/s] 43%|████▎     | 7619/17525 [1:31:37<1:35:48,  1.72it/s] 43%|████▎     | 7620/17525 [1:31:37<1:35:41,  1.73it/s]                                                        {'loss': 0.4634, 'grad_norm': 12.870187759399414, 'learning_rate': 1.206594904194525e-05, 'epoch': 10.87}
 43%|████▎     | 7620/17525 [1:31:37<1:35:41,  1.73it/s] 43%|████▎     | 7621/17525 [1:31:38<1:36:35,  1.71it/s] 43%|████▎     | 7622/17525 [1:31:38<1:36:00,  1.72it/s] 43%|████▎     | 7623/17525 [1:31:39<1:35:33,  1.73it/s] 44%|████▎     | 7624/17525 [1:31:40<1:35:13,  1.73it/s] 44%|████▎     | 7625/17525 [1:31:41<2:15:21,  1.22it/s] 44%|████▎     | 7626/17525 [1:31:42<2:04:30,  1.33it/s] 44%|████▎     | 7627/17525 [1:31:42<1:55:46,  1.42it/s] 44%|████▎     | 7628/17525 [1:31:43<1:49:48,  1.50it/s] 44%|████▎     | 7629/17525 [1:31:43<1:45:35,  1.56it/s] 44%|████▎     | 7630/17525 [1:31:44<2:00:13,  1.37it/s]                                                        {'loss': 0.5732, 'grad_norm': 11.055766105651855, 'learning_rate': 1.2048386068678832e-05, 'epoch': 10.88}
 44%|████▎     | 7630/17525 [1:31:44<2:00:13,  1.37it/s] 44%|████▎     | 7631/17525 [1:31:45<1:53:08,  1.46it/s] 44%|████▎     | 7632/17525 [1:31:45<1:48:08,  1.52it/s] 44%|████▎     | 7633/17525 [1:31:46<1:44:57,  1.57it/s] 44%|████▎     | 7634/17525 [1:31:47<1:42:37,  1.61it/s] 44%|████▎     | 7635/17525 [1:31:47<1:41:43,  1.62it/s] 44%|████▎     | 7636/17525 [1:31:48<1:39:54,  1.65it/s] 44%|████▎     | 7637/17525 [1:31:48<1:39:38,  1.65it/s] 44%|████▎     | 7638/17525 [1:31:49<1:39:24,  1.66it/s] 44%|████▎     | 7639/17525 [1:31:50<1:38:19,  1.68it/s] 44%|████▎     | 7640/17525 [1:31:50<1:37:42,  1.69it/s]                                                        {'loss': 0.554, 'grad_norm': 11.681761741638184, 'learning_rate': 1.2030816497793725e-05, 'epoch': 10.9}
 44%|████▎     | 7640/17525 [1:31:50<1:37:42,  1.69it/s] 44%|████▎     | 7641/17525 [1:31:51<1:37:27,  1.69it/s] 44%|████▎     | 7642/17525 [1:31:51<1:36:53,  1.70it/s] 44%|████▎     | 7643/17525 [1:31:52<1:54:09,  1.44it/s] 44%|████▎     | 7644/17525 [1:31:53<1:48:40,  1.52it/s] 44%|████▎     | 7645/17525 [1:31:53<1:44:53,  1.57it/s] 44%|████▎     | 7646/17525 [1:31:54<1:42:23,  1.61it/s] 44%|████▎     | 7647/17525 [1:31:55<1:40:39,  1.64it/s] 44%|████▎     | 7648/17525 [1:31:55<1:39:20,  1.66it/s] 44%|████▎     | 7649/17525 [1:31:56<1:38:56,  1.66it/s] 44%|████▎     | 7650/17525 [1:31:56<1:38:03,  1.68it/s]                                                        {'loss': 0.5559, 'grad_norm': 17.39217185974121, 'learning_rate': 1.2013240385879511e-05, 'epoch': 10.91}
 44%|████▎     | 7650/17525 [1:31:56<1:38:03,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 03:35:18,213 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7add990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 351377fc-a646-4107-8d49-23e1fd1abda4)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:35:28,285 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:35:28,287 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 44%|████▎     | 7651/17525 [1:32:07<10:01:09,  3.65s/it] 44%|████▎     | 7652/17525 [1:32:08<7:29:45,  2.73s/it]  44%|████▎     | 7653/17525 [1:32:08<5:43:49,  2.09s/it] 44%|████▎     | 7654/17525 [1:32:09<4:29:43,  1.64s/it] 44%|████▎     | 7655/17525 [1:32:09<3:37:17,  1.32s/it] 44%|████▎     | 7656/17525 [1:32:10<3:00:54,  1.10s/it] 44%|████▎     | 7657/17525 [1:32:11<2:35:44,  1.06it/s] 44%|████▎     | 7658/17525 [1:32:11<2:17:28,  1.20it/s] 44%|████▎     | 7659/17525 [1:32:12<2:04:57,  1.32it/s] 44%|████▎     | 7660/17525 [1:32:12<1:56:22,  1.41it/s]                                                        {'loss': 0.5212, 'grad_norm': 11.448750495910645, 'learning_rate': 1.1995657789546856e-05, 'epoch': 10.93}
 44%|████▎     | 7660/17525 [1:32:12<1:56:22,  1.41it/s] 44%|████▎     | 7661/17525 [1:32:13<1:50:13,  1.49it/s] 44%|████▎     | 7662/17525 [1:32:14<1:46:15,  1.55it/s] 44%|████▎     | 7663/17525 [1:32:14<1:43:31,  1.59it/s] 44%|████▎     | 7664/17525 [1:32:15<1:41:19,  1.62it/s] 44%|████▎     | 7665/17525 [1:32:15<1:39:45,  1.65it/s] 44%|████▎     | 7666/17525 [1:32:16<1:39:24,  1.65it/s] 44%|████▎     | 7667/17525 [1:32:16<1:38:27,  1.67it/s] 44%|████▍     | 7668/17525 [1:32:17<1:37:49,  1.68it/s] 44%|████▍     | 7669/17525 [1:32:18<1:37:25,  1.69it/s] 44%|████▍     | 7670/17525 [1:32:18<1:36:50,  1.70it/s]                                                        {'loss': 0.5484, 'grad_norm': 12.585284233093262, 'learning_rate': 1.1978068765427298e-05, 'epoch': 10.94}
 44%|████▍     | 7670/17525 [1:32:18<1:36:50,  1.70it/s] 44%|████▍     | 7671/17525 [1:32:19<1:36:54,  1.69it/s] 44%|████▍     | 7672/17525 [1:32:19<1:36:27,  1.70it/s] 44%|████▍     | 7673/17525 [1:32:20<1:36:29,  1.70it/s] 44%|████▍     | 7674/17525 [1:32:21<1:36:37,  1.70it/s] 44%|████▍     | 7675/17525 [1:32:22<2:27:04,  1.12it/s] 44%|████▍     | 7676/17525 [1:32:23<2:11:20,  1.25it/s] 44%|████▍     | 7677/17525 [1:32:23<2:01:51,  1.35it/s] 44%|████▍     | 7678/17525 [1:32:24<1:54:13,  1.44it/s] 44%|████▍     | 7679/17525 [1:32:25<1:48:31,  1.51it/s] 44%|████▍     | 7680/17525 [1:32:25<1:44:09,  1.58it/s]                                                        {'loss': 0.4188, 'grad_norm': 5.119630336761475, 'learning_rate': 1.1960473370173088e-05, 'epoch': 10.96}
 44%|████▍     | 7680/17525 [1:32:25<1:44:09,  1.58it/s] 44%|████▍     | 7681/17525 [1:32:26<1:41:47,  1.61it/s] 44%|████▍     | 7682/17525 [1:32:26<1:39:39,  1.65it/s] 44%|████▍     | 7683/17525 [1:32:27<1:38:29,  1.67it/s] 44%|████▍     | 7684/17525 [1:32:27<1:38:01,  1.67it/s] 44%|████▍     | 7685/17525 [1:32:28<1:37:28,  1.68it/s] 44%|████▍     | 7686/17525 [1:32:29<1:36:59,  1.69it/s] 44%|████▍     | 7687/17525 [1:32:29<1:36:33,  1.70it/s] 44%|████▍     | 7688/17525 [1:32:30<1:36:05,  1.71it/s] 44%|████▍     | 7689/17525 [1:32:30<1:35:38,  1.71it/s] 44%|████▍     | 7690/17525 [1:32:31<1:35:27,  1.72it/s]                                                        {'loss': 0.4471, 'grad_norm': 6.366305351257324, 'learning_rate': 1.1942871660456991e-05, 'epoch': 10.97}
 44%|████▍     | 7690/17525 [1:32:31<1:35:27,  1.72it/s] 44%|████▍     | 7691/17525 [1:32:32<1:35:19,  1.72it/s] 44%|████▍     | 7692/17525 [1:32:32<1:35:10,  1.72it/s] 44%|████▍     | 7693/17525 [1:32:33<1:35:05,  1.72it/s] 44%|████▍     | 7694/17525 [1:32:33<1:41:38,  1.61it/s] 44%|████▍     | 7695/17525 [1:32:34<1:39:38,  1.64it/s] 44%|████▍     | 7696/17525 [1:32:35<1:37:50,  1.67it/s] 44%|████▍     | 7697/17525 [1:32:35<1:36:45,  1.69it/s] 44%|████▍     | 7698/17525 [1:32:36<1:35:57,  1.71it/s] 44%|████▍     | 7699/17525 [1:32:36<1:35:28,  1.72it/s] 44%|████▍     | 7700/17525 [1:32:37<1:36:32,  1.70it/s]                                                        {'loss': 0.5279, 'grad_norm': 19.21169662475586, 'learning_rate': 1.192526369297212e-05, 'epoch': 10.98}
 44%|████▍     | 7700/17525 [1:32:37<1:36:32,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 03:35:58,794 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:35:58,794 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:35:58,794 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9489613771438599, 'eval_runtime': 4.5937, 'eval_samples_per_second': 96.437, 'eval_steps_per_second': 4.136, 'epoch': 10.98}
 44%|████▍     | 7700/17525 [1:32:41<1:36:32,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 44%|████▍     | 7701/17525 [1:32:42<5:22:02,  1.97s/it] 44%|████▍     | 7702/17525 [1:32:43<4:14:13,  1.55s/it] 44%|████▍     | 7703/17525 [1:32:43<3:26:39,  1.26s/it] 44%|████▍     | 7704/17525 [1:32:44<2:53:01,  1.06s/it] 44%|████▍     | 7705/17525 [1:32:44<2:29:21,  1.10it/s] 44%|████▍     | 7706/17525 [1:32:45<2:12:47,  1.23it/s] 44%|████▍     | 7707/17525 [1:32:46<2:01:30,  1.35it/s] 44%|████▍     | 7708/17525 [1:32:46<1:54:13,  1.43it/s] 44%|████▍     | 7709/17525 [1:32:47<1:48:44,  1.50it/s] 44%|████▍     | 7710/17525 [1:32:47<1:44:17,  1.57it/s]                                                        {'loss': 0.4191, 'grad_norm': 15.058597564697266, 'learning_rate': 1.190764952443173e-05, 'epoch': 11.0}
 44%|████▍     | 7710/17525 [1:32:47<1:44:17,  1.57it/s] 44%|████▍     | 7711/17525 [1:32:48<1:41:39,  1.61it/s] 44%|████▍     | 7712/17525 [1:32:48<1:39:27,  1.64it/s] 44%|████▍     | 7713/17525 [1:32:49<1:37:53,  1.67it/s] 44%|████▍     | 7714/17525 [1:32:50<1:37:19,  1.68it/s] 44%|████▍     | 7715/17525 [1:32:50<1:38:04,  1.67it/s] 44%|████▍     | 7716/17525 [1:32:51<1:36:57,  1.69it/s] 44%|████▍     | 7717/17525 [1:32:51<1:36:05,  1.70it/s] 44%|████▍     | 7718/17525 [1:32:52<1:35:19,  1.71it/s] 44%|████▍     | 7719/17525 [1:32:53<1:35:37,  1.71it/s] 44%|████▍     | 7720/17525 [1:32:53<1:35:19,  1.71it/s]                                                        {'loss': 0.4237, 'grad_norm': 34.25758361816406, 'learning_rate': 1.1890029211569058e-05, 'epoch': 11.01}
 44%|████▍     | 7720/17525 [1:32:53<1:35:19,  1.71it/s] 44%|████▍     | 7721/17525 [1:32:54<1:35:08,  1.72it/s] 44%|████▍     | 7722/17525 [1:32:55<1:44:44,  1.56it/s] 44%|████▍     | 7723/17525 [1:32:55<1:42:07,  1.60it/s] 44%|████▍     | 7724/17525 [1:32:56<1:39:55,  1.63it/s] 44%|████▍     | 7725/17525 [1:32:56<1:38:33,  1.66it/s] 44%|████▍     | 7726/17525 [1:32:57<1:37:20,  1.68it/s] 44%|████▍     | 7727/17525 [1:32:57<1:36:42,  1.69it/s] 44%|████▍     | 7728/17525 [1:32:58<1:36:07,  1.70it/s] 44%|████▍     | 7729/17525 [1:32:59<1:35:46,  1.70it/s] 44%|████▍     | 7730/17525 [1:32:59<1:35:26,  1.71it/s]                                                        {'loss': 0.4313, 'grad_norm': 18.626007080078125, 'learning_rate': 1.1872402811137131e-05, 'epoch': 11.03}
 44%|████▍     | 7730/17525 [1:32:59<1:35:26,  1.71it/s] 44%|████▍     | 7731/17525 [1:33:00<1:35:24,  1.71it/s] 44%|████▍     | 7732/17525 [1:33:00<1:35:10,  1.72it/s] 44%|████▍     | 7733/17525 [1:33:01<1:35:09,  1.72it/s] 44%|████▍     | 7734/17525 [1:33:01<1:35:11,  1.71it/s] 44%|████▍     | 7735/17525 [1:33:02<1:34:50,  1.72it/s] 44%|████▍     | 7736/17525 [1:33:03<1:34:44,  1.72it/s] 44%|████▍     | 7737/17525 [1:33:03<1:34:43,  1.72it/s] 44%|████▍     | 7738/17525 [1:33:04<1:34:28,  1.73it/s] 44%|████▍     | 7739/17525 [1:33:04<1:34:22,  1.73it/s] 44%|████▍     | 7740/17525 [1:33:05<1:34:25,  1.73it/s]                                                        {'loss': 0.4102, 'grad_norm': 9.59385871887207, 'learning_rate': 1.1854770379908575e-05, 'epoch': 11.04}
 44%|████▍     | 7740/17525 [1:33:05<1:34:25,  1.73it/s] 44%|████▍     | 7741/17525 [1:33:06<1:34:49,  1.72it/s] 44%|████▍     | 7742/17525 [1:33:06<1:34:55,  1.72it/s] 44%|████▍     | 7743/17525 [1:33:07<1:35:35,  1.71it/s] 44%|████▍     | 7744/17525 [1:33:07<1:35:17,  1.71it/s] 44%|████▍     | 7745/17525 [1:33:08<1:35:24,  1.71it/s] 44%|████▍     | 7746/17525 [1:33:08<1:35:14,  1.71it/s] 44%|████▍     | 7747/17525 [1:33:09<1:36:12,  1.69it/s] 44%|████▍     | 7748/17525 [1:33:11<2:26:56,  1.11it/s] 44%|████▍     | 7749/17525 [1:33:11<2:11:21,  1.24it/s] 44%|████▍     | 7750/17525 [1:33:12<1:59:58,  1.36it/s]                                                        {'loss': 0.5124, 'grad_norm': 12.73967456817627, 'learning_rate': 1.1837131974675453e-05, 'epoch': 11.06}
 44%|████▍     | 7750/17525 [1:33:12<1:59:58,  1.36it/s] 44%|████▍     | 7751/17525 [1:33:12<1:52:45,  1.44it/s] 44%|████▍     | 7752/17525 [1:33:13<1:46:56,  1.52it/s] 44%|████▍     | 7753/17525 [1:33:14<1:59:55,  1.36it/s] 44%|████▍     | 7754/17525 [1:33:15<1:52:08,  1.45it/s] 44%|████▍     | 7755/17525 [1:33:15<1:46:42,  1.53it/s] 44%|████▍     | 7756/17525 [1:33:16<1:42:40,  1.59it/s] 44%|████▍     | 7757/17525 [1:33:16<1:40:14,  1.62it/s] 44%|████▍     | 7758/17525 [1:33:17<1:38:15,  1.66it/s] 44%|████▍     | 7759/17525 [1:33:17<1:37:17,  1.67it/s] 44%|████▍     | 7760/17525 [1:33:18<1:36:13,  1.69it/s]                                                        {'loss': 0.4196, 'grad_norm': 19.0965518951416, 'learning_rate': 1.1819487652249065e-05, 'epoch': 11.07}
 44%|████▍     | 7760/17525 [1:33:18<1:36:13,  1.69it/s] 44%|████▍     | 7761/17525 [1:33:19<1:36:00,  1.69it/s] 44%|████▍     | 7762/17525 [1:33:19<1:35:29,  1.70it/s] 44%|████▍     | 7763/17525 [1:33:20<1:35:11,  1.71it/s] 44%|████▍     | 7764/17525 [1:33:20<1:34:52,  1.71it/s] 44%|████▍     | 7765/17525 [1:33:21<1:34:51,  1.71it/s] 44%|████▍     | 7766/17525 [1:33:21<1:34:34,  1.72it/s] 44%|████▍     | 7767/17525 [1:33:22<1:34:16,  1.72it/s] 44%|████▍     | 7768/17525 [1:33:23<1:34:13,  1.73it/s] 44%|████▍     | 7769/17525 [1:33:23<1:33:54,  1.73it/s] 44%|████▍     | 7770/17525 [1:33:24<1:33:39,  1.74it/s]                                                        {'loss': 0.5443, 'grad_norm': 15.297598838806152, 'learning_rate': 1.180183746945976e-05, 'epoch': 11.08}
 44%|████▍     | 7770/17525 [1:33:24<1:33:39,  1.74it/s] 44%|████▍     | 7771/17525 [1:33:24<1:33:46,  1.73it/s] 44%|████▍     | 7772/17525 [1:33:25<1:33:32,  1.74it/s] 44%|████▍     | 7773/17525 [1:33:26<1:33:32,  1.74it/s] 44%|████▍     | 7774/17525 [1:33:26<1:33:38,  1.74it/s] 44%|████▍     | 7775/17525 [1:33:27<1:33:52,  1.73it/s] 44%|████▍     | 7776/17525 [1:33:27<1:33:59,  1.73it/s] 44%|████▍     | 7777/17525 [1:33:28<1:34:21,  1.72it/s] 44%|████▍     | 7778/17525 [1:33:28<1:34:26,  1.72it/s] 44%|████▍     | 7779/17525 [1:33:29<1:34:22,  1.72it/s] 44%|████▍     | 7780/17525 [1:33:30<1:34:22,  1.72it/s]                                                        {'loss': 0.467, 'grad_norm': 11.180973052978516, 'learning_rate': 1.1784181483156774e-05, 'epoch': 11.1}
 44%|████▍     | 7780/17525 [1:33:30<1:34:22,  1.72it/s] 44%|████▍     | 7781/17525 [1:33:30<1:34:49,  1.71it/s] 44%|████▍     | 7782/17525 [1:33:31<1:35:02,  1.71it/s] 44%|████▍     | 7783/17525 [1:33:31<1:34:43,  1.71it/s] 44%|████▍     | 7784/17525 [1:33:32<1:34:24,  1.72it/s] 44%|████▍     | 7785/17525 [1:33:32<1:34:32,  1.72it/s] 44%|████▍     | 7786/17525 [1:33:33<1:34:44,  1.71it/s] 44%|████▍     | 7787/17525 [1:33:34<1:34:30,  1.72it/s] 44%|████▍     | 7788/17525 [1:33:34<1:34:26,  1.72it/s] 44%|████▍     | 7789/17525 [1:33:35<1:34:22,  1.72it/s] 44%|████▍     | 7790/17525 [1:33:35<1:34:23,  1.72it/s]                                                        {'loss': 0.43, 'grad_norm': 12.571761131286621, 'learning_rate': 1.1766519750208034e-05, 'epoch': 11.11}
 44%|████▍     | 7790/17525 [1:33:35<1:34:23,  1.72it/s] 44%|████▍     | 7791/17525 [1:33:36<1:34:21,  1.72it/s] 44%|████▍     | 7792/17525 [1:33:37<1:34:15,  1.72it/s] 44%|████▍     | 7793/17525 [1:33:37<1:33:59,  1.73it/s] 44%|████▍     | 7794/17525 [1:33:38<1:33:46,  1.73it/s] 44%|████▍     | 7795/17525 [1:33:38<1:33:24,  1.74it/s] 44%|████▍     | 7796/17525 [1:33:39<1:33:27,  1.73it/s] 44%|████▍     | 7797/17525 [1:33:40<1:43:06,  1.57it/s] 44%|████▍     | 7798/17525 [1:33:40<1:40:16,  1.62it/s] 45%|████▍     | 7799/17525 [1:33:41<1:38:01,  1.65it/s] 45%|████▍     | 7800/17525 [1:33:41<1:36:50,  1.67it/s]                                                        {'loss': 0.4047, 'grad_norm': 5.81886100769043, 'learning_rate': 1.1748852327499975e-05, 'epoch': 11.13}
 45%|████▍     | 7800/17525 [1:33:41<1:36:50,  1.67it/s][INFO|trainer.py:3512] 2024-06-25 03:37:03,270 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:37:03,270 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:37:03,270 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9741730093955994, 'eval_runtime': 4.5972, 'eval_samples_per_second': 96.364, 'eval_steps_per_second': 4.133, 'epoch': 11.13}
 45%|████▍     | 7800/17525 [1:33:46<1:36:50,  1.67it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:37:07,871 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7add990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: dba50de9-fc31-4012-86c9-1aa1097ef542)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:37:17,932 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:37:17,935 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 45%|████▍     | 7801/17525 [1:33:57<13:35:32,  5.03s/it] 45%|████▍     | 7802/17525 [1:33:57<9:58:45,  3.69s/it]  45%|████▍     | 7803/17525 [1:33:58<7:26:47,  2.76s/it] 45%|████▍     | 7804/17525 [1:33:58<5:40:12,  2.10s/it] 45%|████▍     | 7805/17525 [1:33:59<4:25:57,  1.64s/it] 45%|████▍     | 7806/17525 [1:34:00<3:33:55,  1.32s/it] 45%|████▍     | 7807/17525 [1:34:00<2:57:19,  1.09s/it] 45%|████▍     | 7808/17525 [1:34:01<2:31:49,  1.07it/s] 45%|████▍     | 7809/17525 [1:34:01<2:14:03,  1.21it/s] 45%|████▍     | 7810/17525 [1:34:02<2:01:31,  1.33it/s]                                                        {'loss': 0.4206, 'grad_norm': 14.286375999450684, 'learning_rate': 1.1731179271937354e-05, 'epoch': 11.14}
 45%|████▍     | 7810/17525 [1:34:02<2:01:31,  1.33it/s] 45%|████▍     | 7811/17525 [1:34:02<1:53:00,  1.43it/s] 45%|████▍     | 7812/17525 [1:34:03<1:47:51,  1.50it/s] 45%|████▍     | 7813/17525 [1:34:04<1:43:05,  1.57it/s] 45%|████▍     | 7814/17525 [1:34:04<1:39:41,  1.62it/s] 45%|████▍     | 7815/17525 [1:34:05<1:37:32,  1.66it/s] 45%|████▍     | 7816/17525 [1:34:06<2:00:15,  1.35it/s] 45%|████▍     | 7817/17525 [1:34:06<1:51:59,  1.44it/s] 45%|████▍     | 7818/17525 [1:34:07<1:46:16,  1.52it/s] 45%|████▍     | 7819/17525 [1:34:08<1:49:04,  1.48it/s] 45%|████▍     | 7820/17525 [1:34:08<1:44:03,  1.55it/s]                                                        {'loss': 0.4292, 'grad_norm': 12.744832992553711, 'learning_rate': 1.1713500640443074e-05, 'epoch': 11.16}
 45%|████▍     | 7820/17525 [1:34:08<1:44:03,  1.55it/s] 45%|████▍     | 7821/17525 [1:34:09<1:40:34,  1.61it/s] 45%|████▍     | 7822/17525 [1:34:09<1:37:58,  1.65it/s] 45%|████▍     | 7823/17525 [1:34:10<1:36:10,  1.68it/s] 45%|████▍     | 7824/17525 [1:34:11<1:35:00,  1.70it/s] 45%|████▍     | 7825/17525 [1:34:11<1:34:17,  1.71it/s] 45%|████▍     | 7826/17525 [1:34:12<1:33:48,  1.72it/s] 45%|████▍     | 7827/17525 [1:34:12<1:35:40,  1.69it/s] 45%|████▍     | 7828/17525 [1:34:13<1:34:32,  1.71it/s] 45%|████▍     | 7829/17525 [1:34:13<1:33:59,  1.72it/s] 45%|████▍     | 7830/17525 [1:34:14<1:33:26,  1.73it/s]                                                        {'loss': 0.3974, 'grad_norm': 5.29385232925415, 'learning_rate': 1.1695816489958e-05, 'epoch': 11.17}
 45%|████▍     | 7830/17525 [1:34:14<1:33:26,  1.73it/s] 45%|████▍     | 7831/17525 [1:34:15<1:34:05,  1.72it/s] 45%|████▍     | 7832/17525 [1:34:15<1:33:54,  1.72it/s] 45%|████▍     | 7833/17525 [1:34:16<1:33:57,  1.72it/s] 45%|████▍     | 7834/17525 [1:34:16<1:33:59,  1.72it/s] 45%|████▍     | 7835/17525 [1:34:17<1:33:30,  1.73it/s] 45%|████▍     | 7836/17525 [1:34:18<1:33:57,  1.72it/s] 45%|████▍     | 7837/17525 [1:34:18<1:34:06,  1.72it/s] 45%|████▍     | 7838/17525 [1:34:19<1:34:52,  1.70it/s] 45%|████▍     | 7839/17525 [1:34:19<1:34:28,  1.71it/s] 45%|████▍     | 7840/17525 [1:34:20<1:33:45,  1.72it/s]                                                        {'loss': 0.489, 'grad_norm': 13.062797546386719, 'learning_rate': 1.1678126877440771e-05, 'epoch': 11.18}
 45%|████▍     | 7840/17525 [1:34:20<1:33:45,  1.72it/s] 45%|████▍     | 7841/17525 [1:34:20<1:33:30,  1.73it/s] 45%|████▍     | 7842/17525 [1:34:21<1:32:59,  1.74it/s] 45%|████▍     | 7843/17525 [1:34:22<1:32:37,  1.74it/s] 45%|████▍     | 7844/17525 [1:34:22<1:32:26,  1.75it/s] 45%|████▍     | 7845/17525 [1:34:23<1:32:25,  1.75it/s] 45%|████▍     | 7846/17525 [1:34:23<1:32:16,  1.75it/s] 45%|████▍     | 7847/17525 [1:34:24<1:32:06,  1.75it/s] 45%|████▍     | 7848/17525 [1:34:24<1:32:00,  1.75it/s] 45%|████▍     | 7849/17525 [1:34:25<1:31:52,  1.76it/s] 45%|████▍     | 7850/17525 [1:34:26<1:32:04,  1.75it/s]                                                        {'loss': 0.4137, 'grad_norm': 12.270976066589355, 'learning_rate': 1.1660431859867618e-05, 'epoch': 11.2}
 45%|████▍     | 7850/17525 [1:34:26<1:32:04,  1.75it/s] 45%|████▍     | 7851/17525 [1:34:26<1:32:14,  1.75it/s] 45%|████▍     | 7852/17525 [1:34:27<1:32:12,  1.75it/s] 45%|████▍     | 7853/17525 [1:34:27<1:32:04,  1.75it/s] 45%|████▍     | 7854/17525 [1:34:28<1:32:00,  1.75it/s] 45%|████▍     | 7855/17525 [1:34:28<1:32:11,  1.75it/s] 45%|████▍     | 7856/17525 [1:34:29<1:32:05,  1.75it/s] 45%|████▍     | 7857/17525 [1:34:30<1:31:55,  1.75it/s] 45%|████▍     | 7858/17525 [1:34:30<1:32:00,  1.75it/s] 45%|████▍     | 7859/17525 [1:34:31<1:32:00,  1.75it/s] 45%|████▍     | 7860/17525 [1:34:31<1:31:50,  1.75it/s]                                                        {'loss': 0.469, 'grad_norm': 17.20905113220215, 'learning_rate': 1.1642731494232177e-05, 'epoch': 11.21}
 45%|████▍     | 7860/17525 [1:34:31<1:31:50,  1.75it/s] 45%|████▍     | 7861/17525 [1:34:32<1:32:02,  1.75it/s] 45%|████▍     | 7862/17525 [1:34:32<1:32:05,  1.75it/s] 45%|████▍     | 7863/17525 [1:34:33<1:31:55,  1.75it/s] 45%|████▍     | 7864/17525 [1:34:34<1:31:58,  1.75it/s] 45%|████▍     | 7865/17525 [1:34:34<1:31:56,  1.75it/s] 45%|████▍     | 7866/17525 [1:34:35<1:31:56,  1.75it/s] 45%|████▍     | 7867/17525 [1:34:35<1:33:45,  1.72it/s] 45%|████▍     | 7868/17525 [1:34:36<1:33:56,  1.71it/s] 45%|████▍     | 7869/17525 [1:34:36<1:33:21,  1.72it/s] 45%|████▍     | 7870/17525 [1:34:37<1:32:56,  1.73it/s]                                                        {'loss': 0.4659, 'grad_norm': 20.846181869506836, 'learning_rate': 1.1625025837545319e-05, 'epoch': 11.23}
 45%|████▍     | 7870/17525 [1:34:37<1:32:56,  1.73it/s] 45%|████▍     | 7871/17525 [1:34:38<1:32:47,  1.73it/s] 45%|████▍     | 7872/17525 [1:34:38<1:32:25,  1.74it/s] 45%|████▍     | 7873/17525 [1:34:39<1:32:15,  1.74it/s] 45%|████▍     | 7874/17525 [1:34:40<2:09:47,  1.24it/s] 45%|████▍     | 7875/17525 [1:34:41<1:58:21,  1.36it/s] 45%|████▍     | 7876/17525 [1:34:41<1:50:17,  1.46it/s] 45%|████▍     | 7877/17525 [1:34:42<1:44:44,  1.54it/s] 45%|████▍     | 7878/17525 [1:34:42<1:42:21,  1.57it/s] 45%|████▍     | 7879/17525 [1:34:43<1:39:05,  1.62it/s] 45%|████▍     | 7880/17525 [1:34:44<1:36:50,  1.66it/s]                                                        {'loss': 0.4469, 'grad_norm': 8.552330017089844, 'learning_rate': 1.160731494683495e-05, 'epoch': 11.24}
 45%|████▍     | 7880/17525 [1:34:44<1:36:50,  1.66it/s] 45%|████▍     | 7881/17525 [1:34:44<1:35:15,  1.69it/s] 45%|████▍     | 7882/17525 [1:34:45<1:34:02,  1.71it/s] 45%|████▍     | 7883/17525 [1:34:46<1:59:16,  1.35it/s] 45%|████▍     | 7884/17525 [1:34:46<1:50:59,  1.45it/s] 45%|████▍     | 7885/17525 [1:34:47<1:45:05,  1.53it/s] 45%|████▍     | 7886/17525 [1:34:48<1:48:00,  1.49it/s] 45%|████▌     | 7887/17525 [1:34:48<1:43:08,  1.56it/s] 45%|████▌     | 7888/17525 [1:34:49<1:39:44,  1.61it/s] 45%|████▌     | 7889/17525 [1:34:49<1:37:14,  1.65it/s] 45%|████▌     | 7890/17525 [1:34:50<1:35:32,  1.68it/s]                                                        {'loss': 0.4801, 'grad_norm': 20.01175308227539, 'learning_rate': 1.1589598879145831e-05, 'epoch': 11.26}
 45%|████▌     | 7890/17525 [1:34:50<1:35:32,  1.68it/s] 45%|████▌     | 7891/17525 [1:34:51<1:34:31,  1.70it/s] 45%|████▌     | 7892/17525 [1:34:51<1:33:39,  1.71it/s] 45%|████▌     | 7893/17525 [1:34:52<1:32:49,  1.73it/s] 45%|████▌     | 7894/17525 [1:34:52<1:32:22,  1.74it/s] 45%|████▌     | 7895/17525 [1:34:53<1:32:08,  1.74it/s] 45%|████▌     | 7896/17525 [1:34:53<1:31:44,  1.75it/s] 45%|████▌     | 7897/17525 [1:34:54<1:31:37,  1.75it/s] 45%|████▌     | 7898/17525 [1:34:55<1:31:36,  1.75it/s] 45%|████▌     | 7899/17525 [1:34:55<1:31:30,  1.75it/s] 45%|████▌     | 7900/17525 [1:34:56<1:31:31,  1.75it/s]                                                        {'loss': 0.5191, 'grad_norm': 13.65323543548584, 'learning_rate': 1.1571877691539413e-05, 'epoch': 11.27}
 45%|████▌     | 7900/17525 [1:34:56<1:31:31,  1.75it/s][INFO|trainer.py:3512] 2024-06-25 03:38:17,538 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:38:17,538 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:38:17,538 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.56it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.63it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.65it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.72it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.74it/s][A
 74%|███████▎  | 14/19 [00:02<00:01,  4.93it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.07it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.14it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                        
                                               [A{'eval_loss': 0.9605282545089722, 'eval_runtime': 4.6351, 'eval_samples_per_second': 95.574, 'eval_steps_per_second': 4.099, 'epoch': 11.27}
 45%|████▌     | 7900/17525 [1:35:00<1:31:31,  1.75it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 45%|████▌     | 7901/17525 [1:35:01<5:15:06,  1.96s/it] 45%|████▌     | 7902/17525 [1:35:03<4:59:53,  1.87s/it] 45%|████▌     | 7903/17525 [1:35:03<3:57:54,  1.48s/it] 45%|████▌     | 7904/17525 [1:35:04<3:29:50,  1.31s/it] 45%|████▌     | 7905/17525 [1:35:05<2:54:32,  1.09s/it] 45%|████▌     | 7906/17525 [1:35:05<2:29:40,  1.07it/s] 45%|████▌     | 7907/17525 [1:35:06<2:30:02,  1.07it/s] 45%|████▌     | 7908/17525 [1:35:07<2:14:27,  1.19it/s] 45%|████▌     | 7909/17525 [1:35:07<2:04:00,  1.29it/s] 45%|████▌     | 7910/17525 [1:35:08<2:12:14,  1.21it/s]                                                        {'loss': 0.424, 'grad_norm': 22.149517059326172, 'learning_rate': 1.1554151441093618e-05, 'epoch': 11.28}
 45%|████▌     | 7910/17525 [1:35:08<2:12:14,  1.21it/s] 45%|████▌     | 7911/17525 [1:35:09<2:01:06,  1.32it/s] 45%|████▌     | 7912/17525 [1:35:09<1:52:44,  1.42it/s] 45%|████▌     | 7913/17525 [1:35:10<1:46:56,  1.50it/s] 45%|████▌     | 7914/17525 [1:35:11<1:42:54,  1.56it/s] 45%|████▌     | 7915/17525 [1:35:11<1:40:08,  1.60it/s] 45%|████▌     | 7916/17525 [1:35:12<1:38:31,  1.63it/s] 45%|████▌     | 7917/17525 [1:35:12<1:37:23,  1.64it/s] 45%|████▌     | 7918/17525 [1:35:13<1:36:40,  1.66it/s] 45%|████▌     | 7919/17525 [1:35:14<1:35:54,  1.67it/s] 45%|████▌     | 7920/17525 [1:35:14<1:35:20,  1.68it/s]                                                        {'loss': 0.4746, 'grad_norm': 14.332720756530762, 'learning_rate': 1.1536420184902686e-05, 'epoch': 11.3}
 45%|████▌     | 7920/17525 [1:35:14<1:35:20,  1.68it/s] 45%|████▌     | 7921/17525 [1:35:15<1:35:14,  1.68it/s] 45%|████▌     | 7922/17525 [1:35:15<1:34:54,  1.69it/s] 45%|████▌     | 7923/17525 [1:35:16<1:42:48,  1.56it/s] 45%|████▌     | 7924/17525 [1:35:17<1:40:04,  1.60it/s] 45%|████▌     | 7925/17525 [1:35:17<1:37:55,  1.63it/s] 45%|████▌     | 7926/17525 [1:35:18<1:37:16,  1.64it/s] 45%|████▌     | 7927/17525 [1:35:18<1:36:27,  1.66it/s] 45%|████▌     | 7928/17525 [1:35:19<1:35:46,  1.67it/s] 45%|████▌     | 7929/17525 [1:35:20<1:35:32,  1.67it/s] 45%|████▌     | 7930/17525 [1:35:20<1:34:57,  1.68it/s]                                                        {'loss': 0.4224, 'grad_norm': 19.590923309326172, 'learning_rate': 1.1518683980076977e-05, 'epoch': 11.31}
 45%|████▌     | 7930/17525 [1:35:20<1:34:57,  1.68it/s] 45%|████▌     | 7931/17525 [1:35:21<1:34:39,  1.69it/s] 45%|████▌     | 7932/17525 [1:35:21<1:34:24,  1.69it/s] 45%|████▌     | 7933/17525 [1:35:22<1:34:23,  1.69it/s] 45%|████▌     | 7934/17525 [1:35:23<1:34:13,  1.70it/s] 45%|████▌     | 7935/17525 [1:35:23<1:33:55,  1.70it/s] 45%|████▌     | 7936/17525 [1:35:24<1:34:03,  1.70it/s] 45%|████▌     | 7937/17525 [1:35:24<1:34:04,  1.70it/s] 45%|████▌     | 7938/17525 [1:35:25<1:33:57,  1.70it/s] 45%|████▌     | 7939/17525 [1:35:25<1:33:59,  1.70it/s] 45%|████▌     | 7940/17525 [1:35:26<1:33:33,  1.71it/s]                                                        {'loss': 0.5102, 'grad_norm': 20.01837921142578, 'learning_rate': 1.1500942883742795e-05, 'epoch': 11.33}
 45%|████▌     | 7940/17525 [1:35:26<1:33:33,  1.71it/s] 45%|████▌     | 7941/17525 [1:35:27<1:33:06,  1.72it/s] 45%|████▌     | 7942/17525 [1:35:27<1:32:44,  1.72it/s] 45%|████▌     | 7943/17525 [1:35:28<1:33:05,  1.72it/s] 45%|████▌     | 7944/17525 [1:35:28<1:33:19,  1.71it/s] 45%|████▌     | 7945/17525 [1:35:29<1:50:49,  1.44it/s] 45%|████▌     | 7946/17525 [1:35:30<1:52:14,  1.42it/s] 45%|████▌     | 7947/17525 [1:35:31<1:46:39,  1.50it/s] 45%|████▌     | 7948/17525 [1:35:31<1:42:35,  1.56it/s] 45%|████▌     | 7949/17525 [1:35:32<1:39:40,  1.60it/s] 45%|████▌     | 7950/17525 [1:35:32<1:37:48,  1.63it/s]                                                        {'loss': 0.4831, 'grad_norm': 7.932424068450928, 'learning_rate': 1.148319695304219e-05, 'epoch': 11.34}
 45%|████▌     | 7950/17525 [1:35:32<1:37:48,  1.63it/s][INFO|trainer.py:3203] 2024-06-25 03:38:54,310 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: c3bbf725-11cd-4222-bcf5-7425b3d6a6a2)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:39:04,429 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:39:04,432 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-7950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 45%|████▌     | 7951/17525 [1:35:43<9:47:40,  3.68s/it] 45%|████▌     | 7952/17525 [1:35:44<7:19:54,  2.76s/it] 45%|████▌     | 7953/17525 [1:35:44<5:36:19,  2.11s/it] 45%|████▌     | 7954/17525 [1:35:45<4:23:35,  1.65s/it] 45%|████▌     | 7955/17525 [1:35:46<3:33:10,  1.34s/it] 45%|████▌     | 7956/17525 [1:35:46<2:57:33,  1.11s/it] 45%|████▌     | 7957/17525 [1:35:47<2:33:19,  1.04it/s] 45%|████▌     | 7958/17525 [1:35:48<2:22:14,  1.12it/s] 45%|████▌     | 7959/17525 [1:35:48<2:08:10,  1.24it/s] 45%|████▌     | 7960/17525 [1:35:49<1:58:21,  1.35it/s]                                                        {'loss': 0.4358, 'grad_norm': 10.167494773864746, 'learning_rate': 1.146544624513279e-05, 'epoch': 11.36}
 45%|████▌     | 7960/17525 [1:35:49<1:58:21,  1.35it/s] 45%|████▌     | 7961/17525 [1:35:49<1:51:47,  1.43it/s] 45%|████▌     | 7962/17525 [1:35:50<1:46:25,  1.50it/s] 45%|████▌     | 7963/17525 [1:35:51<1:43:05,  1.55it/s] 45%|████▌     | 7964/17525 [1:35:51<1:40:24,  1.59it/s] 45%|████▌     | 7965/17525 [1:35:52<1:38:12,  1.62it/s] 45%|████▌     | 7966/17525 [1:35:52<1:36:39,  1.65it/s] 45%|████▌     | 7967/17525 [1:35:53<1:35:45,  1.66it/s] 45%|████▌     | 7968/17525 [1:35:54<1:35:20,  1.67it/s] 45%|████▌     | 7969/17525 [1:35:54<1:34:30,  1.69it/s] 45%|████▌     | 7970/17525 [1:35:55<1:33:59,  1.69it/s]                                                        {'loss': 0.4832, 'grad_norm': 11.839912414550781, 'learning_rate': 1.1447690817187607e-05, 'epoch': 11.37}
 45%|████▌     | 7970/17525 [1:35:55<1:33:59,  1.69it/s] 45%|████▌     | 7971/17525 [1:35:55<1:33:43,  1.70it/s] 45%|████▌     | 7972/17525 [1:35:56<1:33:31,  1.70it/s] 45%|████▌     | 7973/17525 [1:35:56<1:33:21,  1.71it/s] 46%|████▌     | 7974/17525 [1:35:57<1:33:38,  1.70it/s] 46%|████▌     | 7975/17525 [1:35:58<1:33:29,  1.70it/s] 46%|████▌     | 7976/17525 [1:35:58<1:33:20,  1.71it/s] 46%|████▌     | 7977/17525 [1:35:59<1:33:28,  1.70it/s] 46%|████▌     | 7978/17525 [1:35:59<1:33:30,  1.70it/s] 46%|████▌     | 7979/17525 [1:36:00<1:33:19,  1.70it/s] 46%|████▌     | 7980/17525 [1:36:01<1:33:13,  1.71it/s]                                                        {'loss': 0.4077, 'grad_norm': 13.422809600830078, 'learning_rate': 1.1429930726394855e-05, 'epoch': 11.38}
 46%|████▌     | 7980/17525 [1:36:01<1:33:13,  1.71it/s] 46%|████▌     | 7981/17525 [1:36:01<1:33:17,  1.70it/s] 46%|████▌     | 7982/17525 [1:36:02<1:33:11,  1.71it/s] 46%|████▌     | 7983/17525 [1:36:02<1:33:49,  1.69it/s] 46%|████▌     | 7984/17525 [1:36:03<1:33:31,  1.70it/s] 46%|████▌     | 7985/17525 [1:36:03<1:33:15,  1.70it/s] 46%|████▌     | 7986/17525 [1:36:04<1:33:13,  1.71it/s] 46%|████▌     | 7987/17525 [1:36:05<1:32:59,  1.71it/s] 46%|████▌     | 7988/17525 [1:36:05<1:32:44,  1.71it/s] 46%|████▌     | 7989/17525 [1:36:07<2:09:58,  1.22it/s] 46%|████▌     | 7990/17525 [1:36:07<1:59:00,  1.34it/s]                                                        {'loss': 0.4281, 'grad_norm': 14.682693481445312, 'learning_rate': 1.1412166029957772e-05, 'epoch': 11.4}
 46%|████▌     | 7990/17525 [1:36:07<1:59:00,  1.34it/s] 46%|████▌     | 7991/17525 [1:36:08<1:51:27,  1.43it/s] 46%|████▌     | 7992/17525 [1:36:09<1:53:39,  1.40it/s] 46%|████▌     | 7993/17525 [1:36:09<1:48:07,  1.47it/s] 46%|████▌     | 7994/17525 [1:36:10<1:43:57,  1.53it/s] 46%|████▌     | 7995/17525 [1:36:10<1:40:50,  1.57it/s] 46%|████▌     | 7996/17525 [1:36:11<1:38:39,  1.61it/s] 46%|████▌     | 7997/17525 [1:36:12<2:13:26,  1.19it/s] 46%|████▌     | 7998/17525 [1:36:13<2:01:35,  1.31it/s] 46%|████▌     | 7999/17525 [1:36:13<1:52:40,  1.41it/s] 46%|████▌     | 8000/17525 [1:36:14<1:46:22,  1.49it/s]                                                        {'loss': 0.4701, 'grad_norm': 9.751941680908203, 'learning_rate': 1.139439678509442e-05, 'epoch': 11.41}
 46%|████▌     | 8000/17525 [1:36:14<1:46:22,  1.49it/s][INFO|trainer.py:3512] 2024-06-25 03:39:35,873 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:39:35,873 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:39:35,873 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.36it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.59it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.81it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.31it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.56it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.18it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9583835005760193, 'eval_runtime': 4.6146, 'eval_samples_per_second': 96.0, 'eval_steps_per_second': 4.117, 'epoch': 11.41}
 46%|████▌     | 8000/17525 [1:36:19<1:46:22,  1.49it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 46%|████▌     | 8001/17525 [1:36:19<5:22:38,  2.03s/it] 46%|████▌     | 8002/17525 [1:36:20<4:14:48,  1.61s/it] 46%|████▌     | 8003/17525 [1:36:20<3:27:15,  1.31s/it] 46%|████▌     | 8004/17525 [1:36:21<2:55:46,  1.11s/it] 46%|████▌     | 8005/17525 [1:36:22<2:30:57,  1.05it/s] 46%|████▌     | 8006/17525 [1:36:22<2:13:09,  1.19it/s] 46%|████▌     | 8007/17525 [1:36:23<2:00:51,  1.31it/s] 46%|████▌     | 8008/17525 [1:36:23<1:52:05,  1.42it/s] 46%|████▌     | 8009/17525 [1:36:24<1:46:04,  1.50it/s] 46%|████▌     | 8010/17525 [1:36:25<1:41:48,  1.56it/s]                                                        {'loss': 0.4507, 'grad_norm': 13.818065643310547, 'learning_rate': 1.1376623049037519e-05, 'epoch': 11.43}
 46%|████▌     | 8010/17525 [1:36:25<1:41:48,  1.56it/s] 46%|████▌     | 8011/17525 [1:36:25<1:39:07,  1.60it/s] 46%|████▌     | 8012/17525 [1:36:26<1:37:06,  1.63it/s] 46%|████▌     | 8013/17525 [1:36:26<1:35:19,  1.66it/s] 46%|████▌     | 8014/17525 [1:36:27<1:34:08,  1.68it/s] 46%|████▌     | 8015/17525 [1:36:27<1:33:27,  1.70it/s] 46%|████▌     | 8016/17525 [1:36:28<1:32:58,  1.70it/s] 46%|████▌     | 8017/17525 [1:36:29<1:32:45,  1.71it/s] 46%|████▌     | 8018/17525 [1:36:29<1:32:15,  1.72it/s] 46%|████▌     | 8019/17525 [1:36:30<1:32:12,  1.72it/s] 46%|████▌     | 8020/17525 [1:36:30<1:31:58,  1.72it/s]                                                        {'loss': 0.4946, 'grad_norm': 20.715063095092773, 'learning_rate': 1.1358844879034253e-05, 'epoch': 11.44}
 46%|████▌     | 8020/17525 [1:36:30<1:31:58,  1.72it/s] 46%|████▌     | 8021/17525 [1:36:31<1:33:35,  1.69it/s] 46%|████▌     | 8022/17525 [1:36:32<1:33:04,  1.70it/s] 46%|████▌     | 8023/17525 [1:36:32<1:32:30,  1.71it/s] 46%|████▌     | 8024/17525 [1:36:33<1:32:09,  1.72it/s] 46%|████▌     | 8025/17525 [1:36:33<1:31:39,  1.73it/s] 46%|████▌     | 8026/17525 [1:36:34<1:33:12,  1.70it/s] 46%|████▌     | 8027/17525 [1:36:34<1:32:40,  1.71it/s] 46%|████▌     | 8028/17525 [1:36:35<1:32:26,  1.71it/s] 46%|████▌     | 8029/17525 [1:36:36<1:32:17,  1.71it/s] 46%|████▌     | 8030/17525 [1:36:36<1:32:01,  1.72it/s]                                                        {'loss': 0.3872, 'grad_norm': 18.570701599121094, 'learning_rate': 1.1341062332346087e-05, 'epoch': 11.46}
 46%|████▌     | 8030/17525 [1:36:36<1:32:01,  1.72it/s] 46%|████▌     | 8031/17525 [1:36:37<1:32:07,  1.72it/s] 46%|████▌     | 8032/17525 [1:36:37<1:31:55,  1.72it/s] 46%|████▌     | 8033/17525 [1:36:38<1:32:03,  1.72it/s] 46%|████▌     | 8034/17525 [1:36:39<1:38:33,  1.61it/s] 46%|████▌     | 8035/17525 [1:36:39<1:37:19,  1.63it/s] 46%|████▌     | 8036/17525 [1:36:40<1:35:31,  1.66it/s] 46%|████▌     | 8037/17525 [1:36:40<1:34:23,  1.68it/s] 46%|████▌     | 8038/17525 [1:36:41<1:33:19,  1.69it/s] 46%|████▌     | 8039/17525 [1:36:42<1:32:27,  1.71it/s] 46%|████▌     | 8040/17525 [1:36:42<1:31:52,  1.72it/s]                                                        {'loss': 0.4799, 'grad_norm': 14.532072067260742, 'learning_rate': 1.1323275466248585e-05, 'epoch': 11.47}
 46%|████▌     | 8040/17525 [1:36:42<1:31:52,  1.72it/s] 46%|████▌     | 8041/17525 [1:36:43<1:31:43,  1.72it/s] 46%|████▌     | 8042/17525 [1:36:43<1:31:24,  1.73it/s] 46%|████▌     | 8043/17525 [1:36:44<1:31:09,  1.73it/s] 46%|████▌     | 8044/17525 [1:36:44<1:31:14,  1.73it/s] 46%|████▌     | 8045/17525 [1:36:45<1:31:09,  1.73it/s] 46%|████▌     | 8046/17525 [1:36:46<2:08:14,  1.23it/s] 46%|████▌     | 8047/17525 [1:36:47<1:57:12,  1.35it/s] 46%|████▌     | 8048/17525 [1:36:48<1:49:48,  1.44it/s] 46%|████▌     | 8049/17525 [1:36:48<1:44:34,  1.51it/s] 46%|████▌     | 8050/17525 [1:36:49<1:40:33,  1.57it/s]                                                        {'loss': 0.4447, 'grad_norm': 13.226916313171387, 'learning_rate': 1.1305484338031217e-05, 'epoch': 11.48}
 46%|████▌     | 8050/17525 [1:36:49<1:40:33,  1.57it/s] 46%|████▌     | 8051/17525 [1:36:49<1:37:41,  1.62it/s] 46%|████▌     | 8052/17525 [1:36:50<1:35:42,  1.65it/s] 46%|████▌     | 8053/17525 [1:36:50<1:34:10,  1.68it/s] 46%|████▌     | 8054/17525 [1:36:51<1:33:13,  1.69it/s] 46%|████▌     | 8055/17525 [1:36:52<1:32:25,  1.71it/s] 46%|████▌     | 8056/17525 [1:36:52<1:31:53,  1.72it/s] 46%|████▌     | 8057/17525 [1:36:53<1:31:55,  1.72it/s] 46%|████▌     | 8058/17525 [1:36:53<1:31:32,  1.72it/s] 46%|████▌     | 8059/17525 [1:36:54<1:31:16,  1.73it/s] 46%|████▌     | 8060/17525 [1:36:54<1:31:05,  1.73it/s]                                                        {'loss': 0.597, 'grad_norm': 16.839216232299805, 'learning_rate': 1.1287689004997186e-05, 'epoch': 11.5}
 46%|████▌     | 8060/17525 [1:36:54<1:31:05,  1.73it/s] 46%|████▌     | 8061/17525 [1:36:55<1:30:53,  1.74it/s] 46%|████▌     | 8062/17525 [1:36:56<1:30:49,  1.74it/s] 46%|████▌     | 8063/17525 [1:36:56<1:30:48,  1.74it/s] 46%|████▌     | 8064/17525 [1:36:57<1:31:00,  1.73it/s] 46%|████▌     | 8065/17525 [1:36:57<1:31:00,  1.73it/s] 46%|████▌     | 8066/17525 [1:36:58<1:31:07,  1.73it/s] 46%|████▌     | 8067/17525 [1:36:58<1:30:54,  1.73it/s] 46%|████▌     | 8068/17525 [1:36:59<1:30:51,  1.73it/s] 46%|████▌     | 8069/17525 [1:37:00<1:30:43,  1.74it/s] 46%|████▌     | 8070/17525 [1:37:00<1:30:39,  1.74it/s]                                                        {'loss': 0.5094, 'grad_norm': 5.555300712585449, 'learning_rate': 1.1269889524463238e-05, 'epoch': 11.51}
 46%|████▌     | 8070/17525 [1:37:00<1:30:39,  1.74it/s] 46%|████▌     | 8071/17525 [1:37:01<1:31:06,  1.73it/s] 46%|████▌     | 8072/17525 [1:37:01<1:30:55,  1.73it/s] 46%|████▌     | 8073/17525 [1:37:02<1:31:50,  1.72it/s] 46%|████▌     | 8074/17525 [1:37:03<1:31:25,  1.72it/s] 46%|████▌     | 8075/17525 [1:37:03<1:32:04,  1.71it/s] 46%|████▌     | 8076/17525 [1:37:04<1:31:24,  1.72it/s] 46%|████▌     | 8077/17525 [1:37:04<1:31:04,  1.73it/s] 46%|████▌     | 8078/17525 [1:37:05<1:30:52,  1.73it/s] 46%|████▌     | 8079/17525 [1:37:05<1:30:42,  1.74it/s] 46%|████▌     | 8080/17525 [1:37:06<1:30:32,  1.74it/s]                                                        {'loss': 0.4962, 'grad_norm': 46.358245849609375, 'learning_rate': 1.1252085953759477e-05, 'epoch': 11.53}
 46%|████▌     | 8080/17525 [1:37:06<1:30:32,  1.74it/s] 46%|████▌     | 8081/17525 [1:37:07<1:30:36,  1.74it/s] 46%|████▌     | 8082/17525 [1:37:07<1:30:33,  1.74it/s] 46%|████▌     | 8083/17525 [1:37:08<1:47:42,  1.46it/s] 46%|████▌     | 8084/17525 [1:37:09<1:42:33,  1.53it/s] 46%|████▌     | 8085/17525 [1:37:09<1:39:00,  1.59it/s] 46%|████▌     | 8086/17525 [1:37:10<1:36:28,  1.63it/s] 46%|████▌     | 8087/17525 [1:37:10<1:34:42,  1.66it/s] 46%|████▌     | 8088/17525 [1:37:11<1:33:29,  1.68it/s] 46%|████▌     | 8089/17525 [1:37:12<1:32:36,  1.70it/s] 46%|████▌     | 8090/17525 [1:37:12<1:31:52,  1.71it/s]                                                        {'loss': 0.4969, 'grad_norm': 30.800771713256836, 'learning_rate': 1.1234278350229177e-05, 'epoch': 11.54}
 46%|████▌     | 8090/17525 [1:37:12<1:31:52,  1.71it/s] 46%|████▌     | 8091/17525 [1:37:13<1:31:40,  1.72it/s] 46%|████▌     | 8092/17525 [1:37:13<1:31:27,  1.72it/s] 46%|████▌     | 8093/17525 [1:37:14<1:31:01,  1.73it/s] 46%|████▌     | 8094/17525 [1:37:14<1:30:45,  1.73it/s] 46%|████▌     | 8095/17525 [1:37:15<1:30:37,  1.73it/s] 46%|████▌     | 8096/17525 [1:37:16<1:31:54,  1.71it/s] 46%|████▌     | 8097/17525 [1:37:16<1:31:30,  1.72it/s] 46%|████▌     | 8098/17525 [1:37:17<1:31:17,  1.72it/s] 46%|████▌     | 8099/17525 [1:37:17<1:31:00,  1.73it/s] 46%|████▌     | 8100/17525 [1:37:18<1:30:46,  1.73it/s]                                                        {'loss': 0.5326, 'grad_norm': 13.119623184204102, 'learning_rate': 1.1216466771228612e-05, 'epoch': 11.55}
 46%|████▌     | 8100/17525 [1:37:18<1:30:46,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:40:39,800 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:40:39,800 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:40:39,800 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9621131420135498, 'eval_runtime': 4.5968, 'eval_samples_per_second': 96.372, 'eval_steps_per_second': 4.133, 'epoch': 11.55}
 46%|████▌     | 8100/17525 [1:37:23<1:30:46,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:40:44,400 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7acd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 0a1b6aed-d73d-4359-b842-5575a02bbc07)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:40:54,463 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:40:54,466 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 46%|████▌     | 8101/17525 [1:37:33<13:08:35,  5.02s/it] 46%|████▌     | 8102/17525 [1:37:34<9:39:10,  3.69s/it]  46%|████▌     | 8103/17525 [1:37:34<7:12:20,  2.75s/it] 46%|████▌     | 8104/17525 [1:37:35<5:30:02,  2.10s/it] 46%|████▌     | 8105/17525 [1:37:36<4:18:29,  1.65s/it] 46%|████▋     | 8106/17525 [1:37:37<3:45:10,  1.43s/it] 46%|████▋     | 8107/17525 [1:37:37<3:04:47,  1.18s/it] 46%|████▋     | 8108/17525 [1:37:38<2:36:44,  1.00it/s] 46%|████▋     | 8109/17525 [1:37:38<2:16:37,  1.15it/s] 46%|████▋     | 8110/17525 [1:37:39<2:02:46,  1.28it/s]                                                        {'loss': 0.4719, 'grad_norm': 11.782322883605957, 'learning_rate': 1.1198651274126844e-05, 'epoch': 11.57}
 46%|████▋     | 8110/17525 [1:37:39<2:02:46,  1.28it/s] 46%|████▋     | 8111/17525 [1:37:39<1:54:00,  1.38it/s] 46%|████▋     | 8112/17525 [1:37:40<1:46:34,  1.47it/s] 46%|████▋     | 8113/17525 [1:37:41<1:41:38,  1.54it/s] 46%|████▋     | 8114/17525 [1:37:41<1:38:10,  1.60it/s] 46%|████▋     | 8115/17525 [1:37:42<1:35:50,  1.64it/s] 46%|████▋     | 8116/17525 [1:37:42<1:33:59,  1.67it/s] 46%|████▋     | 8117/17525 [1:37:43<1:32:53,  1.69it/s] 46%|████▋     | 8118/17525 [1:37:43<1:31:59,  1.70it/s] 46%|████▋     | 8119/17525 [1:37:44<1:31:23,  1.72it/s] 46%|████▋     | 8120/17525 [1:37:45<1:31:03,  1.72it/s]                                                        {'loss': 0.4731, 'grad_norm': 5.713451385498047, 'learning_rate': 1.1180831916305568e-05, 'epoch': 11.58}
 46%|████▋     | 8120/17525 [1:37:45<1:31:03,  1.72it/s] 46%|████▋     | 8121/17525 [1:37:45<1:30:54,  1.72it/s] 46%|████▋     | 8122/17525 [1:37:46<1:30:36,  1.73it/s] 46%|████▋     | 8123/17525 [1:37:46<1:30:38,  1.73it/s] 46%|████▋     | 8124/17525 [1:37:47<1:30:31,  1.73it/s] 46%|████▋     | 8125/17525 [1:37:48<1:30:36,  1.73it/s] 46%|████▋     | 8126/17525 [1:37:49<1:50:32,  1.42it/s] 46%|████▋     | 8127/17525 [1:37:49<1:45:23,  1.49it/s] 46%|████▋     | 8128/17525 [1:37:50<1:40:32,  1.56it/s] 46%|████▋     | 8129/17525 [1:37:50<1:37:31,  1.61it/s] 46%|████▋     | 8130/17525 [1:37:51<1:35:58,  1.63it/s]                                                        {'loss': 0.4907, 'grad_norm': 10.121692657470703, 'learning_rate': 1.1163008755158915e-05, 'epoch': 11.6}
 46%|████▋     | 8130/17525 [1:37:51<1:35:58,  1.63it/s] 46%|████▋     | 8131/17525 [1:37:51<1:34:14,  1.66it/s] 46%|████▋     | 8132/17525 [1:37:52<1:32:53,  1.69it/s] 46%|████▋     | 8133/17525 [1:37:53<1:32:03,  1.70it/s] 46%|████▋     | 8134/17525 [1:37:53<1:31:29,  1.71it/s] 46%|████▋     | 8135/17525 [1:37:54<1:31:00,  1.72it/s] 46%|████▋     | 8136/17525 [1:37:54<1:30:32,  1.73it/s] 46%|████▋     | 8137/17525 [1:37:55<1:30:16,  1.73it/s] 46%|████▋     | 8138/17525 [1:37:55<1:30:03,  1.74it/s] 46%|████▋     | 8139/17525 [1:37:56<1:29:59,  1.74it/s] 46%|████▋     | 8140/17525 [1:37:57<1:31:02,  1.72it/s]                                                        {'loss': 0.4072, 'grad_norm': 13.216365814208984, 'learning_rate': 1.1145181848093254e-05, 'epoch': 11.61}
 46%|████▋     | 8140/17525 [1:37:57<1:31:02,  1.72it/s] 46%|████▋     | 8141/17525 [1:37:57<1:30:53,  1.72it/s] 46%|████▋     | 8142/17525 [1:37:58<1:30:33,  1.73it/s] 46%|████▋     | 8143/17525 [1:37:58<1:30:12,  1.73it/s] 46%|████▋     | 8144/17525 [1:37:59<1:30:06,  1.73it/s] 46%|████▋     | 8145/17525 [1:37:59<1:30:03,  1.74it/s] 46%|████▋     | 8146/17525 [1:38:00<1:30:06,  1.73it/s] 46%|████▋     | 8147/17525 [1:38:01<1:30:54,  1.72it/s] 46%|████▋     | 8148/17525 [1:38:01<1:30:40,  1.72it/s] 46%|████▋     | 8149/17525 [1:38:02<1:30:21,  1.73it/s] 47%|████▋     | 8150/17525 [1:38:02<1:30:10,  1.73it/s]                                                        {'loss': 0.4658, 'grad_norm': 9.879809379577637, 'learning_rate': 1.1127351252527029e-05, 'epoch': 11.63}
 47%|████▋     | 8150/17525 [1:38:02<1:30:10,  1.73it/s] 47%|████▋     | 8151/17525 [1:38:03<1:30:11,  1.73it/s] 47%|████▋     | 8152/17525 [1:38:04<1:29:59,  1.74it/s] 47%|████▋     | 8153/17525 [1:38:04<1:46:38,  1.46it/s] 47%|████▋     | 8154/17525 [1:38:05<1:41:34,  1.54it/s] 47%|████▋     | 8155/17525 [1:38:06<1:38:16,  1.59it/s] 47%|████▋     | 8156/17525 [1:38:06<1:35:37,  1.63it/s] 47%|████▋     | 8157/17525 [1:38:07<1:33:41,  1.67it/s] 47%|████▋     | 8158/17525 [1:38:07<1:32:21,  1.69it/s] 47%|████▋     | 8159/17525 [1:38:08<1:31:46,  1.70it/s] 47%|████▋     | 8160/17525 [1:38:08<1:31:36,  1.70it/s]                                                        {'loss': 0.5643, 'grad_norm': 8.924553871154785, 'learning_rate': 1.1109517025890564e-05, 'epoch': 11.64}
 47%|████▋     | 8160/17525 [1:38:08<1:31:36,  1.70it/s] 47%|████▋     | 8161/17525 [1:38:09<1:47:57,  1.45it/s] 47%|████▋     | 8162/17525 [1:38:10<1:49:07,  1.43it/s] 47%|████▋     | 8163/17525 [1:38:11<1:43:24,  1.51it/s] 47%|████▋     | 8164/17525 [1:38:12<1:56:14,  1.34it/s] 47%|████▋     | 8165/17525 [1:38:12<1:48:16,  1.44it/s] 47%|████▋     | 8166/17525 [1:38:13<1:43:00,  1.51it/s] 47%|████▋     | 8167/17525 [1:38:13<1:39:07,  1.57it/s] 47%|████▋     | 8168/17525 [1:38:14<1:36:18,  1.62it/s] 47%|████▋     | 8169/17525 [1:38:15<1:34:18,  1.65it/s] 47%|████▋     | 8170/17525 [1:38:15<1:33:07,  1.67it/s]                                                        {'loss': 0.4844, 'grad_norm': 12.524065017700195, 'learning_rate': 1.109167922562587e-05, 'epoch': 11.65}
 47%|████▋     | 8170/17525 [1:38:15<1:33:07,  1.67it/s] 47%|████▋     | 8171/17525 [1:38:16<1:34:44,  1.65it/s] 47%|████▋     | 8172/17525 [1:38:16<1:33:09,  1.67it/s] 47%|████▋     | 8173/17525 [1:38:17<1:32:00,  1.69it/s] 47%|████▋     | 8174/17525 [1:38:17<1:31:11,  1.71it/s] 47%|████▋     | 8175/17525 [1:38:18<1:30:44,  1.72it/s] 47%|████▋     | 8176/17525 [1:38:19<1:30:29,  1.72it/s] 47%|████▋     | 8177/17525 [1:38:20<1:45:05,  1.48it/s] 47%|████▋     | 8178/17525 [1:38:20<1:40:24,  1.55it/s] 47%|████▋     | 8179/17525 [1:38:21<1:37:18,  1.60it/s] 47%|████▋     | 8180/17525 [1:38:21<1:35:11,  1.64it/s]                                                        {'loss': 0.4835, 'grad_norm': 10.13117504119873, 'learning_rate': 1.1073837909186485e-05, 'epoch': 11.67}
 47%|████▋     | 8180/17525 [1:38:21<1:35:11,  1.64it/s] 47%|████▋     | 8181/17525 [1:38:22<1:34:10,  1.65it/s] 47%|████▋     | 8182/17525 [1:38:22<1:33:24,  1.67it/s] 47%|████▋     | 8183/17525 [1:38:23<1:32:29,  1.68it/s] 47%|████▋     | 8184/17525 [1:38:24<1:31:57,  1.69it/s] 47%|████▋     | 8185/17525 [1:38:24<1:31:26,  1.70it/s] 47%|████▋     | 8186/17525 [1:38:25<1:31:12,  1.71it/s] 47%|████▋     | 8187/17525 [1:38:25<1:30:46,  1.71it/s] 47%|████▋     | 8188/17525 [1:38:26<1:30:34,  1.72it/s] 47%|████▋     | 8189/17525 [1:38:26<1:30:18,  1.72it/s] 47%|████▋     | 8190/17525 [1:38:27<1:29:57,  1.73it/s]                                                        {'loss': 0.5446, 'grad_norm': 7.733379364013672, 'learning_rate': 1.1055993134037248e-05, 'epoch': 11.68}
 47%|████▋     | 8190/17525 [1:38:27<1:29:57,  1.73it/s] 47%|████▋     | 8191/17525 [1:38:28<1:29:59,  1.73it/s] 47%|████▋     | 8192/17525 [1:38:28<1:29:46,  1.73it/s] 47%|████▋     | 8193/17525 [1:38:29<1:29:26,  1.74it/s] 47%|████▋     | 8194/17525 [1:38:29<1:29:21,  1.74it/s] 47%|████▋     | 8195/17525 [1:38:30<1:29:27,  1.74it/s] 47%|████▋     | 8196/17525 [1:38:31<1:29:30,  1.74it/s] 47%|████▋     | 8197/17525 [1:38:31<1:29:31,  1.74it/s] 47%|████▋     | 8198/17525 [1:38:32<1:29:16,  1.74it/s] 47%|████▋     | 8199/17525 [1:38:32<1:29:28,  1.74it/s] 47%|████▋     | 8200/17525 [1:38:33<1:37:16,  1.60it/s]                                                        {'loss': 0.4191, 'grad_norm': 7.796395301818848, 'learning_rate': 1.1038144957654158e-05, 'epoch': 11.7}
 47%|████▋     | 8200/17525 [1:38:33<1:37:16,  1.60it/s][INFO|trainer.py:3512] 2024-06-25 03:41:54,884 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:41:54,884 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:41:54,884 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9805474281311035, 'eval_runtime': 4.596, 'eval_samples_per_second': 96.389, 'eval_steps_per_second': 4.134, 'epoch': 11.7}
 47%|████▋     | 8200/17525 [1:38:38<1:37:16,  1.60it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 47%|████▋     | 8201/17525 [1:38:38<5:09:41,  1.99s/it] 47%|████▋     | 8202/17525 [1:38:39<4:03:31,  1.57s/it] 47%|████▋     | 8203/17525 [1:38:39<3:18:24,  1.28s/it] 47%|████▋     | 8204/17525 [1:38:40<2:45:50,  1.07s/it] 47%|████▋     | 8205/17525 [1:38:41<2:22:59,  1.09it/s] 47%|████▋     | 8206/17525 [1:38:41<2:06:47,  1.23it/s] 47%|████▋     | 8207/17525 [1:38:42<1:55:28,  1.34it/s] 47%|████▋     | 8208/17525 [1:38:42<1:47:22,  1.45it/s] 47%|████▋     | 8209/17525 [1:38:43<1:42:23,  1.52it/s] 47%|████▋     | 8210/17525 [1:38:43<1:38:18,  1.58it/s]                                                        {'loss': 0.3849, 'grad_norm': 24.436365127563477, 'learning_rate': 1.1020293437524165e-05, 'epoch': 11.71}
 47%|████▋     | 8210/17525 [1:38:43<1:38:18,  1.58it/s] 47%|████▋     | 8211/17525 [1:38:44<1:35:35,  1.62it/s] 47%|████▋     | 8212/17525 [1:38:45<1:33:30,  1.66it/s] 47%|████▋     | 8213/17525 [1:38:45<1:32:16,  1.68it/s] 47%|████▋     | 8214/17525 [1:38:46<1:31:24,  1.70it/s] 47%|████▋     | 8215/17525 [1:38:46<1:31:57,  1.69it/s] 47%|████▋     | 8216/17525 [1:38:47<1:31:06,  1.70it/s] 47%|████▋     | 8217/17525 [1:38:47<1:30:36,  1.71it/s] 47%|████▋     | 8218/17525 [1:38:48<1:30:15,  1.72it/s] 47%|████▋     | 8219/17525 [1:38:49<1:29:56,  1.72it/s] 47%|████▋     | 8220/17525 [1:38:49<1:29:39,  1.73it/s]                                                        {'loss': 0.4148, 'grad_norm': 9.100889205932617, 'learning_rate': 1.100243863114498e-05, 'epoch': 11.73}
 47%|████▋     | 8220/17525 [1:38:49<1:29:39,  1.73it/s] 47%|████▋     | 8221/17525 [1:38:50<1:29:46,  1.73it/s] 47%|████▋     | 8222/17525 [1:38:50<1:29:49,  1.73it/s] 47%|████▋     | 8223/17525 [1:38:51<1:30:01,  1.72it/s] 47%|████▋     | 8224/17525 [1:38:51<1:29:53,  1.72it/s] 47%|████▋     | 8225/17525 [1:38:52<1:29:41,  1.73it/s] 47%|████▋     | 8226/17525 [1:38:53<1:29:57,  1.72it/s] 47%|████▋     | 8227/17525 [1:38:53<1:29:57,  1.72it/s] 47%|████▋     | 8228/17525 [1:38:54<1:29:40,  1.73it/s] 47%|████▋     | 8229/17525 [1:38:54<1:29:18,  1.73it/s] 47%|████▋     | 8230/17525 [1:38:55<1:29:23,  1.73it/s]                                                        {'loss': 0.4744, 'grad_norm': 7.887765884399414, 'learning_rate': 1.0984580596024911e-05, 'epoch': 11.74}
 47%|████▋     | 8230/17525 [1:38:55<1:29:23,  1.73it/s] 47%|████▋     | 8231/17525 [1:38:56<1:29:29,  1.73it/s] 47%|████▋     | 8232/17525 [1:38:56<1:29:29,  1.73it/s] 47%|████▋     | 8233/17525 [1:38:57<1:29:28,  1.73it/s] 47%|████▋     | 8234/17525 [1:38:57<1:29:19,  1.73it/s] 47%|████▋     | 8235/17525 [1:38:58<1:29:22,  1.73it/s] 47%|████▋     | 8236/17525 [1:38:58<1:29:17,  1.73it/s] 47%|████▋     | 8237/17525 [1:38:59<1:29:15,  1.73it/s] 47%|████▋     | 8238/17525 [1:39:00<1:28:59,  1.74it/s] 47%|████▋     | 8239/17525 [1:39:00<1:29:08,  1.74it/s] 47%|████▋     | 8240/17525 [1:39:01<1:29:09,  1.74it/s]                                                        {'loss': 0.5059, 'grad_norm': 24.605920791625977, 'learning_rate': 1.0966719389682656e-05, 'epoch': 11.75}
 47%|████▋     | 8240/17525 [1:39:01<1:29:09,  1.74it/s] 47%|████▋     | 8241/17525 [1:39:01<1:29:12,  1.73it/s] 47%|████▋     | 8242/17525 [1:39:02<1:29:00,  1.74it/s] 47%|████▋     | 8243/17525 [1:39:02<1:28:54,  1.74it/s] 47%|████▋     | 8244/17525 [1:39:03<1:49:17,  1.42it/s] 47%|████▋     | 8245/17525 [1:39:04<1:43:17,  1.50it/s] 47%|████▋     | 8246/17525 [1:39:05<1:39:04,  1.56it/s] 47%|████▋     | 8247/17525 [1:39:05<1:37:49,  1.58it/s] 47%|████▋     | 8248/17525 [1:39:06<1:35:14,  1.62it/s] 47%|████▋     | 8249/17525 [1:39:06<1:33:23,  1.66it/s] 47%|████▋     | 8250/17525 [1:39:07<1:32:03,  1.68it/s]                                                        {'loss': 0.516, 'grad_norm': 18.105804443359375, 'learning_rate': 1.0948855069647128e-05, 'epoch': 11.77}
 47%|████▋     | 8250/17525 [1:39:07<1:32:03,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 03:42:28,835 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a5af10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 77ca4fc1-08be-4fef-9b62-70ff0ce5c885)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:42:38,898 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:42:38,900 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 47%|████▋     | 8251/17525 [1:39:18<9:24:25,  3.65s/it] 47%|████▋     | 8252/17525 [1:39:18<7:02:11,  2.73s/it] 47%|████▋     | 8253/17525 [1:39:19<5:22:11,  2.08s/it] 47%|████▋     | 8254/17525 [1:39:19<4:12:25,  1.63s/it] 47%|████▋     | 8255/17525 [1:39:20<3:23:14,  1.32s/it] 47%|████▋     | 8256/17525 [1:39:21<2:49:10,  1.10s/it] 47%|████▋     | 8257/17525 [1:39:21<2:25:11,  1.06it/s] 47%|████▋     | 8258/17525 [1:39:22<2:08:32,  1.20it/s] 47%|████▋     | 8259/17525 [1:39:22<1:56:52,  1.32it/s] 47%|████▋     | 8260/17525 [1:39:23<1:48:32,  1.42it/s]                                                        {'loss': 0.4262, 'grad_norm': 13.811328887939453, 'learning_rate': 1.0930987693457273e-05, 'epoch': 11.78}
 47%|████▋     | 8260/17525 [1:39:23<1:48:32,  1.42it/s] 47%|████▋     | 8261/17525 [1:39:24<2:11:09,  1.18it/s] 47%|████▋     | 8262/17525 [1:39:25<1:58:39,  1.30it/s] 47%|████▋     | 8263/17525 [1:39:25<1:49:58,  1.40it/s] 47%|████▋     | 8264/17525 [1:39:26<1:43:54,  1.49it/s] 47%|████▋     | 8265/17525 [1:39:26<1:39:17,  1.55it/s] 47%|████▋     | 8266/17525 [1:39:27<1:36:17,  1.60it/s] 47%|████▋     | 8267/17525 [1:39:28<1:33:55,  1.64it/s] 47%|████▋     | 8268/17525 [1:39:28<1:32:26,  1.67it/s] 47%|████▋     | 8269/17525 [1:39:29<1:31:27,  1.69it/s] 47%|████▋     | 8270/17525 [1:39:29<1:30:42,  1.70it/s]                                                        {'loss': 0.4267, 'grad_norm': 15.53768253326416, 'learning_rate': 1.0913117318661886e-05, 'epoch': 11.8}
 47%|████▋     | 8270/17525 [1:39:29<1:30:42,  1.70it/s] 47%|████▋     | 8271/17525 [1:39:30<1:30:21,  1.71it/s] 47%|████▋     | 8272/17525 [1:39:30<1:29:56,  1.71it/s] 47%|████▋     | 8273/17525 [1:39:31<1:29:33,  1.72it/s] 47%|████▋     | 8274/17525 [1:39:32<1:29:19,  1.73it/s] 47%|████▋     | 8275/17525 [1:39:32<1:29:07,  1.73it/s] 47%|████▋     | 8276/17525 [1:39:33<1:29:04,  1.73it/s] 47%|████▋     | 8277/17525 [1:39:33<1:29:02,  1.73it/s] 47%|████▋     | 8278/17525 [1:39:34<1:28:49,  1.73it/s] 47%|████▋     | 8279/17525 [1:39:35<1:28:41,  1.74it/s] 47%|████▋     | 8280/17525 [1:39:35<1:28:39,  1.74it/s]                                                        {'loss': 0.4631, 'grad_norm': 9.931090354919434, 'learning_rate': 1.08952440028194e-05, 'epoch': 11.81}
 47%|████▋     | 8280/17525 [1:39:35<1:28:39,  1.74it/s] 47%|████▋     | 8281/17525 [1:39:36<1:28:48,  1.73it/s] 47%|████▋     | 8282/17525 [1:39:36<1:28:41,  1.74it/s] 47%|████▋     | 8283/17525 [1:39:37<1:28:47,  1.73it/s] 47%|████▋     | 8284/17525 [1:39:37<1:28:42,  1.74it/s] 47%|████▋     | 8285/17525 [1:39:39<1:58:15,  1.30it/s] 47%|████▋     | 8286/17525 [1:39:40<2:11:23,  1.17it/s] 47%|████▋     | 8287/17525 [1:39:40<1:58:39,  1.30it/s] 47%|████▋     | 8288/17525 [1:39:41<1:49:38,  1.40it/s] 47%|████▋     | 8289/17525 [1:39:41<1:43:18,  1.49it/s] 47%|████▋     | 8290/17525 [1:39:42<1:47:35,  1.43it/s]                                                        {'loss': 0.4156, 'grad_norm': 15.873477935791016, 'learning_rate': 1.0877367803497742e-05, 'epoch': 11.83}
 47%|████▋     | 8290/17525 [1:39:42<1:47:35,  1.43it/s] 47%|████▋     | 8291/17525 [1:39:43<1:41:56,  1.51it/s] 47%|████▋     | 8292/17525 [1:39:43<1:37:49,  1.57it/s] 47%|████▋     | 8293/17525 [1:39:44<1:34:55,  1.62it/s] 47%|████▋     | 8294/17525 [1:39:44<1:33:11,  1.65it/s] 47%|████▋     | 8295/17525 [1:39:45<1:31:52,  1.67it/s] 47%|████▋     | 8296/17525 [1:39:46<1:30:52,  1.69it/s] 47%|████▋     | 8297/17525 [1:39:46<1:30:06,  1.71it/s] 47%|████▋     | 8298/17525 [1:39:47<1:29:39,  1.72it/s] 47%|████▋     | 8299/17525 [1:39:48<1:49:27,  1.40it/s] 47%|████▋     | 8300/17525 [1:39:48<1:43:03,  1.49it/s]                                                        {'loss': 0.4462, 'grad_norm': 17.329303741455078, 'learning_rate': 1.0859488778274116e-05, 'epoch': 11.84}
 47%|████▋     | 8300/17525 [1:39:48<1:43:03,  1.49it/s][INFO|trainer.py:3512] 2024-06-25 03:43:10,244 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:43:10,244 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:43:10,244 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.82it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.87it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9542235732078552, 'eval_runtime': 4.591, 'eval_samples_per_second': 96.494, 'eval_steps_per_second': 4.139, 'epoch': 11.84}
 47%|████▋     | 8300/17525 [1:39:53<1:43:03,  1.49it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 47%|████▋     | 8301/17525 [1:39:54<5:10:46,  2.02s/it] 47%|████▋     | 8302/17525 [1:39:54<4:03:59,  1.59s/it] 47%|████▋     | 8303/17525 [1:39:55<3:17:25,  1.28s/it] 47%|████▋     | 8304/17525 [1:39:55<2:44:44,  1.07s/it] 47%|████▋     | 8305/17525 [1:39:56<2:22:01,  1.08it/s] 47%|████▋     | 8306/17525 [1:39:56<2:05:50,  1.22it/s] 47%|████▋     | 8307/17525 [1:39:57<1:54:36,  1.34it/s] 47%|████▋     | 8308/17525 [1:39:58<2:05:53,  1.22it/s] 47%|████▋     | 8309/17525 [1:39:59<1:54:40,  1.34it/s] 47%|████▋     | 8310/17525 [1:39:59<1:46:45,  1.44it/s]                                                        {'loss': 0.4424, 'grad_norm': 11.424227714538574, 'learning_rate': 1.0841606984734832e-05, 'epoch': 11.85}
 47%|████▋     | 8310/17525 [1:39:59<1:46:45,  1.44it/s] 47%|████▋     | 8311/17525 [1:40:00<1:41:20,  1.52it/s] 47%|████▋     | 8312/17525 [1:40:00<1:37:33,  1.57it/s] 47%|████▋     | 8313/17525 [1:40:01<1:40:51,  1.52it/s] 47%|████▋     | 8314/17525 [1:40:02<1:36:58,  1.58it/s] 47%|████▋     | 8315/17525 [1:40:02<1:34:14,  1.63it/s] 47%|████▋     | 8316/17525 [1:40:03<1:32:20,  1.66it/s] 47%|████▋     | 8317/17525 [1:40:03<1:31:06,  1.68it/s] 47%|████▋     | 8318/17525 [1:40:04<1:30:21,  1.70it/s] 47%|████▋     | 8319/17525 [1:40:05<1:46:14,  1.44it/s] 47%|████▋     | 8320/17525 [1:40:05<1:40:58,  1.52it/s]                                                        {'loss': 0.4741, 'grad_norm': 12.33713436126709, 'learning_rate': 1.0823722480475114e-05, 'epoch': 11.87}
 47%|████▋     | 8320/17525 [1:40:05<1:40:58,  1.52it/s] 47%|████▋     | 8321/17525 [1:40:06<1:37:33,  1.57it/s] 47%|████▋     | 8322/17525 [1:40:07<1:34:54,  1.62it/s] 47%|████▋     | 8323/17525 [1:40:07<1:33:02,  1.65it/s] 47%|████▋     | 8324/17525 [1:40:08<1:32:34,  1.66it/s] 48%|████▊     | 8325/17525 [1:40:08<1:32:15,  1.66it/s] 48%|████▊     | 8326/17525 [1:40:09<1:31:06,  1.68it/s] 48%|████▊     | 8327/17525 [1:40:09<1:30:13,  1.70it/s] 48%|████▊     | 8328/17525 [1:40:10<1:29:26,  1.71it/s] 48%|████▊     | 8329/17525 [1:40:11<1:29:02,  1.72it/s] 48%|████▊     | 8330/17525 [1:40:11<1:28:45,  1.73it/s]                                                        {'loss': 0.5048, 'grad_norm': 14.863032341003418, 'learning_rate': 1.0805835323098915e-05, 'epoch': 11.88}
 48%|████▊     | 8330/17525 [1:40:11<1:28:45,  1.73it/s] 48%|████▊     | 8331/17525 [1:40:12<1:28:43,  1.73it/s] 48%|████▊     | 8332/17525 [1:40:12<1:28:40,  1.73it/s] 48%|████▊     | 8333/17525 [1:40:13<1:29:45,  1.71it/s] 48%|████▊     | 8334/17525 [1:40:14<1:29:31,  1.71it/s] 48%|████▊     | 8335/17525 [1:40:14<1:29:07,  1.72it/s] 48%|████▊     | 8336/17525 [1:40:15<1:28:43,  1.73it/s] 48%|████▊     | 8337/17525 [1:40:15<1:29:46,  1.71it/s] 48%|████▊     | 8338/17525 [1:40:16<1:29:13,  1.72it/s] 48%|████▊     | 8339/17525 [1:40:16<1:28:57,  1.72it/s] 48%|████▊     | 8340/17525 [1:40:17<1:28:51,  1.72it/s]                                                        {'loss': 0.4469, 'grad_norm': 10.172266006469727, 'learning_rate': 1.0787945570218738e-05, 'epoch': 11.9}
 48%|████▊     | 8340/17525 [1:40:17<1:28:51,  1.72it/s] 48%|████▊     | 8341/17525 [1:40:18<1:28:44,  1.72it/s] 48%|████▊     | 8342/17525 [1:40:18<1:28:40,  1.73it/s] 48%|████▊     | 8343/17525 [1:40:19<1:28:20,  1.73it/s] 48%|████▊     | 8344/17525 [1:40:19<1:28:21,  1.73it/s] 48%|████▊     | 8345/17525 [1:40:20<1:28:08,  1.74it/s] 48%|████▊     | 8346/17525 [1:40:20<1:28:20,  1.73it/s] 48%|████▊     | 8347/17525 [1:40:21<1:28:29,  1.73it/s] 48%|████▊     | 8348/17525 [1:40:22<1:28:20,  1.73it/s] 48%|████▊     | 8349/17525 [1:40:22<1:28:15,  1.73it/s] 48%|████▊     | 8350/17525 [1:40:23<1:28:27,  1.73it/s]                                                        {'loss': 0.537, 'grad_norm': 7.324500560760498, 'learning_rate': 1.0770053279455441e-05, 'epoch': 11.91}
 48%|████▊     | 8350/17525 [1:40:23<1:28:27,  1.73it/s] 48%|████▊     | 8351/17525 [1:40:23<1:28:55,  1.72it/s] 48%|████▊     | 8352/17525 [1:40:24<1:29:09,  1.71it/s] 48%|████▊     | 8353/17525 [1:40:25<1:29:07,  1.72it/s] 48%|████▊     | 8354/17525 [1:40:25<1:29:06,  1.72it/s] 48%|████▊     | 8355/17525 [1:40:26<1:28:45,  1.72it/s] 48%|████▊     | 8356/17525 [1:40:26<1:28:40,  1.72it/s] 48%|████▊     | 8357/17525 [1:40:27<1:28:34,  1.73it/s] 48%|████▊     | 8358/17525 [1:40:27<1:28:25,  1.73it/s] 48%|████▊     | 8359/17525 [1:40:28<1:28:21,  1.73it/s] 48%|████▊     | 8360/17525 [1:40:29<1:28:32,  1.73it/s]                                                        {'loss': 0.4116, 'grad_norm': 15.7454252243042, 'learning_rate': 1.075215850843806e-05, 'epoch': 11.93}
 48%|████▊     | 8360/17525 [1:40:29<1:28:32,  1.73it/s] 48%|████▊     | 8361/17525 [1:40:29<1:29:02,  1.72it/s] 48%|████▊     | 8362/17525 [1:40:30<1:28:37,  1.72it/s] 48%|████▊     | 8363/17525 [1:40:30<1:28:06,  1.73it/s] 48%|████▊     | 8364/17525 [1:40:31<1:28:04,  1.73it/s] 48%|████▊     | 8365/17525 [1:40:31<1:28:46,  1.72it/s] 48%|████▊     | 8366/17525 [1:40:32<1:28:22,  1.73it/s] 48%|████▊     | 8367/17525 [1:40:33<1:28:06,  1.73it/s] 48%|████▊     | 8368/17525 [1:40:33<1:28:06,  1.73it/s] 48%|████▊     | 8369/17525 [1:40:34<1:27:58,  1.73it/s] 48%|████▊     | 8370/17525 [1:40:34<1:27:49,  1.74it/s]                                                        {'loss': 0.4276, 'grad_norm': 16.08527183532715, 'learning_rate': 1.073426131480362e-05, 'epoch': 11.94}
 48%|████▊     | 8370/17525 [1:40:34<1:27:49,  1.74it/s] 48%|████▊     | 8371/17525 [1:40:35<1:27:50,  1.74it/s] 48%|████▊     | 8372/17525 [1:40:36<1:27:54,  1.74it/s] 48%|████▊     | 8373/17525 [1:40:36<1:27:44,  1.74it/s] 48%|████▊     | 8374/17525 [1:40:37<1:27:46,  1.74it/s] 48%|████▊     | 8375/17525 [1:40:37<1:27:43,  1.74it/s] 48%|████▊     | 8376/17525 [1:40:38<1:27:35,  1.74it/s] 48%|████▊     | 8377/17525 [1:40:38<1:27:32,  1.74it/s] 48%|████▊     | 8378/17525 [1:40:39<1:27:31,  1.74it/s] 48%|████▊     | 8379/17525 [1:40:40<1:27:24,  1.74it/s] 48%|████▊     | 8380/17525 [1:40:40<1:27:22,  1.74it/s]                                                        {'loss': 0.4867, 'grad_norm': 6.326227188110352, 'learning_rate': 1.0716361756196944e-05, 'epoch': 11.95}
 48%|████▊     | 8380/17525 [1:40:40<1:27:22,  1.74it/s] 48%|████▊     | 8381/17525 [1:40:41<1:27:27,  1.74it/s] 48%|████▊     | 8382/17525 [1:40:41<1:27:27,  1.74it/s] 48%|████▊     | 8383/17525 [1:40:42<1:27:27,  1.74it/s] 48%|████▊     | 8384/17525 [1:40:42<1:27:26,  1.74it/s] 48%|████▊     | 8385/17525 [1:40:43<1:27:31,  1.74it/s] 48%|████▊     | 8386/17525 [1:40:44<1:27:34,  1.74it/s] 48%|████▊     | 8387/17525 [1:40:44<1:27:42,  1.74it/s] 48%|████▊     | 8388/17525 [1:40:45<1:27:55,  1.73it/s] 48%|████▊     | 8389/17525 [1:40:45<1:27:45,  1.73it/s] 48%|████▊     | 8390/17525 [1:40:46<1:27:48,  1.73it/s]                                                        {'loss': 0.4489, 'grad_norm': 7.261005878448486, 'learning_rate': 1.0698459890270478e-05, 'epoch': 11.97}
 48%|████▊     | 8390/17525 [1:40:46<1:27:48,  1.73it/s] 48%|████▊     | 8391/17525 [1:40:46<1:27:50,  1.73it/s] 48%|████▊     | 8392/17525 [1:40:47<1:28:24,  1.72it/s] 48%|████▊     | 8393/17525 [1:40:48<1:28:05,  1.73it/s] 48%|████▊     | 8394/17525 [1:40:48<1:27:51,  1.73it/s] 48%|████▊     | 8395/17525 [1:40:49<1:27:45,  1.73it/s] 48%|████▊     | 8396/17525 [1:40:49<1:27:47,  1.73it/s] 48%|████▊     | 8397/17525 [1:40:50<1:27:39,  1.74it/s] 48%|████▊     | 8398/17525 [1:40:50<1:27:46,  1.73it/s] 48%|████▊     | 8399/17525 [1:40:51<1:27:42,  1.73it/s] 48%|████▊     | 8400/17525 [1:40:52<1:44:11,  1.46it/s]                                                        {'loss': 0.4513, 'grad_norm': 15.935220718383789, 'learning_rate': 1.0680555774684098e-05, 'epoch': 11.98}
 48%|████▊     | 8400/17525 [1:40:52<1:44:11,  1.46it/s][INFO|trainer.py:3512] 2024-06-25 03:44:13,893 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:44:13,893 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:44:13,893 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9609301090240479, 'eval_runtime': 4.5953, 'eval_samples_per_second': 96.403, 'eval_steps_per_second': 4.135, 'epoch': 11.98}
 48%|████▊     | 8400/17525 [1:40:57<1:44:11,  1.46it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:44:18,492 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7add990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: bedc45d2-5078-486d-be74-d040ba04b37c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:44:28,550 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:44:28,553 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 48%|████▊     | 8401/17525 [1:41:07<12:54:20,  5.09s/it] 48%|████▊     | 8402/17525 [1:41:08<9:28:21,  3.74s/it]  48%|████▊     | 8403/17525 [1:41:09<7:03:59,  2.79s/it] 48%|████▊     | 8404/17525 [1:41:09<5:23:09,  2.13s/it] 48%|████▊     | 8405/17525 [1:41:10<4:12:15,  1.66s/it] 48%|████▊     | 8406/17525 [1:41:10<3:22:36,  1.33s/it] 48%|████▊     | 8407/17525 [1:41:11<2:48:03,  1.11s/it] 48%|████▊     | 8408/17525 [1:41:11<2:23:48,  1.06it/s] 48%|████▊     | 8409/17525 [1:41:12<2:06:56,  1.20it/s] 48%|████▊     | 8410/17525 [1:41:13<1:54:53,  1.32it/s]                                                        {'loss': 0.5017, 'grad_norm': 13.782472610473633, 'learning_rate': 1.0662649467104924e-05, 'epoch': 12.0}
 48%|████▊     | 8410/17525 [1:41:13<1:54:53,  1.32it/s] 48%|████▊     | 8411/17525 [1:41:13<1:47:05,  1.42it/s] 48%|████▊     | 8412/17525 [1:41:14<1:41:01,  1.50it/s] 48%|████▊     | 8413/17525 [1:41:14<1:37:05,  1.56it/s] 48%|████▊     | 8414/17525 [1:41:15<1:34:08,  1.61it/s] 48%|████▊     | 8415/17525 [1:41:15<1:32:19,  1.64it/s] 48%|████▊     | 8416/17525 [1:41:16<1:30:48,  1.67it/s] 48%|████▊     | 8417/17525 [1:41:17<1:30:34,  1.68it/s] 48%|████▊     | 8418/17525 [1:41:17<1:29:31,  1.70it/s] 48%|████▊     | 8419/17525 [1:41:18<1:28:44,  1.71it/s] 48%|████▊     | 8420/17525 [1:41:18<1:28:13,  1.72it/s]                                                        {'loss': 0.3856, 'grad_norm': 5.565700054168701, 'learning_rate': 1.0644741025207138e-05, 'epoch': 12.01}
 48%|████▊     | 8420/17525 [1:41:18<1:28:13,  1.72it/s] 48%|████▊     | 8421/17525 [1:41:19<1:28:01,  1.72it/s] 48%|████▊     | 8422/17525 [1:41:19<1:27:51,  1.73it/s] 48%|████▊     | 8423/17525 [1:41:20<1:27:36,  1.73it/s] 48%|████▊     | 8424/17525 [1:41:21<1:27:49,  1.73it/s] 48%|████▊     | 8425/17525 [1:41:21<1:27:46,  1.73it/s] 48%|████▊     | 8426/17525 [1:41:22<1:28:06,  1.72it/s] 48%|████▊     | 8427/17525 [1:41:22<1:28:27,  1.71it/s] 48%|████▊     | 8428/17525 [1:41:23<1:28:26,  1.71it/s] 48%|████▊     | 8429/17525 [1:41:24<1:28:18,  1.72it/s] 48%|████▊     | 8430/17525 [1:41:24<1:28:05,  1.72it/s]                                                        {'loss': 0.4347, 'grad_norm': 15.083362579345703, 'learning_rate': 1.0626830506671797e-05, 'epoch': 12.03}
 48%|████▊     | 8430/17525 [1:41:24<1:28:05,  1.72it/s] 48%|████▊     | 8431/17525 [1:41:25<1:27:51,  1.73it/s] 48%|████▊     | 8432/17525 [1:41:25<1:27:29,  1.73it/s] 48%|████▊     | 8433/17525 [1:41:26<1:27:25,  1.73it/s] 48%|████▊     | 8434/17525 [1:41:26<1:27:13,  1.74it/s] 48%|████▊     | 8435/17525 [1:41:27<1:27:06,  1.74it/s] 48%|████▊     | 8436/17525 [1:41:28<1:27:13,  1.74it/s] 48%|████▊     | 8437/17525 [1:41:28<1:27:08,  1.74it/s] 48%|████▊     | 8438/17525 [1:41:29<1:27:08,  1.74it/s] 48%|████▊     | 8439/17525 [1:41:29<1:27:28,  1.73it/s] 48%|████▊     | 8440/17525 [1:41:30<1:27:25,  1.73it/s]                                                        {'loss': 0.4158, 'grad_norm': 9.981039047241211, 'learning_rate': 1.060891796918664e-05, 'epoch': 12.04}
 48%|████▊     | 8440/17525 [1:41:30<1:27:25,  1.73it/s] 48%|████▊     | 8441/17525 [1:41:30<1:27:26,  1.73it/s] 48%|████▊     | 8442/17525 [1:41:31<1:27:25,  1.73it/s] 48%|████▊     | 8443/17525 [1:41:32<1:27:21,  1.73it/s] 48%|████▊     | 8444/17525 [1:41:32<1:27:10,  1.74it/s] 48%|████▊     | 8445/17525 [1:41:33<1:43:38,  1.46it/s] 48%|████▊     | 8446/17525 [1:41:34<1:38:38,  1.53it/s] 48%|████▊     | 8447/17525 [1:41:34<1:35:14,  1.59it/s] 48%|████▊     | 8448/17525 [1:41:35<1:32:36,  1.63it/s] 48%|████▊     | 8449/17525 [1:41:35<1:31:06,  1.66it/s] 48%|████▊     | 8450/17525 [1:41:36<1:29:47,  1.68it/s]                                                        {'loss': 0.3236, 'grad_norm': 12.199199676513672, 'learning_rate': 1.0591003470445925e-05, 'epoch': 12.05}
 48%|████▊     | 8450/17525 [1:41:36<1:29:47,  1.68it/s] 48%|████▊     | 8451/17525 [1:41:37<1:29:01,  1.70it/s] 48%|████▊     | 8452/17525 [1:41:37<1:28:32,  1.71it/s] 48%|████▊     | 8453/17525 [1:41:38<1:28:05,  1.72it/s] 48%|████▊     | 8454/17525 [1:41:38<1:27:48,  1.72it/s] 48%|████▊     | 8455/17525 [1:41:39<1:27:38,  1.72it/s] 48%|████▊     | 8456/17525 [1:41:39<1:27:25,  1.73it/s] 48%|████▊     | 8457/17525 [1:41:40<1:27:09,  1.73it/s] 48%|████▊     | 8458/17525 [1:41:41<1:27:09,  1.73it/s] 48%|████▊     | 8459/17525 [1:41:42<1:48:16,  1.40it/s] 48%|████▊     | 8460/17525 [1:41:42<1:42:05,  1.48it/s]                                                        {'loss': 0.4456, 'grad_norm': 16.14023208618164, 'learning_rate': 1.0573087068150202e-05, 'epoch': 12.07}
 48%|████▊     | 8460/17525 [1:41:42<1:42:05,  1.48it/s] 48%|████▊     | 8461/17525 [1:41:43<1:37:35,  1.55it/s] 48%|████▊     | 8462/17525 [1:41:43<1:34:22,  1.60it/s] 48%|████▊     | 8463/17525 [1:41:45<2:18:02,  1.09it/s] 48%|████▊     | 8464/17525 [1:41:46<2:02:43,  1.23it/s] 48%|████▊     | 8465/17525 [1:41:46<1:52:03,  1.35it/s] 48%|████▊     | 8466/17525 [1:41:47<1:44:29,  1.44it/s] 48%|████▊     | 8467/17525 [1:41:47<1:39:16,  1.52it/s] 48%|████▊     | 8468/17525 [1:41:48<1:35:43,  1.58it/s] 48%|████▊     | 8469/17525 [1:41:48<1:33:08,  1.62it/s] 48%|████▊     | 8470/17525 [1:41:49<1:31:23,  1.65it/s]                                                        {'loss': 0.4429, 'grad_norm': 10.608811378479004, 'learning_rate': 1.0555168820006177e-05, 'epoch': 12.08}
 48%|████▊     | 8470/17525 [1:41:49<1:31:23,  1.65it/s] 48%|████▊     | 8471/17525 [1:41:50<1:30:11,  1.67it/s] 48%|████▊     | 8472/17525 [1:41:50<1:29:09,  1.69it/s] 48%|████▊     | 8473/17525 [1:41:51<1:28:32,  1.70it/s] 48%|████▊     | 8474/17525 [1:41:51<1:28:03,  1.71it/s] 48%|████▊     | 8475/17525 [1:41:52<1:28:05,  1.71it/s] 48%|████▊     | 8476/17525 [1:41:52<1:28:00,  1.71it/s] 48%|████▊     | 8477/17525 [1:41:53<1:27:56,  1.71it/s] 48%|████▊     | 8478/17525 [1:41:54<1:27:34,  1.72it/s] 48%|████▊     | 8479/17525 [1:41:54<1:27:21,  1.73it/s] 48%|████▊     | 8480/17525 [1:41:55<1:27:14,  1.73it/s]                                                        {'loss': 0.43, 'grad_norm': 7.3195085525512695, 'learning_rate': 1.0537248783726485e-05, 'epoch': 12.1}
 48%|████▊     | 8480/17525 [1:41:55<1:27:14,  1.73it/s] 48%|████▊     | 8481/17525 [1:41:55<1:28:26,  1.70it/s] 48%|████▊     | 8482/17525 [1:41:56<1:29:11,  1.69it/s] 48%|████▊     | 8483/17525 [1:41:57<1:28:32,  1.70it/s] 48%|████▊     | 8484/17525 [1:41:57<1:28:06,  1.71it/s] 48%|████▊     | 8485/17525 [1:41:58<1:27:56,  1.71it/s] 48%|████▊     | 8486/17525 [1:41:58<1:27:59,  1.71it/s] 48%|████▊     | 8487/17525 [1:41:59<1:27:46,  1.72it/s] 48%|████▊     | 8488/17525 [1:41:59<1:27:30,  1.72it/s] 48%|████▊     | 8489/17525 [1:42:00<1:27:11,  1.73it/s] 48%|████▊     | 8490/17525 [1:42:01<1:27:08,  1.73it/s]                                                        {'loss': 0.4571, 'grad_norm': 10.525867462158203, 'learning_rate': 1.0519327017029528e-05, 'epoch': 12.11}
 48%|████▊     | 8490/17525 [1:42:01<1:27:08,  1.73it/s] 48%|████▊     | 8491/17525 [1:42:01<1:27:30,  1.72it/s] 48%|████▊     | 8492/17525 [1:42:02<1:27:13,  1.73it/s] 48%|████▊     | 8493/17525 [1:42:02<1:27:03,  1.73it/s] 48%|████▊     | 8494/17525 [1:42:03<1:27:51,  1.71it/s] 48%|████▊     | 8495/17525 [1:42:04<1:27:31,  1.72it/s] 48%|████▊     | 8496/17525 [1:42:04<1:27:20,  1.72it/s] 48%|████▊     | 8497/17525 [1:42:05<1:27:13,  1.73it/s] 48%|████▊     | 8498/17525 [1:42:05<1:27:06,  1.73it/s] 48%|████▊     | 8499/17525 [1:42:06<1:27:07,  1.73it/s] 49%|████▊     | 8500/17525 [1:42:06<1:27:00,  1.73it/s]                                                        {'loss': 0.4538, 'grad_norm': 22.10293960571289, 'learning_rate': 1.050140357763928e-05, 'epoch': 12.13}
 49%|████▊     | 8500/17525 [1:42:06<1:27:00,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:45:28,346 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:45:28,346 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:45:28,346 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9910352826118469, 'eval_runtime': 4.6014, 'eval_samples_per_second': 96.276, 'eval_steps_per_second': 4.129, 'epoch': 12.13}
 49%|████▊     | 8500/17525 [1:42:11<1:27:00,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 49%|████▊     | 8501/17525 [1:42:12<4:54:59,  1.96s/it] 49%|████▊     | 8502/17525 [1:42:12<3:54:07,  1.56s/it] 49%|████▊     | 8503/17525 [1:42:13<3:10:07,  1.26s/it] 49%|████▊     | 8504/17525 [1:42:13<2:39:11,  1.06s/it] 49%|████▊     | 8505/17525 [1:42:14<2:17:18,  1.09it/s] 49%|████▊     | 8506/17525 [1:42:15<2:01:57,  1.23it/s] 49%|████▊     | 8507/17525 [1:42:15<1:51:26,  1.35it/s] 49%|████▊     | 8508/17525 [1:42:16<1:44:01,  1.44it/s] 49%|████▊     | 8509/17525 [1:42:16<1:40:38,  1.49it/s] 49%|████▊     | 8510/17525 [1:42:17<1:36:22,  1.56it/s]                                                        {'loss': 0.4083, 'grad_norm': 11.474034309387207, 'learning_rate': 1.0483478523285102e-05, 'epoch': 12.14}
 49%|████▊     | 8510/17525 [1:42:17<1:36:22,  1.56it/s] 49%|████▊     | 8511/17525 [1:42:17<1:33:24,  1.61it/s] 49%|████▊     | 8512/17525 [1:42:18<1:31:25,  1.64it/s] 49%|████▊     | 8513/17525 [1:42:19<1:30:08,  1.67it/s] 49%|████▊     | 8514/17525 [1:42:19<1:29:04,  1.69it/s] 49%|████▊     | 8515/17525 [1:42:20<1:28:20,  1.70it/s] 49%|████▊     | 8516/17525 [1:42:20<1:28:04,  1.70it/s] 49%|████▊     | 8517/17525 [1:42:21<1:27:46,  1.71it/s] 49%|████▊     | 8518/17525 [1:42:22<1:27:31,  1.72it/s] 49%|████▊     | 8519/17525 [1:42:22<1:27:14,  1.72it/s] 49%|████▊     | 8520/17525 [1:42:23<1:27:10,  1.72it/s]                                                        {'loss': 0.4549, 'grad_norm': 12.573101043701172, 'learning_rate': 1.0465551911701554e-05, 'epoch': 12.15}
 49%|████▊     | 8520/17525 [1:42:23<1:27:10,  1.72it/s] 49%|████▊     | 8521/17525 [1:42:23<1:27:07,  1.72it/s] 49%|████▊     | 8522/17525 [1:42:24<1:27:04,  1.72it/s] 49%|████▊     | 8523/17525 [1:42:24<1:26:56,  1.73it/s] 49%|████▊     | 8524/17525 [1:42:25<1:26:58,  1.72it/s] 49%|████▊     | 8525/17525 [1:42:26<2:02:35,  1.22it/s] 49%|████▊     | 8526/17525 [1:42:27<1:51:51,  1.34it/s] 49%|████▊     | 8527/17525 [1:42:28<1:44:14,  1.44it/s] 49%|████▊     | 8528/17525 [1:42:28<1:40:07,  1.50it/s] 49%|████▊     | 8529/17525 [1:42:29<1:36:03,  1.56it/s] 49%|████▊     | 8530/17525 [1:42:29<1:33:11,  1.61it/s]                                                        {'loss': 0.4494, 'grad_norm': 9.066095352172852, 'learning_rate': 1.0447623800628218e-05, 'epoch': 12.17}
 49%|████▊     | 8530/17525 [1:42:29<1:33:11,  1.61it/s] 49%|████▊     | 8531/17525 [1:42:30<1:31:19,  1.64it/s] 49%|████▊     | 8532/17525 [1:42:30<1:29:59,  1.67it/s] 49%|████▊     | 8533/17525 [1:42:31<1:35:32,  1.57it/s] 49%|████▊     | 8534/17525 [1:42:32<1:32:44,  1.62it/s] 49%|████▊     | 8535/17525 [1:42:32<1:30:46,  1.65it/s] 49%|████▊     | 8536/17525 [1:42:33<1:37:30,  1.54it/s] 49%|████▊     | 8537/17525 [1:42:34<1:34:10,  1.59it/s] 49%|████▊     | 8538/17525 [1:42:34<1:31:40,  1.63it/s] 49%|████▊     | 8539/17525 [1:42:35<1:30:11,  1.66it/s] 49%|████▊     | 8540/17525 [1:42:35<1:29:02,  1.68it/s]                                                        {'loss': 0.4835, 'grad_norm': 9.937880516052246, 'learning_rate': 1.0429694247809499e-05, 'epoch': 12.18}
 49%|████▊     | 8540/17525 [1:42:35<1:29:02,  1.68it/s] 49%|████▊     | 8541/17525 [1:42:36<1:28:19,  1.70it/s] 49%|████▊     | 8542/17525 [1:42:37<1:27:49,  1.70it/s] 49%|████▊     | 8543/17525 [1:42:37<1:27:31,  1.71it/s] 49%|████▉     | 8544/17525 [1:42:38<1:27:17,  1.71it/s] 49%|████▉     | 8545/17525 [1:42:38<1:26:49,  1.72it/s] 49%|████▉     | 8546/17525 [1:42:39<1:34:28,  1.58it/s] 49%|████▉     | 8547/17525 [1:42:40<1:32:04,  1.62it/s] 49%|████▉     | 8548/17525 [1:42:40<1:30:28,  1.65it/s] 49%|████▉     | 8549/17525 [1:42:41<1:29:13,  1.68it/s] 49%|████▉     | 8550/17525 [1:42:41<1:28:15,  1.69it/s]                                                        {'loss': 0.4363, 'grad_norm': 16.036911010742188, 'learning_rate': 1.041176331099445e-05, 'epoch': 12.2}
 49%|████▉     | 8550/17525 [1:42:41<1:28:15,  1.69it/s][INFO|trainer.py:3203] 2024-06-25 03:46:03,244 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8550
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b0d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ffcabd3a-1eac-4a4e-9774-11351abb0f5c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:46:13,301 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:46:13,303 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8550/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 49%|████▉     | 8551/17525 [1:42:52<9:05:06,  3.64s/it] 49%|████▉     | 8552/17525 [1:42:53<6:47:22,  2.72s/it] 49%|████▉     | 8553/17525 [1:42:53<5:10:49,  2.08s/it] 49%|████▉     | 8554/17525 [1:42:54<4:03:28,  1.63s/it] 49%|████▉     | 8555/17525 [1:42:54<3:16:19,  1.31s/it] 49%|████▉     | 8556/17525 [1:42:55<2:43:06,  1.09s/it] 49%|████▉     | 8557/17525 [1:42:56<2:28:07,  1.01it/s] 49%|████▉     | 8558/17525 [1:42:56<2:09:31,  1.15it/s] 49%|████▉     | 8559/17525 [1:42:57<1:56:19,  1.28it/s] 49%|████▉     | 8560/17525 [1:42:57<1:47:12,  1.39it/s]                                                        {'loss': 0.4415, 'grad_norm': 17.109712600708008, 'learning_rate': 1.039383104793658e-05, 'epoch': 12.21}
 49%|████▉     | 8560/17525 [1:42:57<1:47:12,  1.39it/s] 49%|████▉     | 8561/17525 [1:42:58<1:40:54,  1.48it/s] 49%|████▉     | 8562/17525 [1:42:59<1:36:26,  1.55it/s] 49%|████▉     | 8563/17525 [1:42:59<1:33:26,  1.60it/s] 49%|████▉     | 8564/17525 [1:43:00<1:31:16,  1.64it/s] 49%|████▉     | 8565/17525 [1:43:00<1:29:32,  1.67it/s] 49%|████▉     | 8566/17525 [1:43:01<1:28:37,  1.68it/s] 49%|████▉     | 8567/17525 [1:43:02<1:27:54,  1.70it/s] 49%|████▉     | 8568/17525 [1:43:02<1:27:24,  1.71it/s] 49%|████▉     | 8569/17525 [1:43:03<1:27:05,  1.71it/s] 49%|████▉     | 8570/17525 [1:43:03<1:26:45,  1.72it/s]                                                        {'loss': 0.485, 'grad_norm': 8.093981742858887, 'learning_rate': 1.0375897516393669e-05, 'epoch': 12.23}
 49%|████▉     | 8570/17525 [1:43:03<1:26:45,  1.72it/s] 49%|████▉     | 8571/17525 [1:43:04<1:26:48,  1.72it/s] 49%|████▉     | 8572/17525 [1:43:04<1:26:35,  1.72it/s] 49%|████▉     | 8573/17525 [1:43:05<1:26:23,  1.73it/s] 49%|████▉     | 8574/17525 [1:43:06<1:26:21,  1.73it/s] 49%|████▉     | 8575/17525 [1:43:06<1:26:19,  1.73it/s] 49%|████▉     | 8576/17525 [1:43:07<1:26:18,  1.73it/s] 49%|████▉     | 8577/17525 [1:43:07<1:26:58,  1.71it/s] 49%|████▉     | 8578/17525 [1:43:08<1:26:40,  1.72it/s] 49%|████▉     | 8579/17525 [1:43:08<1:26:42,  1.72it/s] 49%|████▉     | 8580/17525 [1:43:09<1:26:19,  1.73it/s]                                                        {'loss': 0.4657, 'grad_norm': 9.155369758605957, 'learning_rate': 1.0357962774127587e-05, 'epoch': 12.24}
 49%|████▉     | 8580/17525 [1:43:09<1:26:19,  1.73it/s] 49%|████▉     | 8581/17525 [1:43:10<1:26:19,  1.73it/s] 49%|████▉     | 8582/17525 [1:43:10<1:26:17,  1.73it/s] 49%|████▉     | 8583/17525 [1:43:11<1:26:01,  1.73it/s] 49%|████▉     | 8584/17525 [1:43:11<1:26:09,  1.73it/s] 49%|████▉     | 8585/17525 [1:43:12<1:26:06,  1.73it/s] 49%|████▉     | 8586/17525 [1:43:13<1:26:07,  1.73it/s] 49%|████▉     | 8587/17525 [1:43:13<1:26:02,  1.73it/s] 49%|████▉     | 8588/17525 [1:43:14<1:25:59,  1.73it/s] 49%|████▉     | 8589/17525 [1:43:14<1:25:55,  1.73it/s] 49%|████▉     | 8590/17525 [1:43:15<1:25:50,  1.73it/s]                                                        {'loss': 0.498, 'grad_norm': 5.398709297180176, 'learning_rate': 1.0340026878904097e-05, 'epoch': 12.25}
 49%|████▉     | 8590/17525 [1:43:15<1:25:50,  1.73it/s] 49%|████▉     | 8591/17525 [1:43:15<1:25:59,  1.73it/s] 49%|████▉     | 8592/17525 [1:43:16<1:25:49,  1.73it/s] 49%|████▉     | 8593/17525 [1:43:17<1:25:59,  1.73it/s] 49%|████▉     | 8594/17525 [1:43:17<1:26:11,  1.73it/s] 49%|████▉     | 8595/17525 [1:43:18<1:26:05,  1.73it/s] 49%|████▉     | 8596/17525 [1:43:18<1:26:03,  1.73it/s] 49%|████▉     | 8597/17525 [1:43:19<1:26:29,  1.72it/s] 49%|████▉     | 8598/17525 [1:43:19<1:26:15,  1.73it/s] 49%|████▉     | 8599/17525 [1:43:20<1:26:04,  1.73it/s] 49%|████▉     | 8600/17525 [1:43:21<1:26:18,  1.72it/s]                                                        {'loss': 0.3297, 'grad_norm': 17.97927474975586, 'learning_rate': 1.0322089888492683e-05, 'epoch': 12.27}
 49%|████▉     | 8600/17525 [1:43:21<1:26:18,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:46:42,511 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:46:42,511 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:46:42,511 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9932894706726074, 'eval_runtime': 4.5982, 'eval_samples_per_second': 96.341, 'eval_steps_per_second': 4.132, 'epoch': 12.27}
 49%|████▉     | 8600/17525 [1:43:25<1:26:18,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 49%|████▉     | 8601/17525 [1:43:26<4:51:42,  1.96s/it] 49%|████▉     | 8602/17525 [1:43:26<3:49:57,  1.55s/it] 49%|████▉     | 8603/17525 [1:43:27<3:06:41,  1.26s/it] 49%|████▉     | 8604/17525 [1:43:28<2:36:38,  1.05s/it] 49%|████▉     | 8605/17525 [1:43:28<2:15:31,  1.10it/s] 49%|████▉     | 8606/17525 [1:43:29<2:00:37,  1.23it/s] 49%|████▉     | 8607/17525 [1:43:29<1:50:18,  1.35it/s] 49%|████▉     | 8608/17525 [1:43:30<1:42:58,  1.44it/s] 49%|████▉     | 8609/17525 [1:43:30<1:37:51,  1.52it/s] 49%|████▉     | 8610/17525 [1:43:31<1:34:24,  1.57it/s]                                                        {'loss': 0.4048, 'grad_norm': 7.298853874206543, 'learning_rate': 1.0304151860666345e-05, 'epoch': 12.28}
 49%|████▉     | 8610/17525 [1:43:31<1:34:24,  1.57it/s] 49%|████▉     | 8611/17525 [1:43:32<1:31:58,  1.62it/s] 49%|████▉     | 8612/17525 [1:43:32<1:30:02,  1.65it/s] 49%|████▉     | 8613/17525 [1:43:33<1:28:44,  1.67it/s] 49%|████▉     | 8614/17525 [1:43:33<1:27:54,  1.69it/s] 49%|████▉     | 8615/17525 [1:43:34<1:27:11,  1.70it/s] 49%|████▉     | 8616/17525 [1:43:34<1:26:49,  1.71it/s] 49%|████▉     | 8617/17525 [1:43:35<1:26:25,  1.72it/s] 49%|████▉     | 8618/17525 [1:43:36<1:32:11,  1.61it/s] 49%|████▉     | 8619/17525 [1:43:36<1:30:13,  1.65it/s] 49%|████▉     | 8620/17525 [1:43:37<1:28:55,  1.67it/s]                                                        {'loss': 0.4362, 'grad_norm': 13.62114429473877, 'learning_rate': 1.0286212853201435e-05, 'epoch': 12.3}
 49%|████▉     | 8620/17525 [1:43:37<1:28:55,  1.67it/s] 49%|████▉     | 8621/17525 [1:43:38<1:28:02,  1.69it/s] 49%|████▉     | 8622/17525 [1:43:38<1:27:11,  1.70it/s] 49%|████▉     | 8623/17525 [1:43:39<1:26:43,  1.71it/s] 49%|████▉     | 8624/17525 [1:43:39<1:26:30,  1.71it/s] 49%|████▉     | 8625/17525 [1:43:40<1:26:32,  1.71it/s] 49%|████▉     | 8626/17525 [1:43:40<1:26:19,  1.72it/s] 49%|████▉     | 8627/17525 [1:43:41<1:26:20,  1.72it/s] 49%|████▉     | 8628/17525 [1:43:42<1:26:21,  1.72it/s] 49%|████▉     | 8629/17525 [1:43:42<1:26:05,  1.72it/s] 49%|████▉     | 8630/17525 [1:43:43<1:25:51,  1.73it/s]                                                        {'loss': 0.397, 'grad_norm': 7.087061405181885, 'learning_rate': 1.026827292387746e-05, 'epoch': 12.31}
 49%|████▉     | 8630/17525 [1:43:43<1:25:51,  1.73it/s] 49%|████▉     | 8631/17525 [1:43:43<1:25:40,  1.73it/s] 49%|████▉     | 8632/17525 [1:43:44<1:25:42,  1.73it/s] 49%|████▉     | 8633/17525 [1:43:44<1:25:46,  1.73it/s] 49%|████▉     | 8634/17525 [1:43:45<1:25:41,  1.73it/s] 49%|████▉     | 8635/17525 [1:43:46<1:25:46,  1.73it/s] 49%|████▉     | 8636/17525 [1:43:46<1:25:34,  1.73it/s] 49%|████▉     | 8637/17525 [1:43:47<1:25:28,  1.73it/s] 49%|████▉     | 8638/17525 [1:43:47<1:25:25,  1.73it/s] 49%|████▉     | 8639/17525 [1:43:48<1:26:12,  1.72it/s] 49%|████▉     | 8640/17525 [1:43:49<1:25:46,  1.73it/s]                                                        {'loss': 0.4419, 'grad_norm': 17.756317138671875, 'learning_rate': 1.0250332130476887e-05, 'epoch': 12.33}
 49%|████▉     | 8640/17525 [1:43:49<1:25:46,  1.73it/s] 49%|████▉     | 8641/17525 [1:43:49<1:25:50,  1.72it/s] 49%|████▉     | 8642/17525 [1:43:50<1:25:46,  1.73it/s] 49%|████▉     | 8643/17525 [1:43:50<1:25:45,  1.73it/s] 49%|████▉     | 8644/17525 [1:43:51<1:25:43,  1.73it/s] 49%|████▉     | 8645/17525 [1:43:51<1:25:40,  1.73it/s] 49%|████▉     | 8646/17525 [1:43:52<1:25:38,  1.73it/s] 49%|████▉     | 8647/17525 [1:43:53<1:25:30,  1.73it/s] 49%|████▉     | 8648/17525 [1:43:53<1:25:29,  1.73it/s] 49%|████▉     | 8649/17525 [1:43:54<1:25:24,  1.73it/s] 49%|████▉     | 8650/17525 [1:43:54<1:25:25,  1.73it/s]                                                        {'loss': 0.4642, 'grad_norm': 8.825722694396973, 'learning_rate': 1.0232390530784983e-05, 'epoch': 12.34}
 49%|████▉     | 8650/17525 [1:43:54<1:25:25,  1.73it/s] 49%|████▉     | 8651/17525 [1:43:55<1:25:35,  1.73it/s] 49%|████▉     | 8652/17525 [1:43:56<1:32:09,  1.60it/s] 49%|████▉     | 8653/17525 [1:43:56<1:31:14,  1.62it/s] 49%|████▉     | 8654/17525 [1:43:57<1:29:23,  1.65it/s] 49%|████▉     | 8655/17525 [1:43:57<1:28:19,  1.67it/s] 49%|████▉     | 8656/17525 [1:43:58<1:27:18,  1.69it/s] 49%|████▉     | 8657/17525 [1:43:59<1:28:07,  1.68it/s] 49%|████▉     | 8658/17525 [1:43:59<1:27:18,  1.69it/s] 49%|████▉     | 8659/17525 [1:44:00<1:27:03,  1.70it/s] 49%|████▉     | 8660/17525 [1:44:00<1:26:36,  1.71it/s]                                                        {'loss': 0.3974, 'grad_norm': 7.38497257232666, 'learning_rate': 1.021444818258959e-05, 'epoch': 12.35}
 49%|████▉     | 8660/17525 [1:44:00<1:26:36,  1.71it/s] 49%|████▉     | 8661/17525 [1:44:01<1:26:24,  1.71it/s] 49%|████▉     | 8662/17525 [1:44:01<1:26:09,  1.71it/s] 49%|████▉     | 8663/17525 [1:44:02<1:41:58,  1.45it/s] 49%|████▉     | 8664/17525 [1:44:03<1:36:57,  1.52it/s] 49%|████▉     | 8665/17525 [1:44:04<1:49:27,  1.35it/s] 49%|████▉     | 8666/17525 [1:44:04<1:42:18,  1.44it/s] 49%|████▉     | 8667/17525 [1:44:06<2:12:09,  1.12it/s] 49%|████▉     | 8668/17525 [1:44:06<1:59:01,  1.24it/s] 49%|████▉     | 8669/17525 [1:44:07<1:48:57,  1.35it/s] 49%|████▉     | 8670/17525 [1:44:08<1:41:51,  1.45it/s]                                                        {'loss': 0.4727, 'grad_norm': 14.973581314086914, 'learning_rate': 1.0196505143680977e-05, 'epoch': 12.37}
 49%|████▉     | 8670/17525 [1:44:08<1:41:51,  1.45it/s] 49%|████▉     | 8671/17525 [1:44:08<1:37:07,  1.52it/s] 49%|████▉     | 8672/17525 [1:44:09<1:33:39,  1.58it/s] 49%|████▉     | 8673/17525 [1:44:09<1:31:09,  1.62it/s] 49%|████▉     | 8674/17525 [1:44:10<1:29:22,  1.65it/s] 50%|████▉     | 8675/17525 [1:44:11<1:28:31,  1.67it/s] 50%|████▉     | 8676/17525 [1:44:11<1:27:30,  1.69it/s] 50%|████▉     | 8677/17525 [1:44:12<1:26:41,  1.70it/s] 50%|████▉     | 8678/17525 [1:44:12<1:26:01,  1.71it/s] 50%|████▉     | 8679/17525 [1:44:13<1:25:40,  1.72it/s] 50%|████▉     | 8680/17525 [1:44:13<1:25:26,  1.73it/s]                                                        {'loss': 0.5038, 'grad_norm': 20.745258331298828, 'learning_rate': 1.017856147185163e-05, 'epoch': 12.38}
 50%|████▉     | 8680/17525 [1:44:13<1:25:26,  1.73it/s] 50%|████▉     | 8681/17525 [1:44:14<1:43:31,  1.42it/s] 50%|████▉     | 8682/17525 [1:44:15<1:37:57,  1.50it/s] 50%|████▉     | 8683/17525 [1:44:16<1:34:02,  1.57it/s] 50%|████▉     | 8684/17525 [1:44:16<1:31:13,  1.62it/s] 50%|████▉     | 8685/17525 [1:44:17<1:29:16,  1.65it/s] 50%|████▉     | 8686/17525 [1:44:17<1:27:57,  1.67it/s] 50%|████▉     | 8687/17525 [1:44:18<1:27:03,  1.69it/s] 50%|████▉     | 8688/17525 [1:44:18<1:26:22,  1.71it/s] 50%|████▉     | 8689/17525 [1:44:19<1:25:41,  1.72it/s] 50%|████▉     | 8690/17525 [1:44:20<1:25:32,  1.72it/s]                                                        {'loss': 0.383, 'grad_norm': 11.193401336669922, 'learning_rate': 1.0160617224896082e-05, 'epoch': 12.4}
 50%|████▉     | 8690/17525 [1:44:20<1:25:32,  1.72it/s] 50%|████▉     | 8691/17525 [1:44:20<1:25:27,  1.72it/s] 50%|████▉     | 8692/17525 [1:44:21<1:25:25,  1.72it/s] 50%|████▉     | 8693/17525 [1:44:21<1:25:14,  1.73it/s] 50%|████▉     | 8694/17525 [1:44:22<1:25:06,  1.73it/s] 50%|████▉     | 8695/17525 [1:44:22<1:25:04,  1.73it/s] 50%|████▉     | 8696/17525 [1:44:23<1:25:07,  1.73it/s] 50%|████▉     | 8697/17525 [1:44:24<1:25:21,  1.72it/s] 50%|████▉     | 8698/17525 [1:44:24<1:25:19,  1.72it/s] 50%|████▉     | 8699/17525 [1:44:25<1:24:57,  1.73it/s] 50%|████▉     | 8700/17525 [1:44:25<1:24:59,  1.73it/s]                                                        {'loss': 0.5399, 'grad_norm': 15.912687301635742, 'learning_rate': 1.014267246061071e-05, 'epoch': 12.41}
 50%|████▉     | 8700/17525 [1:44:25<1:24:59,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:47:47,232 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:47:47,232 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:47:47,232 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9913814663887024, 'eval_runtime': 4.5999, 'eval_samples_per_second': 96.306, 'eval_steps_per_second': 4.13, 'epoch': 12.41}
 50%|████▉     | 8700/17525 [1:44:30<1:24:59,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:47:51,836 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8700
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b15990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4075b0c5-c2c8-4101-a7d9-38841e69addd)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:48:01,893 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:48:01,896 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8700/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 50%|████▉     | 8701/17525 [1:44:41<12:23:58,  5.06s/it] 50%|████▉     | 8702/17525 [1:44:41<9:06:18,  3.72s/it]  50%|████▉     | 8703/17525 [1:44:42<7:03:18,  2.88s/it] 50%|████▉     | 8704/17525 [1:44:43<5:21:53,  2.19s/it] 50%|████▉     | 8705/17525 [1:44:44<4:10:41,  1.71s/it] 50%|████▉     | 8706/17525 [1:44:44<3:20:56,  1.37s/it] 50%|████▉     | 8707/17525 [1:44:45<2:46:17,  1.13s/it] 50%|████▉     | 8708/17525 [1:44:45<2:21:53,  1.04it/s] 50%|████▉     | 8709/17525 [1:44:46<2:04:51,  1.18it/s] 50%|████▉     | 8710/17525 [1:44:46<1:54:16,  1.29it/s]                                                        {'loss': 0.4833, 'grad_norm': 14.510512351989746, 'learning_rate': 1.012472723679356e-05, 'epoch': 12.43}
 50%|████▉     | 8710/17525 [1:44:46<1:54:16,  1.29it/s] 50%|████▉     | 8711/17525 [1:44:47<1:45:33,  1.39it/s] 50%|████▉     | 8712/17525 [1:44:48<1:39:29,  1.48it/s] 50%|████▉     | 8713/17525 [1:44:48<1:34:58,  1.55it/s] 50%|████▉     | 8714/17525 [1:44:49<1:32:02,  1.60it/s] 50%|████▉     | 8715/17525 [1:44:49<1:29:50,  1.63it/s] 50%|████▉     | 8716/17525 [1:44:50<1:28:18,  1.66it/s] 50%|████▉     | 8717/17525 [1:44:50<1:27:22,  1.68it/s] 50%|████▉     | 8718/17525 [1:44:51<1:26:34,  1.70it/s] 50%|████▉     | 8719/17525 [1:44:52<1:25:50,  1.71it/s] 50%|████▉     | 8720/17525 [1:44:52<1:25:24,  1.72it/s]                                                        {'loss': 0.4861, 'grad_norm': 13.508307456970215, 'learning_rate': 1.010857619022973e-05, 'epoch': 12.44}
 50%|████▉     | 8720/17525 [1:44:52<1:25:24,  1.72it/s] 50%|████▉     | 8721/17525 [1:44:53<1:25:16,  1.72it/s] 50%|████▉     | 8722/17525 [1:44:53<1:25:02,  1.73it/s] 50%|████▉     | 8723/17525 [1:44:54<1:24:56,  1.73it/s] 50%|████▉     | 8724/17525 [1:44:55<1:24:48,  1.73it/s] 50%|████▉     | 8725/17525 [1:44:55<1:24:50,  1.73it/s] 50%|████▉     | 8726/17525 [1:44:56<1:24:55,  1.73it/s] 50%|████▉     | 8727/17525 [1:44:56<1:24:45,  1.73it/s] 50%|████▉     | 8728/17525 [1:44:57<1:24:39,  1.73it/s] 50%|████▉     | 8729/17525 [1:44:57<1:24:40,  1.73it/s] 50%|████▉     | 8730/17525 [1:44:58<1:24:42,  1.73it/s]                                                        {'loss': 0.4456, 'grad_norm': 9.77454662322998, 'learning_rate': 1.0090630252540969e-05, 'epoch': 12.45}
 50%|████▉     | 8730/17525 [1:44:58<1:24:42,  1.73it/s] 50%|████▉     | 8731/17525 [1:44:59<1:24:50,  1.73it/s] 50%|████▉     | 8732/17525 [1:44:59<1:24:48,  1.73it/s] 50%|████▉     | 8733/17525 [1:45:00<1:24:46,  1.73it/s] 50%|████▉     | 8734/17525 [1:45:00<1:24:43,  1.73it/s] 50%|████▉     | 8735/17525 [1:45:01<1:24:45,  1.73it/s] 50%|████▉     | 8736/17525 [1:45:01<1:24:40,  1.73it/s] 50%|████▉     | 8737/17525 [1:45:02<1:24:37,  1.73it/s] 50%|████▉     | 8738/17525 [1:45:03<1:24:44,  1.73it/s] 50%|████▉     | 8739/17525 [1:45:03<1:24:40,  1.73it/s] 50%|████▉     | 8740/17525 [1:45:04<1:24:39,  1.73it/s]                                                        {'loss': 0.4065, 'grad_norm': 12.084478378295898, 'learning_rate': 1.0072684022942462e-05, 'epoch': 12.47}
 50%|████▉     | 8740/17525 [1:45:04<1:24:39,  1.73it/s] 50%|████▉     | 8741/17525 [1:45:04<1:24:48,  1.73it/s] 50%|████▉     | 8742/17525 [1:45:05<1:27:25,  1.67it/s] 50%|████▉     | 8743/17525 [1:45:06<1:26:40,  1.69it/s] 50%|████▉     | 8744/17525 [1:45:06<1:26:53,  1.68it/s] 50%|████▉     | 8745/17525 [1:45:07<1:26:09,  1.70it/s] 50%|████▉     | 8746/17525 [1:45:07<1:25:44,  1.71it/s] 50%|████▉     | 8747/17525 [1:45:08<1:25:12,  1.72it/s] 50%|████▉     | 8748/17525 [1:45:08<1:24:54,  1.72it/s] 50%|████▉     | 8749/17525 [1:45:09<1:24:50,  1.72it/s] 50%|████▉     | 8750/17525 [1:45:10<1:24:47,  1.72it/s]                                                        {'loss': 0.4547, 'grad_norm': 7.633511066436768, 'learning_rate': 1.0054737559236985e-05, 'epoch': 12.48}
 50%|████▉     | 8750/17525 [1:45:10<1:24:47,  1.72it/s] 50%|████▉     | 8751/17525 [1:45:10<1:24:52,  1.72it/s] 50%|████▉     | 8752/17525 [1:45:11<1:24:32,  1.73it/s] 50%|████▉     | 8753/17525 [1:45:11<1:24:23,  1.73it/s] 50%|████▉     | 8754/17525 [1:45:12<1:24:22,  1.73it/s] 50%|████▉     | 8755/17525 [1:45:13<1:24:32,  1.73it/s] 50%|████▉     | 8756/17525 [1:45:13<1:24:38,  1.73it/s] 50%|████▉     | 8757/17525 [1:45:14<1:24:31,  1.73it/s] 50%|████▉     | 8758/17525 [1:45:14<1:24:30,  1.73it/s] 50%|████▉     | 8759/17525 [1:45:15<1:24:32,  1.73it/s] 50%|████▉     | 8760/17525 [1:45:15<1:24:35,  1.73it/s]                                                        {'loss': 0.4053, 'grad_norm': 9.906832695007324, 'learning_rate': 1.0036790919228045e-05, 'epoch': 12.5}
 50%|████▉     | 8760/17525 [1:45:15<1:24:35,  1.73it/s] 50%|████▉     | 8761/17525 [1:45:16<1:24:32,  1.73it/s] 50%|████▉     | 8762/17525 [1:45:17<1:40:15,  1.46it/s] 50%|█████     | 8763/17525 [1:45:18<1:35:41,  1.53it/s] 50%|█████     | 8764/17525 [1:45:18<1:32:16,  1.58it/s] 50%|█████     | 8765/17525 [1:45:19<1:29:51,  1.62it/s] 50%|█████     | 8766/17525 [1:45:19<1:28:24,  1.65it/s] 50%|█████     | 8767/17525 [1:45:20<1:26:59,  1.68it/s] 50%|█████     | 8768/17525 [1:45:20<1:26:18,  1.69it/s] 50%|█████     | 8769/17525 [1:45:21<1:25:36,  1.70it/s] 50%|█████     | 8770/17525 [1:45:22<1:25:20,  1.71it/s]                                                        {'loss': 0.4316, 'grad_norm': 13.780529022216797, 'learning_rate': 1.0018844160719738e-05, 'epoch': 12.51}
 50%|█████     | 8770/17525 [1:45:22<1:25:20,  1.71it/s] 50%|█████     | 8771/17525 [1:45:22<1:25:08,  1.71it/s] 50%|█████     | 8772/17525 [1:45:23<1:24:57,  1.72it/s] 50%|█████     | 8773/17525 [1:45:23<1:24:47,  1.72it/s] 50%|█████     | 8774/17525 [1:45:24<1:24:31,  1.73it/s] 50%|█████     | 8775/17525 [1:45:24<1:24:30,  1.73it/s] 50%|█████     | 8776/17525 [1:45:25<1:24:40,  1.72it/s] 50%|█████     | 8777/17525 [1:45:26<1:24:37,  1.72it/s] 50%|█████     | 8778/17525 [1:45:26<1:24:30,  1.72it/s] 50%|█████     | 8779/17525 [1:45:27<1:24:14,  1.73it/s] 50%|█████     | 8780/17525 [1:45:27<1:24:23,  1.73it/s]                                                        {'loss': 0.4212, 'grad_norm': 18.108592987060547, 'learning_rate': 1.0000897341516533e-05, 'epoch': 12.52}
 50%|█████     | 8780/17525 [1:45:27<1:24:23,  1.73it/s] 50%|█████     | 8781/17525 [1:45:28<1:40:27,  1.45it/s] 50%|█████     | 8782/17525 [1:45:29<1:35:37,  1.52it/s] 50%|█████     | 8783/17525 [1:45:29<1:32:15,  1.58it/s] 50%|█████     | 8784/17525 [1:45:30<1:29:50,  1.62it/s] 50%|█████     | 8785/17525 [1:45:31<1:27:58,  1.66it/s] 50%|█████     | 8786/17525 [1:45:31<1:26:49,  1.68it/s] 50%|█████     | 8787/17525 [1:45:33<1:59:27,  1.22it/s] 50%|█████     | 8788/17525 [1:45:33<1:48:58,  1.34it/s] 50%|█████     | 8789/17525 [1:45:34<1:41:34,  1.43it/s] 50%|█████     | 8790/17525 [1:45:34<1:36:25,  1.51it/s]                                                        {'loss': 0.3467, 'grad_norm': 64.50592041015625, 'learning_rate': 9.982950519423091e-06, 'epoch': 12.54}
 50%|█████     | 8790/17525 [1:45:34<1:36:25,  1.51it/s] 50%|█████     | 8791/17525 [1:45:35<1:32:46,  1.57it/s] 50%|█████     | 8792/17525 [1:45:35<1:30:14,  1.61it/s] 50%|█████     | 8793/17525 [1:45:36<1:28:15,  1.65it/s] 50%|█████     | 8794/17525 [1:45:37<1:26:56,  1.67it/s] 50%|█████     | 8795/17525 [1:45:37<1:26:12,  1.69it/s] 50%|█████     | 8796/17525 [1:45:38<1:25:31,  1.70it/s] 50%|█████     | 8797/17525 [1:45:38<1:25:05,  1.71it/s] 50%|█████     | 8798/17525 [1:45:39<1:24:44,  1.72it/s] 50%|█████     | 8799/17525 [1:45:39<1:24:36,  1.72it/s] 50%|█████     | 8800/17525 [1:45:40<1:24:49,  1.71it/s]                                                        {'loss': 0.4933, 'grad_norm': 11.247472763061523, 'learning_rate': 9.96500375224409e-06, 'epoch': 12.55}
 50%|█████     | 8800/17525 [1:45:40<1:24:49,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 03:49:01,972 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:49:01,972 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:49:01,972 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9847068190574646, 'eval_runtime': 4.6006, 'eval_samples_per_second': 96.291, 'eval_steps_per_second': 4.13, 'epoch': 12.55}
 50%|█████     | 8800/17525 [1:45:45<1:24:49,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 50%|█████     | 8801/17525 [1:45:45<4:45:50,  1.97s/it] 50%|█████     | 8802/17525 [1:45:46<3:45:17,  1.55s/it] 50%|█████     | 8803/17525 [1:45:46<3:02:55,  1.26s/it] 50%|█████     | 8804/17525 [1:45:47<2:33:16,  1.05s/it] 50%|█████     | 8805/17525 [1:45:48<2:12:34,  1.10it/s] 50%|█████     | 8806/17525 [1:45:48<1:58:00,  1.23it/s] 50%|█████     | 8807/17525 [1:45:49<1:47:48,  1.35it/s] 50%|█████     | 8808/17525 [1:45:49<1:40:38,  1.44it/s] 50%|█████     | 8809/17525 [1:45:50<1:35:25,  1.52it/s] 50%|█████     | 8810/17525 [1:45:50<1:31:54,  1.58it/s]                                                        {'loss': 0.392, 'grad_norm': 8.998680114746094, 'learning_rate': 9.94705709778402e-06, 'epoch': 12.57}
 50%|█████     | 8810/17525 [1:45:50<1:31:54,  1.58it/s] 50%|█████     | 8811/17525 [1:45:51<1:29:34,  1.62it/s] 50%|█████     | 8812/17525 [1:45:52<1:28:48,  1.64it/s] 50%|█████     | 8813/17525 [1:45:52<1:27:13,  1.66it/s] 50%|█████     | 8814/17525 [1:45:53<1:26:25,  1.68it/s] 50%|█████     | 8815/17525 [1:45:53<1:25:42,  1.69it/s] 50%|█████     | 8816/17525 [1:45:54<1:25:11,  1.70it/s] 50%|█████     | 8817/17525 [1:45:55<1:24:39,  1.71it/s] 50%|█████     | 8818/17525 [1:45:55<1:24:23,  1.72it/s] 50%|█████     | 8819/17525 [1:45:56<1:30:46,  1.60it/s] 50%|█████     | 8820/17525 [1:45:56<1:28:44,  1.64it/s]                                                        {'loss': 0.4746, 'grad_norm': 10.34382438659668, 'learning_rate': 9.929110613847027e-06, 'epoch': 12.58}
 50%|█████     | 8820/17525 [1:45:56<1:28:44,  1.64it/s] 50%|█████     | 8821/17525 [1:45:57<1:27:22,  1.66it/s] 50%|█████     | 8822/17525 [1:45:58<1:26:12,  1.68it/s] 50%|█████     | 8823/17525 [1:45:58<1:25:17,  1.70it/s] 50%|█████     | 8824/17525 [1:45:59<1:24:55,  1.71it/s] 50%|█████     | 8825/17525 [1:45:59<1:24:30,  1.72it/s] 50%|█████     | 8826/17525 [1:46:00<1:24:09,  1.72it/s] 50%|█████     | 8827/17525 [1:46:00<1:24:06,  1.72it/s] 50%|█████     | 8828/17525 [1:46:01<1:23:50,  1.73it/s] 50%|█████     | 8829/17525 [1:46:02<1:23:54,  1.73it/s] 50%|█████     | 8830/17525 [1:46:02<1:23:53,  1.73it/s]                                                        {'loss': 0.4469, 'grad_norm': 10.078791618347168, 'learning_rate': 9.911164358236684e-06, 'epoch': 12.6}
 50%|█████     | 8830/17525 [1:46:02<1:23:53,  1.73it/s] 50%|█████     | 8831/17525 [1:46:03<1:24:05,  1.72it/s] 50%|█████     | 8832/17525 [1:46:03<1:23:52,  1.73it/s] 50%|█████     | 8833/17525 [1:46:04<1:23:51,  1.73it/s] 50%|█████     | 8834/17525 [1:46:05<1:23:45,  1.73it/s] 50%|█████     | 8835/17525 [1:46:05<1:23:47,  1.73it/s] 50%|█████     | 8836/17525 [1:46:06<1:23:38,  1.73it/s] 50%|█████     | 8837/17525 [1:46:07<1:39:27,  1.46it/s] 50%|█████     | 8838/17525 [1:46:07<1:34:34,  1.53it/s] 50%|█████     | 8839/17525 [1:46:08<1:31:23,  1.58it/s] 50%|█████     | 8840/17525 [1:46:08<1:29:02,  1.63it/s]                                                        {'loss': 0.4749, 'grad_norm': 20.475801467895508, 'learning_rate': 9.893218388755847e-06, 'epoch': 12.61}
 50%|█████     | 8840/17525 [1:46:08<1:29:02,  1.63it/s] 50%|█████     | 8841/17525 [1:46:09<1:28:23,  1.64it/s] 50%|█████     | 8842/17525 [1:46:10<1:27:04,  1.66it/s] 50%|█████     | 8843/17525 [1:46:10<1:26:01,  1.68it/s] 50%|█████     | 8844/17525 [1:46:11<1:25:11,  1.70it/s] 50%|█████     | 8845/17525 [1:46:12<1:42:46,  1.41it/s] 50%|█████     | 8846/17525 [1:46:12<1:37:05,  1.49it/s] 50%|█████     | 8847/17525 [1:46:13<1:33:12,  1.55it/s] 50%|█████     | 8848/17525 [1:46:13<1:30:19,  1.60it/s] 50%|█████     | 8849/17525 [1:46:14<1:28:16,  1.64it/s] 50%|█████     | 8850/17525 [1:46:15<1:27:33,  1.65it/s]                                                        {'loss': 0.4469, 'grad_norm': 11.453583717346191, 'learning_rate': 9.875272763206445e-06, 'epoch': 12.62}
 50%|█████     | 8850/17525 [1:46:15<1:27:33,  1.65it/s][INFO|trainer.py:3203] 2024-06-25 03:49:36,472 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8850
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b4d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 8dd0873d-946c-4d3e-8b0f-2a0566a80533)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:49:46,535 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:49:46,538 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-8850/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 51%|█████     | 8851/17525 [1:46:25<8:48:42,  3.66s/it] 51%|█████     | 8852/17525 [1:46:26<6:35:26,  2.74s/it] 51%|█████     | 8853/17525 [1:46:27<5:01:53,  2.09s/it] 51%|█████     | 8854/17525 [1:46:27<3:56:19,  1.64s/it] 51%|█████     | 8855/17525 [1:46:28<3:10:49,  1.32s/it] 51%|█████     | 8856/17525 [1:46:28<2:38:42,  1.10s/it] 51%|█████     | 8857/17525 [1:46:29<2:16:18,  1.06it/s] 51%|█████     | 8858/17525 [1:46:29<2:00:27,  1.20it/s] 51%|█████     | 8859/17525 [1:46:30<1:49:19,  1.32it/s] 51%|█████     | 8860/17525 [1:46:31<1:41:31,  1.42it/s]                                                        {'loss': 0.4291, 'grad_norm': 16.09434700012207, 'learning_rate': 9.857327539389293e-06, 'epoch': 12.64}
 51%|█████     | 8860/17525 [1:46:31<1:41:31,  1.42it/s] 51%|█████     | 8861/17525 [1:46:31<1:36:12,  1.50it/s] 51%|█████     | 8862/17525 [1:46:32<1:32:18,  1.56it/s] 51%|█████     | 8863/17525 [1:46:32<1:29:31,  1.61it/s] 51%|█████     | 8864/17525 [1:46:33<1:27:52,  1.64it/s] 51%|█████     | 8865/17525 [1:46:33<1:26:23,  1.67it/s] 51%|█████     | 8866/17525 [1:46:34<1:25:31,  1.69it/s] 51%|█████     | 8867/17525 [1:46:35<1:25:03,  1.70it/s] 51%|█████     | 8868/17525 [1:46:35<1:24:47,  1.70it/s] 51%|█████     | 8869/17525 [1:46:36<1:24:17,  1.71it/s] 51%|█████     | 8870/17525 [1:46:36<1:23:58,  1.72it/s]                                                        {'loss': 0.5615, 'grad_norm': 13.375646591186523, 'learning_rate': 9.839382775103919e-06, 'epoch': 12.65}
 51%|█████     | 8870/17525 [1:46:36<1:23:58,  1.72it/s] 51%|█████     | 8871/17525 [1:46:37<1:23:46,  1.72it/s] 51%|█████     | 8872/17525 [1:46:38<1:23:40,  1.72it/s] 51%|█████     | 8873/17525 [1:46:38<1:23:31,  1.73it/s] 51%|█████     | 8874/17525 [1:46:39<1:23:33,  1.73it/s] 51%|█████     | 8875/17525 [1:46:39<1:23:21,  1.73it/s] 51%|█████     | 8876/17525 [1:46:40<1:23:17,  1.73it/s] 51%|█████     | 8877/17525 [1:46:40<1:23:14,  1.73it/s] 51%|█████     | 8878/17525 [1:46:41<1:23:51,  1.72it/s] 51%|█████     | 8879/17525 [1:46:42<1:23:38,  1.72it/s] 51%|█████     | 8880/17525 [1:46:42<1:24:51,  1.70it/s]                                                        {'loss': 0.4472, 'grad_norm': 22.89727020263672, 'learning_rate': 9.82143852814837e-06, 'epoch': 12.67}
 51%|█████     | 8880/17525 [1:46:42<1:24:51,  1.70it/s] 51%|█████     | 8881/17525 [1:46:43<1:24:30,  1.70it/s] 51%|█████     | 8882/17525 [1:46:43<1:23:52,  1.72it/s] 51%|█████     | 8883/17525 [1:46:44<1:23:43,  1.72it/s] 51%|█████     | 8884/17525 [1:46:44<1:23:32,  1.72it/s] 51%|█████     | 8885/17525 [1:46:45<1:23:17,  1.73it/s] 51%|█████     | 8886/17525 [1:46:46<1:23:16,  1.73it/s] 51%|█████     | 8887/17525 [1:46:46<1:23:01,  1.73it/s] 51%|█████     | 8888/17525 [1:46:47<1:23:08,  1.73it/s] 51%|█████     | 8889/17525 [1:46:47<1:23:13,  1.73it/s] 51%|█████     | 8890/17525 [1:46:48<1:23:05,  1.73it/s]                                                        {'loss': 0.5096, 'grad_norm': 22.34009552001953, 'learning_rate': 9.803494856319028e-06, 'epoch': 12.68}
 51%|█████     | 8890/17525 [1:46:48<1:23:05,  1.73it/s] 51%|█████     | 8891/17525 [1:46:49<1:23:03,  1.73it/s] 51%|█████     | 8892/17525 [1:46:49<1:23:05,  1.73it/s] 51%|█████     | 8893/17525 [1:46:50<1:22:58,  1.73it/s] 51%|█████     | 8894/17525 [1:46:50<1:23:07,  1.73it/s] 51%|█████     | 8895/17525 [1:46:51<1:23:10,  1.73it/s] 51%|█████     | 8896/17525 [1:46:51<1:23:09,  1.73it/s] 51%|█████     | 8897/17525 [1:46:52<1:22:53,  1.73it/s] 51%|█████     | 8898/17525 [1:46:53<1:22:40,  1.74it/s] 51%|█████     | 8899/17525 [1:46:53<1:22:52,  1.73it/s] 51%|█████     | 8900/17525 [1:46:54<1:23:01,  1.73it/s]                                                        {'loss': 0.3765, 'grad_norm': 15.077232360839844, 'learning_rate': 9.785551817410415e-06, 'epoch': 12.7}
 51%|█████     | 8900/17525 [1:46:54<1:23:01,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:50:15,623 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:50:15,623 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:50:15,623 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                        
                                               [A{'eval_loss': 0.9807227849960327, 'eval_runtime': 4.5995, 'eval_samples_per_second': 96.315, 'eval_steps_per_second': 4.131, 'epoch': 12.7}
 51%|█████     | 8900/17525 [1:46:58<1:23:01,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 51%|█████     | 8901/17525 [1:46:59<4:41:40,  1.96s/it] 51%|█████     | 8902/17525 [1:47:00<3:42:34,  1.55s/it] 51%|█████     | 8903/17525 [1:47:00<3:00:35,  1.26s/it] 51%|█████     | 8904/17525 [1:47:01<2:31:14,  1.05s/it] 51%|█████     | 8905/17525 [1:47:01<2:10:42,  1.10it/s] 51%|█████     | 8906/17525 [1:47:02<1:56:20,  1.23it/s] 51%|█████     | 8907/17525 [1:47:02<1:46:15,  1.35it/s] 51%|█████     | 8908/17525 [1:47:03<1:39:21,  1.45it/s] 51%|█████     | 8909/17525 [1:47:04<1:48:20,  1.33it/s] 51%|█████     | 8910/17525 [1:47:04<1:41:00,  1.42it/s]                                                        {'loss': 0.4638, 'grad_norm': 7.115253448486328, 'learning_rate': 9.76760946921502e-06, 'epoch': 12.71}
 51%|█████     | 8910/17525 [1:47:04<1:41:00,  1.42it/s] 51%|█████     | 8911/17525 [1:47:05<1:35:37,  1.50it/s] 51%|█████     | 8912/17525 [1:47:06<1:31:49,  1.56it/s] 51%|█████     | 8913/17525 [1:47:06<1:29:03,  1.61it/s] 51%|█████     | 8914/17525 [1:47:07<1:27:17,  1.64it/s] 51%|█████     | 8915/17525 [1:47:07<1:25:52,  1.67it/s] 51%|█████     | 8916/17525 [1:47:08<1:24:59,  1.69it/s] 51%|█████     | 8917/17525 [1:47:08<1:24:18,  1.70it/s] 51%|█████     | 8918/17525 [1:47:09<1:23:53,  1.71it/s] 51%|█████     | 8919/17525 [1:47:10<1:23:40,  1.71it/s] 51%|█████     | 8920/17525 [1:47:10<1:23:28,  1.72it/s]                                                        {'loss': 0.3972, 'grad_norm': 5.811211585998535, 'learning_rate': 9.749667869523114e-06, 'epoch': 12.72}
 51%|█████     | 8920/17525 [1:47:10<1:23:28,  1.72it/s] 51%|█████     | 8921/17525 [1:47:11<1:23:21,  1.72it/s] 51%|█████     | 8922/17525 [1:47:12<1:49:21,  1.31it/s] 51%|█████     | 8923/17525 [1:47:13<1:48:46,  1.32it/s] 51%|█████     | 8924/17525 [1:47:13<1:40:58,  1.42it/s] 51%|█████     | 8925/17525 [1:47:14<1:35:45,  1.50it/s] 51%|█████     | 8926/17525 [1:47:14<1:32:02,  1.56it/s] 51%|█████     | 8927/17525 [1:47:15<1:29:19,  1.60it/s] 51%|█████     | 8928/17525 [1:47:16<1:27:27,  1.64it/s] 51%|█████     | 8929/17525 [1:47:16<1:25:59,  1.67it/s] 51%|█████     | 8930/17525 [1:47:17<1:25:00,  1.68it/s]                                                        {'loss': 0.4131, 'grad_norm': 21.354671478271484, 'learning_rate': 9.731727076122542e-06, 'epoch': 12.74}
 51%|█████     | 8930/17525 [1:47:17<1:25:00,  1.68it/s] 51%|█████     | 8931/17525 [1:47:17<1:24:12,  1.70it/s] 51%|█████     | 8932/17525 [1:47:18<1:23:43,  1.71it/s] 51%|█████     | 8933/17525 [1:47:19<1:23:13,  1.72it/s] 51%|█████     | 8934/17525 [1:47:19<1:23:05,  1.72it/s] 51%|█████     | 8935/17525 [1:47:20<1:23:00,  1.72it/s] 51%|█████     | 8936/17525 [1:47:20<1:22:54,  1.73it/s] 51%|█████     | 8937/17525 [1:47:21<1:22:58,  1.72it/s] 51%|█████     | 8938/17525 [1:47:21<1:24:00,  1.70it/s] 51%|█████     | 8939/17525 [1:47:22<1:23:32,  1.71it/s] 51%|█████     | 8940/17525 [1:47:23<1:23:20,  1.72it/s]                                                        {'loss': 0.3857, 'grad_norm': 6.888734340667725, 'learning_rate': 9.713787146798568e-06, 'epoch': 12.75}
 51%|█████     | 8940/17525 [1:47:23<1:23:20,  1.72it/s] 51%|█████     | 8941/17525 [1:47:23<1:23:12,  1.72it/s] 51%|█████     | 8942/17525 [1:47:24<1:22:51,  1.73it/s] 51%|█████     | 8943/17525 [1:47:24<1:22:45,  1.73it/s] 51%|█████     | 8944/17525 [1:47:25<1:22:37,  1.73it/s] 51%|█████     | 8945/17525 [1:47:26<1:24:02,  1.70it/s] 51%|█████     | 8946/17525 [1:47:26<1:24:07,  1.70it/s] 51%|█████     | 8947/17525 [1:47:27<1:23:44,  1.71it/s] 51%|█████     | 8948/17525 [1:47:28<2:08:29,  1.11it/s] 51%|█████     | 8949/17525 [1:47:29<1:54:40,  1.25it/s] 51%|█████     | 8950/17525 [1:47:29<1:44:49,  1.36it/s]                                                        {'loss': 0.4779, 'grad_norm': 11.037686347961426, 'learning_rate': 9.69584813933366e-06, 'epoch': 12.77}
 51%|█████     | 8950/17525 [1:47:29<1:44:49,  1.36it/s] 51%|█████     | 8951/17525 [1:47:30<1:38:10,  1.46it/s] 51%|█████     | 8952/17525 [1:47:31<1:33:32,  1.53it/s] 51%|█████     | 8953/17525 [1:47:31<1:30:16,  1.58it/s] 51%|█████     | 8954/17525 [1:47:32<1:27:51,  1.63it/s] 51%|█████     | 8955/17525 [1:47:32<1:26:02,  1.66it/s] 51%|█████     | 8956/17525 [1:47:33<1:25:28,  1.67it/s] 51%|█████     | 8957/17525 [1:47:34<1:38:21,  1.45it/s] 51%|█████     | 8958/17525 [1:47:34<1:33:43,  1.52it/s] 51%|█████     | 8959/17525 [1:47:35<1:30:18,  1.58it/s] 51%|█████     | 8960/17525 [1:47:36<1:28:00,  1.62it/s]                                                        {'loss': 0.4435, 'grad_norm': 5.7880425453186035, 'learning_rate': 9.67791011150732e-06, 'epoch': 12.78}
 51%|█████     | 8960/17525 [1:47:36<1:28:00,  1.62it/s] 51%|█████     | 8961/17525 [1:47:36<1:26:28,  1.65it/s] 51%|█████     | 8962/17525 [1:47:37<1:25:12,  1.67it/s] 51%|█████     | 8963/17525 [1:47:37<1:30:36,  1.57it/s] 51%|█████     | 8964/17525 [1:47:38<1:28:02,  1.62it/s] 51%|█████     | 8965/17525 [1:47:39<1:26:22,  1.65it/s] 51%|█████     | 8966/17525 [1:47:39<1:25:07,  1.68it/s] 51%|█████     | 8967/17525 [1:47:40<1:24:11,  1.69it/s] 51%|█████     | 8968/17525 [1:47:40<1:23:36,  1.71it/s] 51%|█████     | 8969/17525 [1:47:42<2:08:02,  1.11it/s] 51%|█████     | 8970/17525 [1:47:43<1:54:17,  1.25it/s]                                                        {'loss': 0.4603, 'grad_norm': 34.70876693725586, 'learning_rate': 9.659973121095905e-06, 'epoch': 12.8}
 51%|█████     | 8970/17525 [1:47:43<1:54:17,  1.25it/s] 51%|█████     | 8971/17525 [1:47:43<1:44:45,  1.36it/s] 51%|█████     | 8972/17525 [1:47:44<1:38:46,  1.44it/s] 51%|█████     | 8973/17525 [1:47:44<1:33:55,  1.52it/s] 51%|█████     | 8974/17525 [1:47:45<1:31:29,  1.56it/s] 51%|█████     | 8975/17525 [1:47:45<1:28:55,  1.60it/s] 51%|█████     | 8976/17525 [1:47:46<1:27:06,  1.64it/s] 51%|█████     | 8977/17525 [1:47:47<1:25:45,  1.66it/s] 51%|█████     | 8978/17525 [1:47:48<1:41:05,  1.41it/s] 51%|█████     | 8979/17525 [1:47:48<1:35:31,  1.49it/s] 51%|█████     | 8980/17525 [1:47:49<1:31:35,  1.55it/s]                                                        {'loss': 0.4662, 'grad_norm': 6.486772060394287, 'learning_rate': 9.642037225872414e-06, 'epoch': 12.81}
 51%|█████     | 8980/17525 [1:47:49<1:31:35,  1.55it/s] 51%|█████     | 8981/17525 [1:47:49<1:28:55,  1.60it/s] 51%|█████▏    | 8982/17525 [1:47:50<1:26:48,  1.64it/s] 51%|█████▏    | 8983/17525 [1:47:51<1:25:42,  1.66it/s] 51%|█████▏    | 8984/17525 [1:47:51<1:24:54,  1.68it/s] 51%|█████▏    | 8985/17525 [1:47:52<1:24:37,  1.68it/s] 51%|█████▏    | 8986/17525 [1:47:52<1:24:17,  1.69it/s] 51%|█████▏    | 8987/17525 [1:47:53<1:24:00,  1.69it/s] 51%|█████▏    | 8988/17525 [1:47:53<1:23:25,  1.71it/s] 51%|█████▏    | 8989/17525 [1:47:54<1:22:54,  1.72it/s] 51%|█████▏    | 8990/17525 [1:47:55<1:22:41,  1.72it/s]                                                        {'loss': 0.4898, 'grad_norm': 23.569591522216797, 'learning_rate': 9.624102483606333e-06, 'epoch': 12.82}
 51%|█████▏    | 8990/17525 [1:47:55<1:22:41,  1.72it/s] 51%|█████▏    | 8991/17525 [1:47:55<1:22:48,  1.72it/s] 51%|█████▏    | 8992/17525 [1:47:56<1:36:26,  1.47it/s] 51%|█████▏    | 8993/17525 [1:47:57<1:32:19,  1.54it/s] 51%|█████▏    | 8994/17525 [1:47:57<1:29:26,  1.59it/s] 51%|█████▏    | 8995/17525 [1:47:58<1:27:26,  1.63it/s] 51%|█████▏    | 8996/17525 [1:47:59<1:40:58,  1.41it/s] 51%|█████▏    | 8997/17525 [1:47:59<1:35:36,  1.49it/s] 51%|█████▏    | 8998/17525 [1:48:00<1:31:32,  1.55it/s] 51%|█████▏    | 8999/17525 [1:48:00<1:28:54,  1.60it/s] 51%|█████▏    | 9000/17525 [1:48:01<1:26:51,  1.64it/s]                                                        {'loss': 0.4479, 'grad_norm': 11.254426956176758, 'learning_rate': 9.606168952063422e-06, 'epoch': 12.84}
 51%|█████▏    | 9000/17525 [1:48:01<1:26:51,  1.64it/s][INFO|trainer.py:3512] 2024-06-25 03:51:22,960 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:51:22,961 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:51:22,961 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 0.9819791316986084, 'eval_runtime': 4.5985, 'eval_samples_per_second': 96.336, 'eval_steps_per_second': 4.132, 'epoch': 12.84}
 51%|█████▏    | 9000/17525 [1:48:06<1:26:51,  1.64it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:51:27,563 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9000
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b15990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: cd041578-81dc-47a0-a68b-2bd52b944f4d)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:51:37,620 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:51:37,622 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9000/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 51%|█████▏    | 9001/17525 [1:48:16<11:57:40,  5.05s/it] 51%|█████▏    | 9002/17525 [1:48:17<8:46:56,  3.71s/it]  51%|█████▏    | 9003/17525 [1:48:18<6:33:14,  2.77s/it] 51%|█████▏    | 9004/17525 [1:48:18<4:59:43,  2.11s/it] 51%|█████▏    | 9005/17525 [1:48:19<3:54:19,  1.65s/it] 51%|█████▏    | 9006/17525 [1:48:19<3:08:31,  1.33s/it] 51%|█████▏    | 9007/17525 [1:48:20<2:36:18,  1.10s/it] 51%|█████▏    | 9008/17525 [1:48:21<2:14:14,  1.06it/s] 51%|█████▏    | 9009/17525 [1:48:21<1:58:54,  1.19it/s] 51%|█████▏    | 9010/17525 [1:48:22<1:47:43,  1.32it/s]                                                        {'loss': 0.4762, 'grad_norm': 11.20364761352539, 'learning_rate': 9.588236689005552e-06, 'epoch': 12.85}
 51%|█████▏    | 9010/17525 [1:48:22<1:47:43,  1.32it/s] 51%|█████▏    | 9011/17525 [1:48:22<1:40:03,  1.42it/s] 51%|█████▏    | 9012/17525 [1:48:23<1:34:38,  1.50it/s] 51%|█████▏    | 9013/17525 [1:48:23<1:30:51,  1.56it/s] 51%|█████▏    | 9014/17525 [1:48:24<1:28:15,  1.61it/s] 51%|█████▏    | 9015/17525 [1:48:25<1:40:40,  1.41it/s] 51%|█████▏    | 9016/17525 [1:48:25<1:34:50,  1.50it/s] 51%|█████▏    | 9017/17525 [1:48:26<1:31:17,  1.55it/s] 51%|█████▏    | 9018/17525 [1:48:27<1:28:21,  1.60it/s] 51%|█████▏    | 9019/17525 [1:48:27<1:26:16,  1.64it/s] 51%|█████▏    | 9020/17525 [1:48:28<1:40:21,  1.41it/s]                                                        {'loss': 0.4558, 'grad_norm': 12.332306861877441, 'learning_rate': 9.570305752190505e-06, 'epoch': 12.87}
 51%|█████▏    | 9020/17525 [1:48:28<1:40:21,  1.41it/s] 51%|█████▏    | 9021/17525 [1:48:29<1:34:57,  1.49it/s] 51%|█████▏    | 9022/17525 [1:48:29<1:30:54,  1.56it/s] 51%|█████▏    | 9023/17525 [1:48:30<1:28:16,  1.61it/s] 51%|█████▏    | 9024/17525 [1:48:30<1:26:13,  1.64it/s] 51%|█████▏    | 9025/17525 [1:48:31<1:25:02,  1.67it/s] 52%|█████▏    | 9026/17525 [1:48:32<1:24:07,  1.68it/s] 52%|█████▏    | 9027/17525 [1:48:32<1:23:23,  1.70it/s] 52%|█████▏    | 9028/17525 [1:48:33<1:22:52,  1.71it/s] 52%|█████▏    | 9029/17525 [1:48:33<1:23:37,  1.69it/s] 52%|█████▏    | 9030/17525 [1:48:34<1:23:00,  1.71it/s]                                                        {'loss': 0.3739, 'grad_norm': 17.953054428100586, 'learning_rate': 9.552376199371784e-06, 'epoch': 12.88}
 52%|█████▏    | 9030/17525 [1:48:34<1:23:00,  1.71it/s] 52%|█████▏    | 9031/17525 [1:48:35<1:22:56,  1.71it/s] 52%|█████▏    | 9032/17525 [1:48:35<1:22:45,  1.71it/s] 52%|█████▏    | 9033/17525 [1:48:36<1:22:48,  1.71it/s] 52%|█████▏    | 9034/17525 [1:48:36<1:22:27,  1.72it/s] 52%|█████▏    | 9035/17525 [1:48:37<1:22:57,  1.71it/s] 52%|█████▏    | 9036/17525 [1:48:37<1:22:29,  1.72it/s] 52%|█████▏    | 9037/17525 [1:48:38<1:22:17,  1.72it/s] 52%|█████▏    | 9038/17525 [1:48:39<1:21:58,  1.73it/s] 52%|█████▏    | 9039/17525 [1:48:39<1:21:48,  1.73it/s] 52%|█████▏    | 9040/17525 [1:48:40<1:21:46,  1.73it/s]                                                        {'loss': 0.4339, 'grad_norm': 16.128660202026367, 'learning_rate': 9.534448088298447e-06, 'epoch': 12.9}
 52%|█████▏    | 9040/17525 [1:48:40<1:21:46,  1.73it/s] 52%|█████▏    | 9041/17525 [1:48:41<1:42:40,  1.38it/s] 52%|█████▏    | 9042/17525 [1:48:41<1:36:27,  1.47it/s] 52%|█████▏    | 9043/17525 [1:48:42<1:31:59,  1.54it/s] 52%|█████▏    | 9044/17525 [1:48:43<1:29:06,  1.59it/s] 52%|█████▏    | 9045/17525 [1:48:43<1:26:56,  1.63it/s] 52%|█████▏    | 9046/17525 [1:48:44<1:25:20,  1.66it/s] 52%|█████▏    | 9047/17525 [1:48:44<1:24:24,  1.67it/s] 52%|█████▏    | 9048/17525 [1:48:45<1:24:04,  1.68it/s] 52%|█████▏    | 9049/17525 [1:48:45<1:23:27,  1.69it/s] 52%|█████▏    | 9050/17525 [1:48:46<1:23:08,  1.70it/s]                                                        {'loss': 0.4299, 'grad_norm': 13.515787124633789, 'learning_rate': 9.516521476714903e-06, 'epoch': 12.91}
 52%|█████▏    | 9050/17525 [1:48:46<1:23:08,  1.70it/s] 52%|█████▏    | 9051/17525 [1:48:47<1:22:56,  1.70it/s] 52%|█████▏    | 9052/17525 [1:48:47<1:22:47,  1.71it/s] 52%|█████▏    | 9053/17525 [1:48:48<1:22:23,  1.71it/s] 52%|█████▏    | 9054/17525 [1:48:48<1:22:16,  1.72it/s] 52%|█████▏    | 9055/17525 [1:48:49<1:22:06,  1.72it/s] 52%|█████▏    | 9056/17525 [1:48:50<1:21:53,  1.72it/s] 52%|█████▏    | 9057/17525 [1:48:50<1:21:53,  1.72it/s] 52%|█████▏    | 9058/17525 [1:48:51<1:21:50,  1.72it/s] 52%|█████▏    | 9059/17525 [1:48:51<1:21:42,  1.73it/s] 52%|█████▏    | 9060/17525 [1:48:52<1:21:47,  1.72it/s]                                                        {'loss': 0.4372, 'grad_norm': 29.9731388092041, 'learning_rate': 9.49859642236072e-06, 'epoch': 12.92}
 52%|█████▏    | 9060/17525 [1:48:52<1:21:47,  1.72it/s] 52%|█████▏    | 9061/17525 [1:48:52<1:21:37,  1.73it/s] 52%|█████▏    | 9062/17525 [1:48:53<1:21:34,  1.73it/s] 52%|█████▏    | 9063/17525 [1:48:54<1:21:26,  1.73it/s] 52%|█████▏    | 9064/17525 [1:48:54<1:21:24,  1.73it/s] 52%|█████▏    | 9065/17525 [1:48:55<1:27:20,  1.61it/s] 52%|█████▏    | 9066/17525 [1:48:55<1:25:44,  1.64it/s] 52%|█████▏    | 9067/17525 [1:48:56<1:30:21,  1.56it/s] 52%|█████▏    | 9068/17525 [1:48:57<1:27:46,  1.61it/s] 52%|█████▏    | 9069/17525 [1:48:58<1:33:14,  1.51it/s] 52%|█████▏    | 9070/17525 [1:48:58<1:29:39,  1.57it/s]                                                        {'loss': 0.4862, 'grad_norm': 11.510775566101074, 'learning_rate': 9.480672982970475e-06, 'epoch': 12.94}
 52%|█████▏    | 9070/17525 [1:48:58<1:29:39,  1.57it/s] 52%|█████▏    | 9071/17525 [1:48:59<1:27:09,  1.62it/s] 52%|█████▏    | 9072/17525 [1:48:59<1:25:24,  1.65it/s] 52%|█████▏    | 9073/17525 [1:49:00<1:24:07,  1.67it/s] 52%|█████▏    | 9074/17525 [1:49:00<1:23:20,  1.69it/s] 52%|█████▏    | 9075/17525 [1:49:01<1:22:40,  1.70it/s] 52%|█████▏    | 9076/17525 [1:49:02<1:22:18,  1.71it/s] 52%|█████▏    | 9077/17525 [1:49:02<1:22:43,  1.70it/s] 52%|█████▏    | 9078/17525 [1:49:03<1:22:16,  1.71it/s] 52%|█████▏    | 9079/17525 [1:49:03<1:21:57,  1.72it/s] 52%|█████▏    | 9080/17525 [1:49:04<1:21:47,  1.72it/s]                                                        {'loss': 0.5201, 'grad_norm': 17.352174758911133, 'learning_rate': 9.46275121627352e-06, 'epoch': 12.95}
 52%|█████▏    | 9080/17525 [1:49:04<1:21:47,  1.72it/s] 52%|█████▏    | 9081/17525 [1:49:04<1:21:31,  1.73it/s] 52%|█████▏    | 9082/17525 [1:49:05<1:21:18,  1.73it/s] 52%|█████▏    | 9083/17525 [1:49:06<1:21:21,  1.73it/s] 52%|█████▏    | 9084/17525 [1:49:06<1:21:08,  1.73it/s] 52%|█████▏    | 9085/17525 [1:49:07<1:21:25,  1.73it/s] 52%|█████▏    | 9086/17525 [1:49:07<1:21:18,  1.73it/s] 52%|█████▏    | 9087/17525 [1:49:08<1:21:18,  1.73it/s] 52%|█████▏    | 9088/17525 [1:49:09<1:21:18,  1.73it/s] 52%|█████▏    | 9089/17525 [1:49:09<1:21:17,  1.73it/s] 52%|█████▏    | 9090/17525 [1:49:10<1:21:13,  1.73it/s]                                                        {'loss': 0.564, 'grad_norm': 14.87629222869873, 'learning_rate': 9.444831179993825e-06, 'epoch': 12.97}
 52%|█████▏    | 9090/17525 [1:49:10<1:21:13,  1.73it/s] 52%|█████▏    | 9091/17525 [1:49:10<1:21:18,  1.73it/s] 52%|█████▏    | 9092/17525 [1:49:11<1:21:18,  1.73it/s] 52%|█████▏    | 9093/17525 [1:49:11<1:21:19,  1.73it/s] 52%|█████▏    | 9094/17525 [1:49:12<1:21:05,  1.73it/s] 52%|█████▏    | 9095/17525 [1:49:13<1:21:15,  1.73it/s] 52%|█████▏    | 9096/17525 [1:49:13<1:21:18,  1.73it/s] 52%|█████▏    | 9097/17525 [1:49:14<1:21:12,  1.73it/s] 52%|█████▏    | 9098/17525 [1:49:14<1:21:04,  1.73it/s] 52%|█████▏    | 9099/17525 [1:49:15<1:21:05,  1.73it/s] 52%|█████▏    | 9100/17525 [1:49:15<1:21:06,  1.73it/s]                                                        {'loss': 0.4657, 'grad_norm': 11.901260375976562, 'learning_rate': 9.426912931849801e-06, 'epoch': 12.98}
 52%|█████▏    | 9100/17525 [1:49:15<1:21:06,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:52:37,338 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:52:37,338 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:52:37,338 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 0.9946326613426208, 'eval_runtime': 4.6018, 'eval_samples_per_second': 96.267, 'eval_steps_per_second': 4.129, 'epoch': 12.98}
 52%|█████▏    | 9100/17525 [1:49:20<1:21:06,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 52%|█████▏    | 9101/17525 [1:49:21<4:35:09,  1.96s/it] 52%|█████▏    | 9102/17525 [1:49:21<3:36:52,  1.54s/it] 52%|█████▏    | 9103/17525 [1:49:22<3:03:33,  1.31s/it] 52%|█████▏    | 9104/17525 [1:49:23<2:32:53,  1.09s/it] 52%|█████▏    | 9105/17525 [1:49:23<2:11:15,  1.07it/s] 52%|█████▏    | 9106/17525 [1:49:24<1:56:06,  1.21it/s] 52%|█████▏    | 9107/17525 [1:49:24<1:45:28,  1.33it/s] 52%|█████▏    | 9108/17525 [1:49:25<1:37:51,  1.43it/s] 52%|█████▏    | 9109/17525 [1:49:25<1:32:42,  1.51it/s] 52%|█████▏    | 9110/17525 [1:49:26<1:29:20,  1.57it/s]                                                        {'loss': 0.3605, 'grad_norm': 5.958285808563232, 'learning_rate': 9.40899652955408e-06, 'epoch': 13.0}
 52%|█████▏    | 9110/17525 [1:49:26<1:29:20,  1.57it/s] 52%|█████▏    | 9111/17525 [1:49:27<1:45:28,  1.33it/s] 52%|█████▏    | 9112/17525 [1:49:28<1:38:12,  1.43it/s] 52%|█████▏    | 9113/17525 [1:49:28<1:33:02,  1.51it/s] 52%|█████▏    | 9114/17525 [1:49:29<1:29:36,  1.56it/s] 52%|█████▏    | 9115/17525 [1:49:29<1:27:03,  1.61it/s] 52%|█████▏    | 9116/17525 [1:49:30<1:25:21,  1.64it/s] 52%|█████▏    | 9117/17525 [1:49:30<1:24:03,  1.67it/s] 52%|█████▏    | 9118/17525 [1:49:31<1:23:19,  1.68it/s] 52%|█████▏    | 9119/17525 [1:49:32<1:22:46,  1.69it/s] 52%|█████▏    | 9120/17525 [1:49:32<1:22:23,  1.70it/s]                                                        {'loss': 0.3415, 'grad_norm': 7.442164897918701, 'learning_rate': 9.39108203081336e-06, 'epoch': 13.01}
 52%|█████▏    | 9120/17525 [1:49:32<1:22:23,  1.70it/s] 52%|█████▏    | 9121/17525 [1:49:33<1:22:11,  1.70it/s] 52%|█████▏    | 9122/17525 [1:49:33<1:21:45,  1.71it/s] 52%|█████▏    | 9123/17525 [1:49:34<1:21:27,  1.72it/s] 52%|█████▏    | 9124/17525 [1:49:35<1:21:19,  1.72it/s] 52%|█████▏    | 9125/17525 [1:49:35<1:21:08,  1.73it/s] 52%|█████▏    | 9126/17525 [1:49:36<1:21:03,  1.73it/s] 52%|█████▏    | 9127/17525 [1:49:36<1:20:58,  1.73it/s] 52%|█████▏    | 9128/17525 [1:49:37<1:20:57,  1.73it/s] 52%|█████▏    | 9129/17525 [1:49:37<1:20:43,  1.73it/s] 52%|█████▏    | 9130/17525 [1:49:38<1:20:49,  1.73it/s]                                                        {'loss': 0.4244, 'grad_norm': 8.8135986328125, 'learning_rate': 9.373169493328206e-06, 'epoch': 13.02}
 52%|█████▏    | 9130/17525 [1:49:38<1:20:49,  1.73it/s] 52%|█████▏    | 9131/17525 [1:49:39<1:20:50,  1.73it/s] 52%|█████▏    | 9132/17525 [1:49:39<1:20:42,  1.73it/s] 52%|█████▏    | 9133/17525 [1:49:40<1:20:43,  1.73it/s] 52%|█████▏    | 9134/17525 [1:49:40<1:20:36,  1.73it/s] 52%|█████▏    | 9135/17525 [1:49:41<1:21:54,  1.71it/s] 52%|█████▏    | 9136/17525 [1:49:42<1:21:29,  1.72it/s] 52%|█████▏    | 9137/17525 [1:49:42<1:21:11,  1.72it/s] 52%|█████▏    | 9138/17525 [1:49:43<1:21:16,  1.72it/s] 52%|█████▏    | 9139/17525 [1:49:43<1:21:03,  1.72it/s] 52%|█████▏    | 9140/17525 [1:49:44<1:20:56,  1.73it/s]                                                        {'loss': 0.3565, 'grad_norm': 11.514311790466309, 'learning_rate': 9.355258974792863e-06, 'epoch': 13.04}
 52%|█████▏    | 9140/17525 [1:49:44<1:20:56,  1.73it/s] 52%|█████▏    | 9141/17525 [1:49:44<1:20:54,  1.73it/s] 52%|█████▏    | 9142/17525 [1:49:45<1:20:55,  1.73it/s] 52%|█████▏    | 9143/17525 [1:49:46<1:20:53,  1.73it/s] 52%|█████▏    | 9144/17525 [1:49:47<1:47:33,  1.30it/s] 52%|█████▏    | 9145/17525 [1:49:47<1:39:18,  1.41it/s] 52%|█████▏    | 9146/17525 [1:49:48<1:33:40,  1.49it/s] 52%|█████▏    | 9147/17525 [1:49:49<1:30:08,  1.55it/s] 52%|█████▏    | 9148/17525 [1:49:49<1:27:29,  1.60it/s] 52%|█████▏    | 9149/17525 [1:49:50<1:25:21,  1.64it/s] 52%|█████▏    | 9150/17525 [1:49:50<1:23:53,  1.66it/s]                                                        {'loss': 0.41, 'grad_norm': 10.828230857849121, 'learning_rate': 9.33735053289508e-06, 'epoch': 13.05}
 52%|█████▏    | 9150/17525 [1:49:50<1:23:53,  1.66it/s][INFO|trainer.py:3203] 2024-06-25 03:53:12,138 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7acd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f5c08029-329c-475f-b352-9509cb610ce8)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:53:22,235 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:53:22,237 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 52%|█████▏    | 9151/17525 [1:50:01<8:31:39,  3.67s/it] 52%|█████▏    | 9152/17525 [1:50:02<6:22:26,  2.74s/it] 52%|█████▏    | 9153/17525 [1:50:02<4:52:40,  2.10s/it] 52%|█████▏    | 9154/17525 [1:50:03<3:49:07,  1.64s/it] 52%|█████▏    | 9155/17525 [1:50:04<3:10:04,  1.36s/it] 52%|█████▏    | 9156/17525 [1:50:04<2:37:18,  1.13s/it] 52%|█████▏    | 9157/17525 [1:50:05<2:14:27,  1.04it/s] 52%|█████▏    | 9158/17525 [1:50:05<1:58:10,  1.18it/s] 52%|█████▏    | 9159/17525 [1:50:06<1:47:07,  1.30it/s] 52%|█████▏    | 9160/17525 [1:50:07<1:46:59,  1.30it/s]                                                        {'loss': 0.412, 'grad_norm': 9.469324111938477, 'learning_rate': 9.319444225315902e-06, 'epoch': 13.07}
 52%|█████▏    | 9160/17525 [1:50:07<1:46:59,  1.30it/s] 52%|█████▏    | 9161/17525 [1:50:07<1:40:02,  1.39it/s] 52%|█████▏    | 9162/17525 [1:50:08<1:34:03,  1.48it/s] 52%|█████▏    | 9163/17525 [1:50:08<1:29:55,  1.55it/s] 52%|█████▏    | 9164/17525 [1:50:09<1:27:08,  1.60it/s] 52%|█████▏    | 9165/17525 [1:50:10<1:25:09,  1.64it/s] 52%|█████▏    | 9166/17525 [1:50:10<1:24:07,  1.66it/s] 52%|█████▏    | 9167/17525 [1:50:11<1:23:23,  1.67it/s] 52%|█████▏    | 9168/17525 [1:50:11<1:22:27,  1.69it/s] 52%|█████▏    | 9169/17525 [1:50:12<1:21:49,  1.70it/s] 52%|█████▏    | 9170/17525 [1:50:12<1:21:30,  1.71it/s]                                                        {'loss': 0.4211, 'grad_norm': 3.5008301734924316, 'learning_rate': 9.301540109729524e-06, 'epoch': 13.08}
 52%|█████▏    | 9170/17525 [1:50:12<1:21:30,  1.71it/s] 52%|█████▏    | 9171/17525 [1:50:13<1:21:16,  1.71it/s] 52%|█████▏    | 9172/17525 [1:50:14<1:21:03,  1.72it/s] 52%|█████▏    | 9173/17525 [1:50:14<1:20:49,  1.72it/s] 52%|█████▏    | 9174/17525 [1:50:15<1:20:43,  1.72it/s] 52%|█████▏    | 9175/17525 [1:50:15<1:20:31,  1.73it/s] 52%|█████▏    | 9176/17525 [1:50:16<1:20:33,  1.73it/s] 52%|█████▏    | 9177/17525 [1:50:16<1:20:30,  1.73it/s] 52%|█████▏    | 9178/17525 [1:50:17<1:20:25,  1.73it/s] 52%|█████▏    | 9179/17525 [1:50:18<1:20:25,  1.73it/s] 52%|█████▏    | 9180/17525 [1:50:18<1:20:12,  1.73it/s]                                                        {'loss': 0.3748, 'grad_norm': 10.979677200317383, 'learning_rate': 9.28363824380306e-06, 'epoch': 13.1}
 52%|█████▏    | 9180/17525 [1:50:18<1:20:12,  1.73it/s] 52%|█████▏    | 9181/17525 [1:50:19<1:20:27,  1.73it/s] 52%|█████▏    | 9182/17525 [1:50:19<1:20:23,  1.73it/s] 52%|█████▏    | 9183/17525 [1:50:20<1:20:19,  1.73it/s] 52%|█████▏    | 9184/17525 [1:50:21<1:20:21,  1.73it/s] 52%|█████▏    | 9185/17525 [1:50:21<1:20:21,  1.73it/s] 52%|█████▏    | 9186/17525 [1:50:22<1:20:20,  1.73it/s] 52%|█████▏    | 9187/17525 [1:50:22<1:20:19,  1.73it/s] 52%|█████▏    | 9188/17525 [1:50:23<1:20:14,  1.73it/s] 52%|█████▏    | 9189/17525 [1:50:23<1:20:16,  1.73it/s] 52%|█████▏    | 9190/17525 [1:50:24<1:20:12,  1.73it/s]                                                        {'loss': 0.4025, 'grad_norm': 22.59600830078125, 'learning_rate': 9.265738685196383e-06, 'epoch': 13.11}
 52%|█████▏    | 9190/17525 [1:50:24<1:20:12,  1.73it/s] 52%|█████▏    | 9191/17525 [1:50:25<1:20:18,  1.73it/s] 52%|█████▏    | 9192/17525 [1:50:25<1:20:26,  1.73it/s] 52%|█████▏    | 9193/17525 [1:50:26<1:20:23,  1.73it/s] 52%|█████▏    | 9194/17525 [1:50:26<1:20:24,  1.73it/s] 52%|█████▏    | 9195/17525 [1:50:27<1:20:28,  1.73it/s] 52%|█████▏    | 9196/17525 [1:50:27<1:20:28,  1.72it/s] 52%|█████▏    | 9197/17525 [1:50:28<1:20:23,  1.73it/s] 52%|█████▏    | 9198/17525 [1:50:29<1:20:17,  1.73it/s] 52%|█████▏    | 9199/17525 [1:50:29<1:20:09,  1.73it/s] 52%|█████▏    | 9200/17525 [1:50:30<1:20:01,  1.73it/s]                                                        {'loss': 0.3378, 'grad_norm': 11.360370635986328, 'learning_rate': 9.247841491561942e-06, 'epoch': 13.12}
 52%|█████▏    | 9200/17525 [1:50:30<1:20:01,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 03:53:51,670 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:53:51,670 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:53:51,670 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                        
                                               [A{'eval_loss': 1.0124504566192627, 'eval_runtime': 4.5945, 'eval_samples_per_second': 96.419, 'eval_steps_per_second': 4.135, 'epoch': 13.12}
 52%|█████▏    | 9200/17525 [1:50:34<1:20:01,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 53%|█████▎    | 9201/17525 [1:50:35<4:31:53,  1.96s/it] 53%|█████▎    | 9202/17525 [1:50:36<3:34:17,  1.54s/it] 53%|█████▎    | 9203/17525 [1:50:37<3:11:47,  1.38s/it] 53%|█████▎    | 9204/17525 [1:50:37<2:38:34,  1.14s/it] 53%|█████▎    | 9205/17525 [1:50:38<2:15:06,  1.03it/s] 53%|█████▎    | 9206/17525 [1:50:38<1:58:37,  1.17it/s] 53%|█████▎    | 9207/17525 [1:50:39<1:47:08,  1.29it/s] 53%|█████▎    | 9208/17525 [1:50:39<1:39:18,  1.40it/s] 53%|█████▎    | 9209/17525 [1:50:40<1:33:32,  1.48it/s] 53%|█████▎    | 9210/17525 [1:50:41<1:29:36,  1.55it/s]                                                        {'loss': 0.3399, 'grad_norm': 8.280852317810059, 'learning_rate': 9.229946720544562e-06, 'epoch': 13.14}
 53%|█████▎    | 9210/17525 [1:50:41<1:29:36,  1.55it/s] 53%|█████▎    | 9211/17525 [1:50:41<1:26:58,  1.59it/s] 53%|█████▎    | 9212/17525 [1:50:42<1:24:51,  1.63it/s] 53%|█████▎    | 9213/17525 [1:50:42<1:23:16,  1.66it/s] 53%|█████▎    | 9214/17525 [1:50:43<1:22:19,  1.68it/s] 53%|█████▎    | 9215/17525 [1:50:44<1:21:40,  1.70it/s] 53%|█████▎    | 9216/17525 [1:50:44<1:21:06,  1.71it/s] 53%|█████▎    | 9217/17525 [1:50:45<1:20:41,  1.72it/s] 53%|█████▎    | 9218/17525 [1:50:45<1:21:05,  1.71it/s] 53%|█████▎    | 9219/17525 [1:50:46<1:20:47,  1.71it/s] 53%|█████▎    | 9220/17525 [1:50:46<1:20:19,  1.72it/s]                                                        {'loss': 0.4246, 'grad_norm': 8.659378051757812, 'learning_rate': 9.212054429781265e-06, 'epoch': 13.15}
 53%|█████▎    | 9220/17525 [1:50:46<1:20:19,  1.72it/s] 53%|█████▎    | 9221/17525 [1:50:47<1:20:14,  1.72it/s] 53%|█████▎    | 9222/17525 [1:50:48<1:20:12,  1.73it/s] 53%|█████▎    | 9223/17525 [1:50:48<1:20:10,  1.73it/s] 53%|█████▎    | 9224/17525 [1:50:49<1:20:02,  1.73it/s] 53%|█████▎    | 9225/17525 [1:50:49<1:20:05,  1.73it/s] 53%|█████▎    | 9226/17525 [1:50:50<1:25:48,  1.61it/s] 53%|█████▎    | 9227/17525 [1:50:51<1:24:03,  1.65it/s] 53%|█████▎    | 9228/17525 [1:50:51<1:23:31,  1.66it/s] 53%|█████▎    | 9229/17525 [1:50:52<1:22:22,  1.68it/s] 53%|█████▎    | 9230/17525 [1:50:52<1:21:43,  1.69it/s]                                                        {'loss': 0.4458, 'grad_norm': 8.754204750061035, 'learning_rate': 9.194164676901088e-06, 'epoch': 13.17}
 53%|█████▎    | 9230/17525 [1:50:52<1:21:43,  1.69it/s] 53%|█████▎    | 9231/17525 [1:50:53<1:21:28,  1.70it/s] 53%|█████▎    | 9232/17525 [1:50:54<1:21:03,  1.71it/s] 53%|█████▎    | 9233/17525 [1:50:54<1:28:21,  1.56it/s] 53%|█████▎    | 9234/17525 [1:50:55<1:25:48,  1.61it/s] 53%|█████▎    | 9235/17525 [1:50:55<1:23:56,  1.65it/s] 53%|█████▎    | 9236/17525 [1:50:56<1:22:41,  1.67it/s] 53%|█████▎    | 9237/17525 [1:50:57<1:21:44,  1.69it/s] 53%|█████▎    | 9238/17525 [1:50:58<1:35:59,  1.44it/s] 53%|█████▎    | 9239/17525 [1:50:58<1:31:22,  1.51it/s] 53%|█████▎    | 9240/17525 [1:50:59<1:27:45,  1.57it/s]                                                        {'loss': 0.3545, 'grad_norm': 9.251424789428711, 'learning_rate': 9.17627751952489e-06, 'epoch': 13.18}
 53%|█████▎    | 9240/17525 [1:50:59<1:27:45,  1.57it/s] 53%|█████▎    | 9241/17525 [1:50:59<1:25:25,  1.62it/s] 53%|█████▎    | 9242/17525 [1:51:00<1:23:46,  1.65it/s] 53%|█████▎    | 9243/17525 [1:51:00<1:22:35,  1.67it/s] 53%|█████▎    | 9244/17525 [1:51:01<1:21:43,  1.69it/s] 53%|█████▎    | 9245/17525 [1:51:02<1:21:11,  1.70it/s] 53%|█████▎    | 9246/17525 [1:51:02<1:20:43,  1.71it/s] 53%|█████▎    | 9247/17525 [1:51:03<1:20:27,  1.71it/s] 53%|█████▎    | 9248/17525 [1:51:03<1:20:10,  1.72it/s] 53%|█████▎    | 9249/17525 [1:51:04<1:20:05,  1.72it/s] 53%|█████▎    | 9250/17525 [1:51:04<1:19:46,  1.73it/s]                                                        {'loss': 0.4353, 'grad_norm': 16.525840759277344, 'learning_rate': 9.15839301526517e-06, 'epoch': 13.2}
 53%|█████▎    | 9250/17525 [1:51:04<1:19:46,  1.73it/s] 53%|█████▎    | 9251/17525 [1:51:05<1:19:56,  1.73it/s] 53%|█████▎    | 9252/17525 [1:51:06<1:19:58,  1.72it/s] 53%|█████▎    | 9253/17525 [1:51:06<1:19:45,  1.73it/s] 53%|█████▎    | 9254/17525 [1:51:07<1:19:39,  1.73it/s] 53%|█████▎    | 9255/17525 [1:51:07<1:19:34,  1.73it/s] 53%|█████▎    | 9256/17525 [1:51:08<1:19:41,  1.73it/s] 53%|█████▎    | 9257/17525 [1:51:08<1:19:40,  1.73it/s] 53%|█████▎    | 9258/17525 [1:51:10<1:37:22,  1.41it/s] 53%|█████▎    | 9259/17525 [1:51:10<1:31:59,  1.50it/s] 53%|█████▎    | 9260/17525 [1:51:11<1:28:15,  1.56it/s]                                                        {'loss': 0.3354, 'grad_norm': 10.13416576385498, 'learning_rate': 9.140511221725883e-06, 'epoch': 13.21}
 53%|█████▎    | 9260/17525 [1:51:11<1:28:15,  1.56it/s] 53%|█████▎    | 9261/17525 [1:51:11<1:25:42,  1.61it/s] 53%|█████▎    | 9262/17525 [1:51:12<1:23:45,  1.64it/s] 53%|█████▎    | 9263/17525 [1:51:12<1:22:24,  1.67it/s] 53%|█████▎    | 9264/17525 [1:51:13<1:35:03,  1.45it/s] 53%|█████▎    | 9265/17525 [1:51:14<1:30:30,  1.52it/s] 53%|█████▎    | 9266/17525 [1:51:14<1:27:09,  1.58it/s] 53%|█████▎    | 9267/17525 [1:51:15<1:24:56,  1.62it/s] 53%|█████▎    | 9268/17525 [1:51:16<1:23:38,  1.65it/s] 53%|█████▎    | 9269/17525 [1:51:16<1:22:19,  1.67it/s] 53%|█████▎    | 9270/17525 [1:51:17<1:21:27,  1.69it/s]                                                        {'loss': 0.5149, 'grad_norm': 7.790621757507324, 'learning_rate': 9.122632196502261e-06, 'epoch': 13.22}
 53%|█████▎    | 9270/17525 [1:51:17<1:21:27,  1.69it/s] 53%|█████▎    | 9271/17525 [1:51:17<1:20:57,  1.70it/s] 53%|█████▎    | 9272/17525 [1:51:18<1:20:35,  1.71it/s] 53%|█████▎    | 9273/17525 [1:51:19<1:20:11,  1.72it/s] 53%|█████▎    | 9274/17525 [1:51:19<1:19:43,  1.72it/s] 53%|█████▎    | 9275/17525 [1:51:20<1:19:39,  1.73it/s] 53%|█████▎    | 9276/17525 [1:51:20<1:19:34,  1.73it/s] 53%|█████▎    | 9277/17525 [1:51:21<1:19:22,  1.73it/s] 53%|█████▎    | 9278/17525 [1:51:21<1:19:28,  1.73it/s] 53%|█████▎    | 9279/17525 [1:51:22<1:19:28,  1.73it/s] 53%|█████▎    | 9280/17525 [1:51:23<1:19:22,  1.73it/s]                                                        {'loss': 0.4432, 'grad_norm': 8.449944496154785, 'learning_rate': 9.104755997180604e-06, 'epoch': 13.24}
 53%|█████▎    | 9280/17525 [1:51:23<1:19:22,  1.73it/s] 53%|█████▎    | 9281/17525 [1:51:23<1:19:20,  1.73it/s] 53%|█████▎    | 9282/17525 [1:51:24<1:19:08,  1.74it/s] 53%|█████▎    | 9283/17525 [1:51:24<1:19:07,  1.74it/s] 53%|█████▎    | 9284/17525 [1:51:25<1:19:09,  1.74it/s] 53%|█████▎    | 9285/17525 [1:51:25<1:19:02,  1.74it/s] 53%|█████▎    | 9286/17525 [1:51:26<1:19:16,  1.73it/s] 53%|█████▎    | 9287/17525 [1:51:27<1:19:15,  1.73it/s] 53%|█████▎    | 9288/17525 [1:51:27<1:19:18,  1.73it/s] 53%|█████▎    | 9289/17525 [1:51:28<1:19:59,  1.72it/s] 53%|█████▎    | 9290/17525 [1:51:28<1:19:42,  1.72it/s]                                                        {'loss': 0.3807, 'grad_norm': 28.33681297302246, 'learning_rate': 9.086882681338119e-06, 'epoch': 13.25}
 53%|█████▎    | 9290/17525 [1:51:28<1:19:42,  1.72it/s] 53%|█████▎    | 9291/17525 [1:51:29<1:19:42,  1.72it/s] 53%|█████▎    | 9292/17525 [1:51:29<1:19:38,  1.72it/s] 53%|█████▎    | 9293/17525 [1:51:30<1:19:40,  1.72it/s] 53%|█████▎    | 9294/17525 [1:51:31<1:19:45,  1.72it/s] 53%|█████▎    | 9295/17525 [1:51:31<1:19:42,  1.72it/s] 53%|█████▎    | 9296/17525 [1:51:32<1:19:43,  1.72it/s] 53%|█████▎    | 9297/17525 [1:51:33<1:39:24,  1.38it/s] 53%|█████▎    | 9298/17525 [1:51:34<1:41:01,  1.36it/s] 53%|█████▎    | 9299/17525 [1:51:34<1:34:20,  1.45it/s] 53%|█████▎    | 9300/17525 [1:51:35<1:29:42,  1.53it/s]                                                        {'loss': 0.3352, 'grad_norm': 9.962830543518066, 'learning_rate': 9.069012306542728e-06, 'epoch': 13.27}
 53%|█████▎    | 9300/17525 [1:51:35<1:29:42,  1.53it/s][INFO|trainer.py:3512] 2024-06-25 03:54:56,685 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:54:56,685 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:54:56,685 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.044867753982544, 'eval_runtime': 4.5994, 'eval_samples_per_second': 96.317, 'eval_steps_per_second': 4.131, 'epoch': 13.27}
 53%|█████▎    | 9300/17525 [1:51:39<1:29:42,  1.53it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:55:01,288 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7ac5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 967e592d-75ce-4919-8588-9498ee57eb6c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:55:11,346 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:55:11,349 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 53%|█████▎    | 9301/17525 [1:51:50<11:35:16,  5.07s/it] 53%|█████▎    | 9302/17525 [1:51:51<8:30:34,  3.73s/it]  53%|█████▎    | 9303/17525 [1:51:51<6:21:13,  2.78s/it] 53%|█████▎    | 9304/17525 [1:51:52<4:50:33,  2.12s/it] 53%|█████▎    | 9305/17525 [1:51:52<3:47:09,  1.66s/it] 53%|█████▎    | 9306/17525 [1:51:53<3:02:35,  1.33s/it] 53%|█████▎    | 9307/17525 [1:51:54<2:31:31,  1.11s/it] 53%|█████▎    | 9308/17525 [1:51:54<2:09:44,  1.06it/s] 53%|█████▎    | 9309/17525 [1:51:55<1:54:27,  1.20it/s] 53%|█████▎    | 9310/17525 [1:51:55<1:43:42,  1.32it/s]                                                        {'loss': 0.4274, 'grad_norm': 8.012381553649902, 'learning_rate': 9.051144930352874e-06, 'epoch': 13.28}
 53%|█████▎    | 9310/17525 [1:51:55<1:43:42,  1.32it/s] 53%|█████▎    | 9311/17525 [1:51:56<1:36:26,  1.42it/s] 53%|█████▎    | 9312/17525 [1:51:57<1:31:08,  1.50it/s] 53%|█████▎    | 9313/17525 [1:51:57<1:27:31,  1.56it/s] 53%|█████▎    | 9314/17525 [1:51:58<1:25:02,  1.61it/s] 53%|█████▎    | 9315/17525 [1:51:58<1:23:14,  1.64it/s] 53%|█████▎    | 9316/17525 [1:51:59<1:21:49,  1.67it/s] 53%|█████▎    | 9317/17525 [1:51:59<1:21:01,  1.69it/s] 53%|█████▎    | 9318/17525 [1:52:00<1:20:30,  1.70it/s] 53%|█████▎    | 9319/17525 [1:52:01<1:19:52,  1.71it/s] 53%|█████▎    | 9320/17525 [1:52:01<1:19:36,  1.72it/s]                                                        {'loss': 0.4611, 'grad_norm': 10.694463729858398, 'learning_rate': 9.033280610317348e-06, 'epoch': 13.3}
 53%|█████▎    | 9320/17525 [1:52:01<1:19:36,  1.72it/s] 53%|█████▎    | 9321/17525 [1:52:02<1:19:31,  1.72it/s] 53%|█████▎    | 9322/17525 [1:52:02<1:19:20,  1.72it/s] 53%|█████▎    | 9323/17525 [1:52:03<1:19:11,  1.73it/s] 53%|█████▎    | 9324/17525 [1:52:03<1:19:10,  1.73it/s] 53%|█████▎    | 9325/17525 [1:52:04<1:19:04,  1.73it/s] 53%|█████▎    | 9326/17525 [1:52:05<1:19:03,  1.73it/s] 53%|█████▎    | 9327/17525 [1:52:05<1:19:14,  1.72it/s] 53%|█████▎    | 9328/17525 [1:52:06<1:19:04,  1.73it/s] 53%|█████▎    | 9329/17525 [1:52:06<1:18:53,  1.73it/s] 53%|█████▎    | 9330/17525 [1:52:07<1:18:55,  1.73it/s]                                                        {'loss': 0.333, 'grad_norm': 10.811261177062988, 'learning_rate': 9.015419403975094e-06, 'epoch': 13.31}
 53%|█████▎    | 9330/17525 [1:52:07<1:18:55,  1.73it/s] 53%|█████▎    | 9331/17525 [1:52:08<1:19:02,  1.73it/s] 53%|█████▎    | 9332/17525 [1:52:08<1:18:54,  1.73it/s] 53%|█████▎    | 9333/17525 [1:52:09<1:18:57,  1.73it/s] 53%|█████▎    | 9334/17525 [1:52:09<1:18:50,  1.73it/s] 53%|█████▎    | 9335/17525 [1:52:10<1:18:46,  1.73it/s] 53%|█████▎    | 9336/17525 [1:52:10<1:18:41,  1.73it/s] 53%|█████▎    | 9337/17525 [1:52:11<1:18:39,  1.74it/s] 53%|█████▎    | 9338/17525 [1:52:12<1:18:44,  1.73it/s] 53%|█████▎    | 9339/17525 [1:52:12<1:18:39,  1.73it/s] 53%|█████▎    | 9340/17525 [1:52:13<1:18:42,  1.73it/s]                                                        {'loss': 0.3787, 'grad_norm': 21.86992073059082, 'learning_rate': 8.997561368855022e-06, 'epoch': 13.32}
 53%|█████▎    | 9340/17525 [1:52:13<1:18:42,  1.73it/s] 53%|█████▎    | 9341/17525 [1:52:13<1:18:44,  1.73it/s] 53%|█████▎    | 9342/17525 [1:52:14<1:18:31,  1.74it/s] 53%|█████▎    | 9343/17525 [1:52:15<1:33:07,  1.46it/s] 53%|█████▎    | 9344/17525 [1:52:15<1:28:52,  1.53it/s] 53%|█████▎    | 9345/17525 [1:52:16<1:25:47,  1.59it/s] 53%|█████▎    | 9346/17525 [1:52:17<1:23:49,  1.63it/s] 53%|█████▎    | 9347/17525 [1:52:17<1:22:26,  1.65it/s] 53%|█████▎    | 9348/17525 [1:52:18<1:21:21,  1.67it/s] 53%|█████▎    | 9349/17525 [1:52:18<1:20:35,  1.69it/s] 53%|█████▎    | 9350/17525 [1:52:19<1:20:01,  1.70it/s]                                                        {'loss': 0.483, 'grad_norm': 9.664454460144043, 'learning_rate': 8.979706562475836e-06, 'epoch': 13.34}
 53%|█████▎    | 9350/17525 [1:52:19<1:20:01,  1.70it/s] 53%|█████▎    | 9351/17525 [1:52:19<1:19:40,  1.71it/s] 53%|█████▎    | 9352/17525 [1:52:20<1:19:22,  1.72it/s] 53%|█████▎    | 9353/17525 [1:52:21<1:19:18,  1.72it/s] 53%|█████▎    | 9354/17525 [1:52:21<1:19:06,  1.72it/s] 53%|█████▎    | 9355/17525 [1:52:22<1:18:58,  1.72it/s] 53%|█████▎    | 9356/17525 [1:52:22<1:18:46,  1.73it/s] 53%|█████▎    | 9357/17525 [1:52:23<1:18:32,  1.73it/s] 53%|█████▎    | 9358/17525 [1:52:23<1:18:33,  1.73it/s] 53%|█████▎    | 9359/17525 [1:52:24<1:18:37,  1.73it/s] 53%|█████▎    | 9360/17525 [1:52:25<1:18:49,  1.73it/s]                                                        {'loss': 0.4264, 'grad_norm': 9.522260665893555, 'learning_rate': 8.961855042345842e-06, 'epoch': 13.35}
 53%|█████▎    | 9360/17525 [1:52:25<1:18:49,  1.73it/s] 53%|█████▎    | 9361/17525 [1:52:25<1:18:55,  1.72it/s] 53%|█████▎    | 9362/17525 [1:52:26<1:18:48,  1.73it/s] 53%|█████▎    | 9363/17525 [1:52:26<1:18:46,  1.73it/s] 53%|█████▎    | 9364/17525 [1:52:27<1:18:46,  1.73it/s] 53%|█████▎    | 9365/17525 [1:52:28<1:18:49,  1.73it/s] 53%|█████▎    | 9366/17525 [1:52:28<1:18:47,  1.73it/s] 53%|█████▎    | 9367/17525 [1:52:29<1:18:38,  1.73it/s] 53%|█████▎    | 9368/17525 [1:52:29<1:18:36,  1.73it/s] 53%|█████▎    | 9369/17525 [1:52:30<1:18:34,  1.73it/s] 53%|█████▎    | 9370/17525 [1:52:31<1:23:35,  1.63it/s]                                                        {'loss': 0.5293, 'grad_norm': 10.312088012695312, 'learning_rate': 8.944006865962756e-06, 'epoch': 13.37}
 53%|█████▎    | 9370/17525 [1:52:31<1:23:35,  1.63it/s] 53%|█████▎    | 9371/17525 [1:52:32<2:04:46,  1.09it/s] 53%|█████▎    | 9372/17525 [1:52:33<1:50:50,  1.23it/s] 53%|█████▎    | 9373/17525 [1:52:33<1:40:56,  1.35it/s] 53%|█████▎    | 9374/17525 [1:52:34<1:34:11,  1.44it/s] 53%|█████▎    | 9375/17525 [1:52:34<1:29:15,  1.52it/s] 54%|█████▎    | 9376/17525 [1:52:35<1:25:46,  1.58it/s] 54%|█████▎    | 9377/17525 [1:52:36<1:23:39,  1.62it/s] 54%|█████▎    | 9378/17525 [1:52:36<1:21:54,  1.66it/s] 54%|█████▎    | 9379/17525 [1:52:37<1:20:48,  1.68it/s] 54%|█████▎    | 9380/17525 [1:52:37<1:20:03,  1.70it/s]                                                        {'loss': 0.4211, 'grad_norm': 6.401022434234619, 'learning_rate': 8.926162090813521e-06, 'epoch': 13.38}
 54%|█████▎    | 9380/17525 [1:52:37<1:20:03,  1.70it/s] 54%|█████▎    | 9381/17525 [1:52:38<1:19:37,  1.70it/s] 54%|█████▎    | 9382/17525 [1:52:38<1:19:18,  1.71it/s] 54%|█████▎    | 9383/17525 [1:52:39<1:18:49,  1.72it/s] 54%|█████▎    | 9384/17525 [1:52:40<1:18:50,  1.72it/s] 54%|█████▎    | 9385/17525 [1:52:40<1:18:47,  1.72it/s] 54%|█████▎    | 9386/17525 [1:52:41<1:18:30,  1.73it/s] 54%|█████▎    | 9387/17525 [1:52:41<1:18:23,  1.73it/s] 54%|█████▎    | 9388/17525 [1:52:42<1:18:25,  1.73it/s] 54%|█████▎    | 9389/17525 [1:52:43<1:18:18,  1.73it/s] 54%|█████▎    | 9390/17525 [1:52:43<1:18:51,  1.72it/s]                                                        {'loss': 0.3935, 'grad_norm': 14.754081726074219, 'learning_rate': 8.90832077437413e-06, 'epoch': 13.4}
 54%|█████▎    | 9390/17525 [1:52:43<1:18:51,  1.72it/s] 54%|█████▎    | 9391/17525 [1:52:44<1:18:46,  1.72it/s] 54%|█████▎    | 9392/17525 [1:52:44<1:18:33,  1.73it/s] 54%|█████▎    | 9393/17525 [1:52:45<1:18:34,  1.72it/s] 54%|█████▎    | 9394/17525 [1:52:45<1:18:26,  1.73it/s] 54%|█████▎    | 9395/17525 [1:52:46<1:18:21,  1.73it/s] 54%|█████▎    | 9396/17525 [1:52:47<1:18:52,  1.72it/s] 54%|█████▎    | 9397/17525 [1:52:47<1:19:23,  1.71it/s] 54%|█████▎    | 9398/17525 [1:52:48<1:18:55,  1.72it/s] 54%|█████▎    | 9399/17525 [1:52:48<1:18:45,  1.72it/s] 54%|█████▎    | 9400/17525 [1:52:49<1:18:39,  1.72it/s]                                                        {'loss': 0.4589, 'grad_norm': 9.188735008239746, 'learning_rate': 8.89048297410944e-06, 'epoch': 13.41}
 54%|█████▎    | 9400/17525 [1:52:49<1:18:39,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:56:10,823 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:56:10,823 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:56:10,823 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.0245295763015747, 'eval_runtime': 4.5998, 'eval_samples_per_second': 96.308, 'eval_steps_per_second': 4.131, 'epoch': 13.41}
 54%|█████▎    | 9400/17525 [1:52:54<1:18:39,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 54%|█████▎    | 9401/17525 [1:52:54<4:26:05,  1.97s/it] 54%|█████▎    | 9402/17525 [1:52:55<3:29:50,  1.55s/it] 54%|█████▎    | 9403/17525 [1:52:55<2:50:17,  1.26s/it] 54%|█████▎    | 9404/17525 [1:52:56<2:22:30,  1.05s/it] 54%|█████▎    | 9405/17525 [1:52:56<2:03:12,  1.10it/s] 54%|█████▎    | 9406/17525 [1:52:57<1:49:40,  1.23it/s] 54%|█████▎    | 9407/17525 [1:52:58<1:40:18,  1.35it/s] 54%|█████▎    | 9408/17525 [1:52:58<1:33:35,  1.45it/s] 54%|█████▎    | 9409/17525 [1:52:59<1:28:39,  1.53it/s] 54%|█████▎    | 9410/17525 [1:52:59<1:25:31,  1.58it/s]                                                        {'loss': 0.4466, 'grad_norm': 7.73370885848999, 'learning_rate': 8.872648747472974e-06, 'epoch': 13.42}
 54%|█████▎    | 9410/17525 [1:52:59<1:25:31,  1.58it/s] 54%|█████▎    | 9411/17525 [1:53:00<1:23:23,  1.62it/s] 54%|█████▎    | 9412/17525 [1:53:00<1:21:42,  1.66it/s] 54%|█████▎    | 9413/17525 [1:53:01<1:20:32,  1.68it/s] 54%|█████▎    | 9414/17525 [1:53:02<1:19:36,  1.70it/s] 54%|█████▎    | 9415/17525 [1:53:02<1:18:59,  1.71it/s] 54%|█████▎    | 9416/17525 [1:53:03<1:19:32,  1.70it/s] 54%|█████▎    | 9417/17525 [1:53:03<1:18:59,  1.71it/s] 54%|█████▎    | 9418/17525 [1:53:04<1:18:33,  1.72it/s] 54%|█████▎    | 9419/17525 [1:53:05<1:18:16,  1.73it/s] 54%|█████▍    | 9420/17525 [1:53:05<1:18:10,  1.73it/s]                                                        {'loss': 0.4114, 'grad_norm': 17.475393295288086, 'learning_rate': 8.85481815190675e-06, 'epoch': 13.44}
 54%|█████▍    | 9420/17525 [1:53:05<1:18:10,  1.73it/s] 54%|█████▍    | 9421/17525 [1:53:06<1:18:09,  1.73it/s] 54%|█████▍    | 9422/17525 [1:53:06<1:17:59,  1.73it/s] 54%|█████▍    | 9423/17525 [1:53:07<1:17:54,  1.73it/s] 54%|█████▍    | 9424/17525 [1:53:08<2:01:01,  1.12it/s] 54%|█████▍    | 9425/17525 [1:53:09<1:47:56,  1.25it/s] 54%|█████▍    | 9426/17525 [1:53:10<2:10:32,  1.03it/s] 54%|█████▍    | 9427/17525 [1:53:11<1:54:54,  1.17it/s] 54%|█████▍    | 9428/17525 [1:53:12<1:43:39,  1.30it/s] 54%|█████▍    | 9429/17525 [1:53:12<1:35:41,  1.41it/s] 54%|█████▍    | 9430/17525 [1:53:13<1:30:13,  1.50it/s]                                                        {'loss': 0.4411, 'grad_norm': 10.888259887695312, 'learning_rate': 8.83699124484109e-06, 'epoch': 13.45}
 54%|█████▍    | 9430/17525 [1:53:13<1:30:13,  1.50it/s] 54%|█████▍    | 9431/17525 [1:53:13<1:26:36,  1.56it/s] 54%|█████▍    | 9432/17525 [1:53:14<1:23:53,  1.61it/s] 54%|█████▍    | 9433/17525 [1:53:14<1:21:53,  1.65it/s] 54%|█████▍    | 9434/17525 [1:53:15<1:20:36,  1.67it/s] 54%|█████▍    | 9435/17525 [1:53:16<1:19:56,  1.69it/s] 54%|█████▍    | 9436/17525 [1:53:16<1:19:19,  1.70it/s] 54%|█████▍    | 9437/17525 [1:53:17<1:18:58,  1.71it/s] 54%|█████▍    | 9438/17525 [1:53:17<1:19:47,  1.69it/s] 54%|█████▍    | 9439/17525 [1:53:18<1:19:08,  1.70it/s] 54%|█████▍    | 9440/17525 [1:53:19<1:24:29,  1.59it/s]                                                        {'loss': 0.3641, 'grad_norm': 15.638580322265625, 'learning_rate': 8.819168083694432e-06, 'epoch': 13.47}
 54%|█████▍    | 9440/17525 [1:53:19<1:24:29,  1.59it/s] 54%|█████▍    | 9441/17525 [1:53:19<1:22:51,  1.63it/s] 54%|█████▍    | 9442/17525 [1:53:20<1:21:09,  1.66it/s] 54%|█████▍    | 9443/17525 [1:53:20<1:20:07,  1.68it/s] 54%|█████▍    | 9444/17525 [1:53:21<1:19:27,  1.70it/s] 54%|█████▍    | 9445/17525 [1:53:22<1:18:45,  1.71it/s] 54%|█████▍    | 9446/17525 [1:53:22<1:18:17,  1.72it/s] 54%|█████▍    | 9447/17525 [1:53:23<1:18:09,  1.72it/s] 54%|█████▍    | 9448/17525 [1:53:23<1:17:57,  1.73it/s] 54%|█████▍    | 9449/17525 [1:53:24<1:17:58,  1.73it/s] 54%|█████▍    | 9450/17525 [1:53:24<1:17:48,  1.73it/s]                                                        {'loss': 0.3986, 'grad_norm': 21.45943260192871, 'learning_rate': 8.80134872587316e-06, 'epoch': 13.48}
 54%|█████▍    | 9450/17525 [1:53:24<1:17:48,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 03:56:46,308 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a64ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 774ddea1-7fbe-48e1-80e5-bd6256eb97f1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:56:56,365 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:56:56,367 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 54%|█████▍    | 9451/17525 [1:53:35<8:10:02,  3.64s/it] 54%|█████▍    | 9452/17525 [1:53:36<6:06:21,  2.72s/it] 54%|█████▍    | 9453/17525 [1:53:36<4:39:32,  2.08s/it] 54%|█████▍    | 9454/17525 [1:53:37<3:39:03,  1.63s/it] 54%|█████▍    | 9455/17525 [1:53:38<2:56:44,  1.31s/it] 54%|█████▍    | 9456/17525 [1:53:38<2:26:55,  1.09s/it] 54%|█████▍    | 9457/17525 [1:53:39<2:05:54,  1.07it/s] 54%|█████▍    | 9458/17525 [1:53:39<1:51:13,  1.21it/s] 54%|█████▍    | 9459/17525 [1:53:40<1:41:07,  1.33it/s] 54%|█████▍    | 9460/17525 [1:53:40<1:34:04,  1.43it/s]                                                        {'loss': 0.4371, 'grad_norm': 16.896141052246094, 'learning_rate': 8.783533228771395e-06, 'epoch': 13.5}
 54%|█████▍    | 9460/17525 [1:53:40<1:34:04,  1.43it/s] 54%|█████▍    | 9461/17525 [1:53:41<1:29:11,  1.51it/s] 54%|█████▍    | 9462/17525 [1:53:42<1:25:53,  1.56it/s] 54%|█████▍    | 9463/17525 [1:53:42<1:23:28,  1.61it/s] 54%|█████▍    | 9464/17525 [1:53:43<1:21:40,  1.64it/s] 54%|█████▍    | 9465/17525 [1:53:43<1:20:17,  1.67it/s] 54%|█████▍    | 9466/17525 [1:53:44<1:20:04,  1.68it/s] 54%|█████▍    | 9467/17525 [1:53:44<1:19:43,  1.68it/s] 54%|█████▍    | 9468/17525 [1:53:45<1:19:02,  1.70it/s] 54%|█████▍    | 9469/17525 [1:53:46<1:18:21,  1.71it/s] 54%|█████▍    | 9470/17525 [1:53:46<1:18:13,  1.72it/s]                                                        {'loss': 0.4136, 'grad_norm': 9.699288368225098, 'learning_rate': 8.765721649770826e-06, 'epoch': 13.51}
 54%|█████▍    | 9470/17525 [1:53:46<1:18:13,  1.72it/s] 54%|█████▍    | 9471/17525 [1:53:47<1:18:06,  1.72it/s] 54%|█████▍    | 9472/17525 [1:53:47<1:17:54,  1.72it/s] 54%|█████▍    | 9473/17525 [1:53:48<1:17:44,  1.73it/s] 54%|█████▍    | 9474/17525 [1:53:49<1:17:41,  1.73it/s] 54%|█████▍    | 9475/17525 [1:53:49<1:17:40,  1.73it/s] 54%|█████▍    | 9476/17525 [1:53:50<1:17:27,  1.73it/s] 54%|█████▍    | 9477/17525 [1:53:50<1:23:34,  1.61it/s] 54%|█████▍    | 9478/17525 [1:53:51<1:35:49,  1.40it/s] 54%|█████▍    | 9479/17525 [1:53:52<1:30:42,  1.48it/s] 54%|█████▍    | 9480/17525 [1:53:52<1:26:54,  1.54it/s]                                                        {'loss': 0.4564, 'grad_norm': 16.748279571533203, 'learning_rate': 8.747914046240526e-06, 'epoch': 13.52}
 54%|█████▍    | 9480/17525 [1:53:52<1:26:54,  1.54it/s] 54%|█████▍    | 9481/17525 [1:53:53<1:24:20,  1.59it/s] 54%|█████▍    | 9482/17525 [1:53:54<1:22:05,  1.63it/s] 54%|█████▍    | 9483/17525 [1:53:54<1:20:25,  1.67it/s] 54%|█████▍    | 9484/17525 [1:53:55<1:20:48,  1.66it/s] 54%|█████▍    | 9485/17525 [1:53:55<1:19:38,  1.68it/s] 54%|█████▍    | 9486/17525 [1:53:56<1:19:12,  1.69it/s] 54%|█████▍    | 9487/17525 [1:53:57<1:18:46,  1.70it/s] 54%|█████▍    | 9488/17525 [1:53:57<1:18:10,  1.71it/s] 54%|█████▍    | 9489/17525 [1:53:58<1:17:54,  1.72it/s] 54%|█████▍    | 9490/17525 [1:53:58<1:17:39,  1.72it/s]                                                        {'loss': 0.4558, 'grad_norm': 15.572850227355957, 'learning_rate': 8.730110475536764e-06, 'epoch': 13.54}
 54%|█████▍    | 9490/17525 [1:53:58<1:17:39,  1.72it/s] 54%|█████▍    | 9491/17525 [1:53:59<1:17:35,  1.73it/s] 54%|█████▍    | 9492/17525 [1:53:59<1:17:27,  1.73it/s] 54%|█████▍    | 9493/17525 [1:54:00<1:25:20,  1.57it/s] 54%|█████▍    | 9494/17525 [1:54:01<1:23:37,  1.60it/s] 54%|█████▍    | 9495/17525 [1:54:01<1:21:38,  1.64it/s] 54%|█████▍    | 9496/17525 [1:54:02<1:20:02,  1.67it/s] 54%|█████▍    | 9497/17525 [1:54:03<1:19:03,  1.69it/s] 54%|█████▍    | 9498/17525 [1:54:03<1:18:19,  1.71it/s] 54%|█████▍    | 9499/17525 [1:54:04<1:17:55,  1.72it/s] 54%|█████▍    | 9500/17525 [1:54:04<1:17:32,  1.72it/s]                                                        {'loss': 0.5384, 'grad_norm': 14.414188385009766, 'learning_rate': 8.712310995002817e-06, 'epoch': 13.55}
 54%|█████▍    | 9500/17525 [1:54:04<1:17:32,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 03:57:26,150 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:57:26,150 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:57:26,150 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.0055123567581177, 'eval_runtime': 4.5947, 'eval_samples_per_second': 96.415, 'eval_steps_per_second': 4.135, 'epoch': 13.55}
 54%|█████▍    | 9500/17525 [1:54:09<1:17:32,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 54%|█████▍    | 9501/17525 [1:54:09<4:22:06,  1.96s/it] 54%|█████▍    | 9502/17525 [1:54:10<3:26:31,  1.54s/it] 54%|█████▍    | 9503/17525 [1:54:11<2:47:37,  1.25s/it] 54%|█████▍    | 9504/17525 [1:54:11<2:20:31,  1.05s/it] 54%|█████▍    | 9505/17525 [1:54:12<2:01:25,  1.10it/s] 54%|█████▍    | 9506/17525 [1:54:12<1:47:59,  1.24it/s] 54%|█████▍    | 9507/17525 [1:54:13<1:38:40,  1.35it/s] 54%|█████▍    | 9508/17525 [1:54:13<1:32:04,  1.45it/s] 54%|█████▍    | 9509/17525 [1:54:14<1:27:31,  1.53it/s] 54%|█████▍    | 9510/17525 [1:54:15<1:24:03,  1.59it/s]                                                        {'loss': 0.4525, 'grad_norm': 3.6741766929626465, 'learning_rate': 8.694515661968788e-06, 'epoch': 13.57}
 54%|█████▍    | 9510/17525 [1:54:15<1:24:03,  1.59it/s] 54%|█████▍    | 9511/17525 [1:54:15<1:21:59,  1.63it/s] 54%|█████▍    | 9512/17525 [1:54:17<1:51:51,  1.19it/s] 54%|█████▍    | 9513/17525 [1:54:17<1:41:18,  1.32it/s] 54%|█████▍    | 9514/17525 [1:54:18<1:34:28,  1.41it/s] 54%|█████▍    | 9515/17525 [1:54:18<1:29:08,  1.50it/s] 54%|█████▍    | 9516/17525 [1:54:19<1:25:21,  1.56it/s] 54%|█████▍    | 9517/17525 [1:54:19<1:23:32,  1.60it/s] 54%|█████▍    | 9518/17525 [1:54:20<1:21:15,  1.64it/s] 54%|█████▍    | 9519/17525 [1:54:21<1:20:10,  1.66it/s] 54%|█████▍    | 9520/17525 [1:54:21<1:19:18,  1.68it/s]                                                        {'loss': 0.4057, 'grad_norm': 8.140897750854492, 'learning_rate': 8.676724533751417e-06, 'epoch': 13.58}
 54%|█████▍    | 9520/17525 [1:54:21<1:19:18,  1.68it/s] 54%|█████▍    | 9521/17525 [1:54:22<1:18:33,  1.70it/s] 54%|█████▍    | 9522/17525 [1:54:22<1:18:06,  1.71it/s] 54%|█████▍    | 9523/17525 [1:54:23<1:17:45,  1.72it/s] 54%|█████▍    | 9524/17525 [1:54:23<1:17:28,  1.72it/s] 54%|█████▍    | 9525/17525 [1:54:24<1:17:26,  1.72it/s] 54%|█████▍    | 9526/17525 [1:54:25<1:17:26,  1.72it/s] 54%|█████▍    | 9527/17525 [1:54:25<1:17:25,  1.72it/s] 54%|█████▍    | 9528/17525 [1:54:26<1:17:10,  1.73it/s] 54%|█████▍    | 9529/17525 [1:54:26<1:16:51,  1.73it/s] 54%|█████▍    | 9530/17525 [1:54:27<1:16:36,  1.74it/s]                                                        {'loss': 0.4728, 'grad_norm': 12.674546241760254, 'learning_rate': 8.658937667653916e-06, 'epoch': 13.59}
 54%|█████▍    | 9530/17525 [1:54:27<1:16:36,  1.74it/s] 54%|█████▍    | 9531/17525 [1:54:28<1:16:45,  1.74it/s] 54%|█████▍    | 9532/17525 [1:54:28<1:16:38,  1.74it/s] 54%|█████▍    | 9533/17525 [1:54:29<1:16:41,  1.74it/s] 54%|█████▍    | 9534/17525 [1:54:29<1:16:42,  1.74it/s] 54%|█████▍    | 9535/17525 [1:54:30<1:16:39,  1.74it/s] 54%|█████▍    | 9536/17525 [1:54:30<1:16:28,  1.74it/s] 54%|█████▍    | 9537/17525 [1:54:31<1:18:44,  1.69it/s] 54%|█████▍    | 9538/17525 [1:54:32<1:18:05,  1.70it/s] 54%|█████▍    | 9539/17525 [1:54:32<1:18:32,  1.69it/s] 54%|█████▍    | 9540/17525 [1:54:33<1:31:38,  1.45it/s]                                                        {'loss': 0.3224, 'grad_norm': 6.871469020843506, 'learning_rate': 8.641155120965749e-06, 'epoch': 13.61}
 54%|█████▍    | 9540/17525 [1:54:33<1:31:38,  1.45it/s] 54%|█████▍    | 9541/17525 [1:54:34<1:27:08,  1.53it/s] 54%|█████▍    | 9542/17525 [1:54:34<1:23:54,  1.59it/s] 54%|█████▍    | 9543/17525 [1:54:35<1:21:36,  1.63it/s] 54%|█████▍    | 9544/17525 [1:54:36<1:25:41,  1.55it/s] 54%|█████▍    | 9545/17525 [1:54:36<1:22:57,  1.60it/s] 54%|█████▍    | 9546/17525 [1:54:37<1:21:06,  1.64it/s] 54%|█████▍    | 9547/17525 [1:54:37<1:19:41,  1.67it/s] 54%|█████▍    | 9548/17525 [1:54:38<1:18:36,  1.69it/s] 54%|█████▍    | 9549/17525 [1:54:38<1:17:47,  1.71it/s] 54%|█████▍    | 9550/17525 [1:54:39<1:17:24,  1.72it/s]                                                        {'loss': 0.4365, 'grad_norm': 12.5546875, 'learning_rate': 8.623376950962486e-06, 'epoch': 13.62}
 54%|█████▍    | 9550/17525 [1:54:39<1:17:24,  1.72it/s] 54%|█████▍    | 9551/17525 [1:54:40<1:17:14,  1.72it/s] 55%|█████▍    | 9552/17525 [1:54:40<1:16:53,  1.73it/s] 55%|█████▍    | 9553/17525 [1:54:41<1:23:46,  1.59it/s] 55%|█████▍    | 9554/17525 [1:54:41<1:21:34,  1.63it/s] 55%|█████▍    | 9555/17525 [1:54:42<1:20:01,  1.66it/s] 55%|█████▍    | 9556/17525 [1:54:43<1:18:47,  1.69it/s] 55%|█████▍    | 9557/17525 [1:54:43<1:18:07,  1.70it/s] 55%|█████▍    | 9558/17525 [1:54:44<1:17:26,  1.71it/s] 55%|█████▍    | 9559/17525 [1:54:44<1:17:02,  1.72it/s] 55%|█████▍    | 9560/17525 [1:54:45<1:16:49,  1.73it/s]                                                        {'loss': 0.4631, 'grad_norm': 8.825815200805664, 'learning_rate': 8.605603214905587e-06, 'epoch': 13.64}
 55%|█████▍    | 9560/17525 [1:54:45<1:16:49,  1.73it/s] 55%|█████▍    | 9561/17525 [1:54:46<1:17:19,  1.72it/s] 55%|█████▍    | 9562/17525 [1:54:46<1:17:09,  1.72it/s] 55%|█████▍    | 9563/17525 [1:54:47<1:16:54,  1.73it/s] 55%|█████▍    | 9564/17525 [1:54:47<1:16:48,  1.73it/s] 55%|█████▍    | 9565/17525 [1:54:48<1:16:39,  1.73it/s] 55%|█████▍    | 9566/17525 [1:54:48<1:16:31,  1.73it/s] 55%|█████▍    | 9567/17525 [1:54:49<1:16:17,  1.74it/s] 55%|█████▍    | 9568/17525 [1:54:50<1:16:11,  1.74it/s] 55%|█████▍    | 9569/17525 [1:54:50<1:16:04,  1.74it/s] 55%|█████▍    | 9570/17525 [1:54:51<1:15:58,  1.75it/s]                                                        {'loss': 0.3734, 'grad_norm': 9.158417701721191, 'learning_rate': 8.587833970042233e-06, 'epoch': 13.65}
 55%|█████▍    | 9570/17525 [1:54:51<1:15:58,  1.75it/s] 55%|█████▍    | 9571/17525 [1:54:51<1:16:07,  1.74it/s] 55%|█████▍    | 9572/17525 [1:54:52<1:16:05,  1.74it/s] 55%|█████▍    | 9573/17525 [1:54:52<1:16:10,  1.74it/s] 55%|█████▍    | 9574/17525 [1:54:53<1:16:11,  1.74it/s] 55%|█████▍    | 9575/17525 [1:54:54<1:16:04,  1.74it/s] 55%|█████▍    | 9576/17525 [1:54:54<1:16:03,  1.74it/s] 55%|█████▍    | 9577/17525 [1:54:55<1:16:06,  1.74it/s] 55%|█████▍    | 9578/17525 [1:54:55<1:16:12,  1.74it/s] 55%|█████▍    | 9579/17525 [1:54:56<1:16:09,  1.74it/s] 55%|█████▍    | 9580/17525 [1:54:56<1:16:12,  1.74it/s]                                                        {'loss': 0.433, 'grad_norm': 16.676368713378906, 'learning_rate': 8.570069273605148e-06, 'epoch': 13.67}
 55%|█████▍    | 9580/17525 [1:54:56<1:16:12,  1.74it/s] 55%|█████▍    | 9581/17525 [1:54:57<1:16:10,  1.74it/s] 55%|█████▍    | 9582/17525 [1:54:58<1:16:54,  1.72it/s] 55%|█████▍    | 9583/17525 [1:54:58<1:16:49,  1.72it/s] 55%|█████▍    | 9584/17525 [1:54:59<1:16:42,  1.73it/s] 55%|█████▍    | 9585/17525 [1:54:59<1:17:38,  1.70it/s] 55%|█████▍    | 9586/17525 [1:55:00<1:17:05,  1.72it/s] 55%|█████▍    | 9587/17525 [1:55:01<1:16:43,  1.72it/s] 55%|█████▍    | 9588/17525 [1:55:01<1:16:32,  1.73it/s] 55%|█████▍    | 9589/17525 [1:55:02<1:30:36,  1.46it/s] 55%|█████▍    | 9590/17525 [1:55:03<1:26:06,  1.54it/s]                                                        {'loss': 0.5322, 'grad_norm': 25.322786331176758, 'learning_rate': 8.552309182812396e-06, 'epoch': 13.68}
 55%|█████▍    | 9590/17525 [1:55:03<1:26:06,  1.54it/s] 55%|█████▍    | 9591/17525 [1:55:03<1:23:03,  1.59it/s] 55%|█████▍    | 9592/17525 [1:55:04<1:20:57,  1.63it/s] 55%|█████▍    | 9593/17525 [1:55:04<1:19:32,  1.66it/s] 55%|█████▍    | 9594/17525 [1:55:05<1:32:32,  1.43it/s] 55%|█████▍    | 9595/17525 [1:55:06<1:27:32,  1.51it/s] 55%|█████▍    | 9596/17525 [1:55:06<1:23:51,  1.58it/s] 55%|█████▍    | 9597/17525 [1:55:07<1:21:18,  1.62it/s] 55%|█████▍    | 9598/17525 [1:55:08<1:19:32,  1.66it/s] 55%|█████▍    | 9599/17525 [1:55:08<1:18:28,  1.68it/s] 55%|█████▍    | 9600/17525 [1:55:09<1:17:47,  1.70it/s]                                                        {'loss': 0.355, 'grad_norm': 19.703327178955078, 'learning_rate': 8.534553754867214e-06, 'epoch': 13.69}
 55%|█████▍    | 9600/17525 [1:55:09<1:17:47,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 03:58:30,592 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:58:30,592 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:58:30,592 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.0206506252288818, 'eval_runtime': 4.604, 'eval_samples_per_second': 96.222, 'eval_steps_per_second': 4.127, 'epoch': 13.69}
 55%|█████▍    | 9600/17525 [1:55:13<1:17:47,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 03:58:35,200 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b54ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 40bac282-30b9-46ff-a0a4-327060cf22b2)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 03:58:45,259 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 03:58:45,261 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 55%|█████▍    | 9601/17525 [1:55:24<11:04:09,  5.03s/it] 55%|█████▍    | 9602/17525 [1:55:25<8:07:39,  3.69s/it]  55%|█████▍    | 9603/17525 [1:55:25<6:04:08,  2.76s/it] 55%|█████▍    | 9604/17525 [1:55:26<4:37:54,  2.11s/it] 55%|█████▍    | 9605/17525 [1:55:26<3:37:19,  1.65s/it] 55%|█████▍    | 9606/17525 [1:55:27<2:54:56,  1.33s/it] 55%|█████▍    | 9607/17525 [1:55:28<2:25:22,  1.10s/it] 55%|█████▍    | 9608/17525 [1:55:28<2:04:25,  1.06it/s] 55%|█████▍    | 9609/17525 [1:55:29<2:03:26,  1.07it/s] 55%|█████▍    | 9610/17525 [1:55:30<1:49:16,  1.21it/s]                                                        {'loss': 0.5096, 'grad_norm': 47.13862991333008, 'learning_rate': 8.516803046957814e-06, 'epoch': 13.71}
 55%|█████▍    | 9610/17525 [1:55:30<1:49:16,  1.21it/s] 55%|█████▍    | 9611/17525 [1:55:30<1:39:17,  1.33it/s] 55%|█████▍    | 9612/17525 [1:55:31<1:32:12,  1.43it/s] 55%|█████▍    | 9613/17525 [1:55:31<1:27:13,  1.51it/s] 55%|█████▍    | 9614/17525 [1:55:32<1:23:41,  1.58it/s] 55%|█████▍    | 9615/17525 [1:55:32<1:21:13,  1.62it/s] 55%|█████▍    | 9616/17525 [1:55:33<1:19:35,  1.66it/s] 55%|█████▍    | 9617/17525 [1:55:34<1:18:24,  1.68it/s] 55%|█████▍    | 9618/17525 [1:55:34<1:17:33,  1.70it/s] 55%|█████▍    | 9619/17525 [1:55:35<1:18:15,  1.68it/s] 55%|█████▍    | 9620/17525 [1:55:35<1:17:34,  1.70it/s]                                                        {'loss': 0.5025, 'grad_norm': 9.170165061950684, 'learning_rate': 8.499057116257207e-06, 'epoch': 13.72}
 55%|█████▍    | 9620/17525 [1:55:35<1:17:34,  1.70it/s] 55%|█████▍    | 9621/17525 [1:55:36<1:17:09,  1.71it/s] 55%|█████▍    | 9622/17525 [1:55:37<1:16:37,  1.72it/s] 55%|█████▍    | 9623/17525 [1:55:37<1:16:16,  1.73it/s] 55%|█████▍    | 9624/17525 [1:55:38<1:16:09,  1.73it/s] 55%|█████▍    | 9625/17525 [1:55:38<1:15:53,  1.73it/s] 55%|█████▍    | 9626/17525 [1:55:39<1:15:49,  1.74it/s] 55%|█████▍    | 9627/17525 [1:55:39<1:15:48,  1.74it/s] 55%|█████▍    | 9628/17525 [1:55:40<1:15:40,  1.74it/s] 55%|█████▍    | 9629/17525 [1:55:41<1:15:36,  1.74it/s] 55%|█████▍    | 9630/17525 [1:55:41<1:16:17,  1.72it/s]                                                        {'loss': 0.4298, 'grad_norm': 8.245867729187012, 'learning_rate': 8.481316019923026e-06, 'epoch': 13.74}
 55%|█████▍    | 9630/17525 [1:55:41<1:16:17,  1.72it/s] 55%|█████▍    | 9631/17525 [1:55:42<1:16:38,  1.72it/s] 55%|█████▍    | 9632/17525 [1:55:42<1:16:17,  1.72it/s] 55%|█████▍    | 9633/17525 [1:55:43<1:16:06,  1.73it/s] 55%|█████▍    | 9634/17525 [1:55:43<1:15:57,  1.73it/s] 55%|█████▍    | 9635/17525 [1:55:44<1:15:49,  1.73it/s] 55%|█████▍    | 9636/17525 [1:55:45<1:15:34,  1.74it/s] 55%|█████▍    | 9637/17525 [1:55:45<1:15:34,  1.74it/s] 55%|█████▍    | 9638/17525 [1:55:46<1:15:30,  1.74it/s] 55%|█████▌    | 9639/17525 [1:55:46<1:15:29,  1.74it/s] 55%|█████▌    | 9640/17525 [1:55:47<1:15:23,  1.74it/s]                                                        {'loss': 0.3927, 'grad_norm': 9.218440055847168, 'learning_rate': 8.463579815097316e-06, 'epoch': 13.75}
 55%|█████▌    | 9640/17525 [1:55:47<1:15:23,  1.74it/s] 55%|█████▌    | 9641/17525 [1:55:48<1:50:03,  1.19it/s] 55%|█████▌    | 9642/17525 [1:55:49<1:39:54,  1.32it/s] 55%|█████▌    | 9643/17525 [1:55:50<1:32:32,  1.42it/s] 55%|█████▌    | 9644/17525 [1:55:50<1:27:21,  1.50it/s] 55%|█████▌    | 9645/17525 [1:55:51<1:23:45,  1.57it/s] 55%|█████▌    | 9646/17525 [1:55:51<1:21:10,  1.62it/s] 55%|█████▌    | 9647/17525 [1:55:52<1:19:29,  1.65it/s] 55%|█████▌    | 9648/17525 [1:55:52<1:18:11,  1.68it/s] 55%|█████▌    | 9649/17525 [1:55:53<1:17:22,  1.70it/s] 55%|█████▌    | 9650/17525 [1:55:54<1:16:47,  1.71it/s]                                                        {'loss': 0.3827, 'grad_norm': 5.693757057189941, 'learning_rate': 8.445848558906385e-06, 'epoch': 13.77}
 55%|█████▌    | 9650/17525 [1:55:54<1:16:47,  1.71it/s] 55%|█████▌    | 9651/17525 [1:55:54<1:16:30,  1.72it/s] 55%|█████▌    | 9652/17525 [1:55:55<1:16:03,  1.73it/s] 55%|█████▌    | 9653/17525 [1:55:55<1:15:54,  1.73it/s] 55%|█████▌    | 9654/17525 [1:55:56<1:15:51,  1.73it/s] 55%|█████▌    | 9655/17525 [1:55:56<1:15:37,  1.73it/s] 55%|█████▌    | 9656/17525 [1:55:57<1:16:27,  1.72it/s] 55%|█████▌    | 9657/17525 [1:55:58<1:16:20,  1.72it/s] 55%|█████▌    | 9658/17525 [1:55:58<1:16:11,  1.72it/s] 55%|█████▌    | 9659/17525 [1:55:59<1:16:00,  1.72it/s] 55%|█████▌    | 9660/17525 [1:55:59<1:15:49,  1.73it/s]                                                        {'loss': 0.4086, 'grad_norm': 9.022537231445312, 'learning_rate': 8.428122308460592e-06, 'epoch': 13.78}
 55%|█████▌    | 9660/17525 [1:55:59<1:15:49,  1.73it/s] 55%|█████▌    | 9661/17525 [1:56:00<1:15:57,  1.73it/s] 55%|█████▌    | 9662/17525 [1:56:00<1:16:01,  1.72it/s] 55%|█████▌    | 9663/17525 [1:56:01<1:16:03,  1.72it/s] 55%|█████▌    | 9664/17525 [1:56:02<1:15:54,  1.73it/s] 55%|█████▌    | 9665/17525 [1:56:02<1:15:38,  1.73it/s] 55%|█████▌    | 9666/17525 [1:56:03<1:15:27,  1.74it/s] 55%|█████▌    | 9667/17525 [1:56:03<1:15:18,  1.74it/s] 55%|█████▌    | 9668/17525 [1:56:04<1:15:22,  1.74it/s] 55%|█████▌    | 9669/17525 [1:56:05<1:20:39,  1.62it/s] 55%|█████▌    | 9670/17525 [1:56:05<1:19:02,  1.66it/s]                                                        {'loss': 0.409, 'grad_norm': 9.143585205078125, 'learning_rate': 8.410401120854167e-06, 'epoch': 13.79}
 55%|█████▌    | 9670/17525 [1:56:05<1:19:02,  1.66it/s] 55%|█████▌    | 9671/17525 [1:56:06<1:17:57,  1.68it/s] 55%|█████▌    | 9672/17525 [1:56:06<1:17:01,  1.70it/s] 55%|█████▌    | 9673/17525 [1:56:07<1:17:23,  1.69it/s] 55%|█████▌    | 9674/17525 [1:56:08<1:16:47,  1.70it/s] 55%|█████▌    | 9675/17525 [1:56:08<1:16:13,  1.72it/s] 55%|█████▌    | 9676/17525 [1:56:09<1:15:57,  1.72it/s] 55%|█████▌    | 9677/17525 [1:56:09<1:15:43,  1.73it/s] 55%|█████▌    | 9678/17525 [1:56:10<1:15:34,  1.73it/s] 55%|█████▌    | 9679/17525 [1:56:10<1:15:23,  1.73it/s] 55%|█████▌    | 9680/17525 [1:56:11<1:15:48,  1.72it/s]                                                        {'loss': 0.4876, 'grad_norm': 14.461993217468262, 'learning_rate': 8.392685053165054e-06, 'epoch': 13.81}
 55%|█████▌    | 9680/17525 [1:56:11<1:15:48,  1.72it/s] 55%|█████▌    | 9681/17525 [1:56:12<1:15:35,  1.73it/s] 55%|█████▌    | 9682/17525 [1:56:12<1:16:13,  1.71it/s] 55%|█████▌    | 9683/17525 [1:56:13<1:15:57,  1.72it/s] 55%|█████▌    | 9684/17525 [1:56:13<1:15:30,  1.73it/s] 55%|█████▌    | 9685/17525 [1:56:14<1:15:18,  1.73it/s] 55%|█████▌    | 9686/17525 [1:56:14<1:15:10,  1.74it/s] 55%|█████▌    | 9687/17525 [1:56:15<1:15:06,  1.74it/s] 55%|█████▌    | 9688/17525 [1:56:16<1:15:02,  1.74it/s] 55%|█████▌    | 9689/17525 [1:56:16<1:15:09,  1.74it/s] 55%|█████▌    | 9690/17525 [1:56:17<1:15:02,  1.74it/s]                                                        {'loss': 0.4044, 'grad_norm': 9.435968399047852, 'learning_rate': 8.374974162454686e-06, 'epoch': 13.82}
 55%|█████▌    | 9690/17525 [1:56:17<1:15:02,  1.74it/s] 55%|█████▌    | 9691/17525 [1:56:17<1:15:13,  1.74it/s] 55%|█████▌    | 9692/17525 [1:56:18<1:15:04,  1.74it/s] 55%|█████▌    | 9693/17525 [1:56:18<1:14:57,  1.74it/s] 55%|█████▌    | 9694/17525 [1:56:19<1:15:03,  1.74it/s] 55%|█████▌    | 9695/17525 [1:56:20<1:15:05,  1.74it/s] 55%|█████▌    | 9696/17525 [1:56:20<1:15:06,  1.74it/s] 55%|█████▌    | 9697/17525 [1:56:21<1:15:01,  1.74it/s] 55%|█████▌    | 9698/17525 [1:56:22<1:33:27,  1.40it/s] 55%|█████▌    | 9699/17525 [1:56:22<1:28:01,  1.48it/s] 55%|█████▌    | 9700/17525 [1:56:23<1:24:03,  1.55it/s]                                                        {'loss': 0.4612, 'grad_norm': 15.92927074432373, 'learning_rate': 8.357268505767824e-06, 'epoch': 13.84}
 55%|█████▌    | 9700/17525 [1:56:23<1:24:03,  1.55it/s][INFO|trainer.py:3512] 2024-06-25 03:59:44,887 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 03:59:44,887 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 03:59:44,887 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.0061410665512085, 'eval_runtime': 4.5976, 'eval_samples_per_second': 96.355, 'eval_steps_per_second': 4.133, 'epoch': 13.84}
 55%|█████▌    | 9700/17525 [1:56:28<1:24:03,  1.55it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 55%|█████▌    | 9701/17525 [1:56:28<4:21:32,  2.01s/it] 55%|█████▌    | 9702/17525 [1:56:29<3:26:49,  1.59s/it] 55%|█████▌    | 9703/17525 [1:56:30<3:00:57,  1.39s/it] 55%|█████▌    | 9704/17525 [1:56:30<2:29:13,  1.14s/it] 55%|█████▌    | 9705/17525 [1:56:31<2:20:56,  1.08s/it] 55%|█████▌    | 9706/17525 [1:56:32<2:01:01,  1.08it/s] 55%|█████▌    | 9707/17525 [1:56:32<1:47:17,  1.21it/s] 55%|█████▌    | 9708/17525 [1:56:33<1:37:34,  1.34it/s] 55%|█████▌    | 9709/17525 [1:56:34<1:30:45,  1.44it/s] 55%|█████▌    | 9710/17525 [1:56:34<1:25:57,  1.52it/s]                                                        {'loss': 0.4382, 'grad_norm': 15.751285552978516, 'learning_rate': 8.339568140132385e-06, 'epoch': 13.85}
 55%|█████▌    | 9710/17525 [1:56:34<1:25:57,  1.52it/s] 55%|█████▌    | 9711/17525 [1:56:35<1:22:49,  1.57it/s] 55%|█████▌    | 9712/17525 [1:56:35<1:20:37,  1.62it/s] 55%|█████▌    | 9713/17525 [1:56:36<1:19:02,  1.65it/s] 55%|█████▌    | 9714/17525 [1:56:36<1:17:54,  1.67it/s] 55%|█████▌    | 9715/17525 [1:56:37<1:17:09,  1.69it/s] 55%|█████▌    | 9716/17525 [1:56:38<1:16:24,  1.70it/s] 55%|█████▌    | 9717/17525 [1:56:38<1:15:59,  1.71it/s] 55%|█████▌    | 9718/17525 [1:56:39<1:15:42,  1.72it/s] 55%|█████▌    | 9719/17525 [1:56:39<1:15:28,  1.72it/s] 55%|█████▌    | 9720/17525 [1:56:40<1:27:53,  1.48it/s]                                                        {'loss': 0.4775, 'grad_norm': 22.800508499145508, 'learning_rate': 8.32187312255923e-06, 'epoch': 13.87}
 55%|█████▌    | 9720/17525 [1:56:40<1:27:53,  1.48it/s] 55%|█████▌    | 9721/17525 [1:56:41<1:24:09,  1.55it/s] 55%|█████▌    | 9722/17525 [1:56:41<1:21:24,  1.60it/s] 55%|█████▌    | 9723/17525 [1:56:42<1:19:24,  1.64it/s] 55%|█████▌    | 9724/17525 [1:56:42<1:18:09,  1.66it/s] 55%|█████▌    | 9725/17525 [1:56:43<1:17:16,  1.68it/s] 55%|█████▌    | 9726/17525 [1:56:44<1:33:54,  1.38it/s] 56%|█████▌    | 9727/17525 [1:56:45<1:28:19,  1.47it/s] 56%|█████▌    | 9728/17525 [1:56:45<1:24:21,  1.54it/s] 56%|█████▌    | 9729/17525 [1:56:46<1:21:21,  1.60it/s] 56%|█████▌    | 9730/17525 [1:56:46<1:19:13,  1.64it/s]                                                        {'loss': 0.3798, 'grad_norm': 6.015349864959717, 'learning_rate': 8.304183510042002e-06, 'epoch': 13.88}
 56%|█████▌    | 9730/17525 [1:56:46<1:19:13,  1.64it/s] 56%|█████▌    | 9731/17525 [1:56:47<1:17:49,  1.67it/s] 56%|█████▌    | 9732/17525 [1:56:48<1:17:40,  1.67it/s] 56%|█████▌    | 9733/17525 [1:56:48<1:16:51,  1.69it/s] 56%|█████▌    | 9734/17525 [1:56:49<1:16:14,  1.70it/s] 56%|█████▌    | 9735/17525 [1:56:49<1:15:37,  1.72it/s] 56%|█████▌    | 9736/17525 [1:56:50<1:15:08,  1.73it/s] 56%|█████▌    | 9737/17525 [1:56:50<1:15:04,  1.73it/s] 56%|█████▌    | 9738/17525 [1:56:51<1:15:01,  1.73it/s] 56%|█████▌    | 9739/17525 [1:56:52<1:14:51,  1.73it/s] 56%|█████▌    | 9740/17525 [1:56:52<1:27:31,  1.48it/s]                                                        {'loss': 0.4044, 'grad_norm': 4.895003318786621, 'learning_rate': 8.28649935955693e-06, 'epoch': 13.89}
 56%|█████▌    | 9740/17525 [1:56:53<1:27:31,  1.48it/s] 56%|█████▌    | 9741/17525 [1:56:53<1:23:50,  1.55it/s] 56%|█████▌    | 9742/17525 [1:56:54<1:20:52,  1.60it/s] 56%|█████▌    | 9743/17525 [1:56:54<1:19:06,  1.64it/s] 56%|█████▌    | 9744/17525 [1:56:55<1:17:46,  1.67it/s] 56%|█████▌    | 9745/17525 [1:56:55<1:16:47,  1.69it/s] 56%|█████▌    | 9746/17525 [1:56:56<1:16:12,  1.70it/s] 56%|█████▌    | 9747/17525 [1:56:57<1:31:43,  1.41it/s] 56%|█████▌    | 9748/17525 [1:56:58<1:33:40,  1.38it/s] 56%|█████▌    | 9749/17525 [1:56:58<1:27:46,  1.48it/s] 56%|█████▌    | 9750/17525 [1:56:59<1:23:55,  1.54it/s]                                                        {'loss': 0.3634, 'grad_norm': 11.093929290771484, 'learning_rate': 8.26882072806265e-06, 'epoch': 13.91}
 56%|█████▌    | 9750/17525 [1:56:59<1:23:55,  1.54it/s][INFO|trainer.py:3203] 2024-06-25 04:00:20,746 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7abd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 101b0189-afc9-4bb7-8c91-0ec7f100ded2)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:00:30,802 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:00:30,804 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 56%|█████▌    | 9751/17525 [1:57:10<8:11:09,  3.79s/it] 56%|█████▌    | 9752/17525 [1:57:11<6:06:18,  2.83s/it] 56%|█████▌    | 9753/17525 [1:57:11<4:38:43,  2.15s/it] 56%|█████▌    | 9754/17525 [1:57:12<3:37:27,  1.68s/it] 56%|█████▌    | 9755/17525 [1:57:12<2:54:31,  1.35s/it] 56%|█████▌    | 9756/17525 [1:57:13<2:24:37,  1.12s/it] 56%|█████▌    | 9757/17525 [1:57:13<2:03:33,  1.05it/s] 56%|█████▌    | 9758/17525 [1:57:14<1:49:00,  1.19it/s] 56%|█████▌    | 9759/17525 [1:57:15<1:38:51,  1.31it/s] 56%|█████▌    | 9760/17525 [1:57:15<1:31:41,  1.41it/s]                                                        {'loss': 0.4835, 'grad_norm': 10.968609809875488, 'learning_rate': 8.25114767250003e-06, 'epoch': 13.92}
 56%|█████▌    | 9760/17525 [1:57:15<1:31:41,  1.41it/s] 56%|█████▌    | 9761/17525 [1:57:16<1:26:53,  1.49it/s] 56%|█████▌    | 9762/17525 [1:57:17<1:47:47,  1.20it/s] 56%|█████▌    | 9763/17525 [1:57:18<1:37:43,  1.32it/s] 56%|█████▌    | 9764/17525 [1:57:18<1:32:05,  1.40it/s] 56%|█████▌    | 9765/17525 [1:57:19<1:26:49,  1.49it/s] 56%|█████▌    | 9766/17525 [1:57:19<1:23:01,  1.56it/s] 56%|█████▌    | 9767/17525 [1:57:20<1:20:26,  1.61it/s] 56%|█████▌    | 9768/17525 [1:57:20<1:18:38,  1.64it/s] 56%|█████▌    | 9769/17525 [1:57:21<1:17:23,  1.67it/s] 56%|█████▌    | 9770/17525 [1:57:22<1:16:13,  1.70it/s]                                                        {'loss': 0.477, 'grad_norm': 13.343005180358887, 'learning_rate': 8.233480249791966e-06, 'epoch': 13.94}
 56%|█████▌    | 9770/17525 [1:57:22<1:16:13,  1.70it/s] 56%|█████▌    | 9771/17525 [1:57:22<1:15:47,  1.71it/s] 56%|█████▌    | 9772/17525 [1:57:23<1:15:20,  1.72it/s] 56%|█████▌    | 9773/17525 [1:57:23<1:15:00,  1.72it/s] 56%|█████▌    | 9774/17525 [1:57:24<1:14:36,  1.73it/s] 56%|█████▌    | 9775/17525 [1:57:24<1:14:26,  1.74it/s] 56%|█████▌    | 9776/17525 [1:57:25<1:14:16,  1.74it/s] 56%|█████▌    | 9777/17525 [1:57:26<1:14:19,  1.74it/s] 56%|█████▌    | 9778/17525 [1:57:26<1:14:11,  1.74it/s] 56%|█████▌    | 9779/17525 [1:57:27<1:14:00,  1.74it/s] 56%|█████▌    | 9780/17525 [1:57:27<1:14:09,  1.74it/s]                                                        {'loss': 0.4748, 'grad_norm': 24.06768226623535, 'learning_rate': 8.217584432477529e-06, 'epoch': 13.95}
 56%|█████▌    | 9780/17525 [1:57:27<1:14:09,  1.74it/s] 56%|█████▌    | 9781/17525 [1:57:28<1:14:18,  1.74it/s] 56%|█████▌    | 9782/17525 [1:57:28<1:14:18,  1.74it/s] 56%|█████▌    | 9783/17525 [1:57:29<1:14:01,  1.74it/s] 56%|█████▌    | 9784/17525 [1:57:30<1:14:05,  1.74it/s] 56%|█████▌    | 9785/17525 [1:57:30<1:14:04,  1.74it/s] 56%|█████▌    | 9786/17525 [1:57:31<1:14:00,  1.74it/s] 56%|█████▌    | 9787/17525 [1:57:31<1:14:03,  1.74it/s] 56%|█████▌    | 9788/17525 [1:57:32<1:14:14,  1.74it/s] 56%|█████▌    | 9789/17525 [1:57:33<1:44:39,  1.23it/s] 56%|█████▌    | 9790/17525 [1:57:34<1:35:38,  1.35it/s]                                                        {'loss': 0.4457, 'grad_norm': 12.072932243347168, 'learning_rate': 8.1999278689506e-06, 'epoch': 13.97}
 56%|█████▌    | 9790/17525 [1:57:34<1:35:38,  1.35it/s] 56%|█████▌    | 9791/17525 [1:57:35<1:42:47,  1.25it/s] 56%|█████▌    | 9792/17525 [1:57:35<1:34:06,  1.37it/s] 56%|█████▌    | 9793/17525 [1:57:36<1:28:03,  1.46it/s] 56%|█████▌    | 9794/17525 [1:57:37<1:23:55,  1.54it/s] 56%|█████▌    | 9795/17525 [1:57:37<1:21:08,  1.59it/s] 56%|█████▌    | 9796/17525 [1:57:38<1:18:54,  1.63it/s] 56%|█████▌    | 9797/17525 [1:57:38<1:17:39,  1.66it/s] 56%|█████▌    | 9798/17525 [1:57:39<1:16:19,  1.69it/s] 56%|█████▌    | 9799/17525 [1:57:39<1:15:54,  1.70it/s] 56%|█████▌    | 9800/17525 [1:57:40<1:15:20,  1.71it/s]                                                        {'loss': 0.4109, 'grad_norm': 15.07402515411377, 'learning_rate': 8.182277103251405e-06, 'epoch': 13.98}
 56%|█████▌    | 9800/17525 [1:57:40<1:15:20,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 04:01:01,891 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:01:01,891 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:01:01,891 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.003875494003296, 'eval_runtime': 4.5959, 'eval_samples_per_second': 96.391, 'eval_steps_per_second': 4.134, 'epoch': 13.98}
 56%|█████▌    | 9800/17525 [1:57:45<1:15:20,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 56%|█████▌    | 9801/17525 [1:57:45<4:12:46,  1.96s/it] 56%|█████▌    | 9802/17525 [1:57:46<3:19:19,  1.55s/it] 56%|█████▌    | 9803/17525 [1:57:46<2:41:43,  1.26s/it] 56%|█████▌    | 9804/17525 [1:57:47<2:15:25,  1.05s/it] 56%|█████▌    | 9805/17525 [1:57:47<1:56:52,  1.10it/s] 56%|█████▌    | 9806/17525 [1:57:48<1:44:08,  1.24it/s] 56%|█████▌    | 9807/17525 [1:57:49<1:35:04,  1.35it/s] 56%|█████▌    | 9808/17525 [1:57:49<1:29:31,  1.44it/s] 56%|█████▌    | 9809/17525 [1:57:50<1:24:46,  1.52it/s] 56%|█████▌    | 9810/17525 [1:57:50<1:21:38,  1.58it/s]                                                        {'loss': 0.4629, 'grad_norm': 6.793333053588867, 'learning_rate': 8.164632192231041e-06, 'epoch': 13.99}
 56%|█████▌    | 9810/17525 [1:57:50<1:21:38,  1.58it/s] 56%|█████▌    | 9811/17525 [1:57:51<1:19:36,  1.61it/s] 56%|█████▌    | 9812/17525 [1:57:52<1:18:09,  1.64it/s] 56%|█████▌    | 9813/17525 [1:57:52<1:17:46,  1.65it/s] 56%|█████▌    | 9814/17525 [1:57:53<1:16:48,  1.67it/s] 56%|█████▌    | 9815/17525 [1:57:53<1:15:52,  1.69it/s] 56%|█████▌    | 9816/17525 [1:57:54<1:31:34,  1.40it/s] 56%|█████▌    | 9817/17525 [1:57:55<1:26:23,  1.49it/s] 56%|█████▌    | 9818/17525 [1:57:55<1:22:33,  1.56it/s] 56%|█████▌    | 9819/17525 [1:57:56<1:19:56,  1.61it/s] 56%|█████▌    | 9820/17525 [1:57:57<1:32:08,  1.39it/s]                                                        {'loss': 0.3516, 'grad_norm': 14.561105728149414, 'learning_rate': 8.146993192721769e-06, 'epoch': 14.01}
 56%|█████▌    | 9820/17525 [1:57:57<1:32:08,  1.39it/s] 56%|█████▌    | 9821/17525 [1:57:58<1:26:44,  1.48it/s] 56%|█████▌    | 9822/17525 [1:57:58<1:22:46,  1.55it/s] 56%|█████▌    | 9823/17525 [1:57:59<1:20:11,  1.60it/s] 56%|█████▌    | 9824/17525 [1:57:59<1:18:32,  1.63it/s] 56%|█████▌    | 9825/17525 [1:58:00<1:17:09,  1.66it/s] 56%|█████▌    | 9826/17525 [1:58:00<1:16:04,  1.69it/s] 56%|█████▌    | 9827/17525 [1:58:01<1:15:19,  1.70it/s] 56%|█████▌    | 9828/17525 [1:58:02<1:14:45,  1.72it/s] 56%|█████▌    | 9829/17525 [1:58:02<1:14:28,  1.72it/s] 56%|█████▌    | 9830/17525 [1:58:03<1:14:19,  1.73it/s]                                                        {'loss': 0.3764, 'grad_norm': 10.154088020324707, 'learning_rate': 8.129360161536799e-06, 'epoch': 14.02}
 56%|█████▌    | 9830/17525 [1:58:03<1:14:19,  1.73it/s] 56%|█████▌    | 9831/17525 [1:58:03<1:14:11,  1.73it/s] 56%|█████▌    | 9832/17525 [1:58:04<1:14:05,  1.73it/s] 56%|█████▌    | 9833/17525 [1:58:04<1:13:59,  1.73it/s] 56%|█████▌    | 9834/17525 [1:58:05<1:13:58,  1.73it/s] 56%|█████▌    | 9835/17525 [1:58:06<1:14:01,  1.73it/s] 56%|█████▌    | 9836/17525 [1:58:06<1:13:49,  1.74it/s] 56%|█████▌    | 9837/17525 [1:58:07<1:13:48,  1.74it/s] 56%|█████▌    | 9838/17525 [1:58:07<1:13:40,  1.74it/s] 56%|█████▌    | 9839/17525 [1:58:08<1:13:35,  1.74it/s] 56%|█████▌    | 9840/17525 [1:58:09<1:15:11,  1.70it/s]                                                        {'loss': 0.5224, 'grad_norm': 14.133317947387695, 'learning_rate': 8.111733155470113e-06, 'epoch': 14.04}
 56%|█████▌    | 9840/17525 [1:58:09<1:15:11,  1.70it/s] 56%|█████▌    | 9841/17525 [1:58:09<1:14:45,  1.71it/s] 56%|█████▌    | 9842/17525 [1:58:10<1:14:32,  1.72it/s] 56%|█████▌    | 9843/17525 [1:58:10<1:14:13,  1.73it/s] 56%|█████▌    | 9844/17525 [1:58:11<1:14:02,  1.73it/s] 56%|█████▌    | 9845/17525 [1:58:11<1:13:48,  1.73it/s] 56%|█████▌    | 9846/17525 [1:58:12<1:13:34,  1.74it/s] 56%|█████▌    | 9847/17525 [1:58:13<1:13:34,  1.74it/s] 56%|█████▌    | 9848/17525 [1:58:13<1:13:42,  1.74it/s] 56%|█████▌    | 9849/17525 [1:58:14<1:13:43,  1.74it/s] 56%|█████▌    | 9850/17525 [1:58:14<1:13:43,  1.74it/s]                                                        {'loss': 0.4598, 'grad_norm': 5.96848201751709, 'learning_rate': 8.094112231296308e-06, 'epoch': 14.05}
 56%|█████▌    | 9850/17525 [1:58:14<1:13:43,  1.74it/s] 56%|█████▌    | 9851/17525 [1:58:15<1:13:55,  1.73it/s] 56%|█████▌    | 9852/17525 [1:58:15<1:13:45,  1.73it/s] 56%|█████▌    | 9853/17525 [1:58:16<1:13:45,  1.73it/s] 56%|█████▌    | 9854/17525 [1:58:17<1:13:41,  1.73it/s] 56%|█████▌    | 9855/17525 [1:58:17<1:13:28,  1.74it/s] 56%|█████▌    | 9856/17525 [1:58:18<1:13:20,  1.74it/s] 56%|█████▌    | 9857/17525 [1:58:18<1:13:16,  1.74it/s] 56%|█████▋    | 9858/17525 [1:58:19<1:13:23,  1.74it/s] 56%|█████▋    | 9859/17525 [1:58:19<1:13:24,  1.74it/s] 56%|█████▋    | 9860/17525 [1:58:20<1:13:18,  1.74it/s]                                                        {'loss': 0.4344, 'grad_norm': 14.810206413269043, 'learning_rate': 8.076497445770365e-06, 'epoch': 14.07}
 56%|█████▋    | 9860/17525 [1:58:20<1:13:18,  1.74it/s] 56%|█████▋    | 9861/17525 [1:58:21<1:13:30,  1.74it/s] 56%|█████▋    | 9862/17525 [1:58:21<1:13:32,  1.74it/s] 56%|█████▋    | 9863/17525 [1:58:22<1:13:30,  1.74it/s] 56%|█████▋    | 9864/17525 [1:58:22<1:13:21,  1.74it/s] 56%|█████▋    | 9865/17525 [1:58:23<1:14:16,  1.72it/s] 56%|█████▋    | 9866/17525 [1:58:25<1:53:28,  1.12it/s] 56%|█████▋    | 9867/17525 [1:58:26<2:05:18,  1.02it/s] 56%|█████▋    | 9868/17525 [1:58:26<1:49:40,  1.16it/s] 56%|█████▋    | 9869/17525 [1:58:27<1:39:01,  1.29it/s] 56%|█████▋    | 9870/17525 [1:58:27<1:31:22,  1.40it/s]                                                        {'loss': 0.3619, 'grad_norm': 11.565733909606934, 'learning_rate': 8.058888855627512e-06, 'epoch': 14.08}
 56%|█████▋    | 9870/17525 [1:58:27<1:31:22,  1.40it/s] 56%|█████▋    | 9871/17525 [1:58:29<1:44:10,  1.22it/s] 56%|█████▋    | 9872/17525 [1:58:29<1:35:08,  1.34it/s] 56%|█████▋    | 9873/17525 [1:58:30<1:28:28,  1.44it/s] 56%|█████▋    | 9874/17525 [1:58:30<1:23:53,  1.52it/s] 56%|█████▋    | 9875/17525 [1:58:31<1:20:44,  1.58it/s] 56%|█████▋    | 9876/17525 [1:58:31<1:18:32,  1.62it/s] 56%|█████▋    | 9877/17525 [1:58:32<1:16:54,  1.66it/s] 56%|█████▋    | 9878/17525 [1:58:33<1:15:41,  1.68it/s] 56%|█████▋    | 9879/17525 [1:58:33<1:15:03,  1.70it/s] 56%|█████▋    | 9880/17525 [1:58:34<1:14:39,  1.71it/s]                                                        {'loss': 0.3605, 'grad_norm': 15.503401756286621, 'learning_rate': 8.041286517583018e-06, 'epoch': 14.09}
 56%|█████▋    | 9880/17525 [1:58:34<1:14:39,  1.71it/s] 56%|█████▋    | 9881/17525 [1:58:34<1:14:17,  1.71it/s] 56%|█████▋    | 9882/17525 [1:58:35<1:13:54,  1.72it/s] 56%|█████▋    | 9883/17525 [1:58:35<1:13:44,  1.73it/s] 56%|█████▋    | 9884/17525 [1:58:36<1:13:33,  1.73it/s] 56%|█████▋    | 9885/17525 [1:58:37<1:13:23,  1.73it/s] 56%|█████▋    | 9886/17525 [1:58:37<1:13:15,  1.74it/s] 56%|█████▋    | 9887/17525 [1:58:38<1:13:18,  1.74it/s] 56%|█████▋    | 9888/17525 [1:58:38<1:13:11,  1.74it/s] 56%|█████▋    | 9889/17525 [1:58:39<1:13:03,  1.74it/s] 56%|█████▋    | 9890/17525 [1:58:39<1:13:07,  1.74it/s]                                                        {'loss': 0.4328, 'grad_norm': 12.262344360351562, 'learning_rate': 8.023690488332007e-06, 'epoch': 14.11}
 56%|█████▋    | 9890/17525 [1:58:39<1:13:07,  1.74it/s] 56%|█████▋    | 9891/17525 [1:58:40<1:13:15,  1.74it/s] 56%|█████▋    | 9892/17525 [1:58:41<1:13:09,  1.74it/s] 56%|█████▋    | 9893/17525 [1:58:41<1:12:59,  1.74it/s] 56%|█████▋    | 9894/17525 [1:58:42<1:13:01,  1.74it/s] 56%|█████▋    | 9895/17525 [1:58:42<1:13:03,  1.74it/s] 56%|█████▋    | 9896/17525 [1:58:43<1:13:04,  1.74it/s] 56%|█████▋    | 9897/17525 [1:58:43<1:13:28,  1.73it/s] 56%|█████▋    | 9898/17525 [1:58:44<1:14:12,  1.71it/s] 56%|█████▋    | 9899/17525 [1:58:45<1:13:55,  1.72it/s] 56%|█████▋    | 9900/17525 [1:58:45<1:13:36,  1.73it/s]                                                        {'loss': 0.3738, 'grad_norm': 16.299840927124023, 'learning_rate': 8.006100824549294e-06, 'epoch': 14.12}
 56%|█████▋    | 9900/17525 [1:58:45<1:13:36,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:02:07,107 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:02:07,107 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:02:07,107 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                        
                                               [A{'eval_loss': 1.056571125984192, 'eval_runtime': 4.5975, 'eval_samples_per_second': 96.357, 'eval_steps_per_second': 4.133, 'epoch': 14.12}
 56%|█████▋    | 9900/17525 [1:58:50<1:13:36,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:02:11,709 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a6d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: b6f796cd-b9a8-4611-b297-538d71544cc5)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:02:21,766 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:02:21,768 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-9900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 56%|█████▋    | 9901/17525 [1:59:01<11:00:33,  5.20s/it] 57%|█████▋    | 9902/17525 [1:59:02<8:04:19,  3.81s/it]  57%|█████▋    | 9903/17525 [1:59:02<6:00:57,  2.84s/it] 57%|█████▋    | 9904/17525 [1:59:03<4:42:04,  2.22s/it] 57%|█████▋    | 9905/17525 [1:59:04<3:39:31,  1.73s/it] 57%|█████▋    | 9906/17525 [1:59:04<2:55:37,  1.38s/it] 57%|█████▋    | 9907/17525 [1:59:05<2:26:20,  1.15s/it] 57%|█████▋    | 9908/17525 [1:59:05<2:04:29,  1.02it/s] 57%|█████▋    | 9909/17525 [1:59:06<1:48:49,  1.17it/s] 57%|█████▋    | 9910/17525 [1:59:07<1:37:56,  1.30it/s]                                                        {'loss': 0.3518, 'grad_norm': 9.935321807861328, 'learning_rate': 7.988517582889183e-06, 'epoch': 14.14}
 57%|█████▋    | 9910/17525 [1:59:07<1:37:56,  1.30it/s] 57%|█████▋    | 9911/17525 [1:59:07<1:30:33,  1.40it/s] 57%|█████▋    | 9912/17525 [1:59:08<1:25:12,  1.49it/s] 57%|█████▋    | 9913/17525 [1:59:08<1:21:21,  1.56it/s] 57%|█████▋    | 9914/17525 [1:59:09<1:18:46,  1.61it/s] 57%|█████▋    | 9915/17525 [1:59:09<1:16:50,  1.65it/s] 57%|█████▋    | 9916/17525 [1:59:10<1:15:39,  1.68it/s] 57%|█████▋    | 9917/17525 [1:59:11<1:14:42,  1.70it/s] 57%|█████▋    | 9918/17525 [1:59:11<1:14:12,  1.71it/s] 57%|█████▋    | 9919/17525 [1:59:13<1:44:10,  1.22it/s] 57%|█████▋    | 9920/17525 [1:59:13<1:47:45,  1.18it/s]                                                        {'loss': 0.3821, 'grad_norm': 9.261763572692871, 'learning_rate': 7.970940819985303e-06, 'epoch': 14.15}
 57%|█████▋    | 9920/17525 [1:59:13<1:47:45,  1.18it/s] 57%|█████▋    | 9921/17525 [1:59:14<1:37:30,  1.30it/s] 57%|█████▋    | 9922/17525 [1:59:15<1:30:25,  1.40it/s] 57%|█████▋    | 9923/17525 [1:59:15<1:25:28,  1.48it/s] 57%|█████▋    | 9924/17525 [1:59:16<1:21:32,  1.55it/s] 57%|█████▋    | 9925/17525 [1:59:16<1:18:54,  1.61it/s] 57%|█████▋    | 9926/17525 [1:59:17<1:17:02,  1.64it/s] 57%|█████▋    | 9927/17525 [1:59:18<1:15:39,  1.67it/s] 57%|█████▋    | 9928/17525 [1:59:18<1:14:47,  1.69it/s] 57%|█████▋    | 9929/17525 [1:59:19<1:14:06,  1.71it/s] 57%|█████▋    | 9930/17525 [1:59:19<1:18:48,  1.61it/s]                                                        {'loss': 0.4931, 'grad_norm': 4.757301330566406, 'learning_rate': 7.953370592450404e-06, 'epoch': 14.17}
 57%|█████▋    | 9930/17525 [1:59:19<1:18:48,  1.61it/s] 57%|█████▋    | 9931/17525 [1:59:20<1:16:52,  1.65it/s] 57%|█████▋    | 9932/17525 [1:59:21<1:15:36,  1.67it/s] 57%|█████▋    | 9933/17525 [1:59:21<1:14:45,  1.69it/s] 57%|█████▋    | 9934/17525 [1:59:22<1:14:10,  1.71it/s] 57%|█████▋    | 9935/17525 [1:59:22<1:13:38,  1.72it/s] 57%|█████▋    | 9936/17525 [1:59:24<1:42:32,  1.23it/s] 57%|█████▋    | 9937/17525 [1:59:24<1:33:35,  1.35it/s] 57%|█████▋    | 9938/17525 [1:59:25<1:27:21,  1.45it/s] 57%|█████▋    | 9939/17525 [1:59:25<1:22:57,  1.52it/s] 57%|█████▋    | 9940/17525 [1:59:26<1:19:55,  1.58it/s]                                                        {'loss': 0.2819, 'grad_norm': 16.184526443481445, 'learning_rate': 7.93580695687619e-06, 'epoch': 14.18}
 57%|█████▋    | 9940/17525 [1:59:26<1:19:55,  1.58it/s] 57%|█████▋    | 9941/17525 [1:59:26<1:17:44,  1.63it/s] 57%|█████▋    | 9942/17525 [1:59:27<1:16:26,  1.65it/s] 57%|█████▋    | 9943/17525 [1:59:28<1:15:44,  1.67it/s] 57%|█████▋    | 9944/17525 [1:59:28<1:14:58,  1.69it/s] 57%|█████▋    | 9945/17525 [1:59:29<1:14:20,  1.70it/s] 57%|█████▋    | 9946/17525 [1:59:29<1:13:55,  1.71it/s] 57%|█████▋    | 9947/17525 [1:59:30<1:13:30,  1.72it/s] 57%|█████▋    | 9948/17525 [1:59:31<1:13:21,  1.72it/s] 57%|█████▋    | 9949/17525 [1:59:31<1:13:08,  1.73it/s] 57%|█████▋    | 9950/17525 [1:59:32<1:12:56,  1.73it/s]                                                        {'loss': 0.364, 'grad_norm': 11.013021469116211, 'learning_rate': 7.91824996983314e-06, 'epoch': 14.19}
 57%|█████▋    | 9950/17525 [1:59:32<1:12:56,  1.73it/s] 57%|█████▋    | 9951/17525 [1:59:32<1:12:48,  1.73it/s] 57%|█████▋    | 9952/17525 [1:59:33<1:12:43,  1.74it/s] 57%|█████▋    | 9953/17525 [1:59:33<1:12:38,  1.74it/s] 57%|█████▋    | 9954/17525 [1:59:34<1:12:45,  1.73it/s] 57%|█████▋    | 9955/17525 [1:59:35<1:12:43,  1.74it/s] 57%|█████▋    | 9956/17525 [1:59:35<1:13:17,  1.72it/s] 57%|█████▋    | 9957/17525 [1:59:36<1:13:17,  1.72it/s] 57%|█████▋    | 9958/17525 [1:59:36<1:13:02,  1.73it/s] 57%|█████▋    | 9959/17525 [1:59:37<1:13:01,  1.73it/s] 57%|█████▋    | 9960/17525 [1:59:37<1:12:56,  1.73it/s]                                                        {'loss': 0.4206, 'grad_norm': 14.045870780944824, 'learning_rate': 7.900699687870314e-06, 'epoch': 14.21}
 57%|█████▋    | 9960/17525 [1:59:37<1:12:56,  1.73it/s] 57%|█████▋    | 9961/17525 [1:59:38<1:12:48,  1.73it/s] 57%|█████▋    | 9962/17525 [1:59:39<1:12:39,  1.73it/s] 57%|█████▋    | 9963/17525 [1:59:39<1:12:39,  1.73it/s] 57%|█████▋    | 9964/17525 [1:59:40<1:12:31,  1.74it/s] 57%|█████▋    | 9965/17525 [1:59:40<1:12:22,  1.74it/s] 57%|█████▋    | 9966/17525 [1:59:41<1:12:26,  1.74it/s] 57%|█████▋    | 9967/17525 [1:59:42<1:13:20,  1.72it/s] 57%|█████▋    | 9968/17525 [1:59:42<1:13:51,  1.71it/s] 57%|█████▋    | 9969/17525 [1:59:43<1:13:24,  1.72it/s] 57%|█████▋    | 9970/17525 [1:59:43<1:13:16,  1.72it/s]                                                        {'loss': 0.4751, 'grad_norm': 15.650187492370605, 'learning_rate': 7.883156167515167e-06, 'epoch': 14.22}
 57%|█████▋    | 9970/17525 [1:59:43<1:13:16,  1.72it/s] 57%|█████▋    | 9971/17525 [1:59:44<1:13:12,  1.72it/s] 57%|█████▋    | 9972/17525 [1:59:44<1:12:49,  1.73it/s] 57%|█████▋    | 9973/17525 [1:59:45<1:12:44,  1.73it/s] 57%|█████▋    | 9974/17525 [1:59:46<1:12:39,  1.73it/s] 57%|█████▋    | 9975/17525 [1:59:46<1:26:06,  1.46it/s] 57%|█████▋    | 9976/17525 [1:59:47<1:22:09,  1.53it/s] 57%|█████▋    | 9977/17525 [1:59:48<1:19:08,  1.59it/s] 57%|█████▋    | 9978/17525 [1:59:48<1:17:02,  1.63it/s] 57%|█████▋    | 9979/17525 [1:59:49<1:15:30,  1.67it/s] 57%|█████▋    | 9980/17525 [1:59:49<1:14:27,  1.69it/s]                                                        {'loss': 0.3719, 'grad_norm': 20.556522369384766, 'learning_rate': 7.865619465273395e-06, 'epoch': 14.24}
 57%|█████▋    | 9980/17525 [1:59:49<1:14:27,  1.69it/s] 57%|█████▋    | 9981/17525 [1:59:50<1:13:48,  1.70it/s] 57%|█████▋    | 9982/17525 [1:59:51<1:13:28,  1.71it/s] 57%|█████▋    | 9983/17525 [1:59:51<1:13:00,  1.72it/s] 57%|█████▋    | 9984/17525 [1:59:52<1:12:35,  1.73it/s] 57%|█████▋    | 9985/17525 [1:59:52<1:12:36,  1.73it/s] 57%|█████▋    | 9986/17525 [1:59:53<1:12:29,  1.73it/s] 57%|█████▋    | 9987/17525 [1:59:53<1:12:26,  1.73it/s] 57%|█████▋    | 9988/17525 [1:59:54<1:12:24,  1.73it/s] 57%|█████▋    | 9989/17525 [1:59:55<1:12:09,  1.74it/s] 57%|█████▋    | 9990/17525 [1:59:55<1:12:09,  1.74it/s]                                                        {'loss': 0.4577, 'grad_norm': 12.44006633758545, 'learning_rate': 7.848089637628713e-06, 'epoch': 14.25}
 57%|█████▋    | 9990/17525 [1:59:55<1:12:09,  1.74it/s] 57%|█████▋    | 9991/17525 [1:59:56<1:12:19,  1.74it/s] 57%|█████▋    | 9992/17525 [1:59:56<1:12:14,  1.74it/s] 57%|█████▋    | 9993/17525 [1:59:57<1:12:12,  1.74it/s] 57%|█████▋    | 9994/17525 [1:59:57<1:12:16,  1.74it/s] 57%|█████▋    | 9995/17525 [1:59:58<1:12:09,  1.74it/s] 57%|█████▋    | 9996/17525 [1:59:59<1:12:02,  1.74it/s] 57%|█████▋    | 9997/17525 [1:59:59<1:11:59,  1.74it/s] 57%|█████▋    | 9998/17525 [2:00:00<1:12:22,  1.73it/s] 57%|█████▋    | 9999/17525 [2:00:00<1:12:25,  1.73it/s] 57%|█████▋    | 10000/17525 [2:00:01<1:12:21,  1.73it/s]                                                         {'loss': 0.3831, 'grad_norm': 7.612323760986328, 'learning_rate': 7.830566741042711e-06, 'epoch': 14.27}
 57%|█████▋    | 10000/17525 [2:00:01<1:12:21,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:03:22,773 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:03:22,774 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:03:22,774 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.037645697593689, 'eval_runtime': 4.5951, 'eval_samples_per_second': 96.408, 'eval_steps_per_second': 4.135, 'epoch': 14.27}
 57%|█████▋    | 10000/17525 [2:00:05<1:12:21,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 57%|█████▋    | 10001/17525 [2:00:06<4:05:39,  1.96s/it] 57%|█████▋    | 10002/17525 [2:00:07<3:13:44,  1.55s/it] 57%|█████▋    | 10003/17525 [2:00:07<2:37:22,  1.26s/it] 57%|█████▋    | 10004/17525 [2:00:08<2:12:07,  1.05s/it] 57%|█████▋    | 10005/17525 [2:00:08<1:54:14,  1.10it/s] 57%|█████▋    | 10006/17525 [2:00:09<1:42:28,  1.22it/s] 57%|█████▋    | 10007/17525 [2:00:10<1:46:56,  1.17it/s] 57%|█████▋    | 10008/17525 [2:00:10<1:36:14,  1.30it/s] 57%|█████▋    | 10009/17525 [2:00:11<1:34:43,  1.32it/s] 57%|█████▋    | 10010/17525 [2:00:12<1:27:51,  1.43it/s]                                                         {'loss': 0.4232, 'grad_norm': 13.463671684265137, 'learning_rate': 7.813050831954644e-06, 'epoch': 14.28}
 57%|█████▋    | 10010/17525 [2:00:12<1:27:51,  1.43it/s] 57%|█████▋    | 10011/17525 [2:00:12<1:23:16,  1.50it/s] 57%|█████▋    | 10012/17525 [2:00:13<1:20:04,  1.56it/s] 57%|█████▋    | 10013/17525 [2:00:14<1:17:32,  1.61it/s] 57%|█████▋    | 10014/17525 [2:00:14<1:15:53,  1.65it/s] 57%|█████▋    | 10015/17525 [2:00:15<1:14:48,  1.67it/s] 57%|█████▋    | 10016/17525 [2:00:15<1:13:57,  1.69it/s] 57%|█████▋    | 10017/17525 [2:00:16<1:13:17,  1.71it/s] 57%|█████▋    | 10018/17525 [2:00:16<1:12:55,  1.72it/s] 57%|█████▋    | 10019/17525 [2:00:17<1:12:42,  1.72it/s] 57%|█████▋    | 10020/17525 [2:00:18<1:17:23,  1.62it/s]                                                         {'loss': 0.4307, 'grad_norm': 11.273879051208496, 'learning_rate': 7.795541966781262e-06, 'epoch': 14.29}
 57%|█████▋    | 10020/17525 [2:00:18<1:17:23,  1.62it/s] 57%|█████▋    | 10021/17525 [2:00:18<1:15:51,  1.65it/s] 57%|█████▋    | 10022/17525 [2:00:19<1:14:42,  1.67it/s] 57%|█████▋    | 10023/17525 [2:00:19<1:13:46,  1.69it/s] 57%|█████▋    | 10024/17525 [2:00:20<1:13:12,  1.71it/s] 57%|█████▋    | 10025/17525 [2:00:21<1:12:58,  1.71it/s] 57%|█████▋    | 10026/17525 [2:00:21<1:12:41,  1.72it/s] 57%|█████▋    | 10027/17525 [2:00:22<1:12:24,  1.73it/s] 57%|█████▋    | 10028/17525 [2:00:22<1:12:13,  1.73it/s] 57%|█████▋    | 10029/17525 [2:00:23<1:12:11,  1.73it/s] 57%|█████▋    | 10030/17525 [2:00:23<1:12:01,  1.73it/s]                                                         {'loss': 0.4389, 'grad_norm': 14.792292594909668, 'learning_rate': 7.778040201916634e-06, 'epoch': 14.31}
 57%|█████▋    | 10030/17525 [2:00:23<1:12:01,  1.73it/s] 57%|█████▋    | 10031/17525 [2:00:24<1:12:03,  1.73it/s] 57%|█████▋    | 10032/17525 [2:00:25<1:11:54,  1.74it/s] 57%|█████▋    | 10033/17525 [2:00:25<1:11:52,  1.74it/s] 57%|█████▋    | 10034/17525 [2:00:26<1:11:58,  1.73it/s] 57%|█████▋    | 10035/17525 [2:00:26<1:11:58,  1.73it/s] 57%|█████▋    | 10036/17525 [2:00:27<1:11:53,  1.74it/s] 57%|█████▋    | 10037/17525 [2:00:27<1:11:52,  1.74it/s] 57%|█████▋    | 10038/17525 [2:00:28<1:11:54,  1.74it/s] 57%|█████▋    | 10039/17525 [2:00:29<1:11:40,  1.74it/s] 57%|█████▋    | 10040/17525 [2:00:29<1:12:21,  1.72it/s]                                                         {'loss': 0.4189, 'grad_norm': 19.451080322265625, 'learning_rate': 7.760545593731948e-06, 'epoch': 14.32}
 57%|█████▋    | 10040/17525 [2:00:29<1:12:21,  1.72it/s] 57%|█████▋    | 10041/17525 [2:00:30<1:12:15,  1.73it/s] 57%|█████▋    | 10042/17525 [2:00:30<1:11:58,  1.73it/s] 57%|█████▋    | 10043/17525 [2:00:31<1:12:37,  1.72it/s] 57%|█████▋    | 10044/17525 [2:00:32<1:12:20,  1.72it/s] 57%|█████▋    | 10045/17525 [2:00:32<1:12:16,  1.72it/s] 57%|█████▋    | 10046/17525 [2:00:33<1:12:02,  1.73it/s] 57%|█████▋    | 10047/17525 [2:00:33<1:11:57,  1.73it/s] 57%|█████▋    | 10048/17525 [2:00:34<1:11:52,  1.73it/s] 57%|█████▋    | 10049/17525 [2:00:34<1:11:52,  1.73it/s] 57%|█████▋    | 10050/17525 [2:00:35<1:11:41,  1.74it/s]                                                         {'loss': 0.3781, 'grad_norm': 10.036150932312012, 'learning_rate': 7.743058198575359e-06, 'epoch': 14.34}
 57%|█████▋    | 10050/17525 [2:00:35<1:11:41,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 04:03:56,883 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b7a090>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5ebe56bf-a9b9-4446-8716-9368cb88679c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:04:06,940 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:04:06,942 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 57%|█████▋    | 10051/17525 [2:00:46<7:32:38,  3.63s/it] 57%|█████▋    | 10052/17525 [2:00:46<5:38:26,  2.72s/it] 57%|█████▋    | 10053/17525 [2:00:47<4:18:25,  2.08s/it] 57%|█████▋    | 10054/17525 [2:00:47<3:22:23,  1.63s/it] 57%|█████▋    | 10055/17525 [2:00:48<2:43:03,  1.31s/it] 57%|█████▋    | 10056/17525 [2:00:49<2:15:38,  1.09s/it] 57%|█████▋    | 10057/17525 [2:00:49<1:57:10,  1.06it/s] 57%|█████▋    | 10058/17525 [2:00:50<1:43:35,  1.20it/s] 57%|█████▋    | 10059/17525 [2:00:50<1:34:03,  1.32it/s] 57%|█████▋    | 10060/17525 [2:00:51<1:27:27,  1.42it/s]                                                         {'loss': 0.473, 'grad_norm': 13.133386611938477, 'learning_rate': 7.725578072771771e-06, 'epoch': 14.35}
 57%|█████▋    | 10060/17525 [2:00:51<1:27:27,  1.42it/s] 57%|█████▋    | 10061/17525 [2:00:52<1:22:52,  1.50it/s] 57%|█████▋    | 10062/17525 [2:00:52<1:19:38,  1.56it/s] 57%|█████▋    | 10063/17525 [2:00:53<1:17:15,  1.61it/s] 57%|█████▋    | 10064/17525 [2:00:53<1:15:22,  1.65it/s] 57%|█████▋    | 10065/17525 [2:00:54<1:14:16,  1.67it/s] 57%|█████▋    | 10066/17525 [2:00:54<1:13:58,  1.68it/s] 57%|█████▋    | 10067/17525 [2:00:55<1:13:07,  1.70it/s] 57%|█████▋    | 10068/17525 [2:00:56<1:25:50,  1.45it/s] 57%|█████▋    | 10069/17525 [2:00:57<1:21:23,  1.53it/s] 57%|█████▋    | 10070/17525 [2:00:57<1:19:00,  1.57it/s]                                                         {'loss': 0.4131, 'grad_norm': 17.5650577545166, 'learning_rate': 7.70810527262268e-06, 'epoch': 14.37}
 57%|█████▋    | 10070/17525 [2:00:57<1:19:00,  1.57it/s] 57%|█████▋    | 10071/17525 [2:00:58<1:16:53,  1.62it/s] 57%|█████▋    | 10072/17525 [2:00:58<1:15:19,  1.65it/s] 57%|█████▋    | 10073/17525 [2:00:59<1:14:16,  1.67it/s] 57%|█████▋    | 10074/17525 [2:00:59<1:13:24,  1.69it/s] 57%|█████▋    | 10075/17525 [2:01:00<1:12:48,  1.71it/s] 57%|█████▋    | 10076/17525 [2:01:01<1:12:13,  1.72it/s] 58%|█████▊    | 10077/17525 [2:01:01<1:11:56,  1.73it/s] 58%|█████▊    | 10078/17525 [2:01:02<1:11:47,  1.73it/s] 58%|█████▊    | 10079/17525 [2:01:02<1:11:27,  1.74it/s] 58%|█████▊    | 10080/17525 [2:01:03<1:11:16,  1.74it/s]                                                         {'loss': 0.4417, 'grad_norm': 17.34920310974121, 'learning_rate': 7.690639854406002e-06, 'epoch': 14.38}
 58%|█████▊    | 10080/17525 [2:01:03<1:11:16,  1.74it/s] 58%|█████▊    | 10081/17525 [2:01:03<1:11:23,  1.74it/s] 58%|█████▊    | 10082/17525 [2:01:04<1:11:19,  1.74it/s] 58%|█████▊    | 10083/17525 [2:01:05<1:11:17,  1.74it/s] 58%|█████▊    | 10084/17525 [2:01:05<1:11:19,  1.74it/s] 58%|█████▊    | 10085/17525 [2:01:06<1:11:20,  1.74it/s] 58%|█████▊    | 10086/17525 [2:01:06<1:11:12,  1.74it/s] 58%|█████▊    | 10087/17525 [2:01:07<1:11:12,  1.74it/s] 58%|█████▊    | 10088/17525 [2:01:07<1:11:08,  1.74it/s] 58%|█████▊    | 10089/17525 [2:01:08<1:11:17,  1.74it/s] 58%|█████▊    | 10090/17525 [2:01:09<1:11:11,  1.74it/s]                                                         {'loss': 0.4621, 'grad_norm': 15.782512664794922, 'learning_rate': 7.673181874375848e-06, 'epoch': 14.39}
 58%|█████▊    | 10090/17525 [2:01:09<1:11:11,  1.74it/s] 58%|█████▊    | 10091/17525 [2:01:09<1:11:16,  1.74it/s] 58%|█████▊    | 10092/17525 [2:01:10<1:11:16,  1.74it/s] 58%|█████▊    | 10093/17525 [2:01:10<1:11:15,  1.74it/s] 58%|█████▊    | 10094/17525 [2:01:11<1:11:09,  1.74it/s] 58%|█████▊    | 10095/17525 [2:01:12<1:28:38,  1.40it/s] 58%|█████▊    | 10096/17525 [2:01:13<1:23:33,  1.48it/s] 58%|█████▊    | 10097/17525 [2:01:13<1:19:58,  1.55it/s] 58%|█████▊    | 10098/17525 [2:01:14<1:17:22,  1.60it/s] 58%|█████▊    | 10099/17525 [2:01:15<1:28:52,  1.39it/s] 58%|█████▊    | 10100/17525 [2:01:15<1:23:59,  1.47it/s]                                                         {'loss': 0.3377, 'grad_norm': 8.640487670898438, 'learning_rate': 7.6557313887624e-06, 'epoch': 14.41}
 58%|█████▊    | 10100/17525 [2:01:15<1:23:59,  1.47it/s][INFO|trainer.py:3512] 2024-06-25 04:04:37,102 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:04:37,102 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:04:37,102 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                         
                                               [A{'eval_loss': 1.0417242050170898, 'eval_runtime': 4.5935, 'eval_samples_per_second': 96.44, 'eval_steps_per_second': 4.136, 'epoch': 14.41}
 58%|█████▊    | 10100/17525 [2:01:20<1:23:59,  1.47it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 58%|█████▊    | 10101/17525 [2:01:20<4:11:09,  2.03s/it] 58%|█████▊    | 10102/17525 [2:01:21<3:17:13,  1.59s/it] 58%|█████▊    | 10103/17525 [2:01:22<2:39:28,  1.29s/it] 58%|█████▊    | 10104/17525 [2:01:22<2:13:43,  1.08s/it] 58%|█████▊    | 10105/17525 [2:01:23<1:54:56,  1.08it/s] 58%|█████▊    | 10106/17525 [2:01:23<1:41:53,  1.21it/s] 58%|█████▊    | 10107/17525 [2:01:24<1:32:31,  1.34it/s] 58%|█████▊    | 10108/17525 [2:01:24<1:26:02,  1.44it/s] 58%|█████▊    | 10109/17525 [2:01:25<1:21:39,  1.51it/s] 58%|█████▊    | 10110/17525 [2:01:26<1:18:27,  1.58it/s]                                                         {'loss': 0.3525, 'grad_norm': 8.0626220703125, 'learning_rate': 7.638288453771682e-06, 'epoch': 14.42}
 58%|█████▊    | 10110/17525 [2:01:26<1:18:27,  1.58it/s] 58%|█████▊    | 10111/17525 [2:01:26<1:16:25,  1.62it/s] 58%|█████▊    | 10112/17525 [2:01:27<1:14:45,  1.65it/s] 58%|█████▊    | 10113/17525 [2:01:27<1:13:46,  1.67it/s] 58%|█████▊    | 10114/17525 [2:01:28<1:12:54,  1.69it/s] 58%|█████▊    | 10115/17525 [2:01:28<1:12:26,  1.70it/s] 58%|█████▊    | 10116/17525 [2:01:29<1:12:02,  1.71it/s] 58%|█████▊    | 10117/17525 [2:01:30<1:11:52,  1.72it/s] 58%|█████▊    | 10118/17525 [2:01:30<1:12:53,  1.69it/s] 58%|█████▊    | 10119/17525 [2:01:31<1:12:14,  1.71it/s] 58%|█████▊    | 10120/17525 [2:01:31<1:11:55,  1.72it/s]                                                         {'loss': 0.3534, 'grad_norm': 8.85964298248291, 'learning_rate': 7.620853125585407e-06, 'epoch': 14.44}
 58%|█████▊    | 10120/17525 [2:01:31<1:11:55,  1.72it/s] 58%|█████▊    | 10121/17525 [2:01:33<1:41:56,  1.21it/s] 58%|█████▊    | 10122/17525 [2:01:33<1:33:01,  1.33it/s] 58%|█████▊    | 10123/17525 [2:01:34<1:26:52,  1.42it/s] 58%|█████▊    | 10124/17525 [2:01:35<1:22:09,  1.50it/s] 58%|█████▊    | 10125/17525 [2:01:35<1:18:49,  1.56it/s] 58%|█████▊    | 10126/17525 [2:01:36<1:16:30,  1.61it/s] 58%|█████▊    | 10127/17525 [2:01:36<1:14:48,  1.65it/s] 58%|█████▊    | 10128/17525 [2:01:37<1:13:38,  1.67it/s] 58%|█████▊    | 10129/17525 [2:01:37<1:12:47,  1.69it/s] 58%|█████▊    | 10130/17525 [2:01:38<1:12:15,  1.71it/s]                                                         {'loss': 0.4219, 'grad_norm': 25.986486434936523, 'learning_rate': 7.603425460360783e-06, 'epoch': 14.45}
 58%|█████▊    | 10130/17525 [2:01:38<1:12:15,  1.71it/s] 58%|█████▊    | 10131/17525 [2:01:39<1:23:26,  1.48it/s] 58%|█████▊    | 10132/17525 [2:01:39<1:19:44,  1.55it/s] 58%|█████▊    | 10133/17525 [2:01:40<1:17:04,  1.60it/s] 58%|█████▊    | 10134/17525 [2:01:41<1:15:11,  1.64it/s] 58%|█████▊    | 10135/17525 [2:01:41<1:13:54,  1.67it/s] 58%|█████▊    | 10136/17525 [2:01:42<1:13:07,  1.68it/s] 58%|█████▊    | 10137/17525 [2:01:42<1:12:29,  1.70it/s] 58%|█████▊    | 10138/17525 [2:01:43<1:12:05,  1.71it/s] 58%|█████▊    | 10139/17525 [2:01:43<1:11:45,  1.72it/s] 58%|█████▊    | 10140/17525 [2:01:44<1:11:42,  1.72it/s]                                                         {'loss': 0.4784, 'grad_norm': 6.869897842407227, 'learning_rate': 7.58600551423034e-06, 'epoch': 14.47}
 58%|█████▊    | 10140/17525 [2:01:44<1:11:42,  1.72it/s] 58%|█████▊    | 10141/17525 [2:01:45<1:11:35,  1.72it/s] 58%|█████▊    | 10142/17525 [2:01:45<1:11:20,  1.72it/s] 58%|█████▊    | 10143/17525 [2:01:46<1:11:07,  1.73it/s] 58%|█████▊    | 10144/17525 [2:01:46<1:11:33,  1.72it/s] 58%|█████▊    | 10145/17525 [2:01:47<1:11:18,  1.73it/s] 58%|█████▊    | 10146/17525 [2:01:48<1:11:44,  1.71it/s] 58%|█████▊    | 10147/17525 [2:01:48<1:11:28,  1.72it/s] 58%|█████▊    | 10148/17525 [2:01:49<1:11:13,  1.73it/s] 58%|█████▊    | 10149/17525 [2:01:49<1:11:05,  1.73it/s] 58%|█████▊    | 10150/17525 [2:01:50<1:10:55,  1.73it/s]                                                         {'loss': 0.4804, 'grad_norm': 10.395938873291016, 'learning_rate': 7.568593343301749e-06, 'epoch': 14.48}
 58%|█████▊    | 10150/17525 [2:01:50<1:10:55,  1.73it/s] 58%|█████▊    | 10151/17525 [2:01:50<1:11:05,  1.73it/s] 58%|█████▊    | 10152/17525 [2:01:51<1:11:09,  1.73it/s] 58%|█████▊    | 10153/17525 [2:01:52<1:10:58,  1.73it/s] 58%|█████▊    | 10154/17525 [2:01:52<1:11:00,  1.73it/s] 58%|█████▊    | 10155/17525 [2:01:53<1:10:51,  1.73it/s] 58%|█████▊    | 10156/17525 [2:01:54<1:49:35,  1.12it/s] 58%|█████▊    | 10157/17525 [2:01:55<1:38:00,  1.25it/s] 58%|█████▊    | 10158/17525 [2:01:56<1:29:41,  1.37it/s] 58%|█████▊    | 10159/17525 [2:01:56<1:24:04,  1.46it/s] 58%|█████▊    | 10160/17525 [2:01:57<1:20:03,  1.53it/s]                                                         {'loss': 0.3771, 'grad_norm': 14.4260892868042, 'learning_rate': 7.551189003657628e-06, 'epoch': 14.49}
 58%|█████▊    | 10160/17525 [2:01:57<1:20:03,  1.53it/s] 58%|█████▊    | 10161/17525 [2:01:57<1:17:16,  1.59it/s] 58%|█████▊    | 10162/17525 [2:01:58<1:15:23,  1.63it/s] 58%|█████▊    | 10163/17525 [2:01:58<1:13:48,  1.66it/s] 58%|█████▊    | 10164/17525 [2:01:59<1:12:42,  1.69it/s] 58%|█████▊    | 10165/17525 [2:02:00<1:12:07,  1.70it/s] 58%|█████▊    | 10166/17525 [2:02:00<1:11:31,  1.71it/s] 58%|█████▊    | 10167/17525 [2:02:01<1:11:06,  1.72it/s] 58%|█████▊    | 10168/17525 [2:02:01<1:17:29,  1.58it/s] 58%|█████▊    | 10169/17525 [2:02:02<1:15:21,  1.63it/s] 58%|█████▊    | 10170/17525 [2:02:03<1:13:52,  1.66it/s]                                                         {'loss': 0.4338, 'grad_norm': 19.834796905517578, 'learning_rate': 7.533792551355372e-06, 'epoch': 14.51}
 58%|█████▊    | 10170/17525 [2:02:03<1:13:52,  1.66it/s] 58%|█████▊    | 10171/17525 [2:02:03<1:12:56,  1.68it/s] 58%|█████▊    | 10172/17525 [2:02:04<1:12:11,  1.70it/s] 58%|█████▊    | 10173/17525 [2:02:04<1:11:41,  1.71it/s] 58%|█████▊    | 10174/17525 [2:02:05<1:11:11,  1.72it/s] 58%|█████▊    | 10175/17525 [2:02:05<1:11:05,  1.72it/s] 58%|█████▊    | 10176/17525 [2:02:06<1:10:54,  1.73it/s] 58%|█████▊    | 10177/17525 [2:02:07<1:10:42,  1.73it/s] 58%|█████▊    | 10178/17525 [2:02:07<1:10:33,  1.74it/s] 58%|█████▊    | 10179/17525 [2:02:08<1:10:25,  1.74it/s] 58%|█████▊    | 10180/17525 [2:02:08<1:10:22,  1.74it/s]                                                         {'loss': 0.3039, 'grad_norm': 18.76736831665039, 'learning_rate': 7.516404042426989e-06, 'epoch': 14.52}
 58%|█████▊    | 10180/17525 [2:02:08<1:10:22,  1.74it/s] 58%|█████▊    | 10181/17525 [2:02:09<1:10:31,  1.74it/s] 58%|█████▊    | 10182/17525 [2:02:10<1:10:49,  1.73it/s] 58%|█████▊    | 10183/17525 [2:02:10<1:10:38,  1.73it/s] 58%|█████▊    | 10184/17525 [2:02:11<1:10:32,  1.73it/s] 58%|█████▊    | 10185/17525 [2:02:12<1:23:31,  1.46it/s] 58%|█████▊    | 10186/17525 [2:02:12<1:19:30,  1.54it/s] 58%|█████▊    | 10187/17525 [2:02:13<1:17:06,  1.59it/s] 58%|█████▊    | 10188/17525 [2:02:13<1:15:10,  1.63it/s] 58%|█████▊    | 10189/17525 [2:02:14<1:13:49,  1.66it/s] 58%|█████▊    | 10190/17525 [2:02:14<1:12:48,  1.68it/s]                                                         {'loss': 0.4259, 'grad_norm': 86.34934997558594, 'learning_rate': 7.499023532878879e-06, 'epoch': 14.54}
 58%|█████▊    | 10190/17525 [2:02:14<1:12:48,  1.68it/s] 58%|█████▊    | 10191/17525 [2:02:15<1:12:15,  1.69it/s] 58%|█████▊    | 10192/17525 [2:02:16<1:11:41,  1.70it/s] 58%|█████▊    | 10193/17525 [2:02:16<1:11:20,  1.71it/s] 58%|█████▊    | 10194/17525 [2:02:17<1:11:08,  1.72it/s] 58%|█████▊    | 10195/17525 [2:02:17<1:10:56,  1.72it/s] 58%|█████▊    | 10196/17525 [2:02:18<1:22:51,  1.47it/s] 58%|█████▊    | 10197/17525 [2:02:19<1:19:11,  1.54it/s] 58%|█████▊    | 10198/17525 [2:02:19<1:16:31,  1.60it/s] 58%|█████▊    | 10199/17525 [2:02:20<1:14:43,  1.63it/s] 58%|█████▊    | 10200/17525 [2:02:21<1:13:35,  1.66it/s]                                                         {'loss': 0.4127, 'grad_norm': 168.7737579345703, 'learning_rate': 7.481651078691694e-06, 'epoch': 14.55}
 58%|█████▊    | 10200/17525 [2:02:21<1:13:35,  1.66it/s][INFO|trainer.py:3512] 2024-06-25 04:05:42,498 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:05:42,498 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:05:42,499 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.65it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0419666767120361, 'eval_runtime': 4.5942, 'eval_samples_per_second': 96.425, 'eval_steps_per_second': 4.136, 'epoch': 14.55}
 58%|█████▊    | 10200/17525 [2:02:25<1:13:35,  1.66it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:05:47,096 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b7cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 3d871350-fc4e-4ab8-b80a-49af639582aa)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:05:57,214 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:05:57,217 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 58%|█████▊    | 10201/17525 [2:02:36<10:16:52,  5.05s/it] 58%|█████▊    | 10202/17525 [2:02:37<7:33:00,  3.71s/it]  58%|█████▊    | 10203/17525 [2:02:37<5:38:14,  2.77s/it] 58%|█████▊    | 10204/17525 [2:02:38<4:17:53,  2.11s/it] 58%|█████▊    | 10205/17525 [2:02:38<3:21:56,  1.66s/it] 58%|█████▊    | 10206/17525 [2:02:39<2:42:40,  1.33s/it] 58%|█████▊    | 10207/17525 [2:02:40<2:28:08,  1.21s/it] 58%|█████▊    | 10208/17525 [2:02:40<2:05:04,  1.03s/it] 58%|█████▊    | 10209/17525 [2:02:41<1:48:52,  1.12it/s] 58%|█████▊    | 10210/17525 [2:02:42<1:37:18,  1.25it/s]                                                         {'loss': 0.4317, 'grad_norm': 6.738976001739502, 'learning_rate': 7.464286735820134e-06, 'epoch': 14.56}
 58%|█████▊    | 10210/17525 [2:02:42<1:37:18,  1.25it/s] 58%|█████▊    | 10211/17525 [2:02:43<1:42:32,  1.19it/s] 58%|█████▊    | 10212/17525 [2:02:43<1:33:05,  1.31it/s] 58%|█████▊    | 10213/17525 [2:02:44<1:26:39,  1.41it/s] 58%|█████▊    | 10214/17525 [2:02:44<1:21:57,  1.49it/s] 58%|█████▊    | 10215/17525 [2:02:45<1:18:40,  1.55it/s] 58%|█████▊    | 10216/17525 [2:02:45<1:16:14,  1.60it/s] 58%|█████▊    | 10217/17525 [2:02:47<1:30:39,  1.34it/s] 58%|█████▊    | 10218/17525 [2:02:47<1:24:37,  1.44it/s] 58%|█████▊    | 10219/17525 [2:02:48<1:20:21,  1.52it/s] 58%|█████▊    | 10220/17525 [2:02:48<1:17:18,  1.58it/s]                                                         {'loss': 0.419, 'grad_norm': 13.558411598205566, 'learning_rate': 7.446930560192767e-06, 'epoch': 14.58}
 58%|█████▊    | 10220/17525 [2:02:48<1:17:18,  1.58it/s] 58%|█████▊    | 10221/17525 [2:02:49<1:15:18,  1.62it/s] 58%|█████▊    | 10222/17525 [2:02:49<1:13:58,  1.65it/s] 58%|█████▊    | 10223/17525 [2:02:50<1:12:48,  1.67it/s] 58%|█████▊    | 10224/17525 [2:02:51<1:12:16,  1.68it/s] 58%|█████▊    | 10225/17525 [2:02:51<1:11:42,  1.70it/s] 58%|█████▊    | 10226/17525 [2:02:52<1:11:22,  1.70it/s] 58%|█████▊    | 10227/17525 [2:02:52<1:11:00,  1.71it/s] 58%|█████▊    | 10228/17525 [2:02:53<1:17:29,  1.57it/s] 58%|█████▊    | 10229/17525 [2:02:54<1:15:30,  1.61it/s] 58%|█████▊    | 10230/17525 [2:02:54<1:13:56,  1.64it/s]                                                         {'loss': 0.3939, 'grad_norm': 13.773004531860352, 'learning_rate': 7.429582607711871e-06, 'epoch': 14.59}
 58%|█████▊    | 10230/17525 [2:02:54<1:13:56,  1.64it/s] 58%|█████▊    | 10231/17525 [2:02:55<1:12:55,  1.67it/s] 58%|█████▊    | 10232/17525 [2:02:55<1:12:00,  1.69it/s] 58%|█████▊    | 10233/17525 [2:02:56<1:24:36,  1.44it/s] 58%|█████▊    | 10234/17525 [2:02:57<1:20:26,  1.51it/s] 58%|█████▊    | 10235/17525 [2:02:57<1:17:22,  1.57it/s] 58%|█████▊    | 10236/17525 [2:02:58<1:15:22,  1.61it/s] 58%|█████▊    | 10237/17525 [2:02:59<1:13:45,  1.65it/s] 58%|█████▊    | 10238/17525 [2:02:59<1:12:34,  1.67it/s] 58%|█████▊    | 10239/17525 [2:03:00<1:11:52,  1.69it/s] 58%|█████▊    | 10240/17525 [2:03:00<1:11:17,  1.70it/s]                                                         {'loss': 0.3906, 'grad_norm': 17.644962310791016, 'learning_rate': 7.412242934253222e-06, 'epoch': 14.61}
 58%|█████▊    | 10240/17525 [2:03:00<1:11:17,  1.70it/s] 58%|█████▊    | 10241/17525 [2:03:01<1:11:04,  1.71it/s] 58%|█████▊    | 10242/17525 [2:03:02<1:15:50,  1.60it/s] 58%|█████▊    | 10243/17525 [2:03:02<1:14:07,  1.64it/s] 58%|█████▊    | 10244/17525 [2:03:03<1:12:52,  1.67it/s] 58%|█████▊    | 10245/17525 [2:03:03<1:11:58,  1.69it/s] 58%|█████▊    | 10246/17525 [2:03:04<1:11:24,  1.70it/s] 58%|█████▊    | 10247/17525 [2:03:05<1:11:00,  1.71it/s] 58%|█████▊    | 10248/17525 [2:03:05<1:10:37,  1.72it/s] 58%|█████▊    | 10249/17525 [2:03:06<1:10:29,  1.72it/s] 58%|█████▊    | 10250/17525 [2:03:06<1:10:16,  1.73it/s]                                                         {'loss': 0.4093, 'grad_norm': 9.596576690673828, 'learning_rate': 7.394911595665943e-06, 'epoch': 14.62}
 58%|█████▊    | 10250/17525 [2:03:06<1:10:16,  1.73it/s] 58%|█████▊    | 10251/17525 [2:03:07<1:10:19,  1.72it/s] 58%|█████▊    | 10252/17525 [2:03:07<1:10:13,  1.73it/s] 59%|█████▊    | 10253/17525 [2:03:08<1:10:56,  1.71it/s] 59%|█████▊    | 10254/17525 [2:03:09<1:10:43,  1.71it/s] 59%|█████▊    | 10255/17525 [2:03:09<1:10:29,  1.72it/s] 59%|█████▊    | 10256/17525 [2:03:10<1:10:24,  1.72it/s] 59%|█████▊    | 10257/17525 [2:03:10<1:10:15,  1.72it/s] 59%|█████▊    | 10258/17525 [2:03:11<1:10:08,  1.73it/s] 59%|█████▊    | 10259/17525 [2:03:12<1:10:06,  1.73it/s] 59%|█████▊    | 10260/17525 [2:03:12<1:09:56,  1.73it/s]                                                         {'loss': 0.4108, 'grad_norm': 9.343814849853516, 'learning_rate': 7.3775886477723e-06, 'epoch': 14.64}
 59%|█████▊    | 10260/17525 [2:03:12<1:09:56,  1.73it/s] 59%|█████▊    | 10261/17525 [2:03:13<1:10:09,  1.73it/s] 59%|█████▊    | 10262/17525 [2:03:13<1:10:03,  1.73it/s] 59%|█████▊    | 10263/17525 [2:03:14<1:09:50,  1.73it/s] 59%|█████▊    | 10264/17525 [2:03:14<1:09:54,  1.73it/s] 59%|█████▊    | 10265/17525 [2:03:15<1:09:49,  1.73it/s] 59%|█████▊    | 10266/17525 [2:03:16<1:09:51,  1.73it/s] 59%|█████▊    | 10267/17525 [2:03:16<1:09:45,  1.73it/s] 59%|█████▊    | 10268/17525 [2:03:17<1:09:40,  1.74it/s] 59%|█████▊    | 10269/17525 [2:03:17<1:09:37,  1.74it/s] 59%|█████▊    | 10270/17525 [2:03:18<1:09:43,  1.73it/s]                                                         {'loss': 0.3471, 'grad_norm': 8.982877731323242, 'learning_rate': 7.360274146367541e-06, 'epoch': 14.65}
 59%|█████▊    | 10270/17525 [2:03:18<1:09:43,  1.73it/s] 59%|█████▊    | 10271/17525 [2:03:18<1:09:48,  1.73it/s] 59%|█████▊    | 10272/17525 [2:03:19<1:09:49,  1.73it/s] 59%|█████▊    | 10273/17525 [2:03:20<1:16:40,  1.58it/s] 59%|█████▊    | 10274/17525 [2:03:20<1:14:43,  1.62it/s] 59%|█████▊    | 10275/17525 [2:03:21<1:13:18,  1.65it/s] 59%|█████▊    | 10276/17525 [2:03:22<1:12:18,  1.67it/s] 59%|█████▊    | 10277/17525 [2:03:22<1:11:20,  1.69it/s] 59%|█████▊    | 10278/17525 [2:03:23<1:10:47,  1.71it/s] 59%|█████▊    | 10279/17525 [2:03:23<1:10:30,  1.71it/s] 59%|█████▊    | 10280/17525 [2:03:24<1:10:07,  1.72it/s]                                                         {'loss': 0.4193, 'grad_norm': 42.90328598022461, 'learning_rate': 7.3429681472197115e-06, 'epoch': 14.66}
 59%|█████▊    | 10280/17525 [2:03:24<1:10:07,  1.72it/s] 59%|█████▊    | 10281/17525 [2:03:24<1:10:08,  1.72it/s] 59%|█████▊    | 10282/17525 [2:03:25<1:09:58,  1.73it/s] 59%|█████▊    | 10283/17525 [2:03:26<1:09:51,  1.73it/s] 59%|█████▊    | 10284/17525 [2:03:26<1:09:54,  1.73it/s] 59%|█████▊    | 10285/17525 [2:03:27<1:09:42,  1.73it/s] 59%|█████▊    | 10286/17525 [2:03:27<1:15:16,  1.60it/s] 59%|█████▊    | 10287/17525 [2:03:28<1:13:43,  1.64it/s] 59%|█████▊    | 10288/17525 [2:03:29<1:13:33,  1.64it/s] 59%|█████▊    | 10289/17525 [2:03:29<1:12:25,  1.67it/s] 59%|█████▊    | 10290/17525 [2:03:30<1:11:39,  1.68it/s]                                                         {'loss': 0.3565, 'grad_norm': 12.254685401916504, 'learning_rate': 7.325670706069461e-06, 'epoch': 14.68}
 59%|█████▊    | 10290/17525 [2:03:30<1:11:39,  1.68it/s] 59%|█████▊    | 10291/17525 [2:03:30<1:11:12,  1.69it/s] 59%|█████▊    | 10292/17525 [2:03:31<1:10:43,  1.70it/s] 59%|█████▊    | 10293/17525 [2:03:32<1:10:27,  1.71it/s] 59%|█████▊    | 10294/17525 [2:03:32<1:10:09,  1.72it/s] 59%|█████▊    | 10295/17525 [2:03:33<1:22:41,  1.46it/s] 59%|█████▉    | 10296/17525 [2:03:34<1:18:43,  1.53it/s] 59%|█████▉    | 10297/17525 [2:03:34<1:15:50,  1.59it/s] 59%|█████▉    | 10298/17525 [2:03:35<1:20:13,  1.50it/s] 59%|█████▉    | 10299/17525 [2:03:36<1:17:39,  1.55it/s] 59%|█████▉    | 10300/17525 [2:03:36<1:15:26,  1.60it/s]                                                         {'loss': 0.4027, 'grad_norm': 18.528949737548828, 'learning_rate': 7.308381878629882e-06, 'epoch': 14.69}
 59%|█████▉    | 10300/17525 [2:03:36<1:15:26,  1.60it/s][INFO|trainer.py:3512] 2024-06-25 04:06:58,008 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:06:58,008 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:06:58,008 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                         
                                               [A{'eval_loss': 1.0855884552001953, 'eval_runtime': 4.5955, 'eval_samples_per_second': 96.398, 'eval_steps_per_second': 4.134, 'epoch': 14.69}
 59%|█████▉    | 10300/17525 [2:03:41<1:15:26,  1.60it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 59%|█████▉    | 10301/17525 [2:03:41<4:01:07,  2.00s/it] 59%|█████▉    | 10302/17525 [2:03:42<3:09:28,  1.57s/it] 59%|█████▉    | 10303/17525 [2:03:42<2:33:33,  1.28s/it] 59%|█████▉    | 10304/17525 [2:03:43<2:08:20,  1.07s/it] 59%|█████▉    | 10305/17525 [2:03:44<1:50:48,  1.09it/s] 59%|█████▉    | 10306/17525 [2:03:44<1:38:26,  1.22it/s] 59%|█████▉    | 10307/17525 [2:03:45<1:29:55,  1.34it/s] 59%|█████▉    | 10308/17525 [2:03:45<1:24:22,  1.43it/s] 59%|█████▉    | 10309/17525 [2:03:46<1:19:52,  1.51it/s] 59%|█████▉    | 10310/17525 [2:03:47<1:16:40,  1.57it/s]                                                         {'loss': 0.3897, 'grad_norm': 11.798638343811035, 'learning_rate': 7.291101720586328e-06, 'epoch': 14.71}
 59%|█████▉    | 10310/17525 [2:03:47<1:16:40,  1.57it/s] 59%|█████▉    | 10311/17525 [2:03:47<1:14:37,  1.61it/s] 59%|█████▉    | 10312/17525 [2:03:48<1:12:58,  1.65it/s] 59%|█████▉    | 10313/17525 [2:03:48<1:11:50,  1.67it/s] 59%|█████▉    | 10314/17525 [2:03:49<1:10:58,  1.69it/s] 59%|█████▉    | 10315/17525 [2:03:49<1:10:31,  1.70it/s] 59%|█████▉    | 10316/17525 [2:03:50<1:10:13,  1.71it/s] 59%|█████▉    | 10317/17525 [2:03:51<1:10:12,  1.71it/s] 59%|█████▉    | 10318/17525 [2:03:51<1:09:55,  1.72it/s] 59%|█████▉    | 10319/17525 [2:03:52<1:09:45,  1.72it/s] 59%|█████▉    | 10320/17525 [2:03:52<1:09:37,  1.72it/s]                                                         {'loss': 0.4712, 'grad_norm': 11.42212200164795, 'learning_rate': 7.273830287596216e-06, 'epoch': 14.72}
 59%|█████▉    | 10320/17525 [2:03:52<1:09:37,  1.72it/s] 59%|█████▉    | 10321/17525 [2:03:53<1:09:34,  1.73it/s] 59%|█████▉    | 10322/17525 [2:03:53<1:09:22,  1.73it/s] 59%|█████▉    | 10323/17525 [2:03:54<1:09:09,  1.74it/s] 59%|█████▉    | 10324/17525 [2:03:55<1:09:14,  1.73it/s] 59%|█████▉    | 10325/17525 [2:03:55<1:09:18,  1.73it/s] 59%|█████▉    | 10326/17525 [2:03:56<1:09:14,  1.73it/s] 59%|█████▉    | 10327/17525 [2:03:56<1:09:13,  1.73it/s] 59%|█████▉    | 10328/17525 [2:03:57<1:09:13,  1.73it/s] 59%|█████▉    | 10329/17525 [2:03:58<1:09:13,  1.73it/s] 59%|█████▉    | 10330/17525 [2:03:58<1:09:32,  1.72it/s]                                                         {'loss': 0.4332, 'grad_norm': 29.7260684967041, 'learning_rate': 7.256567635288878e-06, 'epoch': 14.74}
 59%|█████▉    | 10330/17525 [2:03:58<1:09:32,  1.72it/s] 59%|█████▉    | 10331/17525 [2:03:59<1:09:38,  1.72it/s] 59%|█████▉    | 10332/17525 [2:03:59<1:09:39,  1.72it/s] 59%|█████▉    | 10333/17525 [2:04:00<1:09:26,  1.73it/s] 59%|█████▉    | 10334/17525 [2:04:00<1:09:26,  1.73it/s] 59%|█████▉    | 10335/17525 [2:04:01<1:09:17,  1.73it/s] 59%|█████▉    | 10336/17525 [2:04:02<1:09:08,  1.73it/s] 59%|█████▉    | 10337/17525 [2:04:02<1:10:26,  1.70it/s] 59%|█████▉    | 10338/17525 [2:04:03<1:10:15,  1.70it/s] 59%|█████▉    | 10339/17525 [2:04:03<1:09:58,  1.71it/s] 59%|█████▉    | 10340/17525 [2:04:04<1:10:46,  1.69it/s]                                                         {'loss': 0.3508, 'grad_norm': 26.89332389831543, 'learning_rate': 7.239313819265349e-06, 'epoch': 14.75}
 59%|█████▉    | 10340/17525 [2:04:04<1:10:46,  1.69it/s] 59%|█████▉    | 10341/17525 [2:04:05<1:10:40,  1.69it/s] 59%|█████▉    | 10342/17525 [2:04:05<1:10:14,  1.70it/s] 59%|█████▉    | 10343/17525 [2:04:06<1:09:57,  1.71it/s] 59%|█████▉    | 10344/17525 [2:04:06<1:09:39,  1.72it/s] 59%|█████▉    | 10345/17525 [2:04:07<1:09:27,  1.72it/s] 59%|█████▉    | 10346/17525 [2:04:07<1:09:21,  1.72it/s] 59%|█████▉    | 10347/17525 [2:04:08<1:14:48,  1.60it/s] 59%|█████▉    | 10348/17525 [2:04:09<1:13:11,  1.63it/s] 59%|█████▉    | 10349/17525 [2:04:09<1:12:00,  1.66it/s] 59%|█████▉    | 10350/17525 [2:04:10<1:11:03,  1.68it/s]                                                         {'loss': 0.3989, 'grad_norm': 9.554277420043945, 'learning_rate': 7.222068895098207e-06, 'epoch': 14.76}
 59%|█████▉    | 10350/17525 [2:04:10<1:11:03,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 04:07:31,795 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a6d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d9069185-baf9-4bc5-817d-84f03c628a6c)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:07:41,850 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:07:41,852 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 59%|█████▉    | 10351/17525 [2:04:21<7:16:10,  3.65s/it] 59%|█████▉    | 10352/17525 [2:04:21<5:26:06,  2.73s/it] 59%|█████▉    | 10353/17525 [2:04:22<4:08:59,  2.08s/it] 59%|█████▉    | 10354/17525 [2:04:22<3:15:08,  1.63s/it] 59%|█████▉    | 10355/17525 [2:04:23<2:37:18,  1.32s/it] 59%|█████▉    | 10356/17525 [2:04:24<2:10:51,  1.10s/it] 59%|█████▉    | 10357/17525 [2:04:24<1:52:20,  1.06it/s] 59%|█████▉    | 10358/17525 [2:04:25<1:39:21,  1.20it/s] 59%|█████▉    | 10359/17525 [2:04:25<1:30:09,  1.32it/s] 59%|█████▉    | 10360/17525 [2:04:26<1:23:54,  1.42it/s]                                                         {'loss': 0.4885, 'grad_norm': 61.40943908691406, 'learning_rate': 7.2048329183313985e-06, 'epoch': 14.78}
 59%|█████▉    | 10360/17525 [2:04:26<1:23:54,  1.42it/s] 59%|█████▉    | 10361/17525 [2:04:26<1:19:27,  1.50it/s] 59%|█████▉    | 10362/17525 [2:04:27<1:16:15,  1.57it/s] 59%|█████▉    | 10363/17525 [2:04:28<1:14:08,  1.61it/s] 59%|█████▉    | 10364/17525 [2:04:28<1:12:30,  1.65it/s] 59%|█████▉    | 10365/17525 [2:04:29<1:11:19,  1.67it/s] 59%|█████▉    | 10366/17525 [2:04:29<1:10:38,  1.69it/s] 59%|█████▉    | 10367/17525 [2:04:30<1:11:02,  1.68it/s] 59%|█████▉    | 10368/17525 [2:04:31<1:10:24,  1.69it/s] 59%|█████▉    | 10369/17525 [2:04:31<1:09:48,  1.71it/s] 59%|█████▉    | 10370/17525 [2:04:32<1:09:31,  1.72it/s]                                                         {'loss': 0.404, 'grad_norm': 18.890520095825195, 'learning_rate': 7.187605944480041e-06, 'epoch': 14.79}
 59%|█████▉    | 10370/17525 [2:04:32<1:09:31,  1.72it/s] 59%|█████▉    | 10371/17525 [2:04:32<1:09:21,  1.72it/s] 59%|█████▉    | 10372/17525 [2:04:33<1:09:15,  1.72it/s] 59%|█████▉    | 10373/17525 [2:04:33<1:09:07,  1.72it/s] 59%|█████▉    | 10374/17525 [2:04:34<1:09:09,  1.72it/s] 59%|█████▉    | 10375/17525 [2:04:35<1:08:57,  1.73it/s] 59%|█████▉    | 10376/17525 [2:04:35<1:08:50,  1.73it/s] 59%|█████▉    | 10377/17525 [2:04:36<1:09:08,  1.72it/s] 59%|█████▉    | 10378/17525 [2:04:36<1:09:02,  1.73it/s] 59%|█████▉    | 10379/17525 [2:04:37<1:09:09,  1.72it/s] 59%|█████▉    | 10380/17525 [2:04:37<1:09:37,  1.71it/s]                                                         {'loss': 0.423, 'grad_norm': 8.446690559387207, 'learning_rate': 7.170388029030262e-06, 'epoch': 14.81}
 59%|█████▉    | 10380/17525 [2:04:37<1:09:37,  1.71it/s] 59%|█████▉    | 10381/17525 [2:04:38<1:09:32,  1.71it/s] 59%|█████▉    | 10382/17525 [2:04:39<1:09:26,  1.71it/s] 59%|█████▉    | 10383/17525 [2:04:39<1:09:13,  1.72it/s] 59%|█████▉    | 10384/17525 [2:04:40<1:09:00,  1.72it/s] 59%|█████▉    | 10385/17525 [2:04:40<1:08:54,  1.73it/s] 59%|█████▉    | 10386/17525 [2:04:41<1:10:02,  1.70it/s] 59%|█████▉    | 10387/17525 [2:04:42<1:09:36,  1.71it/s] 59%|█████▉    | 10388/17525 [2:04:42<1:09:13,  1.72it/s] 59%|█████▉    | 10389/17525 [2:04:43<1:09:09,  1.72it/s] 59%|█████▉    | 10390/17525 [2:04:43<1:09:01,  1.72it/s]                                                         {'loss': 0.4719, 'grad_norm': 14.077474594116211, 'learning_rate': 7.1531792274390075e-06, 'epoch': 14.82}
 59%|█████▉    | 10390/17525 [2:04:43<1:09:01,  1.72it/s] 59%|█████▉    | 10391/17525 [2:04:44<1:09:04,  1.72it/s] 59%|█████▉    | 10392/17525 [2:04:44<1:09:01,  1.72it/s] 59%|█████▉    | 10393/17525 [2:04:45<1:08:49,  1.73it/s] 59%|█████▉    | 10394/17525 [2:04:46<1:08:43,  1.73it/s] 59%|█████▉    | 10395/17525 [2:04:46<1:08:35,  1.73it/s] 59%|█████▉    | 10396/17525 [2:04:47<1:08:35,  1.73it/s] 59%|█████▉    | 10397/17525 [2:04:47<1:08:25,  1.74it/s] 59%|█████▉    | 10398/17525 [2:04:48<1:23:36,  1.42it/s] 59%|█████▉    | 10399/17525 [2:04:49<1:19:03,  1.50it/s] 59%|█████▉    | 10400/17525 [2:04:50<1:15:56,  1.56it/s]                                                         {'loss': 0.2923, 'grad_norm': 3.2965073585510254, 'learning_rate': 7.1359795951338724e-06, 'epoch': 14.84}
 59%|█████▉    | 10400/17525 [2:04:50<1:15:56,  1.56it/s][INFO|trainer.py:3512] 2024-06-25 04:08:11,399 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:08:11,399 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:08:11,399 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0462104082107544, 'eval_runtime': 4.5969, 'eval_samples_per_second': 96.369, 'eval_steps_per_second': 4.133, 'epoch': 14.84}
 59%|█████▉    | 10400/17525 [2:04:54<1:15:56,  1.56it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 59%|█████▉    | 10401/17525 [2:04:55<3:57:53,  2.00s/it] 59%|█████▉    | 10402/17525 [2:04:55<3:07:33,  1.58s/it] 59%|█████▉    | 10403/17525 [2:04:56<2:31:57,  1.28s/it] 59%|█████▉    | 10404/17525 [2:04:56<2:07:07,  1.07s/it] 59%|█████▉    | 10405/17525 [2:04:57<1:54:35,  1.04it/s] 59%|█████▉    | 10406/17525 [2:04:58<1:40:52,  1.18it/s] 59%|█████▉    | 10407/17525 [2:04:58<1:31:08,  1.30it/s] 59%|█████▉    | 10408/17525 [2:04:59<1:24:25,  1.40it/s] 59%|█████▉    | 10409/17525 [2:04:59<1:19:39,  1.49it/s] 59%|█████▉    | 10410/17525 [2:05:00<1:16:14,  1.56it/s]                                                         {'loss': 0.3312, 'grad_norm': 9.84316635131836, 'learning_rate': 7.11878918751292e-06, 'epoch': 14.85}
 59%|█████▉    | 10410/17525 [2:05:00<1:16:14,  1.56it/s] 59%|█████▉    | 10411/17525 [2:05:01<1:14:10,  1.60it/s] 59%|█████▉    | 10412/17525 [2:05:01<1:12:40,  1.63it/s] 59%|█████▉    | 10413/17525 [2:05:02<1:11:48,  1.65it/s] 59%|█████▉    | 10414/17525 [2:05:02<1:11:04,  1.67it/s] 59%|█████▉    | 10415/17525 [2:05:03<1:10:35,  1.68it/s] 59%|█████▉    | 10416/17525 [2:05:04<1:09:51,  1.70it/s] 59%|█████▉    | 10417/17525 [2:05:04<1:10:22,  1.68it/s] 59%|█████▉    | 10418/17525 [2:05:05<1:09:48,  1.70it/s] 59%|█████▉    | 10419/17525 [2:05:05<1:09:30,  1.70it/s] 59%|█████▉    | 10420/17525 [2:05:06<1:10:14,  1.69it/s]                                                         {'loss': 0.4198, 'grad_norm': 11.936620712280273, 'learning_rate': 7.101608059944494e-06, 'epoch': 14.86}
 59%|█████▉    | 10420/17525 [2:05:06<1:10:14,  1.69it/s] 59%|█████▉    | 10421/17525 [2:05:07<1:09:33,  1.70it/s] 59%|█████▉    | 10422/17525 [2:05:07<1:16:15,  1.55it/s] 59%|█████▉    | 10423/17525 [2:05:08<1:13:46,  1.60it/s] 59%|█████▉    | 10424/17525 [2:05:08<1:12:06,  1.64it/s] 59%|█████▉    | 10425/17525 [2:05:09<1:10:54,  1.67it/s] 59%|█████▉    | 10426/17525 [2:05:10<1:10:15,  1.68it/s] 59%|█████▉    | 10427/17525 [2:05:10<1:09:37,  1.70it/s] 60%|█████▉    | 10428/17525 [2:05:11<1:09:09,  1.71it/s] 60%|█████▉    | 10429/17525 [2:05:11<1:08:56,  1.72it/s] 60%|█████▉    | 10430/17525 [2:05:12<1:08:38,  1.72it/s]                                                         {'loss': 0.4444, 'grad_norm': 12.352946281433105, 'learning_rate': 7.0844362677670585e-06, 'epoch': 14.88}
 60%|█████▉    | 10430/17525 [2:05:12<1:08:38,  1.72it/s] 60%|█████▉    | 10431/17525 [2:05:12<1:08:38,  1.72it/s] 60%|█████▉    | 10432/17525 [2:05:13<1:08:37,  1.72it/s] 60%|█████▉    | 10433/17525 [2:05:14<1:08:29,  1.73it/s] 60%|█████▉    | 10434/17525 [2:05:14<1:08:21,  1.73it/s] 60%|█████▉    | 10435/17525 [2:05:15<1:14:22,  1.59it/s] 60%|█████▉    | 10436/17525 [2:05:16<1:25:32,  1.38it/s] 60%|█████▉    | 10437/17525 [2:05:16<1:20:18,  1.47it/s] 60%|█████▉    | 10438/17525 [2:05:17<1:16:41,  1.54it/s] 60%|█████▉    | 10439/17525 [2:05:18<1:14:16,  1.59it/s] 60%|█████▉    | 10440/17525 [2:05:18<1:12:20,  1.63it/s]                                                         {'loss': 0.4404, 'grad_norm': 10.561189651489258, 'learning_rate': 7.0672738662890025e-06, 'epoch': 14.89}
 60%|█████▉    | 10440/17525 [2:05:18<1:12:20,  1.63it/s] 60%|█████▉    | 10441/17525 [2:05:19<1:11:02,  1.66it/s] 60%|█████▉    | 10442/17525 [2:05:19<1:10:13,  1.68it/s] 60%|█████▉    | 10443/17525 [2:05:20<1:10:13,  1.68it/s] 60%|█████▉    | 10444/17525 [2:05:21<1:09:48,  1.69it/s] 60%|█████▉    | 10445/17525 [2:05:21<1:09:36,  1.70it/s] 60%|█████▉    | 10446/17525 [2:05:22<1:09:04,  1.71it/s] 60%|█████▉    | 10447/17525 [2:05:22<1:08:49,  1.71it/s] 60%|█████▉    | 10448/17525 [2:05:24<1:35:49,  1.23it/s] 60%|█████▉    | 10449/17525 [2:05:24<1:27:36,  1.35it/s] 60%|█████▉    | 10450/17525 [2:05:25<1:21:40,  1.44it/s]                                                         {'loss': 0.4512, 'grad_norm': 17.59269905090332, 'learning_rate': 7.050120910788466e-06, 'epoch': 14.91}
 60%|█████▉    | 10450/17525 [2:05:25<1:21:40,  1.44it/s] 60%|█████▉    | 10451/17525 [2:05:25<1:17:41,  1.52it/s] 60%|█████▉    | 10452/17525 [2:05:26<1:14:43,  1.58it/s] 60%|█████▉    | 10453/17525 [2:05:27<1:12:43,  1.62it/s] 60%|█████▉    | 10454/17525 [2:05:27<1:11:19,  1.65it/s] 60%|█████▉    | 10455/17525 [2:05:28<1:10:29,  1.67it/s] 60%|█████▉    | 10456/17525 [2:05:28<1:09:42,  1.69it/s] 60%|█████▉    | 10457/17525 [2:05:29<1:09:14,  1.70it/s] 60%|█████▉    | 10458/17525 [2:05:29<1:08:51,  1.71it/s] 60%|█████▉    | 10459/17525 [2:05:30<1:08:30,  1.72it/s] 60%|█████▉    | 10460/17525 [2:05:31<1:08:15,  1.73it/s]                                                         {'loss': 0.3793, 'grad_norm': 8.234278678894043, 'learning_rate': 7.032977456513177e-06, 'epoch': 14.92}
 60%|█████▉    | 10460/17525 [2:05:31<1:08:15,  1.73it/s] 60%|█████▉    | 10461/17525 [2:05:31<1:08:22,  1.72it/s] 60%|█████▉    | 10462/17525 [2:05:32<1:08:15,  1.72it/s] 60%|█████▉    | 10463/17525 [2:05:32<1:08:13,  1.73it/s] 60%|█████▉    | 10464/17525 [2:05:33<1:08:01,  1.73it/s] 60%|█████▉    | 10465/17525 [2:05:33<1:07:57,  1.73it/s] 60%|█████▉    | 10466/17525 [2:05:34<1:07:51,  1.73it/s] 60%|█████▉    | 10467/17525 [2:05:35<1:07:47,  1.74it/s] 60%|█████▉    | 10468/17525 [2:05:35<1:07:53,  1.73it/s] 60%|█████▉    | 10469/17525 [2:05:36<1:07:56,  1.73it/s] 60%|█████▉    | 10470/17525 [2:05:36<1:07:49,  1.73it/s]                                                         {'loss': 0.4, 'grad_norm': 17.22205924987793, 'learning_rate': 7.015843558680244e-06, 'epoch': 14.94}
 60%|█████▉    | 10470/17525 [2:05:36<1:07:49,  1.73it/s] 60%|█████▉    | 10471/17525 [2:05:37<1:07:49,  1.73it/s] 60%|█████▉    | 10472/17525 [2:05:37<1:07:46,  1.73it/s] 60%|█████▉    | 10473/17525 [2:05:38<1:07:43,  1.74it/s] 60%|█████▉    | 10474/17525 [2:05:39<1:07:59,  1.73it/s] 60%|█████▉    | 10475/17525 [2:05:39<1:08:00,  1.73it/s] 60%|█████▉    | 10476/17525 [2:05:40<1:07:52,  1.73it/s] 60%|█████▉    | 10477/17525 [2:05:40<1:07:45,  1.73it/s] 60%|█████▉    | 10478/17525 [2:05:41<1:07:45,  1.73it/s] 60%|█████▉    | 10479/17525 [2:05:42<1:07:58,  1.73it/s] 60%|█████▉    | 10480/17525 [2:05:42<1:07:51,  1.73it/s]                                                         {'loss': 0.4122, 'grad_norm': 8.67504596710205, 'learning_rate': 6.998719272476013e-06, 'epoch': 14.95}
 60%|█████▉    | 10480/17525 [2:05:42<1:07:51,  1.73it/s] 60%|█████▉    | 10481/17525 [2:05:43<1:08:08,  1.72it/s] 60%|█████▉    | 10482/17525 [2:05:43<1:08:02,  1.73it/s] 60%|█████▉    | 10483/17525 [2:05:44<1:07:58,  1.73it/s] 60%|█████▉    | 10484/17525 [2:05:44<1:08:04,  1.72it/s] 60%|█████▉    | 10485/17525 [2:05:45<1:08:35,  1.71it/s] 60%|█████▉    | 10486/17525 [2:05:46<1:08:16,  1.72it/s] 60%|█████▉    | 10487/17525 [2:05:46<1:08:10,  1.72it/s] 60%|█████▉    | 10488/17525 [2:05:47<1:08:19,  1.72it/s] 60%|█████▉    | 10489/17525 [2:05:47<1:08:01,  1.72it/s] 60%|█████▉    | 10490/17525 [2:05:48<1:07:45,  1.73it/s]                                                         {'loss': 0.5151, 'grad_norm': 11.007956504821777, 'learning_rate': 6.981604653055863e-06, 'epoch': 14.96}
 60%|█████▉    | 10490/17525 [2:05:48<1:07:45,  1.73it/s] 60%|█████▉    | 10491/17525 [2:05:49<1:07:52,  1.73it/s] 60%|█████▉    | 10492/17525 [2:05:49<1:07:46,  1.73it/s] 60%|█████▉    | 10493/17525 [2:05:50<1:07:49,  1.73it/s] 60%|█████▉    | 10494/17525 [2:05:50<1:07:40,  1.73it/s] 60%|█████▉    | 10495/17525 [2:05:51<1:07:37,  1.73it/s] 60%|█████▉    | 10496/17525 [2:05:51<1:07:34,  1.73it/s] 60%|█████▉    | 10497/17525 [2:05:52<1:22:41,  1.42it/s] 60%|█████▉    | 10498/17525 [2:05:53<1:18:10,  1.50it/s] 60%|█████▉    | 10499/17525 [2:05:54<1:14:47,  1.57it/s] 60%|█████▉    | 10500/17525 [2:05:54<1:12:23,  1.62it/s]                                                         {'loss': 0.4131, 'grad_norm': 12.264091491699219, 'learning_rate': 6.964499755544029e-06, 'epoch': 14.98}
 60%|█████▉    | 10500/17525 [2:05:54<1:12:23,  1.62it/s][INFO|trainer.py:3512] 2024-06-25 04:09:16,014 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:09:16,014 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:09:16,014 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.024503469467163, 'eval_runtime': 4.6006, 'eval_samples_per_second': 96.292, 'eval_steps_per_second': 4.13, 'epoch': 14.98}
 60%|█████▉    | 10500/17525 [2:05:59<1:12:23,  1.62it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:09:20,618 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7ac5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 26a043b5-52c8-40de-976f-5c29bba54a64)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:09:30,676 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:09:30,679 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 60%|█████▉    | 10501/17525 [2:06:10<9:51:07,  5.05s/it] 60%|█████▉    | 10502/17525 [2:06:10<7:14:05,  3.71s/it] 60%|█████▉    | 10503/17525 [2:06:11<5:24:10,  2.77s/it] 60%|█████▉    | 10504/17525 [2:06:11<4:07:15,  2.11s/it] 60%|█████▉    | 10505/17525 [2:06:12<3:13:24,  1.65s/it] 60%|█████▉    | 10506/17525 [2:06:12<2:35:32,  1.33s/it] 60%|█████▉    | 10507/17525 [2:06:13<2:09:07,  1.10s/it] 60%|█████▉    | 10508/17525 [2:06:14<1:50:45,  1.06it/s] 60%|█████▉    | 10509/17525 [2:06:14<1:37:50,  1.20it/s] 60%|█████▉    | 10510/17525 [2:06:15<1:28:37,  1.32it/s]                                                         {'loss': 0.406, 'grad_norm': 9.447219848632812, 'learning_rate': 6.94740463503345e-06, 'epoch': 14.99}
 60%|█████▉    | 10510/17525 [2:06:15<1:28:37,  1.32it/s] 60%|█████▉    | 10511/17525 [2:06:15<1:22:22,  1.42it/s] 60%|█████▉    | 10512/17525 [2:06:16<1:17:54,  1.50it/s] 60%|█████▉    | 10513/17525 [2:06:16<1:14:49,  1.56it/s] 60%|█████▉    | 10514/17525 [2:06:17<1:12:30,  1.61it/s] 60%|██████    | 10515/17525 [2:06:18<1:10:59,  1.65it/s] 60%|██████    | 10516/17525 [2:06:18<1:10:17,  1.66it/s] 60%|██████    | 10517/17525 [2:06:19<1:09:21,  1.68it/s] 60%|██████    | 10518/17525 [2:06:19<1:08:42,  1.70it/s] 60%|██████    | 10519/17525 [2:06:20<1:08:19,  1.71it/s] 60%|██████    | 10520/17525 [2:06:21<1:08:17,  1.71it/s]                                                         {'loss': 0.3916, 'grad_norm': 8.125944137573242, 'learning_rate': 6.930319346585559e-06, 'epoch': 15.01}
 60%|██████    | 10520/17525 [2:06:21<1:08:17,  1.71it/s] 60%|██████    | 10521/17525 [2:06:21<1:08:35,  1.70it/s] 60%|██████    | 10522/17525 [2:06:22<1:08:04,  1.71it/s] 60%|██████    | 10523/17525 [2:06:22<1:07:48,  1.72it/s] 60%|██████    | 10524/17525 [2:06:23<1:07:35,  1.73it/s] 60%|██████    | 10525/17525 [2:06:23<1:07:31,  1.73it/s] 60%|██████    | 10526/17525 [2:06:24<1:07:29,  1.73it/s] 60%|██████    | 10527/17525 [2:06:25<1:07:30,  1.73it/s] 60%|██████    | 10528/17525 [2:06:25<1:07:26,  1.73it/s] 60%|██████    | 10529/17525 [2:06:26<1:07:27,  1.73it/s] 60%|██████    | 10530/17525 [2:06:26<1:07:23,  1.73it/s]                                                         {'loss': 0.3344, 'grad_norm': 12.466215133666992, 'learning_rate': 6.913243945230137e-06, 'epoch': 15.02}
 60%|██████    | 10530/17525 [2:06:26<1:07:23,  1.73it/s] 60%|██████    | 10531/17525 [2:06:27<1:07:30,  1.73it/s] 60%|██████    | 10532/17525 [2:06:27<1:07:39,  1.72it/s] 60%|██████    | 10533/17525 [2:06:28<1:07:37,  1.72it/s] 60%|██████    | 10534/17525 [2:06:29<1:07:35,  1.72it/s] 60%|██████    | 10535/17525 [2:06:29<1:07:31,  1.73it/s] 60%|██████    | 10536/17525 [2:06:30<1:07:21,  1.73it/s] 60%|██████    | 10537/17525 [2:06:30<1:07:23,  1.73it/s] 60%|██████    | 10538/17525 [2:06:31<1:07:24,  1.73it/s] 60%|██████    | 10539/17525 [2:06:32<1:07:52,  1.72it/s] 60%|██████    | 10540/17525 [2:06:32<1:07:35,  1.72it/s]                                                         {'loss': 0.3103, 'grad_norm': 6.263455867767334, 'learning_rate': 6.896178485965105e-06, 'epoch': 15.04}
 60%|██████    | 10540/17525 [2:06:32<1:07:35,  1.72it/s] 60%|██████    | 10541/17525 [2:06:33<1:07:41,  1.72it/s] 60%|██████    | 10542/17525 [2:06:33<1:07:31,  1.72it/s] 60%|██████    | 10543/17525 [2:06:34<1:07:44,  1.72it/s] 60%|██████    | 10544/17525 [2:06:34<1:07:31,  1.72it/s] 60%|██████    | 10545/17525 [2:06:35<1:07:17,  1.73it/s] 60%|██████    | 10546/17525 [2:06:36<1:07:31,  1.72it/s] 60%|██████    | 10547/17525 [2:06:36<1:07:36,  1.72it/s] 60%|██████    | 10548/17525 [2:06:37<1:07:35,  1.72it/s] 60%|██████    | 10549/17525 [2:06:37<1:07:36,  1.72it/s] 60%|██████    | 10550/17525 [2:06:38<1:07:37,  1.72it/s]                                                         {'loss': 0.3864, 'grad_norm': 10.288965225219727, 'learning_rate': 6.879123023756364e-06, 'epoch': 15.05}
 60%|██████    | 10550/17525 [2:06:38<1:07:37,  1.72it/s] 60%|██████    | 10551/17525 [2:06:38<1:07:44,  1.72it/s] 60%|██████    | 10552/17525 [2:06:39<1:07:44,  1.72it/s] 60%|██████    | 10553/17525 [2:06:40<1:07:36,  1.72it/s] 60%|██████    | 10554/17525 [2:06:40<1:07:23,  1.72it/s] 60%|██████    | 10555/17525 [2:06:41<1:07:46,  1.71it/s] 60%|██████    | 10556/17525 [2:06:41<1:07:28,  1.72it/s] 60%|██████    | 10557/17525 [2:06:42<1:07:23,  1.72it/s] 60%|██████    | 10558/17525 [2:06:43<1:07:15,  1.73it/s] 60%|██████    | 10559/17525 [2:06:43<1:07:11,  1.73it/s] 60%|██████    | 10560/17525 [2:06:44<1:07:58,  1.71it/s]                                                         {'loss': 0.4166, 'grad_norm': 9.049339294433594, 'learning_rate': 6.862077613537629e-06, 'epoch': 15.06}
 60%|██████    | 10560/17525 [2:06:44<1:07:58,  1.71it/s] 60%|██████    | 10561/17525 [2:06:44<1:07:51,  1.71it/s] 60%|██████    | 10562/17525 [2:06:45<1:07:40,  1.72it/s] 60%|██████    | 10563/17525 [2:06:45<1:07:25,  1.72it/s] 60%|██████    | 10564/17525 [2:06:46<1:07:19,  1.72it/s] 60%|██████    | 10565/17525 [2:06:47<1:07:14,  1.73it/s] 60%|██████    | 10566/17525 [2:06:47<1:07:10,  1.73it/s] 60%|██████    | 10567/17525 [2:06:48<1:08:05,  1.70it/s] 60%|██████    | 10568/17525 [2:06:48<1:07:43,  1.71it/s] 60%|██████    | 10569/17525 [2:06:49<1:07:36,  1.71it/s] 60%|██████    | 10570/17525 [2:06:50<1:07:19,  1.72it/s]                                                         {'loss': 0.444, 'grad_norm': 5.8265533447265625, 'learning_rate': 6.8450423102102235e-06, 'epoch': 15.08}
 60%|██████    | 10570/17525 [2:06:50<1:07:19,  1.72it/s] 60%|██████    | 10571/17525 [2:06:50<1:07:22,  1.72it/s] 60%|██████    | 10572/17525 [2:06:51<1:07:24,  1.72it/s] 60%|██████    | 10573/17525 [2:06:51<1:07:17,  1.72it/s] 60%|██████    | 10574/17525 [2:06:52<1:07:16,  1.72it/s] 60%|██████    | 10575/17525 [2:06:52<1:07:19,  1.72it/s] 60%|██████    | 10576/17525 [2:06:53<1:19:07,  1.46it/s] 60%|██████    | 10577/17525 [2:06:54<1:15:51,  1.53it/s] 60%|██████    | 10578/17525 [2:06:55<1:13:18,  1.58it/s] 60%|██████    | 10579/17525 [2:06:55<1:11:33,  1.62it/s] 60%|██████    | 10580/17525 [2:06:56<1:10:12,  1.65it/s]                                                         {'loss': 0.4567, 'grad_norm': 17.53372573852539, 'learning_rate': 6.828017168642918e-06, 'epoch': 15.09}
 60%|██████    | 10580/17525 [2:06:56<1:10:12,  1.65it/s] 60%|██████    | 10581/17525 [2:06:56<1:09:20,  1.67it/s] 60%|██████    | 10582/17525 [2:06:57<1:08:35,  1.69it/s] 60%|██████    | 10583/17525 [2:06:57<1:08:07,  1.70it/s] 60%|██████    | 10584/17525 [2:06:58<1:08:22,  1.69it/s] 60%|██████    | 10585/17525 [2:06:59<1:07:56,  1.70it/s] 60%|██████    | 10586/17525 [2:06:59<1:07:45,  1.71it/s] 60%|██████    | 10587/17525 [2:07:00<1:07:34,  1.71it/s] 60%|██████    | 10588/17525 [2:07:00<1:07:30,  1.71it/s] 60%|██████    | 10589/17525 [2:07:01<1:07:24,  1.71it/s] 60%|██████    | 10590/17525 [2:07:02<1:07:19,  1.72it/s]                                                         {'loss': 0.3535, 'grad_norm': 11.492887496948242, 'learning_rate': 6.8110022436717686e-06, 'epoch': 15.11}
 60%|██████    | 10590/17525 [2:07:02<1:07:19,  1.72it/s] 60%|██████    | 10591/17525 [2:07:02<1:07:20,  1.72it/s] 60%|██████    | 10592/17525 [2:07:03<1:07:13,  1.72it/s] 60%|██████    | 10593/17525 [2:07:03<1:07:07,  1.72it/s] 60%|██████    | 10594/17525 [2:07:04<1:07:11,  1.72it/s] 60%|██████    | 10595/17525 [2:07:04<1:07:13,  1.72it/s] 60%|██████    | 10596/17525 [2:07:05<1:07:01,  1.72it/s] 60%|██████    | 10597/17525 [2:07:06<1:06:57,  1.72it/s] 60%|██████    | 10598/17525 [2:07:06<1:06:59,  1.72it/s] 60%|██████    | 10599/17525 [2:07:07<1:22:04,  1.41it/s] 60%|██████    | 10600/17525 [2:07:08<1:17:27,  1.49it/s]                                                         {'loss': 0.395, 'grad_norm': 10.094806671142578, 'learning_rate': 6.7939975900999054e-06, 'epoch': 15.12}
 60%|██████    | 10600/17525 [2:07:08<1:17:27,  1.49it/s][INFO|trainer.py:3512] 2024-06-25 04:10:29,664 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:10:29,664 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:10:29,664 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0745956897735596, 'eval_runtime': 4.602, 'eval_samples_per_second': 96.263, 'eval_steps_per_second': 4.129, 'epoch': 15.12}
 60%|██████    | 10600/17525 [2:07:12<1:17:27,  1.49it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 60%|██████    | 10601/17525 [2:07:13<3:54:09,  2.03s/it] 60%|██████    | 10602/17525 [2:07:14<3:04:05,  1.60s/it] 61%|██████    | 10603/17525 [2:07:14<2:28:55,  1.29s/it] 61%|██████    | 10604/17525 [2:07:15<2:04:22,  1.08s/it] 61%|██████    | 10605/17525 [2:07:15<1:47:10,  1.08it/s] 61%|██████    | 10606/17525 [2:07:16<1:35:08,  1.21it/s] 61%|██████    | 10607/17525 [2:07:16<1:26:54,  1.33it/s] 61%|██████    | 10608/17525 [2:07:17<1:20:48,  1.43it/s] 61%|██████    | 10609/17525 [2:07:18<1:16:30,  1.51it/s] 61%|██████    | 10610/17525 [2:07:19<1:24:13,  1.37it/s]                                                         {'loss': 0.4823, 'grad_norm': 4.451353073120117, 'learning_rate': 6.7770032626973926e-06, 'epoch': 15.14}
 61%|██████    | 10610/17525 [2:07:19<1:24:13,  1.37it/s] 61%|██████    | 10611/17525 [2:07:19<1:19:09,  1.46it/s] 61%|██████    | 10612/17525 [2:07:20<1:15:15,  1.53it/s] 61%|██████    | 10613/17525 [2:07:20<1:12:44,  1.58it/s] 61%|██████    | 10614/17525 [2:07:21<1:10:49,  1.63it/s] 61%|██████    | 10615/17525 [2:07:21<1:09:32,  1.66it/s] 61%|██████    | 10616/17525 [2:07:22<1:24:30,  1.36it/s] 61%|██████    | 10617/17525 [2:07:23<1:19:22,  1.45it/s] 61%|██████    | 10618/17525 [2:07:24<1:16:30,  1.50it/s] 61%|██████    | 10619/17525 [2:07:24<1:13:47,  1.56it/s] 61%|██████    | 10620/17525 [2:07:25<1:11:53,  1.60it/s]                                                         {'loss': 0.3845, 'grad_norm': 9.777850151062012, 'learning_rate': 6.760019316201023e-06, 'epoch': 15.15}
 61%|██████    | 10620/17525 [2:07:25<1:11:53,  1.60it/s] 61%|██████    | 10621/17525 [2:07:25<1:10:29,  1.63it/s] 61%|██████    | 10622/17525 [2:07:26<1:09:19,  1.66it/s] 61%|██████    | 10623/17525 [2:07:27<1:08:23,  1.68it/s] 61%|██████    | 10624/17525 [2:07:27<1:20:19,  1.43it/s] 61%|██████    | 10625/17525 [2:07:28<1:16:12,  1.51it/s] 61%|██████    | 10626/17525 [2:07:29<1:13:19,  1.57it/s] 61%|██████    | 10627/17525 [2:07:29<1:11:15,  1.61it/s] 61%|██████    | 10628/17525 [2:07:30<1:09:40,  1.65it/s] 61%|██████    | 10629/17525 [2:07:31<1:15:03,  1.53it/s] 61%|██████    | 10630/17525 [2:07:31<1:12:34,  1.58it/s]                                                         {'loss': 0.4186, 'grad_norm': 16.79788589477539, 'learning_rate': 6.743045805314155e-06, 'epoch': 15.16}
 61%|██████    | 10630/17525 [2:07:31<1:12:34,  1.58it/s] 61%|██████    | 10631/17525 [2:07:32<1:10:44,  1.62it/s] 61%|██████    | 10632/17525 [2:07:32<1:09:20,  1.66it/s] 61%|██████    | 10633/17525 [2:07:33<1:09:32,  1.65it/s] 61%|██████    | 10634/17525 [2:07:33<1:09:10,  1.66it/s] 61%|██████    | 10635/17525 [2:07:34<1:08:25,  1.68it/s] 61%|██████    | 10636/17525 [2:07:35<1:07:46,  1.69it/s] 61%|██████    | 10637/17525 [2:07:35<1:07:22,  1.70it/s] 61%|██████    | 10638/17525 [2:07:36<1:07:06,  1.71it/s] 61%|██████    | 10639/17525 [2:07:36<1:06:49,  1.72it/s] 61%|██████    | 10640/17525 [2:07:37<1:06:48,  1.72it/s]                                                         {'loss': 0.3724, 'grad_norm': 18.91135597229004, 'learning_rate': 6.726082784706545e-06, 'epoch': 15.18}
 61%|██████    | 10640/17525 [2:07:37<1:06:48,  1.72it/s] 61%|██████    | 10641/17525 [2:07:38<1:21:39,  1.40it/s] 61%|██████    | 10642/17525 [2:07:39<1:17:00,  1.49it/s] 61%|██████    | 10643/17525 [2:07:39<1:13:43,  1.56it/s] 61%|██████    | 10644/17525 [2:07:40<1:11:29,  1.60it/s] 61%|██████    | 10645/17525 [2:07:40<1:09:58,  1.64it/s] 61%|██████    | 10646/17525 [2:07:41<1:09:17,  1.65it/s] 61%|██████    | 10647/17525 [2:07:42<1:11:32,  1.60it/s] 61%|██████    | 10648/17525 [2:07:42<1:15:34,  1.52it/s] 61%|██████    | 10649/17525 [2:07:43<1:12:52,  1.57it/s] 61%|██████    | 10650/17525 [2:07:43<1:10:53,  1.62it/s]                                                         {'loss': 0.5106, 'grad_norm': 25.028581619262695, 'learning_rate': 6.709130309014145e-06, 'epoch': 15.19}
 61%|██████    | 10650/17525 [2:07:43<1:10:53,  1.62it/s][INFO|trainer.py:3203] 2024-06-25 04:11:05,369 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b7cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d7a14ea6-d0b2-41e4-9afa-d16f740ed6b2)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:11:15,426 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:11:15,428 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 61%|██████    | 10651/17525 [2:07:54<7:01:10,  3.68s/it] 61%|██████    | 10652/17525 [2:07:55<5:14:42,  2.75s/it] 61%|██████    | 10653/17525 [2:07:55<4:00:07,  2.10s/it] 61%|██████    | 10654/17525 [2:07:56<3:08:00,  1.64s/it] 61%|██████    | 10655/17525 [2:07:57<2:31:28,  1.32s/it] 61%|██████    | 10656/17525 [2:07:57<2:05:50,  1.10s/it] 61%|██████    | 10657/17525 [2:07:58<1:49:10,  1.05it/s] 61%|██████    | 10658/17525 [2:07:58<1:36:11,  1.19it/s] 61%|██████    | 10659/17525 [2:07:59<1:27:06,  1.31it/s] 61%|██████    | 10660/17525 [2:08:00<1:20:43,  1.42it/s]                                                         {'loss': 0.3613, 'grad_norm': 6.832496166229248, 'learning_rate': 6.6921884328389595e-06, 'epoch': 15.21}
 61%|██████    | 10660/17525 [2:08:00<1:20:43,  1.42it/s] 61%|██████    | 10661/17525 [2:08:00<1:16:25,  1.50it/s] 61%|██████    | 10662/17525 [2:08:01<1:13:16,  1.56it/s] 61%|██████    | 10663/17525 [2:08:01<1:11:03,  1.61it/s] 61%|██████    | 10664/17525 [2:08:02<1:10:52,  1.61it/s] 61%|██████    | 10665/17525 [2:08:02<1:09:19,  1.65it/s] 61%|██████    | 10666/17525 [2:08:03<1:08:16,  1.67it/s] 61%|██████    | 10667/17525 [2:08:04<1:07:34,  1.69it/s] 61%|██████    | 10668/17525 [2:08:04<1:07:08,  1.70it/s] 61%|██████    | 10669/17525 [2:08:05<1:06:47,  1.71it/s] 61%|██████    | 10670/17525 [2:08:05<1:06:40,  1.71it/s]                                                         {'loss': 0.3208, 'grad_norm': 143.43820190429688, 'learning_rate': 6.6752572107488464e-06, 'epoch': 15.22}
 61%|██████    | 10670/17525 [2:08:05<1:06:40,  1.71it/s] 61%|██████    | 10671/17525 [2:08:06<1:06:24,  1.72it/s] 61%|██████    | 10672/17525 [2:08:06<1:06:06,  1.73it/s] 61%|██████    | 10673/17525 [2:08:07<1:05:51,  1.73it/s] 61%|██████    | 10674/17525 [2:08:08<1:05:52,  1.73it/s] 61%|██████    | 10675/17525 [2:08:09<1:17:52,  1.47it/s] 61%|██████    | 10676/17525 [2:08:09<1:14:10,  1.54it/s] 61%|██████    | 10677/17525 [2:08:10<1:11:25,  1.60it/s] 61%|██████    | 10678/17525 [2:08:10<1:09:38,  1.64it/s] 61%|██████    | 10679/17525 [2:08:11<1:08:23,  1.67it/s] 61%|██████    | 10680/17525 [2:08:11<1:07:34,  1.69it/s]                                                         {'loss': 0.3182, 'grad_norm': 15.343001365661621, 'learning_rate': 6.65833669727734e-06, 'epoch': 15.24}
 61%|██████    | 10680/17525 [2:08:11<1:07:34,  1.69it/s] 61%|██████    | 10681/17525 [2:08:12<1:07:02,  1.70it/s] 61%|██████    | 10682/17525 [2:08:13<1:06:33,  1.71it/s] 61%|██████    | 10683/17525 [2:08:13<1:06:22,  1.72it/s] 61%|██████    | 10684/17525 [2:08:14<1:06:06,  1.72it/s] 61%|██████    | 10685/17525 [2:08:14<1:06:01,  1.73it/s] 61%|██████    | 10686/17525 [2:08:15<1:05:54,  1.73it/s] 61%|██████    | 10687/17525 [2:08:15<1:05:47,  1.73it/s] 61%|██████    | 10688/17525 [2:08:16<1:05:42,  1.73it/s] 61%|██████    | 10689/17525 [2:08:17<1:05:38,  1.74it/s] 61%|██████    | 10690/17525 [2:08:17<1:05:37,  1.74it/s]                                                         {'loss': 0.3705, 'grad_norm': 10.044992446899414, 'learning_rate': 6.6414269469234995e-06, 'epoch': 15.25}
 61%|██████    | 10690/17525 [2:08:17<1:05:37,  1.74it/s] 61%|██████    | 10691/17525 [2:08:18<1:05:36,  1.74it/s] 61%|██████    | 10692/17525 [2:08:18<1:05:30,  1.74it/s] 61%|██████    | 10693/17525 [2:08:19<1:06:28,  1.71it/s] 61%|██████    | 10694/17525 [2:08:20<1:06:13,  1.72it/s] 61%|██████    | 10695/17525 [2:08:20<1:05:58,  1.73it/s] 61%|██████    | 10696/17525 [2:08:21<1:05:53,  1.73it/s] 61%|██████    | 10697/17525 [2:08:22<1:31:53,  1.24it/s] 61%|██████    | 10698/17525 [2:08:23<1:24:44,  1.34it/s] 61%|██████    | 10699/17525 [2:08:23<1:18:53,  1.44it/s] 61%|██████    | 10700/17525 [2:08:24<1:15:08,  1.51it/s]                                                         {'loss': 0.3473, 'grad_norm': 30.42681884765625, 'learning_rate': 6.624528014151701e-06, 'epoch': 15.26}
 61%|██████    | 10700/17525 [2:08:24<1:15:08,  1.51it/s][INFO|trainer.py:3512] 2024-06-25 04:11:45,765 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:11:45,765 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:11:45,765 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.76it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.32it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.57it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.09it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.08it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.55it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.96it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.72it/s][A                                                         
                                               [A{'eval_loss': 1.1054036617279053, 'eval_runtime': 4.6939, 'eval_samples_per_second': 94.377, 'eval_steps_per_second': 4.048, 'epoch': 15.26}
 61%|██████    | 10700/17525 [2:08:29<1:15:08,  1.51it/s]
100%|██████████| 19/19 [00:04<00:00,  3.72it/s][A
                                               [A 61%|██████    | 10701/17525 [2:08:29<3:56:38,  2.08s/it] 61%|██████    | 10702/17525 [2:08:30<3:05:24,  1.63s/it] 61%|██████    | 10703/17525 [2:08:31<2:44:05,  1.44s/it] 61%|██████    | 10704/17525 [2:08:31<2:14:55,  1.19s/it] 61%|██████    | 10705/17525 [2:08:32<1:54:06,  1.00s/it] 61%|██████    | 10706/17525 [2:08:32<1:39:52,  1.14it/s] 61%|██████    | 10707/17525 [2:08:33<1:29:41,  1.27it/s] 61%|██████    | 10708/17525 [2:08:34<1:22:19,  1.38it/s] 61%|██████    | 10709/17525 [2:08:34<1:17:36,  1.46it/s] 61%|██████    | 10710/17525 [2:08:35<1:13:49,  1.54it/s]                                                         {'loss': 0.4199, 'grad_norm': 12.806507110595703, 'learning_rate': 6.607639953391495e-06, 'epoch': 15.28}
 61%|██████    | 10710/17525 [2:08:35<1:13:49,  1.54it/s] 61%|██████    | 10711/17525 [2:08:35<1:11:20,  1.59it/s] 61%|██████    | 10712/17525 [2:08:36<1:09:30,  1.63it/s] 61%|██████    | 10713/17525 [2:08:37<1:08:12,  1.66it/s] 61%|██████    | 10714/17525 [2:08:37<1:07:15,  1.69it/s] 61%|██████    | 10715/17525 [2:08:38<1:06:59,  1.69it/s] 61%|██████    | 10716/17525 [2:08:38<1:06:32,  1.71it/s] 61%|██████    | 10717/17525 [2:08:39<1:06:06,  1.72it/s] 61%|██████    | 10718/17525 [2:08:39<1:05:46,  1.72it/s] 61%|██████    | 10719/17525 [2:08:40<1:05:37,  1.73it/s] 61%|██████    | 10720/17525 [2:08:41<1:05:34,  1.73it/s]                                                         {'loss': 0.4636, 'grad_norm': 10.018242835998535, 'learning_rate': 6.5907628190373994e-06, 'epoch': 15.29}
 61%|██████    | 10720/17525 [2:08:41<1:05:34,  1.73it/s] 61%|██████    | 10721/17525 [2:08:41<1:05:41,  1.73it/s] 61%|██████    | 10722/17525 [2:08:42<1:12:40,  1.56it/s] 61%|██████    | 10723/17525 [2:08:43<1:10:43,  1.60it/s] 61%|██████    | 10724/17525 [2:08:43<1:09:25,  1.63it/s] 61%|██████    | 10725/17525 [2:08:44<1:08:11,  1.66it/s] 61%|██████    | 10726/17525 [2:08:44<1:07:29,  1.68it/s] 61%|██████    | 10727/17525 [2:08:45<1:06:50,  1.70it/s] 61%|██████    | 10728/17525 [2:08:45<1:06:16,  1.71it/s] 61%|██████    | 10729/17525 [2:08:46<1:18:08,  1.45it/s] 61%|██████    | 10730/17525 [2:08:47<1:14:17,  1.52it/s]                                                         {'loss': 0.4044, 'grad_norm': 14.527454376220703, 'learning_rate': 6.573896665448747e-06, 'epoch': 15.31}
 61%|██████    | 10730/17525 [2:08:47<1:14:17,  1.52it/s] 61%|██████    | 10731/17525 [2:08:48<1:11:58,  1.57it/s] 61%|██████    | 10732/17525 [2:08:48<1:11:04,  1.59it/s] 61%|██████    | 10733/17525 [2:08:49<1:21:22,  1.39it/s] 61%|██████    | 10734/17525 [2:08:50<1:16:45,  1.47it/s] 61%|██████▏   | 10735/17525 [2:08:50<1:13:21,  1.54it/s] 61%|██████▏   | 10736/17525 [2:08:51<1:10:52,  1.60it/s] 61%|██████▏   | 10737/17525 [2:08:51<1:09:03,  1.64it/s] 61%|██████▏   | 10738/17525 [2:08:52<1:07:50,  1.67it/s] 61%|██████▏   | 10739/17525 [2:08:53<1:06:53,  1.69it/s] 61%|██████▏   | 10740/17525 [2:08:53<1:07:23,  1.68it/s]                                                         {'loss': 0.3904, 'grad_norm': 5.390201091766357, 'learning_rate': 6.5570415469495e-06, 'epoch': 15.32}
 61%|██████▏   | 10740/17525 [2:08:53<1:07:23,  1.68it/s] 61%|██████▏   | 10741/17525 [2:08:54<1:06:44,  1.69it/s] 61%|██████▏   | 10742/17525 [2:08:54<1:10:39,  1.60it/s] 61%|██████▏   | 10743/17525 [2:08:55<1:08:57,  1.64it/s] 61%|██████▏   | 10744/17525 [2:08:56<1:08:01,  1.66it/s] 61%|██████▏   | 10745/17525 [2:08:56<1:07:10,  1.68it/s] 61%|██████▏   | 10746/17525 [2:08:57<1:06:37,  1.70it/s] 61%|██████▏   | 10747/17525 [2:08:57<1:05:59,  1.71it/s] 61%|██████▏   | 10748/17525 [2:08:58<1:05:40,  1.72it/s] 61%|██████▏   | 10749/17525 [2:08:58<1:05:30,  1.72it/s] 61%|██████▏   | 10750/17525 [2:08:59<1:05:23,  1.73it/s]                                                         {'loss': 0.4165, 'grad_norm': 14.502131462097168, 'learning_rate': 6.54019751782808e-06, 'epoch': 15.34}
 61%|██████▏   | 10750/17525 [2:08:59<1:05:23,  1.73it/s] 61%|██████▏   | 10751/17525 [2:09:00<1:05:23,  1.73it/s] 61%|██████▏   | 10752/17525 [2:09:00<1:05:06,  1.73it/s] 61%|██████▏   | 10753/17525 [2:09:01<1:05:03,  1.73it/s] 61%|██████▏   | 10754/17525 [2:09:01<1:05:08,  1.73it/s] 61%|██████▏   | 10755/17525 [2:09:03<1:26:19,  1.31it/s] 61%|██████▏   | 10756/17525 [2:09:03<1:19:52,  1.41it/s] 61%|██████▏   | 10757/17525 [2:09:04<1:15:10,  1.50it/s] 61%|██████▏   | 10758/17525 [2:09:04<1:12:04,  1.56it/s] 61%|██████▏   | 10759/17525 [2:09:05<1:09:55,  1.61it/s] 61%|██████▏   | 10760/17525 [2:09:05<1:08:32,  1.64it/s]                                                         {'loss': 0.3984, 'grad_norm': 10.360816955566406, 'learning_rate': 6.523364632337193e-06, 'epoch': 15.35}
 61%|██████▏   | 10760/17525 [2:09:05<1:08:32,  1.64it/s] 61%|██████▏   | 10761/17525 [2:09:06<1:07:36,  1.67it/s] 61%|██████▏   | 10762/17525 [2:09:07<1:06:47,  1.69it/s] 61%|██████▏   | 10763/17525 [2:09:07<1:06:07,  1.70it/s] 61%|██████▏   | 10764/17525 [2:09:08<1:05:39,  1.72it/s] 61%|██████▏   | 10765/17525 [2:09:08<1:05:24,  1.72it/s] 61%|██████▏   | 10766/17525 [2:09:09<1:05:10,  1.73it/s] 61%|██████▏   | 10767/17525 [2:09:09<1:05:06,  1.73it/s] 61%|██████▏   | 10768/17525 [2:09:10<1:05:00,  1.73it/s] 61%|██████▏   | 10769/17525 [2:09:11<1:04:49,  1.74it/s] 61%|██████▏   | 10770/17525 [2:09:11<1:04:47,  1.74it/s]                                                         {'loss': 0.4285, 'grad_norm': 9.759902000427246, 'learning_rate': 6.506542944693648e-06, 'epoch': 15.36}
 61%|██████▏   | 10770/17525 [2:09:11<1:04:47,  1.74it/s] 61%|██████▏   | 10771/17525 [2:09:12<1:04:53,  1.73it/s] 61%|██████▏   | 10772/17525 [2:09:12<1:04:54,  1.73it/s] 61%|██████▏   | 10773/17525 [2:09:13<1:04:45,  1.74it/s] 61%|██████▏   | 10774/17525 [2:09:13<1:04:46,  1.74it/s] 61%|██████▏   | 10775/17525 [2:09:14<1:04:39,  1.74it/s] 61%|██████▏   | 10776/17525 [2:09:15<1:04:40,  1.74it/s] 61%|██████▏   | 10777/17525 [2:09:15<1:04:35,  1.74it/s] 62%|██████▏   | 10778/17525 [2:09:16<1:04:36,  1.74it/s] 62%|██████▏   | 10779/17525 [2:09:16<1:04:28,  1.74it/s] 62%|██████▏   | 10780/17525 [2:09:17<1:04:28,  1.74it/s]                                                         {'loss': 0.4229, 'grad_norm': 11.236956596374512, 'learning_rate': 6.489732509078184e-06, 'epoch': 15.38}
 62%|██████▏   | 10780/17525 [2:09:17<1:04:28,  1.74it/s] 62%|██████▏   | 10781/17525 [2:09:17<1:04:37,  1.74it/s] 62%|██████▏   | 10782/17525 [2:09:18<1:04:32,  1.74it/s] 62%|██████▏   | 10783/17525 [2:09:19<1:04:37,  1.74it/s] 62%|██████▏   | 10784/17525 [2:09:19<1:04:44,  1.74it/s] 62%|██████▏   | 10785/17525 [2:09:20<1:04:39,  1.74it/s] 62%|██████▏   | 10786/17525 [2:09:20<1:04:44,  1.73it/s] 62%|██████▏   | 10787/17525 [2:09:21<1:04:48,  1.73it/s] 62%|██████▏   | 10788/17525 [2:09:22<1:05:29,  1.71it/s] 62%|██████▏   | 10789/17525 [2:09:22<1:05:23,  1.72it/s] 62%|██████▏   | 10790/17525 [2:09:23<1:05:09,  1.72it/s]                                                         {'loss': 0.3836, 'grad_norm': 25.273548126220703, 'learning_rate': 6.472933379635313e-06, 'epoch': 15.39}
 62%|██████▏   | 10790/17525 [2:09:23<1:05:09,  1.72it/s] 62%|██████▏   | 10791/17525 [2:09:23<1:04:57,  1.73it/s] 62%|██████▏   | 10792/17525 [2:09:24<1:04:45,  1.73it/s] 62%|██████▏   | 10793/17525 [2:09:24<1:04:43,  1.73it/s] 62%|██████▏   | 10794/17525 [2:09:25<1:04:34,  1.74it/s] 62%|██████▏   | 10795/17525 [2:09:26<1:30:34,  1.24it/s] 62%|██████▏   | 10796/17525 [2:09:27<1:22:46,  1.35it/s] 62%|██████▏   | 10797/17525 [2:09:27<1:17:21,  1.45it/s] 62%|██████▏   | 10798/17525 [2:09:28<1:13:28,  1.53it/s] 62%|██████▏   | 10799/17525 [2:09:29<1:10:49,  1.58it/s] 62%|██████▏   | 10800/17525 [2:09:30<1:21:09,  1.38it/s]                                                         {'loss': 0.3839, 'grad_norm': 7.219038963317871, 'learning_rate': 6.45614561047311e-06, 'epoch': 15.41}
 62%|██████▏   | 10800/17525 [2:09:30<1:21:09,  1.38it/s][INFO|trainer.py:3512] 2024-06-25 04:12:51,479 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:12:51,480 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:12:51,480 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.76it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0702980756759644, 'eval_runtime': 4.6057, 'eval_samples_per_second': 96.185, 'eval_steps_per_second': 4.125, 'epoch': 15.41}
 62%|██████▏   | 10800/17525 [2:09:34<1:21:09,  1.38it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:12:56,089 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b49790>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: eb4c8d65-95d6-4155-8ec1-354b837606d4)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:13:06,355 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:13:06,357 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 62%|██████▏   | 10801/17525 [2:09:45<9:41:35,  5.19s/it] 62%|██████▏   | 10802/17525 [2:09:46<7:06:32,  3.81s/it] 62%|██████▏   | 10803/17525 [2:09:47<5:52:09,  3.14s/it] 62%|██████▏   | 10804/17525 [2:09:48<4:25:50,  2.37s/it] 62%|██████▏   | 10805/17525 [2:09:49<3:25:29,  1.83s/it] 62%|██████▏   | 10806/17525 [2:09:49<2:43:07,  1.46s/it] 62%|██████▏   | 10807/17525 [2:09:50<2:13:37,  1.19s/it] 62%|██████▏   | 10808/17525 [2:09:50<1:52:54,  1.01s/it] 62%|██████▏   | 10809/17525 [2:09:51<1:38:16,  1.14it/s] 62%|██████▏   | 10810/17525 [2:09:52<1:34:17,  1.19it/s]                                                         {'loss': 0.3997, 'grad_norm': 17.523096084594727, 'learning_rate': 6.439369255663084e-06, 'epoch': 15.42}
 62%|██████▏   | 10810/17525 [2:09:52<1:34:17,  1.19it/s] 62%|██████▏   | 10811/17525 [2:09:52<1:25:27,  1.31it/s] 62%|██████▏   | 10812/17525 [2:09:53<1:19:07,  1.41it/s] 62%|██████▏   | 10813/17525 [2:09:53<1:14:40,  1.50it/s] 62%|██████▏   | 10814/17525 [2:09:54<1:11:34,  1.56it/s] 62%|██████▏   | 10815/17525 [2:09:54<1:09:28,  1.61it/s] 62%|██████▏   | 10816/17525 [2:09:55<1:07:56,  1.65it/s] 62%|██████▏   | 10817/17525 [2:09:56<1:06:54,  1.67it/s] 62%|██████▏   | 10818/17525 [2:09:56<1:06:05,  1.69it/s] 62%|██████▏   | 10819/17525 [2:09:57<1:05:34,  1.70it/s] 62%|██████▏   | 10820/17525 [2:09:57<1:05:16,  1.71it/s]                                                         {'loss': 0.3203, 'grad_norm': 8.329092979431152, 'learning_rate': 6.422604369239958e-06, 'epoch': 15.44}
 62%|██████▏   | 10820/17525 [2:09:57<1:05:16,  1.71it/s] 62%|██████▏   | 10821/17525 [2:09:58<1:05:13,  1.71it/s] 62%|██████▏   | 10822/17525 [2:09:59<1:05:09,  1.71it/s] 62%|██████▏   | 10823/17525 [2:09:59<1:05:08,  1.71it/s] 62%|██████▏   | 10824/17525 [2:10:00<1:05:09,  1.71it/s] 62%|██████▏   | 10825/17525 [2:10:00<1:05:15,  1.71it/s] 62%|██████▏   | 10826/17525 [2:10:01<1:05:14,  1.71it/s] 62%|██████▏   | 10827/17525 [2:10:01<1:04:57,  1.72it/s] 62%|██████▏   | 10828/17525 [2:10:02<1:04:42,  1.72it/s] 62%|██████▏   | 10829/17525 [2:10:03<1:04:35,  1.73it/s] 62%|██████▏   | 10830/17525 [2:10:03<1:04:35,  1.73it/s]                                                         {'loss': 0.4544, 'grad_norm': 14.562475204467773, 'learning_rate': 6.405851005201524e-06, 'epoch': 15.45}
 62%|██████▏   | 10830/17525 [2:10:03<1:04:35,  1.73it/s] 62%|██████▏   | 10831/17525 [2:10:04<1:04:34,  1.73it/s] 62%|██████▏   | 10832/17525 [2:10:04<1:04:32,  1.73it/s] 62%|██████▏   | 10833/17525 [2:10:05<1:04:26,  1.73it/s] 62%|██████▏   | 10834/17525 [2:10:05<1:04:23,  1.73it/s] 62%|██████▏   | 10835/17525 [2:10:06<1:04:23,  1.73it/s] 62%|██████▏   | 10836/17525 [2:10:07<1:04:13,  1.74it/s] 62%|██████▏   | 10837/17525 [2:10:07<1:04:08,  1.74it/s] 62%|██████▏   | 10838/17525 [2:10:08<1:04:04,  1.74it/s] 62%|██████▏   | 10839/17525 [2:10:08<1:04:06,  1.74it/s] 62%|██████▏   | 10840/17525 [2:10:09<1:04:03,  1.74it/s]                                                         {'loss': 0.3847, 'grad_norm': 25.4328670501709, 'learning_rate': 6.390782873805128e-06, 'epoch': 15.46}
 62%|██████▏   | 10840/17525 [2:10:09<1:04:03,  1.74it/s] 62%|██████▏   | 10841/17525 [2:10:09<1:04:07,  1.74it/s] 62%|██████▏   | 10842/17525 [2:10:11<1:20:10,  1.39it/s] 62%|██████▏   | 10843/17525 [2:10:11<1:15:20,  1.48it/s] 62%|██████▏   | 10844/17525 [2:10:12<1:22:11,  1.35it/s] 62%|██████▏   | 10845/17525 [2:10:13<1:17:14,  1.44it/s] 62%|██████▏   | 10846/17525 [2:10:13<1:13:37,  1.51it/s] 62%|██████▏   | 10847/17525 [2:10:14<1:10:57,  1.57it/s] 62%|██████▏   | 10848/17525 [2:10:14<1:08:51,  1.62it/s] 62%|██████▏   | 10849/17525 [2:10:15<1:07:20,  1.65it/s] 62%|██████▏   | 10850/17525 [2:10:15<1:06:18,  1.68it/s]                                                         {'loss': 0.4148, 'grad_norm': 14.27526569366455, 'learning_rate': 6.3740515509284806e-06, 'epoch': 15.48}
 62%|██████▏   | 10850/17525 [2:10:15<1:06:18,  1.68it/s] 62%|██████▏   | 10851/17525 [2:10:16<1:05:37,  1.69it/s] 62%|██████▏   | 10852/17525 [2:10:17<1:05:04,  1.71it/s] 62%|██████▏   | 10853/17525 [2:10:17<1:04:40,  1.72it/s] 62%|██████▏   | 10854/17525 [2:10:18<1:04:33,  1.72it/s] 62%|██████▏   | 10855/17525 [2:10:18<1:04:20,  1.73it/s] 62%|██████▏   | 10856/17525 [2:10:19<1:04:32,  1.72it/s] 62%|██████▏   | 10857/17525 [2:10:20<1:08:30,  1.62it/s] 62%|██████▏   | 10858/17525 [2:10:21<1:19:02,  1.41it/s] 62%|██████▏   | 10859/17525 [2:10:21<1:14:36,  1.49it/s] 62%|██████▏   | 10860/17525 [2:10:22<1:11:31,  1.55it/s]                                                         {'loss': 0.4132, 'grad_norm': 7.544606685638428, 'learning_rate': 6.357331906819641e-06, 'epoch': 15.49}
 62%|██████▏   | 10860/17525 [2:10:22<1:11:31,  1.55it/s] 62%|██████▏   | 10861/17525 [2:10:22<1:09:13,  1.60it/s] 62%|██████▏   | 10862/17525 [2:10:23<1:07:32,  1.64it/s] 62%|██████▏   | 10863/17525 [2:10:23<1:06:16,  1.68it/s] 62%|██████▏   | 10864/17525 [2:10:24<1:05:22,  1.70it/s] 62%|██████▏   | 10865/17525 [2:10:25<1:15:42,  1.47it/s] 62%|██████▏   | 10866/17525 [2:10:25<1:12:07,  1.54it/s] 62%|██████▏   | 10867/17525 [2:10:26<1:09:44,  1.59it/s] 62%|██████▏   | 10868/17525 [2:10:27<1:07:55,  1.63it/s] 62%|██████▏   | 10869/17525 [2:10:27<1:06:36,  1.67it/s] 62%|██████▏   | 10870/17525 [2:10:28<1:06:00,  1.68it/s]                                                         {'loss': 0.4198, 'grad_norm': 27.854162216186523, 'learning_rate': 6.340623995330677e-06, 'epoch': 15.51}
 62%|██████▏   | 10870/17525 [2:10:28<1:06:00,  1.68it/s] 62%|██████▏   | 10871/17525 [2:10:28<1:05:36,  1.69it/s] 62%|██████▏   | 10872/17525 [2:10:29<1:05:04,  1.70it/s] 62%|██████▏   | 10873/17525 [2:10:30<1:04:30,  1.72it/s] 62%|██████▏   | 10874/17525 [2:10:30<1:04:15,  1.73it/s] 62%|██████▏   | 10875/17525 [2:10:31<1:04:11,  1.73it/s] 62%|██████▏   | 10876/17525 [2:10:31<1:04:05,  1.73it/s] 62%|██████▏   | 10877/17525 [2:10:32<1:03:55,  1.73it/s] 62%|██████▏   | 10878/17525 [2:10:33<1:19:54,  1.39it/s] 62%|██████▏   | 10879/17525 [2:10:33<1:15:03,  1.48it/s] 62%|██████▏   | 10880/17525 [2:10:34<1:11:36,  1.55it/s]                                                         {'loss': 0.3868, 'grad_norm': 19.50021743774414, 'learning_rate': 6.323927870275879e-06, 'epoch': 15.52}
 62%|██████▏   | 10880/17525 [2:10:34<1:11:36,  1.55it/s] 62%|██████▏   | 10881/17525 [2:10:35<1:10:13,  1.58it/s] 62%|██████▏   | 10882/17525 [2:10:35<1:08:19,  1.62it/s] 62%|██████▏   | 10883/17525 [2:10:36<1:07:01,  1.65it/s] 62%|██████▏   | 10884/17525 [2:10:36<1:06:00,  1.68it/s] 62%|██████▏   | 10885/17525 [2:10:37<1:05:24,  1.69it/s] 62%|██████▏   | 10886/17525 [2:10:38<1:05:04,  1.70it/s] 62%|██████▏   | 10887/17525 [2:10:38<1:04:42,  1.71it/s] 62%|██████▏   | 10888/17525 [2:10:39<1:04:24,  1.72it/s] 62%|██████▏   | 10889/17525 [2:10:39<1:04:12,  1.72it/s] 62%|██████▏   | 10890/17525 [2:10:40<1:04:04,  1.73it/s]                                                         {'loss': 0.3345, 'grad_norm': 7.0905022621154785, 'learning_rate': 6.307243585431563e-06, 'epoch': 15.53}
 62%|██████▏   | 10890/17525 [2:10:40<1:04:04,  1.73it/s] 62%|██████▏   | 10891/17525 [2:10:40<1:04:01,  1.73it/s] 62%|██████▏   | 10892/17525 [2:10:41<1:03:48,  1.73it/s] 62%|██████▏   | 10893/17525 [2:10:42<1:03:41,  1.74it/s] 62%|██████▏   | 10894/17525 [2:10:42<1:03:42,  1.73it/s] 62%|██████▏   | 10895/17525 [2:10:43<1:03:47,  1.73it/s] 62%|██████▏   | 10896/17525 [2:10:43<1:03:45,  1.73it/s] 62%|██████▏   | 10897/17525 [2:10:44<1:03:32,  1.74it/s] 62%|██████▏   | 10898/17525 [2:10:44<1:03:31,  1.74it/s] 62%|██████▏   | 10899/17525 [2:10:45<1:03:28,  1.74it/s] 62%|██████▏   | 10900/17525 [2:10:46<1:03:27,  1.74it/s]                                                         {'loss': 0.4971, 'grad_norm': 17.871131896972656, 'learning_rate': 6.2905711945359125e-06, 'epoch': 15.55}
 62%|██████▏   | 10900/17525 [2:10:46<1:03:27,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:14:07,488 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:14:07,488 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:14:07,488 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0878316164016724, 'eval_runtime': 4.6022, 'eval_samples_per_second': 96.259, 'eval_steps_per_second': 4.129, 'epoch': 15.55}
 62%|██████▏   | 10900/17525 [2:10:50<1:03:27,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 62%|██████▏   | 10901/17525 [2:10:51<3:36:05,  1.96s/it] 62%|██████▏   | 10902/17525 [2:10:51<2:50:18,  1.54s/it] 62%|██████▏   | 10903/17525 [2:10:52<2:18:22,  1.25s/it] 62%|██████▏   | 10904/17525 [2:10:53<1:55:58,  1.05s/it] 62%|██████▏   | 10905/17525 [2:10:53<1:40:19,  1.10it/s] 62%|██████▏   | 10906/17525 [2:10:54<1:29:11,  1.24it/s] 62%|██████▏   | 10907/17525 [2:10:54<1:26:26,  1.28it/s] 62%|██████▏   | 10908/17525 [2:10:55<1:19:41,  1.38it/s] 62%|██████▏   | 10909/17525 [2:10:56<1:14:50,  1.47it/s] 62%|██████▏   | 10910/17525 [2:10:56<1:11:34,  1.54it/s]                                                         {'loss': 0.3501, 'grad_norm': 14.060249328613281, 'learning_rate': 6.273910751288807e-06, 'epoch': 15.56}
 62%|██████▏   | 10910/17525 [2:10:56<1:11:34,  1.54it/s] 62%|██████▏   | 10911/17525 [2:10:57<1:09:17,  1.59it/s] 62%|██████▏   | 10912/17525 [2:10:57<1:07:36,  1.63it/s] 62%|██████▏   | 10913/17525 [2:10:58<1:06:27,  1.66it/s] 62%|██████▏   | 10914/17525 [2:10:58<1:05:33,  1.68it/s] 62%|██████▏   | 10915/17525 [2:10:59<1:04:47,  1.70it/s] 62%|██████▏   | 10916/17525 [2:11:00<1:04:16,  1.71it/s] 62%|██████▏   | 10917/17525 [2:11:00<1:03:59,  1.72it/s] 62%|██████▏   | 10918/17525 [2:11:01<1:03:57,  1.72it/s] 62%|██████▏   | 10919/17525 [2:11:01<1:03:45,  1.73it/s] 62%|██████▏   | 10920/17525 [2:11:02<1:03:43,  1.73it/s]                                                         {'loss': 0.4386, 'grad_norm': 12.137064933776855, 'learning_rate': 6.257262309351637e-06, 'epoch': 15.58}
 62%|██████▏   | 10920/17525 [2:11:02<1:03:43,  1.73it/s] 62%|██████▏   | 10921/17525 [2:11:02<1:03:42,  1.73it/s] 62%|██████▏   | 10922/17525 [2:11:03<1:03:26,  1.73it/s] 62%|██████▏   | 10923/17525 [2:11:04<1:03:27,  1.73it/s] 62%|██████▏   | 10924/17525 [2:11:04<1:03:17,  1.74it/s] 62%|██████▏   | 10925/17525 [2:11:05<1:03:22,  1.74it/s] 62%|██████▏   | 10926/17525 [2:11:05<1:03:25,  1.73it/s] 62%|██████▏   | 10927/17525 [2:11:06<1:03:25,  1.73it/s] 62%|██████▏   | 10928/17525 [2:11:06<1:03:26,  1.73it/s] 62%|██████▏   | 10929/17525 [2:11:07<1:04:28,  1.70it/s] 62%|██████▏   | 10930/17525 [2:11:08<1:04:08,  1.71it/s]                                                         {'loss': 0.3703, 'grad_norm': 6.833255290985107, 'learning_rate': 6.240625922347148e-06, 'epoch': 15.59}
 62%|██████▏   | 10930/17525 [2:11:08<1:04:08,  1.71it/s] 62%|██████▏   | 10931/17525 [2:11:08<1:03:56,  1.72it/s] 62%|██████▏   | 10932/17525 [2:11:09<1:03:44,  1.72it/s] 62%|██████▏   | 10933/17525 [2:11:09<1:03:22,  1.73it/s] 62%|██████▏   | 10934/17525 [2:11:10<1:03:12,  1.74it/s] 62%|██████▏   | 10935/17525 [2:11:11<1:03:04,  1.74it/s] 62%|██████▏   | 10936/17525 [2:11:11<1:03:01,  1.74it/s] 62%|██████▏   | 10937/17525 [2:11:12<1:03:01,  1.74it/s] 62%|██████▏   | 10938/17525 [2:11:12<1:03:09,  1.74it/s] 62%|██████▏   | 10939/17525 [2:11:13<1:03:14,  1.74it/s] 62%|██████▏   | 10940/17525 [2:11:13<1:03:16,  1.73it/s]                                                         {'loss': 0.3901, 'grad_norm': 5.971122741699219, 'learning_rate': 6.224001643859247e-06, 'epoch': 15.61}
 62%|██████▏   | 10940/17525 [2:11:13<1:03:16,  1.73it/s] 62%|██████▏   | 10941/17525 [2:11:14<1:03:13,  1.74it/s] 62%|██████▏   | 10942/17525 [2:11:15<1:03:18,  1.73it/s] 62%|██████▏   | 10943/17525 [2:11:15<1:03:24,  1.73it/s] 62%|██████▏   | 10944/17525 [2:11:16<1:03:15,  1.73it/s] 62%|██████▏   | 10945/17525 [2:11:16<1:03:08,  1.74it/s] 62%|██████▏   | 10946/17525 [2:11:17<1:03:07,  1.74it/s] 62%|██████▏   | 10947/17525 [2:11:17<1:03:04,  1.74it/s] 62%|██████▏   | 10948/17525 [2:11:18<1:02:58,  1.74it/s] 62%|██████▏   | 10949/17525 [2:11:19<1:03:01,  1.74it/s] 62%|██████▏   | 10950/17525 [2:11:19<1:02:52,  1.74it/s]                                                         {'loss': 0.3725, 'grad_norm': 6.802760601043701, 'learning_rate': 6.207389527432841e-06, 'epoch': 15.62}
 62%|██████▏   | 10950/17525 [2:11:19<1:02:52,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 04:14:41,081 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b85990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4014e46f-2f66-4d20-9161-087829804f60)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:14:51,294 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:14:51,296 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-10950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 62%|██████▏   | 10951/17525 [2:11:30<6:49:03,  3.73s/it] 62%|██████▏   | 10952/17525 [2:11:31<5:06:43,  2.80s/it] 62%|██████▏   | 10953/17525 [2:11:32<3:54:43,  2.14s/it] 63%|██████▎   | 10954/17525 [2:11:32<3:03:13,  1.67s/it] 63%|██████▎   | 10955/17525 [2:11:33<2:27:59,  1.35s/it] 63%|██████▎   | 10956/17525 [2:11:33<2:03:29,  1.13s/it] 63%|██████▎   | 10957/17525 [2:11:34<1:57:08,  1.07s/it] 63%|██████▎   | 10958/17525 [2:11:35<1:41:02,  1.08it/s] 63%|██████▎   | 10959/17525 [2:11:35<1:29:34,  1.22it/s] 63%|██████▎   | 10960/17525 [2:11:36<1:21:40,  1.34it/s]                                                         {'loss': 0.4317, 'grad_norm': 11.435881614685059, 'learning_rate': 6.190789626573679e-06, 'epoch': 15.63}
 63%|██████▎   | 10960/17525 [2:11:36<1:21:40,  1.34it/s] 63%|██████▎   | 10961/17525 [2:11:37<1:16:16,  1.43it/s] 63%|██████▎   | 10962/17525 [2:11:37<1:12:31,  1.51it/s] 63%|██████▎   | 10963/17525 [2:11:38<1:13:14,  1.49it/s] 63%|██████▎   | 10964/17525 [2:11:38<1:09:59,  1.56it/s] 63%|██████▎   | 10965/17525 [2:11:39<1:08:16,  1.60it/s] 63%|██████▎   | 10966/17525 [2:11:40<1:06:33,  1.64it/s] 63%|██████▎   | 10967/17525 [2:11:40<1:05:40,  1.66it/s] 63%|██████▎   | 10968/17525 [2:11:41<1:04:48,  1.69it/s] 63%|██████▎   | 10969/17525 [2:11:41<1:04:08,  1.70it/s] 63%|██████▎   | 10970/17525 [2:11:42<1:04:44,  1.69it/s]                                                         {'loss': 0.4078, 'grad_norm': 9.585143089294434, 'learning_rate': 6.174201994748146e-06, 'epoch': 15.65}
 63%|██████▎   | 10970/17525 [2:11:42<1:04:44,  1.69it/s] 63%|██████▎   | 10971/17525 [2:11:42<1:04:18,  1.70it/s] 63%|██████▎   | 10972/17525 [2:11:43<1:03:56,  1.71it/s] 63%|██████▎   | 10973/17525 [2:11:44<1:03:33,  1.72it/s] 63%|██████▎   | 10974/17525 [2:11:44<1:03:17,  1.73it/s] 63%|██████▎   | 10975/17525 [2:11:45<1:03:03,  1.73it/s] 63%|██████▎   | 10976/17525 [2:11:45<1:03:34,  1.72it/s] 63%|██████▎   | 10977/17525 [2:11:46<1:03:08,  1.73it/s] 63%|██████▎   | 10978/17525 [2:11:47<1:03:02,  1.73it/s] 63%|██████▎   | 10979/17525 [2:11:47<1:02:54,  1.73it/s] 63%|██████▎   | 10980/17525 [2:11:48<1:03:30,  1.72it/s]                                                         {'loss': 0.2957, 'grad_norm': 7.057013034820557, 'learning_rate': 6.1576266853831234e-06, 'epoch': 15.66}
 63%|██████▎   | 10980/17525 [2:11:48<1:03:30,  1.72it/s] 63%|██████▎   | 10981/17525 [2:11:48<1:08:13,  1.60it/s] 63%|██████▎   | 10982/17525 [2:11:49<1:06:36,  1.64it/s] 63%|██████▎   | 10983/17525 [2:11:50<1:05:20,  1.67it/s] 63%|██████▎   | 10984/17525 [2:11:50<1:04:25,  1.69it/s] 63%|██████▎   | 10985/17525 [2:11:51<1:04:05,  1.70it/s] 63%|██████▎   | 10986/17525 [2:11:51<1:03:39,  1.71it/s] 63%|██████▎   | 10987/17525 [2:11:52<1:03:18,  1.72it/s] 63%|██████▎   | 10988/17525 [2:11:52<1:03:10,  1.72it/s] 63%|██████▎   | 10989/17525 [2:11:53<1:03:15,  1.72it/s] 63%|██████▎   | 10990/17525 [2:11:54<1:29:02,  1.22it/s]                                                         {'loss': 0.3931, 'grad_norm': 10.08238410949707, 'learning_rate': 6.141063751865799e-06, 'epoch': 15.68}
 63%|██████▎   | 10990/17525 [2:11:54<1:29:02,  1.22it/s] 63%|██████▎   | 10991/17525 [2:11:56<1:46:32,  1.02it/s] 63%|██████▎   | 10992/17525 [2:11:56<1:33:41,  1.16it/s] 63%|██████▎   | 10993/17525 [2:11:57<1:24:20,  1.29it/s] 63%|██████▎   | 10994/17525 [2:11:57<1:17:47,  1.40it/s] 63%|██████▎   | 10995/17525 [2:11:58<1:13:37,  1.48it/s] 63%|██████▎   | 10996/17525 [2:11:59<1:10:19,  1.55it/s] 63%|██████▎   | 10997/17525 [2:11:59<1:07:53,  1.60it/s] 63%|██████▎   | 10998/17525 [2:12:00<1:06:25,  1.64it/s] 63%|██████▎   | 10999/17525 [2:12:00<1:05:25,  1.66it/s] 63%|██████▎   | 11000/17525 [2:12:01<1:04:31,  1.69it/s]                                                         {'loss': 0.3804, 'grad_norm': 20.72783088684082, 'learning_rate': 6.1245132475434935e-06, 'epoch': 15.69}
 63%|██████▎   | 11000/17525 [2:12:01<1:04:31,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 04:15:22,839 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:15:22,840 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:15:22,840 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.67it/s][A
 21%|██        | 4/19 [00:00<00:03,  3.98it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.34it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.60it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.18it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.1009714603424072, 'eval_runtime': 4.6478, 'eval_samples_per_second': 95.315, 'eval_steps_per_second': 4.088, 'epoch': 15.69}
 63%|██████▎   | 11000/17525 [2:12:06<1:04:31,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 63%|██████▎   | 11001/17525 [2:12:06<3:35:40,  1.98s/it] 63%|██████▎   | 11002/17525 [2:12:07<2:49:43,  1.56s/it] 63%|██████▎   | 11003/17525 [2:12:07<2:17:38,  1.27s/it] 63%|██████▎   | 11004/17525 [2:12:08<1:55:01,  1.06s/it] 63%|██████▎   | 11005/17525 [2:12:08<1:39:16,  1.09it/s] 63%|██████▎   | 11006/17525 [2:12:09<1:28:08,  1.23it/s] 63%|██████▎   | 11007/17525 [2:12:10<1:20:24,  1.35it/s] 63%|██████▎   | 11008/17525 [2:12:10<1:21:00,  1.34it/s] 63%|██████▎   | 11009/17525 [2:12:11<1:15:20,  1.44it/s] 63%|██████▎   | 11010/17525 [2:12:12<1:11:20,  1.52it/s]                                                         {'loss': 0.3222, 'grad_norm': 25.402528762817383, 'learning_rate': 6.107975225723506e-06, 'epoch': 15.71}
 63%|██████▎   | 11010/17525 [2:12:12<1:11:20,  1.52it/s] 63%|██████▎   | 11011/17525 [2:12:12<1:11:56,  1.51it/s] 63%|██████▎   | 11012/17525 [2:12:13<1:10:39,  1.54it/s] 63%|██████▎   | 11013/17525 [2:12:13<1:08:22,  1.59it/s] 63%|██████▎   | 11014/17525 [2:12:14<1:11:22,  1.52it/s] 63%|██████▎   | 11015/17525 [2:12:15<1:09:20,  1.56it/s] 63%|██████▎   | 11016/17525 [2:12:15<1:07:27,  1.61it/s] 63%|██████▎   | 11017/17525 [2:12:16<1:07:03,  1.62it/s] 63%|██████▎   | 11018/17525 [2:12:16<1:05:37,  1.65it/s] 63%|██████▎   | 11019/17525 [2:12:17<1:04:42,  1.68it/s] 63%|██████▎   | 11020/17525 [2:12:18<1:04:27,  1.68it/s]                                                         {'loss': 0.3733, 'grad_norm': 16.67759132385254, 'learning_rate': 6.0914497396729236e-06, 'epoch': 15.72}
 63%|██████▎   | 11020/17525 [2:12:18<1:04:27,  1.68it/s] 63%|██████▎   | 11021/17525 [2:12:18<1:03:51,  1.70it/s] 63%|██████▎   | 11022/17525 [2:12:19<1:04:05,  1.69it/s] 63%|██████▎   | 11023/17525 [2:12:20<1:18:11,  1.39it/s] 63%|██████▎   | 11024/17525 [2:12:20<1:13:28,  1.47it/s] 63%|██████▎   | 11025/17525 [2:12:21<1:10:08,  1.54it/s] 63%|██████▎   | 11026/17525 [2:12:22<1:08:25,  1.58it/s] 63%|██████▎   | 11027/17525 [2:12:22<1:07:01,  1.62it/s] 63%|██████▎   | 11028/17525 [2:12:23<1:06:01,  1.64it/s] 63%|██████▎   | 11029/17525 [2:12:23<1:05:09,  1.66it/s] 63%|██████▎   | 11030/17525 [2:12:24<1:04:20,  1.68it/s]                                                         {'loss': 0.4687, 'grad_norm': 10.028447151184082, 'learning_rate': 6.074936842618457e-06, 'epoch': 15.73}
 63%|██████▎   | 11030/17525 [2:12:24<1:04:20,  1.68it/s] 63%|██████▎   | 11031/17525 [2:12:25<1:03:40,  1.70it/s] 63%|██████▎   | 11032/17525 [2:12:25<1:03:27,  1.71it/s] 63%|██████▎   | 11033/17525 [2:12:26<1:03:28,  1.70it/s] 63%|██████▎   | 11034/17525 [2:12:26<1:03:05,  1.71it/s] 63%|██████▎   | 11035/17525 [2:12:27<1:09:07,  1.56it/s] 63%|██████▎   | 11036/17525 [2:12:28<1:07:18,  1.61it/s] 63%|██████▎   | 11037/17525 [2:12:28<1:05:54,  1.64it/s] 63%|██████▎   | 11038/17525 [2:12:29<1:04:47,  1.67it/s] 63%|██████▎   | 11039/17525 [2:12:29<1:04:38,  1.67it/s] 63%|██████▎   | 11040/17525 [2:12:30<1:03:50,  1.69it/s]                                                         {'loss': 0.3918, 'grad_norm': 7.733761787414551, 'learning_rate': 6.05843658774627e-06, 'epoch': 15.75}
 63%|██████▎   | 11040/17525 [2:12:30<1:03:50,  1.69it/s] 63%|██████▎   | 11041/17525 [2:12:31<1:04:00,  1.69it/s] 63%|██████▎   | 11042/17525 [2:12:31<1:03:29,  1.70it/s] 63%|██████▎   | 11043/17525 [2:12:32<1:03:08,  1.71it/s] 63%|██████▎   | 11044/17525 [2:12:32<1:02:48,  1.72it/s] 63%|██████▎   | 11045/17525 [2:12:33<1:03:01,  1.71it/s] 63%|██████▎   | 11046/17525 [2:12:33<1:02:46,  1.72it/s] 63%|██████▎   | 11047/17525 [2:12:34<1:02:58,  1.71it/s] 63%|██████▎   | 11048/17525 [2:12:35<1:03:13,  1.71it/s] 63%|██████▎   | 11049/17525 [2:12:35<1:02:50,  1.72it/s] 63%|██████▎   | 11050/17525 [2:12:36<1:02:35,  1.72it/s]                                                         {'loss': 0.4452, 'grad_norm': 10.56912899017334, 'learning_rate': 6.04194902820181e-06, 'epoch': 15.76}
 63%|██████▎   | 11050/17525 [2:12:36<1:02:35,  1.72it/s] 63%|██████▎   | 11051/17525 [2:12:36<1:02:42,  1.72it/s] 63%|██████▎   | 11052/17525 [2:12:37<1:02:29,  1.73it/s] 63%|██████▎   | 11053/17525 [2:12:38<1:03:07,  1.71it/s] 63%|██████▎   | 11054/17525 [2:12:38<1:03:37,  1.70it/s] 63%|██████▎   | 11055/17525 [2:12:39<1:03:48,  1.69it/s] 63%|██████▎   | 11056/17525 [2:12:39<1:03:07,  1.71it/s] 63%|██████▎   | 11057/17525 [2:12:40<1:02:52,  1.71it/s] 63%|██████▎   | 11058/17525 [2:12:40<1:03:11,  1.71it/s] 63%|██████▎   | 11059/17525 [2:12:41<1:03:09,  1.71it/s] 63%|██████▎   | 11060/17525 [2:12:42<1:02:49,  1.72it/s]                                                         {'loss': 0.4589, 'grad_norm': 11.081841468811035, 'learning_rate': 6.025474217089634e-06, 'epoch': 15.78}
 63%|██████▎   | 11060/17525 [2:12:42<1:02:49,  1.72it/s] 63%|██████▎   | 11061/17525 [2:12:42<1:02:35,  1.72it/s] 63%|██████▎   | 11062/17525 [2:12:43<1:03:36,  1.69it/s] 63%|██████▎   | 11063/17525 [2:12:43<1:03:28,  1.70it/s] 63%|██████▎   | 11064/17525 [2:12:44<1:08:49,  1.56it/s] 63%|██████▎   | 11065/17525 [2:12:45<1:13:17,  1.47it/s] 63%|██████▎   | 11066/17525 [2:12:46<1:10:20,  1.53it/s] 63%|██████▎   | 11067/17525 [2:12:46<1:07:49,  1.59it/s] 63%|██████▎   | 11068/17525 [2:12:47<1:06:10,  1.63it/s] 63%|██████▎   | 11069/17525 [2:12:47<1:05:20,  1.65it/s] 63%|██████▎   | 11070/17525 [2:12:48<1:04:26,  1.67it/s]                                                         {'loss': 0.4076, 'grad_norm': 11.163582801818848, 'learning_rate': 6.009012207473228e-06, 'epoch': 15.79}
 63%|██████▎   | 11070/17525 [2:12:48<1:04:26,  1.67it/s] 63%|██████▎   | 11071/17525 [2:12:48<1:03:42,  1.69it/s] 63%|██████▎   | 11072/17525 [2:12:49<1:04:07,  1.68it/s] 63%|██████▎   | 11073/17525 [2:12:50<1:03:22,  1.70it/s] 63%|██████▎   | 11074/17525 [2:12:50<1:02:52,  1.71it/s] 63%|██████▎   | 11075/17525 [2:12:51<1:03:09,  1.70it/s] 63%|██████▎   | 11076/17525 [2:12:51<1:02:41,  1.71it/s] 63%|██████▎   | 11077/17525 [2:12:52<1:02:18,  1.72it/s] 63%|██████▎   | 11078/17525 [2:12:52<1:02:04,  1.73it/s] 63%|██████▎   | 11079/17525 [2:12:53<1:02:00,  1.73it/s] 63%|██████▎   | 11080/17525 [2:12:54<1:01:54,  1.73it/s]                                                         {'loss': 0.3918, 'grad_norm': 16.96151351928711, 'learning_rate': 5.992563052374865e-06, 'epoch': 15.81}
 63%|██████▎   | 11080/17525 [2:12:54<1:01:54,  1.73it/s] 63%|██████▎   | 11081/17525 [2:12:54<1:01:52,  1.74it/s] 63%|██████▎   | 11082/17525 [2:12:55<1:01:42,  1.74it/s] 63%|██████▎   | 11083/17525 [2:12:55<1:01:38,  1.74it/s] 63%|██████▎   | 11084/17525 [2:12:56<1:01:31,  1.74it/s] 63%|██████▎   | 11085/17525 [2:12:56<1:01:32,  1.74it/s] 63%|██████▎   | 11086/17525 [2:12:57<1:01:31,  1.74it/s] 63%|██████▎   | 11087/17525 [2:12:58<1:01:59,  1.73it/s] 63%|██████▎   | 11088/17525 [2:12:58<1:01:56,  1.73it/s] 63%|██████▎   | 11089/17525 [2:12:59<1:01:49,  1.73it/s] 63%|██████▎   | 11090/17525 [2:12:59<1:01:47,  1.74it/s]                                                         {'loss': 0.4039, 'grad_norm': 13.5120849609375, 'learning_rate': 5.976126804775397e-06, 'epoch': 15.82}
 63%|██████▎   | 11090/17525 [2:12:59<1:01:47,  1.74it/s] 63%|██████▎   | 11091/17525 [2:13:00<1:01:50,  1.73it/s] 63%|██████▎   | 11092/17525 [2:13:01<1:01:44,  1.74it/s] 63%|██████▎   | 11093/17525 [2:13:01<1:03:42,  1.68it/s] 63%|██████▎   | 11094/17525 [2:13:02<1:03:02,  1.70it/s] 63%|██████▎   | 11095/17525 [2:13:02<1:05:29,  1.64it/s] 63%|██████▎   | 11096/17525 [2:13:03<1:08:16,  1.57it/s] 63%|██████▎   | 11097/17525 [2:13:04<1:07:54,  1.58it/s] 63%|██████▎   | 11098/17525 [2:13:04<1:07:55,  1.58it/s] 63%|██████▎   | 11099/17525 [2:13:05<1:09:22,  1.54it/s] 63%|██████▎   | 11100/17525 [2:13:06<1:08:23,  1.57it/s]                                                         {'loss': 0.3997, 'grad_norm': 37.41001892089844, 'learning_rate': 5.959703517614107e-06, 'epoch': 15.83}
 63%|██████▎   | 11100/17525 [2:13:06<1:08:23,  1.57it/s][INFO|trainer.py:3512] 2024-06-25 04:16:27,555 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:16:27,555 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:16:27,555 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:03,  5.43it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.59it/s][A
 21%|██        | 4/19 [00:00<00:03,  3.90it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.08it/s][A
 32%|███▏      | 6/19 [00:01<00:03,  4.29it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.59it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  3.94it/s][A
 47%|████▋     | 9/19 [00:02<00:02,  4.18it/s][A
 53%|█████▎    | 10/19 [00:02<00:02,  4.29it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.32it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.47it/s][A
 68%|██████▊   | 13/19 [00:03<00:01,  4.34it/s][A
 74%|███████▎  | 14/19 [00:03<00:01,  4.59it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  4.80it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  4.81it/s][A
 89%|████████▉ | 17/19 [00:04<00:00,  3.47it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.89it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.68it/s][A                                                         
                                               [A{'eval_loss': 1.082035779953003, 'eval_runtime': 4.8861, 'eval_samples_per_second': 90.666, 'eval_steps_per_second': 3.889, 'epoch': 15.83}
 63%|██████▎   | 11100/17525 [2:13:11<1:08:23,  1.57it/s]
100%|██████████| 19/19 [00:04<00:00,  3.68it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:16:32,445 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b8d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 35e896ed-7f7a-4ba5-bd2d-2185e322b4b9)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:16:42,502 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:16:42,504 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 63%|██████▎   | 11101/17525 [2:13:22<9:16:41,  5.20s/it] 63%|██████▎   | 11102/17525 [2:13:22<6:50:11,  3.83s/it] 63%|██████▎   | 11103/17525 [2:13:23<5:07:17,  2.87s/it] 63%|██████▎   | 11104/17525 [2:13:23<3:53:51,  2.19s/it] 63%|██████▎   | 11105/17525 [2:13:24<3:04:16,  1.72s/it] 63%|██████▎   | 11106/17525 [2:13:25<2:28:37,  1.39s/it] 63%|██████▎   | 11107/17525 [2:13:25<2:03:00,  1.15s/it] 63%|██████▎   | 11108/17525 [2:13:26<1:45:08,  1.02it/s] 63%|██████▎   | 11109/17525 [2:13:26<1:33:57,  1.14it/s] 63%|██████▎   | 11110/17525 [2:13:27<1:24:45,  1.26it/s]                                                         {'loss': 0.3338, 'grad_norm': 13.694150924682617, 'learning_rate': 5.943293243788544e-06, 'epoch': 15.85}
 63%|██████▎   | 11110/17525 [2:13:27<1:24:45,  1.26it/s] 63%|██████▎   | 11111/17525 [2:13:28<1:18:50,  1.36it/s] 63%|██████▎   | 11112/17525 [2:13:28<1:13:58,  1.44it/s] 63%|██████▎   | 11113/17525 [2:13:29<1:10:33,  1.51it/s] 63%|██████▎   | 11114/17525 [2:13:29<1:08:38,  1.56it/s] 63%|██████▎   | 11115/17525 [2:13:30<1:07:20,  1.59it/s] 63%|██████▎   | 11116/17525 [2:13:31<1:06:38,  1.60it/s] 63%|██████▎   | 11117/17525 [2:13:31<1:07:26,  1.58it/s] 63%|██████▎   | 11118/17525 [2:13:32<1:05:56,  1.62it/s] 63%|██████▎   | 11119/17525 [2:13:32<1:05:01,  1.64it/s] 63%|██████▎   | 11120/17525 [2:13:33<1:05:39,  1.63it/s]                                                         {'loss': 0.4625, 'grad_norm': 7.411827564239502, 'learning_rate': 5.926896036154325e-06, 'epoch': 15.86}
 63%|██████▎   | 11120/17525 [2:13:33<1:05:39,  1.63it/s] 63%|██████▎   | 11121/17525 [2:13:34<1:04:27,  1.66it/s] 63%|██████▎   | 11122/17525 [2:13:34<1:03:59,  1.67it/s] 63%|██████▎   | 11123/17525 [2:13:35<1:04:07,  1.66it/s] 63%|██████▎   | 11124/17525 [2:13:35<1:04:13,  1.66it/s] 63%|██████▎   | 11125/17525 [2:13:36<1:04:29,  1.65it/s] 63%|██████▎   | 11126/17525 [2:13:37<1:15:35,  1.41it/s] 63%|██████▎   | 11127/17525 [2:13:38<1:12:22,  1.47it/s] 63%|██████▎   | 11128/17525 [2:13:38<1:09:51,  1.53it/s] 64%|██████▎   | 11129/17525 [2:13:39<1:07:57,  1.57it/s] 64%|██████▎   | 11130/17525 [2:13:39<1:06:13,  1.61it/s]                                                         {'loss': 0.386, 'grad_norm': 10.81446647644043, 'learning_rate': 5.910511947525002e-06, 'epoch': 15.88}
 64%|██████▎   | 11130/17525 [2:13:39<1:06:13,  1.61it/s] 64%|██████▎   | 11131/17525 [2:13:40<1:05:13,  1.63it/s] 64%|██████▎   | 11132/17525 [2:13:41<1:04:54,  1.64it/s] 64%|██████▎   | 11133/17525 [2:13:41<1:03:52,  1.67it/s] 64%|██████▎   | 11134/17525 [2:13:43<1:39:06,  1.07it/s] 64%|██████▎   | 11135/17525 [2:13:43<1:28:06,  1.21it/s] 64%|██████▎   | 11136/17525 [2:13:44<1:20:32,  1.32it/s] 64%|██████▎   | 11137/17525 [2:13:45<1:16:33,  1.39it/s] 64%|██████▎   | 11138/17525 [2:13:45<1:12:32,  1.47it/s] 64%|██████▎   | 11139/17525 [2:13:46<1:10:36,  1.51it/s] 64%|██████▎   | 11140/17525 [2:13:46<1:08:08,  1.56it/s]                                                         {'loss': 0.4366, 'grad_norm': 10.640594482421875, 'learning_rate': 5.894141030671856e-06, 'epoch': 15.89}
 64%|██████▎   | 11140/17525 [2:13:46<1:08:08,  1.56it/s] 64%|██████▎   | 11141/17525 [2:13:47<1:06:43,  1.59it/s] 64%|██████▎   | 11142/17525 [2:13:48<1:05:35,  1.62it/s] 64%|██████▎   | 11143/17525 [2:13:48<1:04:30,  1.65it/s] 64%|██████▎   | 11144/17525 [2:13:49<1:04:23,  1.65it/s] 64%|██████▎   | 11145/17525 [2:13:49<1:03:47,  1.67it/s] 64%|██████▎   | 11146/17525 [2:13:50<1:02:51,  1.69it/s] 64%|██████▎   | 11147/17525 [2:13:51<1:02:56,  1.69it/s] 64%|██████▎   | 11148/17525 [2:13:51<1:03:48,  1.67it/s] 64%|██████▎   | 11149/17525 [2:13:52<1:03:27,  1.67it/s] 64%|██████▎   | 11150/17525 [2:13:52<1:03:13,  1.68it/s]                                                         {'loss': 0.4048, 'grad_norm': 11.807668685913086, 'learning_rate': 5.877783338323751e-06, 'epoch': 15.91}
 64%|██████▎   | 11150/17525 [2:13:52<1:03:13,  1.68it/s] 64%|██████▎   | 11151/17525 [2:13:53<1:04:23,  1.65it/s] 64%|██████▎   | 11152/17525 [2:13:54<1:03:30,  1.67it/s] 64%|██████▎   | 11153/17525 [2:13:54<1:03:08,  1.68it/s] 64%|██████▎   | 11154/17525 [2:13:55<1:02:26,  1.70it/s] 64%|██████▎   | 11155/17525 [2:13:55<1:02:12,  1.71it/s] 64%|██████▎   | 11156/17525 [2:13:56<1:02:30,  1.70it/s] 64%|██████▎   | 11157/17525 [2:13:57<1:02:51,  1.69it/s] 64%|██████▎   | 11158/17525 [2:13:57<1:03:17,  1.68it/s] 64%|██████▎   | 11159/17525 [2:13:58<1:14:07,  1.43it/s] 64%|██████▎   | 11160/17525 [2:13:59<1:10:18,  1.51it/s]                                                         {'loss': 0.3212, 'grad_norm': 22.559314727783203, 'learning_rate': 5.8614389231669554e-06, 'epoch': 15.92}
 64%|██████▎   | 11160/17525 [2:13:59<1:10:18,  1.51it/s] 64%|██████▎   | 11161/17525 [2:13:59<1:08:15,  1.55it/s] 64%|██████▎   | 11162/17525 [2:14:00<1:06:10,  1.60it/s] 64%|██████▎   | 11163/17525 [2:14:00<1:04:36,  1.64it/s] 64%|██████▎   | 11164/17525 [2:14:01<1:03:31,  1.67it/s] 64%|██████▎   | 11165/17525 [2:14:02<1:02:41,  1.69it/s] 64%|██████▎   | 11166/17525 [2:14:02<1:02:14,  1.70it/s] 64%|██████▎   | 11167/17525 [2:14:03<1:04:38,  1.64it/s] 64%|██████▎   | 11168/17525 [2:14:04<1:08:20,  1.55it/s] 64%|██████▎   | 11169/17525 [2:14:04<1:06:37,  1.59it/s] 64%|██████▎   | 11170/17525 [2:14:05<1:06:15,  1.60it/s]                                                         {'loss': 0.3745, 'grad_norm': 9.186868667602539, 'learning_rate': 5.845107837844968e-06, 'epoch': 15.93}
 64%|██████▎   | 11170/17525 [2:14:05<1:06:15,  1.60it/s] 64%|██████▎   | 11171/17525 [2:14:05<1:05:18,  1.62it/s] 64%|██████▎   | 11172/17525 [2:14:06<1:05:18,  1.62it/s] 64%|██████▍   | 11173/17525 [2:14:07<1:04:53,  1.63it/s] 64%|██████▍   | 11174/17525 [2:14:07<1:04:20,  1.65it/s] 64%|██████▍   | 11175/17525 [2:14:08<1:03:49,  1.66it/s] 64%|██████▍   | 11176/17525 [2:14:08<1:03:22,  1.67it/s] 64%|██████▍   | 11177/17525 [2:14:09<1:02:41,  1.69it/s] 64%|██████▍   | 11178/17525 [2:14:10<1:02:25,  1.69it/s] 64%|██████▍   | 11179/17525 [2:14:10<1:14:56,  1.41it/s] 64%|██████▍   | 11180/17525 [2:14:11<1:10:44,  1.49it/s]                                                         {'loss': 0.3715, 'grad_norm': 6.947944641113281, 'learning_rate': 5.828790134958364e-06, 'epoch': 15.95}
 64%|██████▍   | 11180/17525 [2:14:11<1:10:44,  1.49it/s] 64%|██████▍   | 11181/17525 [2:14:12<1:07:49,  1.56it/s] 64%|██████▍   | 11182/17525 [2:14:12<1:07:26,  1.57it/s] 64%|██████▍   | 11183/17525 [2:14:13<1:06:53,  1.58it/s] 64%|██████▍   | 11184/17525 [2:14:13<1:05:00,  1.63it/s] 64%|██████▍   | 11185/17525 [2:14:14<1:04:25,  1.64it/s] 64%|██████▍   | 11186/17525 [2:14:15<1:03:30,  1.66it/s] 64%|██████▍   | 11187/17525 [2:14:15<1:02:49,  1.68it/s] 64%|██████▍   | 11188/17525 [2:14:16<1:03:08,  1.67it/s] 64%|██████▍   | 11189/17525 [2:14:16<1:03:27,  1.66it/s] 64%|██████▍   | 11190/17525 [2:14:17<1:03:37,  1.66it/s]                                                         {'loss': 0.4067, 'grad_norm': 8.750561714172363, 'learning_rate': 5.812485867064608e-06, 'epoch': 15.96}
 64%|██████▍   | 11190/17525 [2:14:17<1:03:37,  1.66it/s] 64%|██████▍   | 11191/17525 [2:14:18<1:22:37,  1.28it/s] 64%|██████▍   | 11192/17525 [2:14:19<1:16:52,  1.37it/s] 64%|██████▍   | 11193/17525 [2:14:19<1:12:36,  1.45it/s] 64%|██████▍   | 11194/17525 [2:14:20<1:09:30,  1.52it/s] 64%|██████▍   | 11195/17525 [2:14:21<1:07:10,  1.57it/s] 64%|██████▍   | 11196/17525 [2:14:21<1:06:09,  1.59it/s] 64%|██████▍   | 11197/17525 [2:14:22<1:05:21,  1.61it/s] 64%|██████▍   | 11198/17525 [2:14:22<1:04:02,  1.65it/s] 64%|██████▍   | 11199/17525 [2:14:23<1:02:54,  1.68it/s] 64%|██████▍   | 11200/17525 [2:14:24<1:02:12,  1.69it/s]                                                         {'loss': 0.4432, 'grad_norm': 53.392921447753906, 'learning_rate': 5.796195086677891e-06, 'epoch': 15.98}
 64%|██████▍   | 11200/17525 [2:14:24<1:02:12,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 04:17:45,450 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:17:45,450 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:17:45,450 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.75it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.83it/s][A
 74%|███████▎  | 14/19 [00:02<00:01,  4.99it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.11it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.18it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.0736937522888184, 'eval_runtime': 4.6133, 'eval_samples_per_second': 96.026, 'eval_steps_per_second': 4.118, 'epoch': 15.98}
 64%|██████▍   | 11200/17525 [2:14:28<1:02:12,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 64%|██████▍   | 11201/17525 [2:14:29<3:27:50,  1.97s/it] 64%|██████▍   | 11202/17525 [2:14:29<2:44:00,  1.56s/it] 64%|██████▍   | 11203/17525 [2:14:30<2:17:49,  1.31s/it] 64%|██████▍   | 11204/17525 [2:14:31<1:54:40,  1.09s/it] 64%|██████▍   | 11205/17525 [2:14:31<1:38:53,  1.07it/s] 64%|██████▍   | 11206/17525 [2:14:32<1:27:22,  1.21it/s] 64%|██████▍   | 11207/17525 [2:14:32<1:19:38,  1.32it/s] 64%|██████▍   | 11208/17525 [2:14:33<1:14:07,  1.42it/s] 64%|██████▍   | 11209/17525 [2:14:34<1:10:07,  1.50it/s] 64%|██████▍   | 11210/17525 [2:14:34<1:07:21,  1.56it/s]                                                         {'loss': 0.2773, 'grad_norm': 11.284566879272461, 'learning_rate': 5.7799178462689695e-06, 'epoch': 15.99}
 64%|██████▍   | 11210/17525 [2:14:34<1:07:21,  1.56it/s] 64%|██████▍   | 11211/17525 [2:14:35<1:05:34,  1.60it/s] 64%|██████▍   | 11212/17525 [2:14:35<1:04:24,  1.63it/s] 64%|██████▍   | 11213/17525 [2:14:36<1:03:15,  1.66it/s] 64%|██████▍   | 11214/17525 [2:14:36<1:02:58,  1.67it/s] 64%|██████▍   | 11215/17525 [2:14:37<1:02:03,  1.69it/s] 64%|██████▍   | 11216/17525 [2:14:38<1:01:28,  1.71it/s] 64%|██████▍   | 11217/17525 [2:14:38<1:01:32,  1.71it/s] 64%|██████▍   | 11218/17525 [2:14:39<1:01:44,  1.70it/s] 64%|██████▍   | 11219/17525 [2:14:39<1:02:00,  1.69it/s] 64%|██████▍   | 11220/17525 [2:14:40<1:01:31,  1.71it/s]                                                         {'loss': 0.3251, 'grad_norm': 5.412952899932861, 'learning_rate': 5.763654198264985e-06, 'epoch': 16.01}
 64%|██████▍   | 11220/17525 [2:14:40<1:01:31,  1.71it/s] 64%|██████▍   | 11221/17525 [2:14:41<1:01:41,  1.70it/s] 64%|██████▍   | 11222/17525 [2:14:41<1:01:20,  1.71it/s] 64%|██████▍   | 11223/17525 [2:14:42<1:01:29,  1.71it/s] 64%|██████▍   | 11224/17525 [2:14:42<1:01:03,  1.72it/s] 64%|██████▍   | 11225/17525 [2:14:43<1:00:57,  1.72it/s] 64%|██████▍   | 11226/17525 [2:14:43<1:01:28,  1.71it/s] 64%|██████▍   | 11227/17525 [2:14:44<1:01:00,  1.72it/s] 64%|██████▍   | 11228/17525 [2:14:45<1:00:42,  1.73it/s] 64%|██████▍   | 11229/17525 [2:14:45<1:01:11,  1.71it/s] 64%|██████▍   | 11230/17525 [2:14:46<1:00:51,  1.72it/s]                                                         {'loss': 0.4822, 'grad_norm': 12.666601181030273, 'learning_rate': 5.747404195049293e-06, 'epoch': 16.02}
 64%|██████▍   | 11230/17525 [2:14:46<1:00:51,  1.72it/s] 64%|██████▍   | 11231/17525 [2:14:46<1:00:58,  1.72it/s] 64%|██████▍   | 11232/17525 [2:14:47<1:00:46,  1.73it/s] 64%|██████▍   | 11233/17525 [2:14:48<1:00:48,  1.72it/s] 64%|██████▍   | 11234/17525 [2:14:48<1:00:34,  1.73it/s] 64%|██████▍   | 11235/17525 [2:14:49<1:00:17,  1.74it/s] 64%|██████▍   | 11236/17525 [2:14:49<1:04:44,  1.62it/s] 64%|██████▍   | 11237/17525 [2:14:50<1:04:01,  1.64it/s] 64%|██████▍   | 11238/17525 [2:14:51<1:02:59,  1.66it/s] 64%|██████▍   | 11239/17525 [2:14:51<1:08:00,  1.54it/s] 64%|██████▍   | 11240/17525 [2:14:52<1:05:42,  1.59it/s]                                                         {'loss': 0.4103, 'grad_norm': 319.3575744628906, 'learning_rate': 5.731167888961311e-06, 'epoch': 16.03}
 64%|██████▍   | 11240/17525 [2:14:52<1:05:42,  1.59it/s] 64%|██████▍   | 11241/17525 [2:14:52<1:04:10,  1.63it/s] 64%|██████▍   | 11242/17525 [2:14:53<1:03:19,  1.65it/s] 64%|██████▍   | 11243/17525 [2:14:54<1:02:28,  1.68it/s] 64%|██████▍   | 11244/17525 [2:14:54<1:01:35,  1.70it/s] 64%|██████▍   | 11245/17525 [2:14:55<1:01:20,  1.71it/s] 64%|██████▍   | 11246/17525 [2:14:55<1:00:59,  1.72it/s] 64%|██████▍   | 11247/17525 [2:14:56<1:00:46,  1.72it/s] 64%|██████▍   | 11248/17525 [2:14:57<1:00:30,  1.73it/s] 64%|██████▍   | 11249/17525 [2:14:57<1:00:16,  1.74it/s] 64%|██████▍   | 11250/17525 [2:14:58<1:00:31,  1.73it/s]                                                         {'loss': 0.3791, 'grad_norm': 8.474753379821777, 'learning_rate': 5.7149453322963334e-06, 'epoch': 16.05}
 64%|██████▍   | 11250/17525 [2:14:58<1:00:31,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 04:18:19,553 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bbc2d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: bbd854e6-1a51-4919-a32b-42aed845304e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:18:29,608 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:18:29,610 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 64%|██████▍   | 11251/17525 [2:15:08<6:20:18,  3.64s/it] 64%|██████▍   | 11252/17525 [2:15:09<4:44:37,  2.72s/it] 64%|██████▍   | 11253/17525 [2:15:10<3:48:57,  2.19s/it] 64%|██████▍   | 11254/17525 [2:15:11<2:58:18,  1.71s/it] 64%|██████▍   | 11255/17525 [2:15:11<2:22:47,  1.37s/it] 64%|██████▍   | 11256/17525 [2:15:12<1:58:05,  1.13s/it] 64%|██████▍   | 11257/17525 [2:15:12<1:40:53,  1.04it/s] 64%|██████▍   | 11258/17525 [2:15:13<1:28:36,  1.18it/s] 64%|██████▍   | 11259/17525 [2:15:13<1:19:55,  1.31it/s] 64%|██████▍   | 11260/17525 [2:15:15<1:46:15,  1.02s/it]                                                         {'loss': 0.305, 'grad_norm': 8.12529182434082, 'learning_rate': 5.6987365773053725e-06, 'epoch': 16.06}
 64%|██████▍   | 11260/17525 [2:15:15<1:46:15,  1.02s/it] 64%|██████▍   | 11261/17525 [2:15:16<1:32:27,  1.13it/s] 64%|██████▍   | 11262/17525 [2:15:17<1:37:33,  1.07it/s] 64%|██████▍   | 11263/17525 [2:15:17<1:26:22,  1.21it/s] 64%|██████▍   | 11264/17525 [2:15:18<1:18:26,  1.33it/s] 64%|██████▍   | 11265/17525 [2:15:18<1:12:51,  1.43it/s] 64%|██████▍   | 11266/17525 [2:15:19<1:08:47,  1.52it/s] 64%|██████▍   | 11267/17525 [2:15:20<1:05:58,  1.58it/s] 64%|██████▍   | 11268/17525 [2:15:20<1:04:23,  1.62it/s] 64%|██████▍   | 11269/17525 [2:15:21<1:03:11,  1.65it/s] 64%|██████▍   | 11270/17525 [2:15:21<1:02:17,  1.67it/s]                                                         {'loss': 0.4182, 'grad_norm': 7.3371052742004395, 'learning_rate': 5.682541676194991e-06, 'epoch': 16.08}
 64%|██████▍   | 11270/17525 [2:15:21<1:02:17,  1.67it/s] 64%|██████▍   | 11271/17525 [2:15:22<1:02:12,  1.68it/s] 64%|██████▍   | 11272/17525 [2:15:22<1:01:27,  1.70it/s] 64%|██████▍   | 11273/17525 [2:15:23<1:01:25,  1.70it/s] 64%|██████▍   | 11274/17525 [2:15:24<1:00:57,  1.71it/s] 64%|██████▍   | 11275/17525 [2:15:24<1:00:37,  1.72it/s] 64%|██████▍   | 11276/17525 [2:15:25<1:00:30,  1.72it/s] 64%|██████▍   | 11277/17525 [2:15:25<1:04:00,  1.63it/s] 64%|██████▍   | 11278/17525 [2:15:26<1:02:53,  1.66it/s] 64%|██████▍   | 11279/17525 [2:15:27<1:01:51,  1.68it/s] 64%|██████▍   | 11280/17525 [2:15:27<1:02:27,  1.67it/s]                                                         {'loss': 0.4295, 'grad_norm': 12.075693130493164, 'learning_rate': 5.666360681127109e-06, 'epoch': 16.09}
 64%|██████▍   | 11280/17525 [2:15:27<1:02:27,  1.67it/s] 64%|██████▍   | 11281/17525 [2:15:28<1:02:08,  1.67it/s] 64%|██████▍   | 11282/17525 [2:15:28<1:01:26,  1.69it/s] 64%|██████▍   | 11283/17525 [2:15:29<1:00:50,  1.71it/s] 64%|██████▍   | 11284/17525 [2:15:30<1:00:18,  1.72it/s] 64%|██████▍   | 11285/17525 [2:15:30<59:57,  1.73it/s]   64%|██████▍   | 11286/17525 [2:15:31<59:56,  1.73it/s] 64%|██████▍   | 11287/17525 [2:15:31<1:00:00,  1.73it/s] 64%|██████▍   | 11288/17525 [2:15:32<59:49,  1.74it/s]   64%|██████▍   | 11289/17525 [2:15:32<59:55,  1.73it/s] 64%|██████▍   | 11290/17525 [2:15:33<1:00:17,  1.72it/s]                                                         {'loss': 0.4403, 'grad_norm': 19.196043014526367, 'learning_rate': 5.650193644218891e-06, 'epoch': 16.11}
 64%|██████▍   | 11290/17525 [2:15:33<1:00:17,  1.72it/s] 64%|██████▍   | 11291/17525 [2:15:34<1:25:06,  1.22it/s] 64%|██████▍   | 11292/17525 [2:15:35<1:18:28,  1.32it/s] 64%|██████▍   | 11293/17525 [2:15:36<1:12:48,  1.43it/s] 64%|██████▍   | 11294/17525 [2:15:36<1:08:44,  1.51it/s] 64%|██████▍   | 11295/17525 [2:15:37<1:05:55,  1.57it/s] 64%|██████▍   | 11296/17525 [2:15:37<1:04:03,  1.62it/s] 64%|██████▍   | 11297/17525 [2:15:38<1:03:27,  1.64it/s] 64%|██████▍   | 11298/17525 [2:15:38<1:02:18,  1.67it/s] 64%|██████▍   | 11299/17525 [2:15:39<1:01:26,  1.69it/s] 64%|██████▍   | 11300/17525 [2:15:40<1:00:54,  1.70it/s]                                                         {'loss': 0.3761, 'grad_norm': 21.200214385986328, 'learning_rate': 5.63404061754251e-06, 'epoch': 16.12}
 64%|██████▍   | 11300/17525 [2:15:40<1:00:54,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 04:19:01,466 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:19:01,466 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:19:01,466 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.65it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                         
                                               [A{'eval_loss': 1.095686912536621, 'eval_runtime': 4.5943, 'eval_samples_per_second': 96.423, 'eval_steps_per_second': 4.136, 'epoch': 16.12}
 64%|██████▍   | 11300/17525 [2:15:44<1:00:54,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 64%|██████▍   | 11301/17525 [2:15:45<3:23:45,  1.96s/it] 64%|██████▍   | 11302/17525 [2:15:45<2:40:29,  1.55s/it] 64%|██████▍   | 11303/17525 [2:15:46<2:11:09,  1.26s/it] 65%|██████▍   | 11304/17525 [2:15:47<1:50:09,  1.06s/it] 65%|██████▍   | 11305/17525 [2:15:47<1:35:03,  1.09it/s] 65%|██████▍   | 11306/17525 [2:15:48<1:24:23,  1.23it/s] 65%|██████▍   | 11307/17525 [2:15:48<1:16:58,  1.35it/s] 65%|██████▍   | 11308/17525 [2:15:49<1:12:05,  1.44it/s] 65%|██████▍   | 11309/17525 [2:15:49<1:08:16,  1.52it/s] 65%|██████▍   | 11310/17525 [2:15:50<1:05:40,  1.58it/s]                                                         {'loss': 0.3881, 'grad_norm': 9.827369689941406, 'learning_rate': 5.617901653125043e-06, 'epoch': 16.13}
 65%|██████▍   | 11310/17525 [2:15:50<1:05:40,  1.58it/s] 65%|██████▍   | 11311/17525 [2:15:51<1:05:35,  1.58it/s] 65%|██████▍   | 11312/17525 [2:15:51<1:03:46,  1.62it/s] 65%|██████▍   | 11313/17525 [2:15:52<1:02:25,  1.66it/s] 65%|██████▍   | 11314/17525 [2:15:52<1:01:50,  1.67it/s] 65%|██████▍   | 11315/17525 [2:15:53<1:01:08,  1.69it/s] 65%|██████▍   | 11316/17525 [2:15:53<1:00:35,  1.71it/s] 65%|██████▍   | 11317/17525 [2:15:54<1:00:17,  1.72it/s] 65%|██████▍   | 11318/17525 [2:15:55<1:00:01,  1.72it/s] 65%|██████▍   | 11319/17525 [2:15:55<1:00:24,  1.71it/s] 65%|██████▍   | 11320/17525 [2:15:56<1:00:10,  1.72it/s]                                                         {'loss': 0.3624, 'grad_norm': 3.3396198749542236, 'learning_rate': 5.601776802948249e-06, 'epoch': 16.15}
 65%|██████▍   | 11320/17525 [2:15:56<1:00:10,  1.72it/s] 65%|██████▍   | 11321/17525 [2:15:56<1:00:45,  1.70it/s] 65%|██████▍   | 11322/17525 [2:15:57<1:00:21,  1.71it/s] 65%|██████▍   | 11323/17525 [2:15:58<1:00:02,  1.72it/s] 65%|██████▍   | 11324/17525 [2:15:58<59:49,  1.73it/s]   65%|██████▍   | 11325/17525 [2:15:59<1:00:15,  1.72it/s] 65%|██████▍   | 11326/17525 [2:15:59<59:57,  1.72it/s]   65%|██████▍   | 11327/17525 [2:16:00<59:37,  1.73it/s] 65%|██████▍   | 11328/17525 [2:16:00<59:35,  1.73it/s] 65%|██████▍   | 11329/17525 [2:16:01<59:35,  1.73it/s] 65%|██████▍   | 11330/17525 [2:16:02<59:48,  1.73it/s]                                                       {'loss': 0.416, 'grad_norm': 12.026127815246582, 'learning_rate': 5.5856661189484404e-06, 'epoch': 16.16}
 65%|██████▍   | 11330/17525 [2:16:02<59:48,  1.73it/s] 65%|██████▍   | 11331/17525 [2:16:02<59:47,  1.73it/s] 65%|██████▍   | 11332/17525 [2:16:03<59:40,  1.73it/s] 65%|██████▍   | 11333/17525 [2:16:03<59:35,  1.73it/s] 65%|██████▍   | 11334/17525 [2:16:04<59:54,  1.72it/s] 65%|██████▍   | 11335/17525 [2:16:05<59:43,  1.73it/s] 65%|██████▍   | 11336/17525 [2:16:05<59:36,  1.73it/s] 65%|██████▍   | 11337/17525 [2:16:06<59:31,  1.73it/s] 65%|██████▍   | 11338/17525 [2:16:06<59:25,  1.74it/s] 65%|██████▍   | 11339/17525 [2:16:07<59:18,  1.74it/s] 65%|██████▍   | 11340/17525 [2:16:07<59:21,  1.74it/s]                                                       {'loss': 0.3404, 'grad_norm': 7.338919162750244, 'learning_rate': 5.5695696530163e-06, 'epoch': 16.18}
 65%|██████▍   | 11340/17525 [2:16:07<59:21,  1.74it/s] 65%|██████▍   | 11341/17525 [2:16:08<59:22,  1.74it/s] 65%|██████▍   | 11342/17525 [2:16:09<59:07,  1.74it/s] 65%|██████▍   | 11343/17525 [2:16:09<59:06,  1.74it/s] 65%|██████▍   | 11344/17525 [2:16:10<59:23,  1.73it/s] 65%|██████▍   | 11345/17525 [2:16:10<59:09,  1.74it/s] 65%|██████▍   | 11346/17525 [2:16:11<58:58,  1.75it/s] 65%|██████▍   | 11347/17525 [2:16:11<58:58,  1.75it/s] 65%|██████▍   | 11348/17525 [2:16:12<58:59,  1.74it/s] 65%|██████▍   | 11349/17525 [2:16:13<59:06,  1.74it/s] 65%|██████▍   | 11350/17525 [2:16:13<59:03,  1.74it/s]                                                       {'loss': 0.3654, 'grad_norm': 14.527523040771484, 'learning_rate': 5.553487456996716e-06, 'epoch': 16.19}
 65%|██████▍   | 11350/17525 [2:16:13<59:03,  1.74it/s] 65%|██████▍   | 11351/17525 [2:16:14<58:58,  1.74it/s] 65%|██████▍   | 11352/17525 [2:16:14<1:04:52,  1.59it/s] 65%|██████▍   | 11353/17525 [2:16:15<1:03:56,  1.61it/s] 65%|██████▍   | 11354/17525 [2:16:16<1:02:37,  1.64it/s] 65%|██████▍   | 11355/17525 [2:16:16<1:01:30,  1.67it/s] 65%|██████▍   | 11356/17525 [2:16:17<1:00:41,  1.69it/s] 65%|██████▍   | 11357/17525 [2:16:17<1:00:10,  1.71it/s] 65%|██████▍   | 11358/17525 [2:16:18<59:46,  1.72it/s]   65%|██████▍   | 11359/17525 [2:16:18<59:28,  1.73it/s] 65%|██████▍   | 11360/17525 [2:16:19<59:13,  1.73it/s]                                                       {'loss': 0.3264, 'grad_norm': 9.827339172363281, 'learning_rate': 5.537419582688615e-06, 'epoch': 16.21}
 65%|██████▍   | 11360/17525 [2:16:19<59:13,  1.73it/s] 65%|██████▍   | 11361/17525 [2:16:20<59:12,  1.74it/s] 65%|██████▍   | 11362/17525 [2:16:20<59:08,  1.74it/s] 65%|██████▍   | 11363/17525 [2:16:21<59:11,  1.74it/s] 65%|██████▍   | 11364/17525 [2:16:21<59:08,  1.74it/s] 65%|██████▍   | 11365/17525 [2:16:22<58:58,  1.74it/s] 65%|██████▍   | 11366/17525 [2:16:23<58:56,  1.74it/s] 65%|██████▍   | 11367/17525 [2:16:23<58:50,  1.74it/s] 65%|██████▍   | 11368/17525 [2:16:24<58:47,  1.75it/s] 65%|██████▍   | 11369/17525 [2:16:24<58:50,  1.74it/s] 65%|██████▍   | 11370/17525 [2:16:25<59:18,  1.73it/s]                                                       {'loss': 0.356, 'grad_norm': 13.595123291015625, 'learning_rate': 5.521366081844788e-06, 'epoch': 16.22}
 65%|██████▍   | 11370/17525 [2:16:25<59:18,  1.73it/s] 65%|██████▍   | 11371/17525 [2:16:26<1:10:21,  1.46it/s] 65%|██████▍   | 11372/17525 [2:16:26<1:06:55,  1.53it/s] 65%|██████▍   | 11373/17525 [2:16:27<1:04:25,  1.59it/s] 65%|██████▍   | 11374/17525 [2:16:29<1:34:17,  1.09it/s] 65%|██████▍   | 11375/17525 [2:16:29<1:23:38,  1.23it/s] 65%|██████▍   | 11376/17525 [2:16:30<1:16:09,  1.35it/s] 65%|██████▍   | 11377/17525 [2:16:30<1:11:04,  1.44it/s] 65%|██████▍   | 11378/17525 [2:16:31<1:26:36,  1.18it/s] 65%|██████▍   | 11379/17525 [2:16:32<1:18:10,  1.31it/s] 65%|██████▍   | 11380/17525 [2:16:33<1:12:15,  1.42it/s]                                                         {'loss': 0.4005, 'grad_norm': 7.142857074737549, 'learning_rate': 5.50532700617174e-06, 'epoch': 16.23}
 65%|██████▍   | 11380/17525 [2:16:33<1:12:15,  1.42it/s] 65%|██████▍   | 11381/17525 [2:16:33<1:08:15,  1.50it/s] 65%|██████▍   | 11382/17525 [2:16:34<1:05:24,  1.57it/s] 65%|██████▍   | 11383/17525 [2:16:34<1:03:22,  1.62it/s] 65%|██████▍   | 11384/17525 [2:16:35<1:01:58,  1.65it/s] 65%|██████▍   | 11385/17525 [2:16:35<1:01:07,  1.67it/s] 65%|██████▍   | 11386/17525 [2:16:36<1:00:32,  1.69it/s] 65%|██████▍   | 11387/17525 [2:16:37<1:00:03,  1.70it/s] 65%|██████▍   | 11388/17525 [2:16:37<59:33,  1.72it/s]   65%|██████▍   | 11389/17525 [2:16:38<59:14,  1.73it/s] 65%|██████▍   | 11390/17525 [2:16:38<58:59,  1.73it/s]                                                       {'loss': 0.3169, 'grad_norm': 10.261838912963867, 'learning_rate': 5.489302407329511e-06, 'epoch': 16.25}
 65%|██████▍   | 11390/17525 [2:16:38<58:59,  1.73it/s] 65%|██████▍   | 11391/17525 [2:16:39<59:01,  1.73it/s] 65%|██████▌   | 11392/17525 [2:16:39<58:57,  1.73it/s] 65%|██████▌   | 11393/17525 [2:16:40<58:47,  1.74it/s] 65%|██████▌   | 11394/17525 [2:16:41<58:44,  1.74it/s] 65%|██████▌   | 11395/17525 [2:16:41<58:43,  1.74it/s] 65%|██████▌   | 11396/17525 [2:16:42<59:02,  1.73it/s] 65%|██████▌   | 11397/17525 [2:16:42<58:56,  1.73it/s] 65%|██████▌   | 11398/17525 [2:16:43<58:54,  1.73it/s] 65%|██████▌   | 11399/17525 [2:16:44<58:39,  1.74it/s] 65%|██████▌   | 11400/17525 [2:16:44<58:39,  1.74it/s]                                                       {'loss': 0.3875, 'grad_norm': 7.420726299285889, 'learning_rate': 5.473292336931511e-06, 'epoch': 16.26}
 65%|██████▌   | 11400/17525 [2:16:44<58:39,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:20:05,972 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:20:05,972 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:20:05,972 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.101654052734375, 'eval_runtime': 4.5971, 'eval_samples_per_second': 96.365, 'eval_steps_per_second': 4.133, 'epoch': 16.26}
 65%|██████▌   | 11400/17525 [2:16:49<58:39,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:20:10,572 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a6d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 149b3c89-428f-44dd-b82a-027b31094335)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:20:20,654 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:20:20,657 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 65%|██████▌   | 11401/17525 [2:16:59<8:32:40,  5.02s/it] 65%|██████▌   | 11402/17525 [2:17:00<6:16:26,  3.69s/it] 65%|██████▌   | 11403/17525 [2:17:01<4:41:11,  2.76s/it] 65%|██████▌   | 11404/17525 [2:17:01<3:34:28,  2.10s/it] 65%|██████▌   | 11405/17525 [2:17:02<2:47:43,  1.64s/it] 65%|██████▌   | 11406/17525 [2:17:02<2:15:04,  1.32s/it] 65%|██████▌   | 11407/17525 [2:17:03<1:52:04,  1.10s/it] 65%|██████▌   | 11408/17525 [2:17:04<1:36:19,  1.06it/s] 65%|██████▌   | 11409/17525 [2:17:04<1:24:59,  1.20it/s] 65%|██████▌   | 11410/17525 [2:17:05<1:16:56,  1.32it/s]                                                         {'loss': 0.4012, 'grad_norm': 11.475132942199707, 'learning_rate': 5.457296846544358e-06, 'epoch': 16.28}
 65%|██████▌   | 11410/17525 [2:17:05<1:16:56,  1.32it/s] 65%|██████▌   | 11411/17525 [2:17:05<1:11:29,  1.43it/s] 65%|██████▌   | 11412/17525 [2:17:06<1:07:37,  1.51it/s] 65%|██████▌   | 11413/17525 [2:17:06<1:05:40,  1.55it/s] 65%|██████▌   | 11414/17525 [2:17:07<1:03:29,  1.60it/s] 65%|██████▌   | 11415/17525 [2:17:08<1:12:53,  1.40it/s] 65%|██████▌   | 11416/17525 [2:17:08<1:08:30,  1.49it/s] 65%|██████▌   | 11417/17525 [2:17:09<1:05:32,  1.55it/s] 65%|██████▌   | 11418/17525 [2:17:10<1:03:23,  1.61it/s] 65%|██████▌   | 11419/17525 [2:17:10<1:01:52,  1.64it/s] 65%|██████▌   | 11420/17525 [2:17:11<1:00:51,  1.67it/s]                                                         {'loss': 0.4034, 'grad_norm': 14.615250587463379, 'learning_rate': 5.441315987687712e-06, 'epoch': 16.29}
 65%|██████▌   | 11420/17525 [2:17:11<1:00:51,  1.67it/s] 65%|██████▌   | 11421/17525 [2:17:11<1:00:10,  1.69it/s] 65%|██████▌   | 11422/17525 [2:17:12<59:38,  1.71it/s]   65%|██████▌   | 11423/17525 [2:17:13<59:15,  1.72it/s] 65%|██████▌   | 11424/17525 [2:17:13<59:01,  1.72it/s] 65%|██████▌   | 11425/17525 [2:17:14<58:54,  1.73it/s] 65%|██████▌   | 11426/17525 [2:17:14<58:43,  1.73it/s] 65%|██████▌   | 11427/17525 [2:17:15<58:44,  1.73it/s] 65%|██████▌   | 11428/17525 [2:17:15<58:54,  1.72it/s] 65%|██████▌   | 11429/17525 [2:17:16<58:47,  1.73it/s] 65%|██████▌   | 11430/17525 [2:17:17<58:39,  1.73it/s]                                                       {'loss': 0.4546, 'grad_norm': 7.222377300262451, 'learning_rate': 5.425349811834091e-06, 'epoch': 16.31}
 65%|██████▌   | 11430/17525 [2:17:17<58:39,  1.73it/s] 65%|██████▌   | 11431/17525 [2:17:17<58:40,  1.73it/s] 65%|██████▌   | 11432/17525 [2:17:18<59:07,  1.72it/s] 65%|██████▌   | 11433/17525 [2:17:18<58:51,  1.73it/s] 65%|██████▌   | 11434/17525 [2:17:19<58:41,  1.73it/s] 65%|██████▌   | 11435/17525 [2:17:19<58:28,  1.74it/s] 65%|██████▌   | 11436/17525 [2:17:20<58:22,  1.74it/s] 65%|██████▌   | 11437/17525 [2:17:21<58:27,  1.74it/s] 65%|██████▌   | 11438/17525 [2:17:21<58:20,  1.74it/s] 65%|██████▌   | 11439/17525 [2:17:22<58:17,  1.74it/s] 65%|██████▌   | 11440/17525 [2:17:22<58:06,  1.75it/s]                                                       {'loss': 0.3486, 'grad_norm': 11.716784477233887, 'learning_rate': 5.4093983704087485e-06, 'epoch': 16.32}
 65%|██████▌   | 11440/17525 [2:17:22<58:06,  1.75it/s] 65%|██████▌   | 11441/17525 [2:17:23<58:15,  1.74it/s] 65%|██████▌   | 11442/17525 [2:17:23<58:15,  1.74it/s] 65%|██████▌   | 11443/17525 [2:17:24<58:23,  1.74it/s] 65%|██████▌   | 11444/17525 [2:17:25<58:12,  1.74it/s] 65%|██████▌   | 11445/17525 [2:17:25<58:13,  1.74it/s] 65%|██████▌   | 11446/17525 [2:17:26<58:18,  1.74it/s] 65%|██████▌   | 11447/17525 [2:17:26<58:22,  1.74it/s] 65%|██████▌   | 11448/17525 [2:17:27<58:22,  1.73it/s] 65%|██████▌   | 11449/17525 [2:17:28<58:22,  1.73it/s] 65%|██████▌   | 11450/17525 [2:17:28<58:12,  1.74it/s]                                                       {'loss': 0.3602, 'grad_norm': 4.4411468505859375, 'learning_rate': 5.393461714789452e-06, 'epoch': 16.33}
 65%|██████▌   | 11450/17525 [2:17:28<58:12,  1.74it/s] 65%|██████▌   | 11451/17525 [2:17:29<1:22:07,  1.23it/s] 65%|██████▌   | 11452/17525 [2:17:30<1:14:52,  1.35it/s] 65%|██████▌   | 11453/17525 [2:17:31<1:09:48,  1.45it/s] 65%|██████▌   | 11454/17525 [2:17:31<1:06:14,  1.53it/s] 65%|██████▌   | 11455/17525 [2:17:32<1:03:46,  1.59it/s] 65%|██████▌   | 11456/17525 [2:17:32<1:03:18,  1.60it/s] 65%|██████▌   | 11457/17525 [2:17:33<1:01:34,  1.64it/s] 65%|██████▌   | 11458/17525 [2:17:33<1:00:30,  1.67it/s] 65%|██████▌   | 11459/17525 [2:17:34<59:45,  1.69it/s]   65%|██████▌   | 11460/17525 [2:17:35<59:38,  1.69it/s]                                                       {'loss': 0.3934, 'grad_norm': 12.287644386291504, 'learning_rate': 5.377539896306363e-06, 'epoch': 16.35}
 65%|██████▌   | 11460/17525 [2:17:35<59:38,  1.69it/s] 65%|██████▌   | 11461/17525 [2:17:35<59:18,  1.70it/s] 65%|██████▌   | 11462/17525 [2:17:36<59:09,  1.71it/s] 65%|██████▌   | 11463/17525 [2:17:36<59:00,  1.71it/s] 65%|██████▌   | 11464/17525 [2:17:37<58:51,  1.72it/s] 65%|██████▌   | 11465/17525 [2:17:38<58:45,  1.72it/s] 65%|██████▌   | 11466/17525 [2:17:38<58:35,  1.72it/s] 65%|██████▌   | 11467/17525 [2:17:39<58:26,  1.73it/s] 65%|██████▌   | 11468/17525 [2:17:39<58:14,  1.73it/s] 65%|██████▌   | 11469/17525 [2:17:40<58:13,  1.73it/s] 65%|██████▌   | 11470/17525 [2:17:40<58:13,  1.73it/s]                                                       {'loss': 0.4131, 'grad_norm': 21.291799545288086, 'learning_rate': 5.361632966241852e-06, 'epoch': 16.36}
 65%|██████▌   | 11470/17525 [2:17:40<58:13,  1.73it/s] 65%|██████▌   | 11471/17525 [2:17:41<58:09,  1.74it/s] 65%|██████▌   | 11472/17525 [2:17:42<1:03:59,  1.58it/s] 65%|██████▌   | 11473/17525 [2:17:42<1:02:00,  1.63it/s] 65%|██████▌   | 11474/17525 [2:17:43<1:00:45,  1.66it/s] 65%|██████▌   | 11475/17525 [2:17:43<59:55,  1.68it/s]   65%|██████▌   | 11476/17525 [2:17:44<59:20,  1.70it/s] 65%|██████▌   | 11477/17525 [2:17:45<58:50,  1.71it/s] 65%|██████▌   | 11478/17525 [2:17:45<1:02:47,  1.60it/s] 66%|██████▌   | 11479/17525 [2:17:46<1:01:11,  1.65it/s] 66%|██████▌   | 11480/17525 [2:17:47<1:00:52,  1.66it/s]                                                         {'loss': 0.4192, 'grad_norm': 7.38722038269043, 'learning_rate': 5.345740975830321e-06, 'epoch': 16.38}
 66%|██████▌   | 11480/17525 [2:17:47<1:00:52,  1.66it/s] 66%|██████▌   | 11481/17525 [2:17:47<1:10:51,  1.42it/s] 66%|██████▌   | 11482/17525 [2:17:48<1:06:53,  1.51it/s] 66%|██████▌   | 11483/17525 [2:17:49<1:04:07,  1.57it/s] 66%|██████▌   | 11484/17525 [2:17:49<1:02:18,  1.62it/s] 66%|██████▌   | 11485/17525 [2:17:50<1:00:58,  1.65it/s] 66%|██████▌   | 11486/17525 [2:17:50<1:00:00,  1.68it/s] 66%|██████▌   | 11487/17525 [2:17:51<59:22,  1.69it/s]   66%|██████▌   | 11488/17525 [2:17:51<58:52,  1.71it/s] 66%|██████▌   | 11489/17525 [2:17:52<1:11:08,  1.41it/s] 66%|██████▌   | 11490/17525 [2:17:53<1:07:14,  1.50it/s]                                                         {'loss': 0.3894, 'grad_norm': 10.61341667175293, 'learning_rate': 5.329863976258081e-06, 'epoch': 16.39}
 66%|██████▌   | 11490/17525 [2:17:53<1:07:14,  1.50it/s] 66%|██████▌   | 11491/17525 [2:17:54<1:04:33,  1.56it/s] 66%|██████▌   | 11492/17525 [2:17:54<1:02:32,  1.61it/s] 66%|██████▌   | 11493/17525 [2:17:55<1:01:01,  1.65it/s] 66%|██████▌   | 11494/17525 [2:17:55<1:00:03,  1.67it/s] 66%|██████▌   | 11495/17525 [2:17:56<59:20,  1.69it/s]   66%|██████▌   | 11496/17525 [2:17:57<59:30,  1.69it/s] 66%|██████▌   | 11497/17525 [2:17:57<58:56,  1.70it/s] 66%|██████▌   | 11498/17525 [2:17:58<58:31,  1.72it/s] 66%|██████▌   | 11499/17525 [2:17:58<58:06,  1.73it/s] 66%|██████▌   | 11500/17525 [2:17:59<58:00,  1.73it/s]                                                       {'loss': 0.3915, 'grad_norm': 8.403424263000488, 'learning_rate': 5.314002018663129e-06, 'epoch': 16.41}
 66%|██████▌   | 11500/17525 [2:17:59<58:00,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:21:20,713 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:21:20,713 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:21:20,713 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.0916558504104614, 'eval_runtime': 4.5963, 'eval_samples_per_second': 96.383, 'eval_steps_per_second': 4.134, 'epoch': 16.41}
 66%|██████▌   | 11500/17525 [2:18:03<58:00,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 66%|██████▌   | 11501/17525 [2:18:04<3:16:37,  1.96s/it] 66%|██████▌   | 11502/17525 [2:18:05<2:34:50,  1.54s/it] 66%|██████▌   | 11503/17525 [2:18:05<2:05:40,  1.25s/it] 66%|██████▌   | 11504/17525 [2:18:06<1:45:16,  1.05s/it] 66%|██████▌   | 11505/17525 [2:18:06<1:31:00,  1.10it/s] 66%|██████▌   | 11506/17525 [2:18:07<1:20:55,  1.24it/s] 66%|██████▌   | 11507/17525 [2:18:07<1:13:59,  1.36it/s] 66%|██████▌   | 11508/17525 [2:18:08<1:09:02,  1.45it/s] 66%|██████▌   | 11509/17525 [2:18:09<1:05:35,  1.53it/s] 66%|██████▌   | 11510/17525 [2:18:09<1:03:00,  1.59it/s]                                                         {'loss': 0.4367, 'grad_norm': 14.024028778076172, 'learning_rate': 5.298155154135034e-06, 'epoch': 16.42}
 66%|██████▌   | 11510/17525 [2:18:09<1:03:00,  1.59it/s] 66%|██████▌   | 11511/17525 [2:18:10<1:01:28,  1.63it/s] 66%|██████▌   | 11512/17525 [2:18:10<1:00:20,  1.66it/s] 66%|██████▌   | 11513/17525 [2:18:11<59:24,  1.69it/s]   66%|██████▌   | 11514/17525 [2:18:11<58:54,  1.70it/s] 66%|██████▌   | 11515/17525 [2:18:12<58:27,  1.71it/s] 66%|██████▌   | 11516/17525 [2:18:13<58:21,  1.72it/s] 66%|██████▌   | 11517/17525 [2:18:13<57:58,  1.73it/s] 66%|██████▌   | 11518/17525 [2:18:14<57:52,  1.73it/s] 66%|██████▌   | 11519/17525 [2:18:14<57:54,  1.73it/s] 66%|██████▌   | 11520/17525 [2:18:15<57:44,  1.73it/s]                                                       {'loss': 0.3852, 'grad_norm': 7.310291290283203, 'learning_rate': 5.282323433714744e-06, 'epoch': 16.43}
 66%|██████▌   | 11520/17525 [2:18:15<57:44,  1.73it/s] 66%|██████▌   | 11521/17525 [2:18:15<57:41,  1.73it/s] 66%|██████▌   | 11522/17525 [2:18:16<58:01,  1.72it/s] 66%|██████▌   | 11523/17525 [2:18:17<57:52,  1.73it/s] 66%|██████▌   | 11524/17525 [2:18:17<57:45,  1.73it/s] 66%|██████▌   | 11525/17525 [2:18:18<57:41,  1.73it/s] 66%|██████▌   | 11526/17525 [2:18:18<57:39,  1.73it/s] 66%|██████▌   | 11527/17525 [2:18:19<57:36,  1.74it/s] 66%|██████▌   | 11528/17525 [2:18:20<57:29,  1.74it/s] 66%|██████▌   | 11529/17525 [2:18:20<57:27,  1.74it/s] 66%|██████▌   | 11530/17525 [2:18:21<57:29,  1.74it/s]                                                       {'loss': 0.3733, 'grad_norm': 6.278637409210205, 'learning_rate': 5.266506908394431e-06, 'epoch': 16.45}
 66%|██████▌   | 11530/17525 [2:18:21<57:29,  1.74it/s] 66%|██████▌   | 11531/17525 [2:18:21<57:27,  1.74it/s] 66%|██████▌   | 11532/17525 [2:18:22<57:54,  1.72it/s] 66%|██████▌   | 11533/17525 [2:18:22<57:39,  1.73it/s] 66%|██████▌   | 11534/17525 [2:18:24<1:21:09,  1.23it/s] 66%|██████▌   | 11535/17525 [2:18:24<1:14:08,  1.35it/s] 66%|██████▌   | 11536/17525 [2:18:25<1:08:59,  1.45it/s] 66%|██████▌   | 11537/17525 [2:18:26<1:05:32,  1.52it/s] 66%|██████▌   | 11538/17525 [2:18:26<1:03:10,  1.58it/s] 66%|██████▌   | 11539/17525 [2:18:27<1:01:21,  1.63it/s] 66%|██████▌   | 11540/17525 [2:18:27<1:00:09,  1.66it/s]                                                         {'loss': 0.3329, 'grad_norm': 5.791928768157959, 'learning_rate': 5.250705629117326e-06, 'epoch': 16.46}
 66%|██████▌   | 11540/17525 [2:18:27<1:00:09,  1.66it/s] 66%|██████▌   | 11541/17525 [2:18:28<59:29,  1.68it/s]   66%|██████▌   | 11542/17525 [2:18:28<58:55,  1.69it/s] 66%|██████▌   | 11543/17525 [2:18:29<58:33,  1.70it/s] 66%|██████▌   | 11544/17525 [2:18:30<58:15,  1.71it/s] 66%|██████▌   | 11545/17525 [2:18:30<57:46,  1.72it/s] 66%|██████▌   | 11546/17525 [2:18:31<58:23,  1.71it/s] 66%|██████▌   | 11547/17525 [2:18:31<58:08,  1.71it/s] 66%|██████▌   | 11548/17525 [2:18:32<57:58,  1.72it/s] 66%|██████▌   | 11549/17525 [2:18:32<57:41,  1.73it/s] 66%|██████▌   | 11550/17525 [2:18:33<57:35,  1.73it/s]                                                       {'loss': 0.3551, 'grad_norm': 13.74731159210205, 'learning_rate': 5.234919646777557e-06, 'epoch': 16.48}
 66%|██████▌   | 11550/17525 [2:18:33<57:35,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 04:21:54,917 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11550
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b85990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 84c367a0-45d0-49bd-b3e8-2976b10f3242)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:22:04,972 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:22:04,974 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11550/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 66%|██████▌   | 11551/17525 [2:18:44<6:06:07,  3.68s/it] 66%|██████▌   | 11552/17525 [2:18:45<4:33:29,  2.75s/it] 66%|██████▌   | 11553/17525 [2:18:45<3:28:30,  2.09s/it] 66%|██████▌   | 11554/17525 [2:18:46<2:43:00,  1.64s/it] 66%|██████▌   | 11555/17525 [2:18:46<2:11:07,  1.32s/it] 66%|██████▌   | 11556/17525 [2:18:47<1:49:05,  1.10s/it] 66%|██████▌   | 11557/17525 [2:18:47<1:33:26,  1.06it/s] 66%|██████▌   | 11558/17525 [2:18:48<1:22:42,  1.20it/s] 66%|██████▌   | 11559/17525 [2:18:49<1:15:01,  1.33it/s] 66%|██████▌   | 11560/17525 [2:18:49<1:09:44,  1.43it/s]                                                         {'loss': 0.345, 'grad_norm': 13.55750560760498, 'learning_rate': 5.219149012219966e-06, 'epoch': 16.49}
 66%|██████▌   | 11560/17525 [2:18:49<1:09:44,  1.43it/s] 66%|██████▌   | 11561/17525 [2:18:50<1:06:01,  1.51it/s] 66%|██████▌   | 11562/17525 [2:18:50<1:04:42,  1.54it/s] 66%|██████▌   | 11563/17525 [2:18:51<1:02:29,  1.59it/s] 66%|██████▌   | 11564/17525 [2:18:51<1:01:15,  1.62it/s] 66%|██████▌   | 11565/17525 [2:18:52<1:00:09,  1.65it/s] 66%|██████▌   | 11566/17525 [2:18:53<59:27,  1.67it/s]   66%|██████▌   | 11567/17525 [2:18:53<58:51,  1.69it/s] 66%|██████▌   | 11568/17525 [2:18:54<58:09,  1.71it/s] 66%|██████▌   | 11569/17525 [2:18:54<57:44,  1.72it/s] 66%|██████▌   | 11570/17525 [2:18:55<57:31,  1.73it/s]                                                       {'loss': 0.4251, 'grad_norm': 34.32472229003906, 'learning_rate': 5.203393776239992e-06, 'epoch': 16.5}
 66%|██████▌   | 11570/17525 [2:18:55<57:31,  1.73it/s] 66%|██████▌   | 11571/17525 [2:18:56<57:26,  1.73it/s] 66%|██████▌   | 11572/17525 [2:18:56<57:16,  1.73it/s] 66%|██████▌   | 11573/17525 [2:18:57<57:10,  1.73it/s] 66%|██████▌   | 11574/17525 [2:18:57<57:14,  1.73it/s] 66%|██████▌   | 11575/17525 [2:18:58<57:12,  1.73it/s] 66%|██████▌   | 11576/17525 [2:18:58<57:31,  1.72it/s] 66%|██████▌   | 11577/17525 [2:18:59<57:17,  1.73it/s] 66%|██████▌   | 11578/17525 [2:19:00<57:06,  1.74it/s] 66%|██████▌   | 11579/17525 [2:19:00<1:07:25,  1.47it/s] 66%|██████▌   | 11580/17525 [2:19:01<1:04:19,  1.54it/s]                                                         {'loss': 0.3544, 'grad_norm': 8.030562400817871, 'learning_rate': 5.187653989583446e-06, 'epoch': 16.52}
 66%|██████▌   | 11580/17525 [2:19:01<1:04:19,  1.54it/s] 66%|██████▌   | 11581/17525 [2:19:02<1:02:11,  1.59it/s] 66%|██████▌   | 11582/17525 [2:19:02<1:00:32,  1.64it/s] 66%|██████▌   | 11583/17525 [2:19:03<59:15,  1.67it/s]   66%|██████▌   | 11584/17525 [2:19:03<58:33,  1.69it/s] 66%|██████▌   | 11585/17525 [2:19:04<58:02,  1.71it/s] 66%|██████▌   | 11586/17525 [2:19:04<57:30,  1.72it/s] 66%|██████▌   | 11587/17525 [2:19:05<57:19,  1.73it/s] 66%|██████▌   | 11588/17525 [2:19:06<57:09,  1.73it/s] 66%|██████▌   | 11589/17525 [2:19:06<56:55,  1.74it/s] 66%|██████▌   | 11590/17525 [2:19:07<56:50,  1.74it/s]                                                       {'loss': 0.3449, 'grad_norm': 11.253279685974121, 'learning_rate': 5.171929702946397e-06, 'epoch': 16.53}
 66%|██████▌   | 11590/17525 [2:19:07<56:50,  1.74it/s] 66%|██████▌   | 11591/17525 [2:19:08<1:07:49,  1.46it/s] 66%|██████▌   | 11592/17525 [2:19:08<1:08:41,  1.44it/s] 66%|██████▌   | 11593/17525 [2:19:09<1:05:03,  1.52it/s] 66%|██████▌   | 11594/17525 [2:19:10<1:02:32,  1.58it/s] 66%|██████▌   | 11595/17525 [2:19:10<1:00:46,  1.63it/s] 66%|██████▌   | 11596/17525 [2:19:11<59:29,  1.66it/s]   66%|██████▌   | 11597/17525 [2:19:11<58:35,  1.69it/s] 66%|██████▌   | 11598/17525 [2:19:12<57:53,  1.71it/s] 66%|██████▌   | 11599/17525 [2:19:12<57:27,  1.72it/s] 66%|██████▌   | 11600/17525 [2:19:13<57:11,  1.73it/s]                                                       {'loss': 0.3999, 'grad_norm': 7.921664714813232, 'learning_rate': 5.156220966974985e-06, 'epoch': 16.55}
 66%|██████▌   | 11600/17525 [2:19:13<57:11,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:22:34,903 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:22:34,903 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:22:34,903 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.0835626125335693, 'eval_runtime': 4.5926, 'eval_samples_per_second': 96.459, 'eval_steps_per_second': 4.137, 'epoch': 16.55}
 66%|██████▌   | 11600/17525 [2:19:18<57:11,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 66%|██████▌   | 11601/17525 [2:19:18<3:13:20,  1.96s/it] 66%|██████▌   | 11602/17525 [2:19:19<2:32:29,  1.54s/it] 66%|██████▌   | 11603/17525 [2:19:19<2:04:33,  1.26s/it] 66%|██████▌   | 11604/17525 [2:19:20<1:44:11,  1.06s/it] 66%|██████▌   | 11605/17525 [2:19:21<1:30:07,  1.09it/s] 66%|██████▌   | 11606/17525 [2:19:21<1:20:05,  1.23it/s] 66%|██████▌   | 11607/17525 [2:19:22<1:13:10,  1.35it/s] 66%|██████▌   | 11608/17525 [2:19:22<1:08:15,  1.44it/s] 66%|██████▌   | 11609/17525 [2:19:23<1:04:40,  1.52it/s] 66%|██████▌   | 11610/17525 [2:19:23<1:02:05,  1.59it/s]                                                         {'loss': 0.3589, 'grad_norm': 9.178892135620117, 'learning_rate': 5.140527832265256e-06, 'epoch': 16.56}
 66%|██████▌   | 11610/17525 [2:19:23<1:02:05,  1.59it/s] 66%|██████▋   | 11611/17525 [2:19:24<1:00:25,  1.63it/s] 66%|██████▋   | 11612/17525 [2:19:25<59:15,  1.66it/s]   66%|██████▋   | 11613/17525 [2:19:25<58:23,  1.69it/s] 66%|██████▋   | 11614/17525 [2:19:26<57:45,  1.71it/s] 66%|██████▋   | 11615/17525 [2:19:26<57:33,  1.71it/s] 66%|██████▋   | 11616/17525 [2:19:27<57:09,  1.72it/s] 66%|██████▋   | 11617/17525 [2:19:27<57:02,  1.73it/s] 66%|██████▋   | 11618/17525 [2:19:28<56:51,  1.73it/s] 66%|██████▋   | 11619/17525 [2:19:29<56:41,  1.74it/s] 66%|██████▋   | 11620/17525 [2:19:29<56:32,  1.74it/s]                                                       {'loss': 0.3964, 'grad_norm': 9.509858131408691, 'learning_rate': 5.124850349363027e-06, 'epoch': 16.58}
 66%|██████▋   | 11620/17525 [2:19:29<56:32,  1.74it/s] 66%|██████▋   | 11621/17525 [2:19:30<56:44,  1.73it/s] 66%|██████▋   | 11622/17525 [2:19:31<1:06:27,  1.48it/s] 66%|██████▋   | 11623/17525 [2:19:31<1:03:29,  1.55it/s] 66%|██████▋   | 11624/17525 [2:19:32<1:01:42,  1.59it/s] 66%|██████▋   | 11625/17525 [2:19:32<1:00:27,  1.63it/s] 66%|██████▋   | 11626/17525 [2:19:33<59:25,  1.65it/s]   66%|██████▋   | 11627/17525 [2:19:34<58:34,  1.68it/s] 66%|██████▋   | 11628/17525 [2:19:34<1:08:20,  1.44it/s] 66%|██████▋   | 11629/17525 [2:19:35<1:04:42,  1.52it/s] 66%|██████▋   | 11630/17525 [2:19:36<1:02:17,  1.58it/s]                                                         {'loss': 0.4304, 'grad_norm': 10.3966703414917, 'learning_rate': 5.109188568763673e-06, 'epoch': 16.59}
 66%|██████▋   | 11630/17525 [2:19:36<1:02:17,  1.58it/s] 66%|██████▋   | 11631/17525 [2:19:36<1:00:27,  1.62it/s] 66%|██████▋   | 11632/17525 [2:19:37<59:04,  1.66it/s]   66%|██████▋   | 11633/17525 [2:19:37<58:16,  1.69it/s] 66%|██████▋   | 11634/17525 [2:19:38<57:42,  1.70it/s] 66%|██████▋   | 11635/17525 [2:19:38<57:22,  1.71it/s] 66%|██████▋   | 11636/17525 [2:19:39<57:03,  1.72it/s] 66%|██████▋   | 11637/17525 [2:19:40<56:51,  1.73it/s] 66%|██████▋   | 11638/17525 [2:19:40<56:43,  1.73it/s] 66%|██████▋   | 11639/17525 [2:19:41<1:10:27,  1.39it/s] 66%|██████▋   | 11640/17525 [2:19:42<1:06:13,  1.48it/s]                                                         {'loss': 0.4214, 'grad_norm': 8.469341278076172, 'learning_rate': 5.093542540912024e-06, 'epoch': 16.6}
 66%|██████▋   | 11640/17525 [2:19:42<1:06:13,  1.48it/s] 66%|██████▋   | 11641/17525 [2:19:42<1:03:15,  1.55it/s] 66%|██████▋   | 11642/17525 [2:19:43<1:01:05,  1.61it/s] 66%|██████▋   | 11643/17525 [2:19:44<59:39,  1.64it/s]   66%|██████▋   | 11644/17525 [2:19:45<1:11:05,  1.38it/s] 66%|██████▋   | 11645/17525 [2:19:45<1:06:39,  1.47it/s] 66%|██████▋   | 11646/17525 [2:19:46<1:03:29,  1.54it/s] 66%|██████▋   | 11647/17525 [2:19:46<1:01:17,  1.60it/s] 66%|██████▋   | 11648/17525 [2:19:47<59:45,  1.64it/s]   66%|██████▋   | 11649/17525 [2:19:47<58:37,  1.67it/s] 66%|██████▋   | 11650/17525 [2:19:48<57:52,  1.69it/s]                                                       {'loss': 0.3967, 'grad_norm': 13.577763557434082, 'learning_rate': 5.077912316202146e-06, 'epoch': 16.62}
 66%|██████▋   | 11650/17525 [2:19:48<57:52,  1.69it/s] 66%|██████▋   | 11651/17525 [2:19:49<58:31,  1.67it/s] 66%|██████▋   | 11652/17525 [2:19:49<57:44,  1.70it/s] 66%|██████▋   | 11653/17525 [2:19:50<57:23,  1.71it/s] 66%|██████▋   | 11654/17525 [2:19:50<57:03,  1.72it/s] 67%|██████▋   | 11655/17525 [2:19:51<56:48,  1.72it/s] 67%|██████▋   | 11656/17525 [2:19:51<56:35,  1.73it/s] 67%|██████▋   | 11657/17525 [2:19:52<56:29,  1.73it/s] 67%|██████▋   | 11658/17525 [2:19:53<56:24,  1.73it/s] 67%|██████▋   | 11659/17525 [2:19:53<56:18,  1.74it/s] 67%|██████▋   | 11660/17525 [2:19:54<1:15:08,  1.30it/s]                                                         {'loss': 0.4786, 'grad_norm': 33.861427307128906, 'learning_rate': 5.062297944977219e-06, 'epoch': 16.63}
 67%|██████▋   | 11660/17525 [2:19:54<1:15:08,  1.30it/s] 67%|██████▋   | 11661/17525 [2:19:55<1:19:32,  1.23it/s] 67%|██████▋   | 11662/17525 [2:19:56<1:12:25,  1.35it/s] 67%|██████▋   | 11663/17525 [2:19:56<1:07:31,  1.45it/s] 67%|██████▋   | 11664/17525 [2:19:57<1:04:07,  1.52it/s] 67%|██████▋   | 11665/17525 [2:19:58<1:01:41,  1.58it/s] 67%|██████▋   | 11666/17525 [2:19:58<59:59,  1.63it/s]   67%|██████▋   | 11667/17525 [2:19:59<58:44,  1.66it/s] 67%|██████▋   | 11668/17525 [2:19:59<57:50,  1.69it/s] 67%|██████▋   | 11669/17525 [2:20:00<57:16,  1.70it/s] 67%|██████▋   | 11670/17525 [2:20:00<56:55,  1.71it/s]                                                       {'loss': 0.402, 'grad_norm': 9.169264793395996, 'learning_rate': 5.04669947752936e-06, 'epoch': 16.65}
 67%|██████▋   | 11670/17525 [2:20:00<56:55,  1.71it/s] 67%|██████▋   | 11671/17525 [2:20:01<1:07:16,  1.45it/s] 67%|██████▋   | 11672/17525 [2:20:02<1:04:02,  1.52it/s] 67%|██████▋   | 11673/17525 [2:20:03<1:01:40,  1.58it/s] 67%|██████▋   | 11674/17525 [2:20:03<1:04:16,  1.52it/s] 67%|██████▋   | 11675/17525 [2:20:04<1:01:52,  1.58it/s] 67%|██████▋   | 11676/17525 [2:20:04<1:00:59,  1.60it/s] 67%|██████▋   | 11677/17525 [2:20:05<59:56,  1.63it/s]   67%|██████▋   | 11678/17525 [2:20:06<59:11,  1.65it/s] 67%|██████▋   | 11679/17525 [2:20:06<58:23,  1.67it/s] 67%|██████▋   | 11680/17525 [2:20:07<1:10:55,  1.37it/s]                                                         {'loss': 0.3526, 'grad_norm': 16.264589309692383, 'learning_rate': 5.031116964099459e-06, 'epoch': 16.66}
 67%|██████▋   | 11680/17525 [2:20:07<1:10:55,  1.37it/s] 67%|██████▋   | 11681/17525 [2:20:08<1:06:34,  1.46it/s] 67%|██████▋   | 11682/17525 [2:20:08<1:04:06,  1.52it/s] 67%|██████▋   | 11683/17525 [2:20:09<1:01:42,  1.58it/s] 67%|██████▋   | 11684/17525 [2:20:10<1:00:22,  1.61it/s] 67%|██████▋   | 11685/17525 [2:20:10<59:20,  1.64it/s]   67%|██████▋   | 11686/17525 [2:20:11<58:18,  1.67it/s] 67%|██████▋   | 11687/17525 [2:20:11<57:33,  1.69it/s] 67%|██████▋   | 11688/17525 [2:20:12<57:14,  1.70it/s] 67%|██████▋   | 11689/17525 [2:20:12<56:49,  1.71it/s] 67%|██████▋   | 11690/17525 [2:20:13<56:51,  1.71it/s]                                                       {'loss': 0.3602, 'grad_norm': 9.999673843383789, 'learning_rate': 5.0155504548770195e-06, 'epoch': 16.68}
 67%|██████▋   | 11690/17525 [2:20:13<56:51,  1.71it/s] 67%|██████▋   | 11691/17525 [2:20:14<56:34,  1.72it/s] 67%|██████▋   | 11692/17525 [2:20:14<56:19,  1.73it/s] 67%|██████▋   | 11693/17525 [2:20:15<56:13,  1.73it/s] 67%|██████▋   | 11694/17525 [2:20:15<56:27,  1.72it/s] 67%|██████▋   | 11695/17525 [2:20:16<56:14,  1.73it/s] 67%|██████▋   | 11696/17525 [2:20:17<56:16,  1.73it/s] 67%|██████▋   | 11697/17525 [2:20:17<56:23,  1.72it/s] 67%|██████▋   | 11698/17525 [2:20:18<56:10,  1.73it/s] 67%|██████▋   | 11699/17525 [2:20:18<55:58,  1.73it/s] 67%|██████▋   | 11700/17525 [2:20:19<55:45,  1.74it/s]                                                       {'loss': 0.4094, 'grad_norm': 6.76801872253418, 'learning_rate': 5.000000000000003e-06, 'epoch': 16.69}
 67%|██████▋   | 11700/17525 [2:20:19<55:45,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:23:40,740 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:23:40,741 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:23:40,741 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:03,  5.43it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.70it/s][A
 21%|██        | 4/19 [00:00<00:03,  3.98it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.34it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.60it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.66it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.72it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.79it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.86it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.106545329093933, 'eval_runtime': 4.6279, 'eval_samples_per_second': 95.724, 'eval_steps_per_second': 4.106, 'epoch': 16.69}
 67%|██████▋   | 11700/17525 [2:20:23<55:45,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:23:45,372 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11700
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b54ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 1ebfe835-4a1b-43ee-b3c7-11bd4c7b5ea0)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:23:55,427 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:23:55,429 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11700/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 67%|██████▋   | 11701/17525 [2:20:34<8:12:10,  5.07s/it] 67%|██████▋   | 11702/17525 [2:20:35<6:01:26,  3.72s/it] 67%|██████▋   | 11703/17525 [2:20:36<4:29:41,  2.78s/it] 67%|██████▋   | 11704/17525 [2:20:36<3:25:51,  2.12s/it] 67%|██████▋   | 11705/17525 [2:20:37<2:41:32,  1.67s/it] 67%|██████▋   | 11706/17525 [2:20:37<2:09:40,  1.34s/it] 67%|██████▋   | 11707/17525 [2:20:38<1:47:29,  1.11s/it] 67%|██████▋   | 11708/17525 [2:20:38<1:31:51,  1.06it/s] 67%|██████▋   | 11709/17525 [2:20:39<1:21:03,  1.20it/s] 67%|██████▋   | 11710/17525 [2:20:40<1:13:25,  1.32it/s]                                                         {'loss': 0.3149, 'grad_norm': 11.313129425048828, 'learning_rate': 4.984465649554649e-06, 'epoch': 16.7}
 67%|██████▋   | 11710/17525 [2:20:40<1:13:25,  1.32it/s] 67%|██████▋   | 11711/17525 [2:20:40<1:08:07,  1.42it/s] 67%|██████▋   | 11712/17525 [2:20:41<1:05:01,  1.49it/s] 67%|██████▋   | 11713/17525 [2:20:41<1:02:50,  1.54it/s] 67%|██████▋   | 11714/17525 [2:20:42<1:00:42,  1.60it/s] 67%|██████▋   | 11715/17525 [2:20:43<59:22,  1.63it/s]   67%|██████▋   | 11716/17525 [2:20:43<58:20,  1.66it/s] 67%|██████▋   | 11717/17525 [2:20:44<57:24,  1.69it/s] 67%|██████▋   | 11718/17525 [2:20:44<56:54,  1.70it/s] 67%|██████▋   | 11719/17525 [2:20:45<56:33,  1.71it/s] 67%|██████▋   | 11720/17525 [2:20:45<56:15,  1.72it/s]                                                       {'loss': 0.3854, 'grad_norm': 8.518688201904297, 'learning_rate': 4.968947453575337e-06, 'epoch': 16.72}
 67%|██████▋   | 11720/17525 [2:20:45<56:15,  1.72it/s] 67%|██████▋   | 11721/17525 [2:20:46<56:07,  1.72it/s] 67%|██████▋   | 11722/17525 [2:20:47<55:56,  1.73it/s] 67%|██████▋   | 11723/17525 [2:20:47<56:26,  1.71it/s] 67%|██████▋   | 11724/17525 [2:20:48<56:05,  1.72it/s] 67%|██████▋   | 11725/17525 [2:20:48<55:55,  1.73it/s] 67%|██████▋   | 11726/17525 [2:20:49<55:52,  1.73it/s] 67%|██████▋   | 11727/17525 [2:20:49<56:12,  1.72it/s] 67%|██████▋   | 11728/17525 [2:20:50<55:56,  1.73it/s] 67%|██████▋   | 11729/17525 [2:20:51<57:12,  1.69it/s] 67%|██████▋   | 11730/17525 [2:20:51<56:48,  1.70it/s]                                                       {'loss': 0.3831, 'grad_norm': 15.464177131652832, 'learning_rate': 4.953445462044415e-06, 'epoch': 16.73}
 67%|██████▋   | 11730/17525 [2:20:51<56:48,  1.70it/s] 67%|██████▋   | 11731/17525 [2:20:52<56:27,  1.71it/s] 67%|██████▋   | 11732/17525 [2:20:52<56:13,  1.72it/s] 67%|██████▋   | 11733/17525 [2:20:53<56:44,  1.70it/s] 67%|██████▋   | 11734/17525 [2:20:54<56:27,  1.71it/s] 67%|██████▋   | 11735/17525 [2:20:54<56:07,  1.72it/s] 67%|██████▋   | 11736/17525 [2:20:55<55:55,  1.73it/s] 67%|██████▋   | 11737/17525 [2:20:55<55:48,  1.73it/s] 67%|██████▋   | 11738/17525 [2:20:56<55:43,  1.73it/s] 67%|██████▋   | 11739/17525 [2:20:56<55:39,  1.73it/s] 67%|██████▋   | 11740/17525 [2:20:57<55:35,  1.73it/s]                                                       {'loss': 0.2981, 'grad_norm': 10.713311195373535, 'learning_rate': 4.937959724892035e-06, 'epoch': 16.75}
 67%|██████▋   | 11740/17525 [2:20:57<55:35,  1.73it/s] 67%|██████▋   | 11741/17525 [2:20:58<55:42,  1.73it/s] 67%|██████▋   | 11742/17525 [2:20:58<55:37,  1.73it/s] 67%|██████▋   | 11743/17525 [2:20:59<55:36,  1.73it/s] 67%|██████▋   | 11744/17525 [2:20:59<55:37,  1.73it/s] 67%|██████▋   | 11745/17525 [2:21:00<55:32,  1.73it/s] 67%|██████▋   | 11746/17525 [2:21:01<56:01,  1.72it/s] 67%|██████▋   | 11747/17525 [2:21:01<55:46,  1.73it/s] 67%|██████▋   | 11748/17525 [2:21:02<57:15,  1.68it/s] 67%|██████▋   | 11749/17525 [2:21:03<1:06:38,  1.44it/s] 67%|██████▋   | 11750/17525 [2:21:03<1:04:01,  1.50it/s]                                                         {'loss': 0.3497, 'grad_norm': 11.255224227905273, 'learning_rate': 4.922490291995999e-06, 'epoch': 16.76}
 67%|██████▋   | 11750/17525 [2:21:03<1:04:01,  1.50it/s] 67%|██████▋   | 11751/17525 [2:21:04<1:01:26,  1.57it/s] 67%|██████▋   | 11752/17525 [2:21:04<59:44,  1.61it/s]   67%|██████▋   | 11753/17525 [2:21:05<58:24,  1.65it/s] 67%|██████▋   | 11754/17525 [2:21:06<57:38,  1.67it/s] 67%|██████▋   | 11755/17525 [2:21:06<56:54,  1.69it/s] 67%|██████▋   | 11756/17525 [2:21:07<57:03,  1.69it/s] 67%|██████▋   | 11757/17525 [2:21:07<56:37,  1.70it/s] 67%|██████▋   | 11758/17525 [2:21:08<56:28,  1.70it/s] 67%|██████▋   | 11759/17525 [2:21:08<56:08,  1.71it/s] 67%|██████▋   | 11760/17525 [2:21:09<59:32,  1.61it/s]                                                       {'loss': 0.3916, 'grad_norm': 15.08369255065918, 'learning_rate': 4.907037213181581e-06, 'epoch': 16.78}
 67%|██████▋   | 11760/17525 [2:21:09<59:32,  1.61it/s] 67%|██████▋   | 11761/17525 [2:21:10<59:24,  1.62it/s] 67%|██████▋   | 11762/17525 [2:21:10<58:30,  1.64it/s] 67%|██████▋   | 11763/17525 [2:21:11<57:28,  1.67it/s] 67%|██████▋   | 11764/17525 [2:21:12<56:50,  1.69it/s] 67%|██████▋   | 11765/17525 [2:21:12<56:20,  1.70it/s] 67%|██████▋   | 11766/17525 [2:21:13<56:08,  1.71it/s] 67%|██████▋   | 11767/17525 [2:21:13<55:49,  1.72it/s] 67%|██████▋   | 11768/17525 [2:21:14<56:15,  1.71it/s] 67%|██████▋   | 11769/17525 [2:21:14<55:58,  1.71it/s] 67%|██████▋   | 11770/17525 [2:21:15<55:52,  1.72it/s]                                                       {'loss': 0.3311, 'grad_norm': 7.316864967346191, 'learning_rate': 4.891600538221407e-06, 'epoch': 16.79}
 67%|██████▋   | 11770/17525 [2:21:15<55:52,  1.72it/s] 67%|██████▋   | 11771/17525 [2:21:16<55:44,  1.72it/s] 67%|██████▋   | 11772/17525 [2:21:16<56:16,  1.70it/s] 67%|██████▋   | 11773/17525 [2:21:17<55:58,  1.71it/s] 67%|██████▋   | 11774/17525 [2:21:17<55:39,  1.72it/s] 67%|██████▋   | 11775/17525 [2:21:18<55:30,  1.73it/s] 67%|██████▋   | 11776/17525 [2:21:18<55:27,  1.73it/s] 67%|██████▋   | 11777/17525 [2:21:19<55:21,  1.73it/s] 67%|██████▋   | 11778/17525 [2:21:20<55:18,  1.73it/s] 67%|██████▋   | 11779/17525 [2:21:20<55:19,  1.73it/s] 67%|██████▋   | 11780/17525 [2:21:21<55:26,  1.73it/s]                                                       {'loss': 0.3106, 'grad_norm': 14.255607604980469, 'learning_rate': 4.876180316835241e-06, 'epoch': 16.8}
 67%|██████▋   | 11780/17525 [2:21:21<55:26,  1.73it/s] 67%|██████▋   | 11781/17525 [2:21:21<55:30,  1.72it/s] 67%|██████▋   | 11782/17525 [2:21:22<55:18,  1.73it/s] 67%|██████▋   | 11783/17525 [2:21:23<1:04:33,  1.48it/s] 67%|██████▋   | 11784/17525 [2:21:24<1:19:22,  1.21it/s] 67%|██████▋   | 11785/17525 [2:21:25<1:12:00,  1.33it/s] 67%|██████▋   | 11786/17525 [2:21:25<1:06:55,  1.43it/s] 67%|██████▋   | 11787/17525 [2:21:26<1:03:30,  1.51it/s] 67%|██████▋   | 11788/17525 [2:21:26<1:00:58,  1.57it/s] 67%|██████▋   | 11789/17525 [2:21:27<1:00:23,  1.58it/s] 67%|██████▋   | 11790/17525 [2:21:28<58:45,  1.63it/s]                                                         {'loss': 0.3787, 'grad_norm': 4.131056785583496, 'learning_rate': 4.860776598689866e-06, 'epoch': 16.82}
 67%|██████▋   | 11790/17525 [2:21:28<58:45,  1.63it/s] 67%|██████▋   | 11791/17525 [2:21:28<57:45,  1.65it/s] 67%|██████▋   | 11792/17525 [2:21:29<56:55,  1.68it/s] 67%|██████▋   | 11793/17525 [2:21:29<56:31,  1.69it/s] 67%|██████▋   | 11794/17525 [2:21:30<56:07,  1.70it/s] 67%|██████▋   | 11795/17525 [2:21:30<55:48,  1.71it/s] 67%|██████▋   | 11796/17525 [2:21:31<55:36,  1.72it/s] 67%|██████▋   | 11797/17525 [2:21:32<55:26,  1.72it/s] 67%|██████▋   | 11798/17525 [2:21:32<55:16,  1.73it/s] 67%|██████▋   | 11799/17525 [2:21:33<55:13,  1.73it/s] 67%|██████▋   | 11800/17525 [2:21:33<55:03,  1.73it/s]                                                       {'loss': 0.4811, 'grad_norm': 7.687560558319092, 'learning_rate': 4.845389433398908e-06, 'epoch': 16.83}
 67%|██████▋   | 11800/17525 [2:21:33<55:03,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:24:55,221 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:24:55,221 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:24:55,221 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.0989090204238892, 'eval_runtime': 4.6004, 'eval_samples_per_second': 96.295, 'eval_steps_per_second': 4.13, 'epoch': 16.83}
 67%|██████▋   | 11800/17525 [2:21:38<55:03,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 67%|██████▋   | 11801/17525 [2:21:39<3:06:57,  1.96s/it] 67%|██████▋   | 11802/17525 [2:21:39<2:27:18,  1.54s/it] 67%|██████▋   | 11803/17525 [2:21:40<1:59:37,  1.25s/it] 67%|██████▋   | 11804/17525 [2:21:40<1:40:18,  1.05s/it] 67%|██████▋   | 11805/17525 [2:21:41<1:26:46,  1.10it/s] 67%|██████▋   | 11806/17525 [2:21:41<1:17:18,  1.23it/s] 67%|██████▋   | 11807/17525 [2:21:42<1:10:36,  1.35it/s] 67%|██████▋   | 11808/17525 [2:21:43<1:05:59,  1.44it/s] 67%|██████▋   | 11809/17525 [2:21:43<1:03:16,  1.51it/s] 67%|██████▋   | 11810/17525 [2:21:44<1:04:56,  1.47it/s]                                                         {'loss': 0.3386, 'grad_norm': 11.54041862487793, 'learning_rate': 4.830018870522678e-06, 'epoch': 16.85}
 67%|██████▋   | 11810/17525 [2:21:44<1:04:56,  1.47it/s] 67%|██████▋   | 11811/17525 [2:21:44<1:02:06,  1.53it/s] 67%|██████▋   | 11812/17525 [2:21:45<1:00:00,  1.59it/s] 67%|██████▋   | 11813/17525 [2:21:46<58:22,  1.63it/s]   67%|██████▋   | 11814/17525 [2:21:46<57:45,  1.65it/s] 67%|██████▋   | 11815/17525 [2:21:47<56:49,  1.67it/s] 67%|██████▋   | 11816/17525 [2:21:47<56:12,  1.69it/s] 67%|██████▋   | 11817/17525 [2:21:48<55:38,  1.71it/s] 67%|██████▋   | 11818/17525 [2:21:49<55:24,  1.72it/s] 67%|██████▋   | 11819/17525 [2:21:49<1:05:11,  1.46it/s] 67%|██████▋   | 11820/17525 [2:21:50<1:02:02,  1.53it/s]                                                         {'loss': 0.4206, 'grad_norm': 33.070518493652344, 'learning_rate': 4.8146649595680104e-06, 'epoch': 16.86}
 67%|██████▋   | 11820/17525 [2:21:50<1:02:02,  1.53it/s] 67%|██████▋   | 11821/17525 [2:21:51<59:48,  1.59it/s]   67%|██████▋   | 11822/17525 [2:21:51<58:13,  1.63it/s] 67%|██████▋   | 11823/17525 [2:21:52<57:02,  1.67it/s] 67%|██████▋   | 11824/17525 [2:21:52<56:15,  1.69it/s] 67%|██████▋   | 11825/17525 [2:21:53<55:44,  1.70it/s] 67%|██████▋   | 11826/17525 [2:21:53<55:15,  1.72it/s] 67%|██████▋   | 11827/17525 [2:21:54<55:19,  1.72it/s] 67%|██████▋   | 11828/17525 [2:21:55<55:08,  1.72it/s] 67%|██████▋   | 11829/17525 [2:21:55<55:01,  1.73it/s] 68%|██████▊   | 11830/17525 [2:21:56<55:01,  1.72it/s]                                                       {'loss': 0.3915, 'grad_norm': 10.805294036865234, 'learning_rate': 4.799327749988113e-06, 'epoch': 16.88}
 68%|██████▊   | 11830/17525 [2:21:56<55:01,  1.72it/s] 68%|██████▊   | 11831/17525 [2:21:56<54:59,  1.73it/s] 68%|██████▊   | 11832/17525 [2:21:57<54:53,  1.73it/s] 68%|██████▊   | 11833/17525 [2:21:58<55:13,  1.72it/s] 68%|██████▊   | 11834/17525 [2:21:58<55:02,  1.72it/s] 68%|██████▊   | 11835/17525 [2:21:59<59:07,  1.60it/s] 68%|██████▊   | 11836/17525 [2:21:59<57:43,  1.64it/s] 68%|██████▊   | 11837/17525 [2:22:00<56:45,  1.67it/s] 68%|██████▊   | 11838/17525 [2:22:01<56:05,  1.69it/s] 68%|██████▊   | 11839/17525 [2:22:01<55:35,  1.70it/s] 68%|██████▊   | 11840/17525 [2:22:02<55:10,  1.72it/s]                                                       {'loss': 0.4622, 'grad_norm': 13.18381118774414, 'learning_rate': 4.784007291182385e-06, 'epoch': 16.89}
 68%|██████▊   | 11840/17525 [2:22:02<55:10,  1.72it/s] 68%|██████▊   | 11841/17525 [2:22:03<1:05:01,  1.46it/s] 68%|██████▊   | 11842/17525 [2:22:03<1:01:54,  1.53it/s] 68%|██████▊   | 11843/17525 [2:22:04<59:36,  1.59it/s]   68%|██████▊   | 11844/17525 [2:22:04<57:59,  1.63it/s] 68%|██████▊   | 11845/17525 [2:22:05<56:51,  1.66it/s] 68%|██████▊   | 11846/17525 [2:22:05<56:12,  1.68it/s] 68%|██████▊   | 11847/17525 [2:22:06<59:05,  1.60it/s] 68%|██████▊   | 11848/17525 [2:22:07<58:18,  1.62it/s] 68%|██████▊   | 11849/17525 [2:22:07<57:10,  1.65it/s] 68%|██████▊   | 11850/17525 [2:22:08<56:15,  1.68it/s]                                                       {'loss': 0.3303, 'grad_norm': 11.470691680908203, 'learning_rate': 4.768703632496288e-06, 'epoch': 16.9}
 68%|██████▊   | 11850/17525 [2:22:08<56:15,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 04:25:29,825 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11850
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bdd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: fac32d49-109c-47c1-a2b1-93287f8dafda)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:25:39,881 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:25:39,883 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-11850/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 68%|██████▊   | 11851/17525 [2:22:19<5:49:49,  3.70s/it] 68%|██████▊   | 11852/17525 [2:22:19<4:21:21,  2.76s/it] 68%|██████▊   | 11853/17525 [2:22:20<3:19:16,  2.11s/it] 68%|██████▊   | 11854/17525 [2:22:21<2:35:51,  1.65s/it] 68%|██████▊   | 11855/17525 [2:22:21<2:05:28,  1.33s/it] 68%|██████▊   | 11856/17525 [2:22:22<1:44:06,  1.10s/it] 68%|██████▊   | 11857/17525 [2:22:22<1:29:08,  1.06it/s] 68%|██████▊   | 11858/17525 [2:22:23<1:18:42,  1.20it/s] 68%|██████▊   | 11859/17525 [2:22:23<1:11:20,  1.32it/s] 68%|██████▊   | 11860/17525 [2:22:24<1:06:14,  1.43it/s]                                                         {'loss': 0.379, 'grad_norm': 11.558510780334473, 'learning_rate': 4.753416823221166e-06, 'epoch': 16.92}
 68%|██████▊   | 11860/17525 [2:22:24<1:06:14,  1.43it/s] 68%|██████▊   | 11861/17525 [2:22:25<1:03:11,  1.49it/s] 68%|██████▊   | 11862/17525 [2:22:25<1:00:26,  1.56it/s] 68%|██████▊   | 11863/17525 [2:22:26<58:32,  1.61it/s]   68%|██████▊   | 11864/17525 [2:22:26<57:10,  1.65it/s] 68%|██████▊   | 11865/17525 [2:22:27<56:10,  1.68it/s] 68%|██████▊   | 11866/17525 [2:22:28<55:38,  1.69it/s] 68%|██████▊   | 11867/17525 [2:22:28<55:11,  1.71it/s] 68%|██████▊   | 11868/17525 [2:22:29<54:47,  1.72it/s] 68%|██████▊   | 11869/17525 [2:22:29<54:34,  1.73it/s] 68%|██████▊   | 11870/17525 [2:22:30<54:20,  1.73it/s]                                                       {'loss': 0.4113, 'grad_norm': 6.596225738525391, 'learning_rate': 4.738146912594095e-06, 'epoch': 16.93}
 68%|██████▊   | 11870/17525 [2:22:30<54:20,  1.73it/s] 68%|██████▊   | 11871/17525 [2:22:30<54:20,  1.73it/s] 68%|██████▊   | 11872/17525 [2:22:31<54:15,  1.74it/s] 68%|██████▊   | 11873/17525 [2:22:32<54:13,  1.74it/s] 68%|██████▊   | 11874/17525 [2:22:32<54:10,  1.74it/s] 68%|██████▊   | 11875/17525 [2:22:33<54:07,  1.74it/s] 68%|██████▊   | 11876/17525 [2:22:33<54:00,  1.74it/s] 68%|██████▊   | 11877/17525 [2:22:34<54:02,  1.74it/s] 68%|██████▊   | 11878/17525 [2:22:34<54:00,  1.74it/s] 68%|██████▊   | 11879/17525 [2:22:35<53:52,  1.75it/s] 68%|██████▊   | 11880/17525 [2:22:36<54:04,  1.74it/s]                                                       {'loss': 0.3083, 'grad_norm': 11.53213882446289, 'learning_rate': 4.722893949797725e-06, 'epoch': 16.95}
 68%|██████▊   | 11880/17525 [2:22:36<54:04,  1.74it/s] 68%|██████▊   | 11881/17525 [2:22:36<54:14,  1.73it/s] 68%|██████▊   | 11882/17525 [2:22:37<54:07,  1.74it/s] 68%|██████▊   | 11883/17525 [2:22:37<54:28,  1.73it/s] 68%|██████▊   | 11884/17525 [2:22:38<54:20,  1.73it/s] 68%|██████▊   | 11885/17525 [2:22:38<54:11,  1.73it/s] 68%|██████▊   | 11886/17525 [2:22:39<54:08,  1.74it/s] 68%|██████▊   | 11887/17525 [2:22:40<53:57,  1.74it/s] 68%|██████▊   | 11888/17525 [2:22:40<53:55,  1.74it/s] 68%|██████▊   | 11889/17525 [2:22:41<53:47,  1.75it/s] 68%|██████▊   | 11890/17525 [2:22:41<53:41,  1.75it/s]                                                       {'loss': 0.3269, 'grad_norm': 15.078261375427246, 'learning_rate': 4.707657983960102e-06, 'epoch': 16.96}
 68%|██████▊   | 11890/17525 [2:22:41<53:41,  1.75it/s] 68%|██████▊   | 11891/17525 [2:22:42<53:50,  1.74it/s] 68%|██████▊   | 11892/17525 [2:22:43<1:15:56,  1.24it/s] 68%|██████▊   | 11893/17525 [2:22:44<1:09:22,  1.35it/s] 68%|██████▊   | 11894/17525 [2:22:44<1:04:35,  1.45it/s] 68%|██████▊   | 11895/17525 [2:22:45<1:01:30,  1.53it/s] 68%|██████▊   | 11896/17525 [2:22:46<59:18,  1.58it/s]   68%|██████▊   | 11897/17525 [2:22:46<57:43,  1.63it/s] 68%|██████▊   | 11898/17525 [2:22:47<56:34,  1.66it/s] 68%|██████▊   | 11899/17525 [2:22:47<55:52,  1.68it/s] 68%|██████▊   | 11900/17525 [2:22:48<55:18,  1.70it/s]                                                       {'loss': 0.3444, 'grad_norm': 4.951507568359375, 'learning_rate': 4.692439064154559e-06, 'epoch': 16.98}
 68%|██████▊   | 11900/17525 [2:22:48<55:18,  1.70it/s][INFO|trainer.py:3512] 2024-06-25 04:26:09,742 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:26:09,743 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:26:09,743 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.65it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.106743335723877, 'eval_runtime': 4.5895, 'eval_samples_per_second': 96.525, 'eval_steps_per_second': 4.14, 'epoch': 16.98}
 68%|██████▊   | 11900/17525 [2:22:52<55:18,  1.70it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 68%|██████▊   | 11901/17525 [2:22:53<3:04:07,  1.96s/it] 68%|██████▊   | 11902/17525 [2:22:54<2:25:43,  1.55s/it] 68%|██████▊   | 11903/17525 [2:22:54<1:58:05,  1.26s/it] 68%|██████▊   | 11904/17525 [2:22:55<1:38:52,  1.06s/it] 68%|██████▊   | 11905/17525 [2:22:55<1:25:57,  1.09it/s] 68%|██████▊   | 11906/17525 [2:22:56<1:16:23,  1.23it/s] 68%|██████▊   | 11907/17525 [2:22:57<1:09:42,  1.34it/s] 68%|██████▊   | 11908/17525 [2:22:57<1:04:59,  1.44it/s] 68%|██████▊   | 11909/17525 [2:22:58<1:01:35,  1.52it/s] 68%|██████▊   | 11910/17525 [2:22:58<59:16,  1.58it/s]                                                         {'loss': 0.4087, 'grad_norm': 17.692537307739258, 'learning_rate': 4.6772372393994895e-06, 'epoch': 16.99}
 68%|██████▊   | 11910/17525 [2:22:58<59:16,  1.58it/s] 68%|██████▊   | 11911/17525 [2:22:59<57:35,  1.62it/s] 68%|██████▊   | 11912/17525 [2:22:59<56:23,  1.66it/s] 68%|██████▊   | 11913/17525 [2:23:00<55:34,  1.68it/s] 68%|██████▊   | 11914/17525 [2:23:01<54:54,  1.70it/s] 68%|██████▊   | 11915/17525 [2:23:01<54:36,  1.71it/s] 68%|██████▊   | 11916/17525 [2:23:02<1:00:31,  1.54it/s] 68%|██████▊   | 11917/17525 [2:23:02<58:23,  1.60it/s]   68%|██████▊   | 11918/17525 [2:23:03<57:12,  1.63it/s] 68%|██████▊   | 11919/17525 [2:23:04<56:07,  1.66it/s] 68%|██████▊   | 11920/17525 [2:23:04<55:15,  1.69it/s]                                                       {'loss': 0.3236, 'grad_norm': 6.227060794830322, 'learning_rate': 4.662052558658259e-06, 'epoch': 17.0}
 68%|██████▊   | 11920/17525 [2:23:04<55:15,  1.69it/s] 68%|██████▊   | 11921/17525 [2:23:05<1:08:36,  1.36it/s] 68%|██████▊   | 11922/17525 [2:23:06<1:04:01,  1.46it/s] 68%|██████▊   | 11923/17525 [2:23:06<1:01:39,  1.51it/s] 68%|██████▊   | 11924/17525 [2:23:08<1:13:12,  1.28it/s] 68%|██████▊   | 11925/17525 [2:23:08<1:07:30,  1.38it/s] 68%|██████▊   | 11926/17525 [2:23:09<1:03:21,  1.47it/s] 68%|██████▊   | 11927/17525 [2:23:09<1:00:30,  1.54it/s] 68%|██████▊   | 11928/17525 [2:23:10<58:24,  1.60it/s]   68%|██████▊   | 11929/17525 [2:23:10<56:53,  1.64it/s] 68%|██████▊   | 11930/17525 [2:23:11<55:53,  1.67it/s]                                                       {'loss': 0.3597, 'grad_norm': 6.9602251052856445, 'learning_rate': 4.646885070838986e-06, 'epoch': 17.02}
 68%|██████▊   | 11930/17525 [2:23:11<55:53,  1.67it/s] 68%|██████▊   | 11931/17525 [2:23:12<55:36,  1.68it/s] 68%|██████▊   | 11932/17525 [2:23:12<55:02,  1.69it/s] 68%|██████▊   | 11933/17525 [2:23:13<54:41,  1.70it/s] 68%|██████▊   | 11934/17525 [2:23:13<54:26,  1.71it/s] 68%|██████▊   | 11935/17525 [2:23:14<54:09,  1.72it/s] 68%|██████▊   | 11936/17525 [2:23:14<53:58,  1.73it/s] 68%|██████▊   | 11937/17525 [2:23:15<53:48,  1.73it/s] 68%|██████▊   | 11938/17525 [2:23:16<53:44,  1.73it/s] 68%|██████▊   | 11939/17525 [2:23:16<53:43,  1.73it/s] 68%|██████▊   | 11940/17525 [2:23:17<53:39,  1.73it/s]                                                       {'loss': 0.4278, 'grad_norm': 11.882519721984863, 'learning_rate': 4.631734824794428e-06, 'epoch': 17.03}
 68%|██████▊   | 11940/17525 [2:23:17<53:39,  1.73it/s] 68%|██████▊   | 11941/17525 [2:23:17<53:43,  1.73it/s] 68%|██████▊   | 11942/17525 [2:23:18<53:43,  1.73it/s] 68%|██████▊   | 11943/17525 [2:23:18<53:39,  1.73it/s] 68%|██████▊   | 11944/17525 [2:23:19<54:02,  1.72it/s] 68%|██████▊   | 11945/17525 [2:23:20<53:59,  1.72it/s] 68%|██████▊   | 11946/17525 [2:23:20<53:49,  1.73it/s] 68%|██████▊   | 11947/17525 [2:23:21<53:46,  1.73it/s] 68%|██████▊   | 11948/17525 [2:23:21<53:44,  1.73it/s] 68%|██████▊   | 11949/17525 [2:23:22<53:39,  1.73it/s] 68%|██████▊   | 11950/17525 [2:23:23<53:37,  1.73it/s]                                                       {'loss': 0.3799, 'grad_norm': 21.130308151245117, 'learning_rate': 4.616601869321807e-06, 'epoch': 17.05}
 68%|██████▊   | 11950/17525 [2:23:23<53:37,  1.73it/s] 68%|██████▊   | 11951/17525 [2:23:23<53:37,  1.73it/s] 68%|██████▊   | 11952/17525 [2:23:24<53:34,  1.73it/s] 68%|██████▊   | 11953/17525 [2:23:24<53:27,  1.74it/s] 68%|██████▊   | 11954/17525 [2:23:25<53:24,  1.74it/s] 68%|██████▊   | 11955/17525 [2:23:25<53:25,  1.74it/s] 68%|██████▊   | 11956/17525 [2:23:26<53:25,  1.74it/s] 68%|██████▊   | 11957/17525 [2:23:27<53:54,  1.72it/s] 68%|██████▊   | 11958/17525 [2:23:27<53:47,  1.72it/s] 68%|██████▊   | 11959/17525 [2:23:28<54:34,  1.70it/s] 68%|██████▊   | 11960/17525 [2:23:28<54:53,  1.69it/s]                                                       {'loss': 0.4377, 'grad_norm': 8.811655044555664, 'learning_rate': 4.601486253162651e-06, 'epoch': 17.06}
 68%|██████▊   | 11960/17525 [2:23:28<54:53,  1.69it/s] 68%|██████▊   | 11961/17525 [2:23:29<59:49,  1.55it/s] 68%|██████▊   | 11962/17525 [2:23:30<57:55,  1.60it/s] 68%|██████▊   | 11963/17525 [2:23:30<56:32,  1.64it/s] 68%|██████▊   | 11964/17525 [2:23:31<55:33,  1.67it/s] 68%|██████▊   | 11965/17525 [2:23:31<54:52,  1.69it/s] 68%|██████▊   | 11966/17525 [2:23:32<54:17,  1.71it/s] 68%|██████▊   | 11967/17525 [2:23:33<53:52,  1.72it/s] 68%|██████▊   | 11968/17525 [2:23:33<53:43,  1.72it/s] 68%|██████▊   | 11969/17525 [2:23:34<54:14,  1.71it/s] 68%|██████▊   | 11970/17525 [2:23:34<53:56,  1.72it/s]                                                       {'loss': 0.3241, 'grad_norm': 10.436858177185059, 'learning_rate': 4.586388025002647e-06, 'epoch': 17.08}
 68%|██████▊   | 11970/17525 [2:23:34<53:56,  1.72it/s] 68%|██████▊   | 11971/17525 [2:23:35<53:47,  1.72it/s] 68%|██████▊   | 11972/17525 [2:23:35<53:34,  1.73it/s] 68%|██████▊   | 11973/17525 [2:23:36<53:20,  1.73it/s] 68%|██████▊   | 11974/17525 [2:23:37<53:15,  1.74it/s] 68%|██████▊   | 11975/17525 [2:23:37<53:05,  1.74it/s] 68%|██████▊   | 11976/17525 [2:23:38<53:05,  1.74it/s] 68%|██████▊   | 11977/17525 [2:23:38<53:10,  1.74it/s] 68%|██████▊   | 11978/17525 [2:23:39<58:08,  1.59it/s] 68%|██████▊   | 11979/17525 [2:23:40<56:40,  1.63it/s] 68%|██████▊   | 11980/17525 [2:23:40<55:36,  1.66it/s]                                                       {'loss': 0.433, 'grad_norm': 8.670056343078613, 'learning_rate': 4.571307233471464e-06, 'epoch': 17.09}
 68%|██████▊   | 11980/17525 [2:23:40<55:36,  1.66it/s] 68%|██████▊   | 11981/17525 [2:23:41<54:51,  1.68it/s] 68%|██████▊   | 11982/17525 [2:23:41<54:14,  1.70it/s] 68%|██████▊   | 11983/17525 [2:23:42<53:47,  1.72it/s] 68%|██████▊   | 11984/17525 [2:23:43<57:25,  1.61it/s] 68%|██████▊   | 11985/17525 [2:23:43<56:05,  1.65it/s] 68%|██████▊   | 11986/17525 [2:23:44<55:07,  1.67it/s] 68%|██████▊   | 11987/17525 [2:23:44<54:29,  1.69it/s] 68%|██████▊   | 11988/17525 [2:23:45<54:04,  1.71it/s] 68%|██████▊   | 11989/17525 [2:23:46<53:38,  1.72it/s] 68%|██████▊   | 11990/17525 [2:23:46<53:33,  1.72it/s]                                                       {'loss': 0.3527, 'grad_norm': 9.558023452758789, 'learning_rate': 4.556243927142619e-06, 'epoch': 17.1}
 68%|██████▊   | 11990/17525 [2:23:46<53:33,  1.72it/s] 68%|██████▊   | 11991/17525 [2:23:47<53:25,  1.73it/s] 68%|██████▊   | 11992/17525 [2:23:47<53:50,  1.71it/s] 68%|██████▊   | 11993/17525 [2:23:48<58:57,  1.56it/s] 68%|██████▊   | 11994/17525 [2:23:49<1:02:04,  1.48it/s] 68%|██████▊   | 11995/17525 [2:23:49<1:00:07,  1.53it/s] 68%|██████▊   | 11996/17525 [2:23:50<57:52,  1.59it/s]   68%|██████▊   | 11997/17525 [2:23:51<56:25,  1.63it/s] 68%|██████▊   | 11998/17525 [2:23:52<1:07:29,  1.36it/s] 68%|██████▊   | 11999/17525 [2:23:52<1:08:09,  1.35it/s] 68%|██████▊   | 12000/17525 [2:23:53<1:03:30,  1.45it/s]                                                         {'loss': 0.5093, 'grad_norm': 7.834928035736084, 'learning_rate': 4.541198154533312e-06, 'epoch': 17.12}
 68%|██████▊   | 12000/17525 [2:23:53<1:03:30,  1.45it/s][INFO|trainer.py:3512] 2024-06-25 04:27:14,818 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:27:14,818 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:27:14,818 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                         
                                               [A{'eval_loss': 1.1066339015960693, 'eval_runtime': 4.6016, 'eval_samples_per_second': 96.272, 'eval_steps_per_second': 4.129, 'epoch': 17.12}
 68%|██████▊   | 12000/17525 [2:23:58<1:03:30,  1.45it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:27:19,423 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12000
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7be5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6deca582-281e-4859-bc43-adacadb68c9a)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:27:29,478 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:27:29,481 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12000/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 68%|██████▊   | 12001/17525 [2:24:08<7:49:11,  5.10s/it] 68%|██████▊   | 12002/17525 [2:24:09<5:44:23,  3.74s/it] 68%|██████▊   | 12003/17525 [2:24:09<4:16:55,  2.79s/it] 68%|██████▊   | 12004/17525 [2:24:10<3:15:30,  2.12s/it] 69%|██████▊   | 12005/17525 [2:24:11<2:32:39,  1.66s/it] 69%|██████▊   | 12006/17525 [2:24:11<2:02:44,  1.33s/it] 69%|██████▊   | 12007/17525 [2:24:12<1:41:47,  1.11s/it] 69%|██████▊   | 12008/17525 [2:24:12<1:27:05,  1.06it/s] 69%|██████▊   | 12009/17525 [2:24:13<1:16:54,  1.20it/s] 69%|██████▊   | 12010/17525 [2:24:13<1:09:39,  1.32it/s]                                                         {'loss': 0.3929, 'grad_norm': 10.864151000976562, 'learning_rate': 4.526169964104264e-06, 'epoch': 17.13}
 69%|██████▊   | 12010/17525 [2:24:13<1:09:39,  1.32it/s] 69%|██████▊   | 12011/17525 [2:24:14<1:04:36,  1.42it/s] 69%|██████▊   | 12012/17525 [2:24:15<1:01:06,  1.50it/s] 69%|██████▊   | 12013/17525 [2:24:15<58:30,  1.57it/s]   69%|██████▊   | 12014/17525 [2:24:16<1:06:31,  1.38it/s] 69%|██████▊   | 12015/17525 [2:24:17<1:02:34,  1.47it/s] 69%|██████▊   | 12016/17525 [2:24:17<59:40,  1.54it/s]   69%|██████▊   | 12017/17525 [2:24:18<57:39,  1.59it/s] 69%|██████▊   | 12018/17525 [2:24:18<56:09,  1.63it/s] 69%|██████▊   | 12019/17525 [2:24:19<55:07,  1.66it/s] 69%|██████▊   | 12020/17525 [2:24:20<54:27,  1.68it/s]                                                       {'loss': 0.3588, 'grad_norm': 9.459837913513184, 'learning_rate': 4.51115940425957e-06, 'epoch': 17.15}
 69%|██████▊   | 12020/17525 [2:24:20<54:27,  1.68it/s] 69%|██████▊   | 12021/17525 [2:24:20<53:54,  1.70it/s] 69%|██████▊   | 12022/17525 [2:24:21<53:36,  1.71it/s] 69%|██████▊   | 12023/17525 [2:24:21<53:21,  1.72it/s] 69%|██████▊   | 12024/17525 [2:24:22<53:13,  1.72it/s] 69%|██████▊   | 12025/17525 [2:24:22<53:05,  1.73it/s] 69%|██████▊   | 12026/17525 [2:24:23<52:54,  1.73it/s] 69%|██████▊   | 12027/17525 [2:24:24<52:46,  1.74it/s] 69%|██████▊   | 12028/17525 [2:24:24<52:46,  1.74it/s] 69%|██████▊   | 12029/17525 [2:24:25<52:42,  1.74it/s] 69%|██████▊   | 12030/17525 [2:24:25<52:40,  1.74it/s]                                                       {'loss': 0.3837, 'grad_norm': 12.13105297088623, 'learning_rate': 4.49616652334654e-06, 'epoch': 17.16}
 69%|██████▊   | 12030/17525 [2:24:25<52:40,  1.74it/s] 69%|██████▊   | 12031/17525 [2:24:26<52:53,  1.73it/s] 69%|██████▊   | 12032/17525 [2:24:27<56:30,  1.62it/s] 69%|██████▊   | 12033/17525 [2:24:27<55:40,  1.64it/s] 69%|██████▊   | 12034/17525 [2:24:28<54:45,  1.67it/s] 69%|██████▊   | 12035/17525 [2:24:28<54:02,  1.69it/s] 69%|██████▊   | 12036/17525 [2:24:29<1:02:15,  1.47it/s] 69%|██████▊   | 12037/17525 [2:24:30<59:14,  1.54it/s]   69%|██████▊   | 12038/17525 [2:24:30<57:07,  1.60it/s] 69%|██████▊   | 12039/17525 [2:24:31<55:46,  1.64it/s] 69%|██████▊   | 12040/17525 [2:24:32<54:47,  1.67it/s]                                                       {'loss': 0.3176, 'grad_norm': 6.1925554275512695, 'learning_rate': 4.481191369655528e-06, 'epoch': 17.18}
 69%|██████▊   | 12040/17525 [2:24:32<54:47,  1.67it/s] 69%|██████▊   | 12041/17525 [2:24:32<54:13,  1.69it/s] 69%|██████▊   | 12042/17525 [2:24:33<53:34,  1.71it/s] 69%|██████▊   | 12043/17525 [2:24:33<53:17,  1.71it/s] 69%|██████▊   | 12044/17525 [2:24:34<53:01,  1.72it/s] 69%|██████▊   | 12045/17525 [2:24:34<53:07,  1.72it/s] 69%|██████▊   | 12046/17525 [2:24:35<52:59,  1.72it/s] 69%|██████▊   | 12047/17525 [2:24:36<53:00,  1.72it/s] 69%|██████▊   | 12048/17525 [2:24:36<52:52,  1.73it/s] 69%|██████▉   | 12049/17525 [2:24:37<52:46,  1.73it/s] 69%|██████▉   | 12050/17525 [2:24:38<1:02:46,  1.45it/s]                                                         {'loss': 0.3585, 'grad_norm': 6.4966278076171875, 'learning_rate': 4.466233991419817e-06, 'epoch': 17.19}
 69%|██████▉   | 12050/17525 [2:24:38<1:02:46,  1.45it/s] 69%|██████▉   | 12051/17525 [2:24:38<1:00:16,  1.51it/s] 69%|██████▉   | 12052/17525 [2:24:39<58:44,  1.55it/s]   69%|██████▉   | 12053/17525 [2:24:39<56:49,  1.60it/s] 69%|██████▉   | 12054/17525 [2:24:40<55:31,  1.64it/s] 69%|██████▉   | 12055/17525 [2:24:41<54:30,  1.67it/s] 69%|██████▉   | 12056/17525 [2:24:41<53:55,  1.69it/s] 69%|██████▉   | 12057/17525 [2:24:42<53:24,  1.71it/s] 69%|██████▉   | 12058/17525 [2:24:42<53:05,  1.72it/s] 69%|██████▉   | 12059/17525 [2:24:43<53:03,  1.72it/s] 69%|██████▉   | 12060/17525 [2:24:43<52:45,  1.73it/s]                                                       {'loss': 0.329, 'grad_norm': 8.316664695739746, 'learning_rate': 4.451294436815412e-06, 'epoch': 17.2}
 69%|██████▉   | 12060/17525 [2:24:43<52:45,  1.73it/s] 69%|██████▉   | 12061/17525 [2:24:44<52:42,  1.73it/s] 69%|██████▉   | 12062/17525 [2:24:45<52:34,  1.73it/s] 69%|██████▉   | 12063/17525 [2:24:45<52:22,  1.74it/s] 69%|██████▉   | 12064/17525 [2:24:46<52:16,  1.74it/s] 69%|██████▉   | 12065/17525 [2:24:46<52:10,  1.74it/s] 69%|██████▉   | 12066/17525 [2:24:47<52:12,  1.74it/s] 69%|██████▉   | 12067/17525 [2:24:48<52:12,  1.74it/s] 69%|██████▉   | 12068/17525 [2:24:48<52:16,  1.74it/s] 69%|██████▉   | 12069/17525 [2:24:49<52:16,  1.74it/s] 69%|██████▉   | 12070/17525 [2:24:50<1:01:46,  1.47it/s]                                                         {'loss': 0.3428, 'grad_norm': 16.137060165405273, 'learning_rate': 4.436372753960922e-06, 'epoch': 17.22}
 69%|██████▉   | 12070/17525 [2:24:50<1:01:46,  1.47it/s] 69%|██████▉   | 12071/17525 [2:24:51<1:08:57,  1.32it/s] 69%|██████▉   | 12072/17525 [2:24:51<1:04:00,  1.42it/s] 69%|██████▉   | 12073/17525 [2:24:52<1:00:34,  1.50it/s] 69%|██████▉   | 12074/17525 [2:24:52<58:13,  1.56it/s]   69%|██████▉   | 12075/17525 [2:24:53<56:28,  1.61it/s] 69%|██████▉   | 12076/17525 [2:24:53<55:21,  1.64it/s] 69%|██████▉   | 12077/17525 [2:24:54<54:35,  1.66it/s] 69%|██████▉   | 12078/17525 [2:24:55<54:05,  1.68it/s] 69%|██████▉   | 12079/17525 [2:24:55<53:36,  1.69it/s] 69%|██████▉   | 12080/17525 [2:24:56<53:13,  1.70it/s]                                                       {'loss': 0.2695, 'grad_norm': 55.92970275878906, 'learning_rate': 4.421468990917392e-06, 'epoch': 17.23}
 69%|██████▉   | 12080/17525 [2:24:56<53:13,  1.70it/s] 69%|██████▉   | 12081/17525 [2:24:56<53:01,  1.71it/s] 69%|██████▉   | 12082/17525 [2:24:57<52:44,  1.72it/s] 69%|██████▉   | 12083/17525 [2:24:57<52:39,  1.72it/s] 69%|██████▉   | 12084/17525 [2:24:58<52:32,  1.73it/s] 69%|██████▉   | 12085/17525 [2:24:59<52:25,  1.73it/s] 69%|██████▉   | 12086/17525 [2:24:59<52:16,  1.73it/s] 69%|██████▉   | 12087/17525 [2:25:00<52:12,  1.74it/s] 69%|██████▉   | 12088/17525 [2:25:00<52:41,  1.72it/s] 69%|██████▉   | 12089/17525 [2:25:01<57:25,  1.58it/s] 69%|██████▉   | 12090/17525 [2:25:02<55:50,  1.62it/s]                                                       {'loss': 0.3525, 'grad_norm': 14.343676567077637, 'learning_rate': 4.40658319568815e-06, 'epoch': 17.25}
 69%|██████▉   | 12090/17525 [2:25:02<55:50,  1.62it/s] 69%|██████▉   | 12091/17525 [2:25:02<54:46,  1.65it/s] 69%|██████▉   | 12092/17525 [2:25:03<54:00,  1.68it/s] 69%|██████▉   | 12093/17525 [2:25:03<53:23,  1.70it/s] 69%|██████▉   | 12094/17525 [2:25:04<52:55,  1.71it/s] 69%|██████▉   | 12095/17525 [2:25:05<52:45,  1.72it/s] 69%|██████▉   | 12096/17525 [2:25:05<52:26,  1.73it/s] 69%|██████▉   | 12097/17525 [2:25:06<52:19,  1.73it/s] 69%|██████▉   | 12098/17525 [2:25:06<52:14,  1.73it/s] 69%|██████▉   | 12099/17525 [2:25:07<52:18,  1.73it/s] 69%|██████▉   | 12100/17525 [2:25:07<52:11,  1.73it/s]                                                       {'loss': 0.3222, 'grad_norm': 9.283136367797852, 'learning_rate': 4.391715416218653e-06, 'epoch': 17.26}
 69%|██████▉   | 12100/17525 [2:25:07<52:11,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:28:29,353 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:28:29,354 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:28:29,354 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.87it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1333725452423096, 'eval_runtime': 4.6008, 'eval_samples_per_second': 96.288, 'eval_steps_per_second': 4.13, 'epoch': 17.26}
 69%|██████▉   | 12100/17525 [2:25:12<52:11,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 69%|██████▉   | 12101/17525 [2:25:13<2:57:10,  1.96s/it] 69%|██████▉   | 12102/17525 [2:25:13<2:19:35,  1.54s/it] 69%|██████▉   | 12103/17525 [2:25:14<2:10:18,  1.44s/it] 69%|██████▉   | 12104/17525 [2:25:15<1:46:41,  1.18s/it] 69%|██████▉   | 12105/17525 [2:25:16<1:30:16,  1.00it/s] 69%|██████▉   | 12106/17525 [2:25:16<1:18:47,  1.15it/s] 69%|██████▉   | 12107/17525 [2:25:17<1:10:37,  1.28it/s] 69%|██████▉   | 12108/17525 [2:25:17<1:05:02,  1.39it/s] 69%|██████▉   | 12109/17525 [2:25:18<1:00:58,  1.48it/s] 69%|██████▉   | 12110/17525 [2:25:18<58:17,  1.55it/s]                                                         {'loss': 0.3593, 'grad_norm': 13.408552169799805, 'learning_rate': 4.37686570039632e-06, 'epoch': 17.28}
 69%|██████▉   | 12110/17525 [2:25:18<58:17,  1.55it/s] 69%|██████▉   | 12111/17525 [2:25:19<56:19,  1.60it/s] 69%|██████▉   | 12112/17525 [2:25:20<55:02,  1.64it/s] 69%|██████▉   | 12113/17525 [2:25:20<54:51,  1.64it/s] 69%|██████▉   | 12114/17525 [2:25:21<53:53,  1.67it/s] 69%|██████▉   | 12115/17525 [2:25:21<53:44,  1.68it/s] 69%|██████▉   | 12116/17525 [2:25:22<53:06,  1.70it/s] 69%|██████▉   | 12117/17525 [2:25:23<52:42,  1.71it/s] 69%|██████▉   | 12118/17525 [2:25:23<52:23,  1.72it/s] 69%|██████▉   | 12119/17525 [2:25:24<52:12,  1.73it/s] 69%|██████▉   | 12120/17525 [2:25:24<51:58,  1.73it/s]                                                       {'loss': 0.3883, 'grad_norm': 6.3732829093933105, 'learning_rate': 4.3620340960504035e-06, 'epoch': 17.29}
 69%|██████▉   | 12120/17525 [2:25:24<51:58,  1.73it/s] 69%|██████▉   | 12121/17525 [2:25:25<51:58,  1.73it/s] 69%|██████▉   | 12122/17525 [2:25:25<51:53,  1.74it/s] 69%|██████▉   | 12123/17525 [2:25:26<51:54,  1.73it/s] 69%|██████▉   | 12124/17525 [2:25:27<51:55,  1.73it/s] 69%|██████▉   | 12125/17525 [2:25:27<51:51,  1.74it/s] 69%|██████▉   | 12126/17525 [2:25:28<51:52,  1.73it/s] 69%|██████▉   | 12127/17525 [2:25:28<51:48,  1.74it/s] 69%|██████▉   | 12128/17525 [2:25:29<51:39,  1.74it/s] 69%|██████▉   | 12129/17525 [2:25:29<51:37,  1.74it/s] 69%|██████▉   | 12130/17525 [2:25:30<51:34,  1.74it/s]                                                       {'loss': 0.3523, 'grad_norm': 13.048770904541016, 'learning_rate': 4.347220650951816e-06, 'epoch': 17.3}
 69%|██████▉   | 12130/17525 [2:25:30<51:34,  1.74it/s] 69%|██████▉   | 12131/17525 [2:25:31<51:43,  1.74it/s] 69%|██████▉   | 12132/17525 [2:25:31<51:37,  1.74it/s] 69%|██████▉   | 12133/17525 [2:25:32<51:34,  1.74it/s] 69%|██████▉   | 12134/17525 [2:25:32<51:32,  1.74it/s] 69%|██████▉   | 12135/17525 [2:25:33<51:32,  1.74it/s] 69%|██████▉   | 12136/17525 [2:25:33<51:34,  1.74it/s] 69%|██████▉   | 12137/17525 [2:25:34<51:28,  1.74it/s] 69%|██████▉   | 12138/17525 [2:25:35<51:24,  1.75it/s] 69%|██████▉   | 12139/17525 [2:25:35<51:26,  1.75it/s] 69%|██████▉   | 12140/17525 [2:25:36<51:28,  1.74it/s]                                                       {'loss': 0.2855, 'grad_norm': 4.393628120422363, 'learning_rate': 4.332425412812978e-06, 'epoch': 17.32}
 69%|██████▉   | 12140/17525 [2:25:36<51:28,  1.74it/s] 69%|██████▉   | 12141/17525 [2:25:36<51:28,  1.74it/s] 69%|██████▉   | 12142/17525 [2:25:37<51:36,  1.74it/s] 69%|██████▉   | 12143/17525 [2:25:37<51:26,  1.74it/s] 69%|██████▉   | 12144/17525 [2:25:38<51:25,  1.74it/s] 69%|██████▉   | 12145/17525 [2:25:39<51:28,  1.74it/s] 69%|██████▉   | 12146/17525 [2:25:39<51:31,  1.74it/s] 69%|██████▉   | 12147/17525 [2:25:40<51:25,  1.74it/s] 69%|██████▉   | 12148/17525 [2:25:40<52:04,  1.72it/s] 69%|██████▉   | 12149/17525 [2:25:41<55:37,  1.61it/s] 69%|██████▉   | 12150/17525 [2:25:42<54:27,  1.65it/s]                                                       {'loss': 0.3756, 'grad_norm': 8.383626937866211, 'learning_rate': 4.317648429287671e-06, 'epoch': 17.33}
 69%|██████▉   | 12150/17525 [2:25:42<54:27,  1.65it/s][INFO|trainer.py:3203] 2024-06-25 04:29:03,517 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a794af10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: df13439c-3b21-461a-8352-b634b8cfeb52)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:29:13,572 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:29:13,575 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 69%|██████▉   | 12151/17525 [2:25:52<5:27:42,  3.66s/it] 69%|██████▉   | 12152/17525 [2:25:53<4:04:52,  2.73s/it] 69%|██████▉   | 12153/17525 [2:25:54<3:06:49,  2.09s/it] 69%|██████▉   | 12154/17525 [2:25:54<2:26:15,  1.63s/it] 69%|██████▉   | 12155/17525 [2:25:55<1:57:44,  1.32s/it] 69%|██████▉   | 12156/17525 [2:25:55<1:37:52,  1.09s/it] 69%|██████▉   | 12157/17525 [2:25:56<1:24:00,  1.07it/s] 69%|██████▉   | 12158/17525 [2:25:56<1:14:17,  1.20it/s] 69%|██████▉   | 12159/17525 [2:25:57<1:07:33,  1.32it/s] 69%|██████▉   | 12160/17525 [2:25:58<1:02:47,  1.42it/s]                                                         {'loss': 0.4683, 'grad_norm': 11.696954727172852, 'learning_rate': 4.302889747970882e-06, 'epoch': 17.35}
 69%|██████▉   | 12160/17525 [2:25:58<1:02:47,  1.42it/s] 69%|██████▉   | 12161/17525 [2:25:58<59:29,  1.50it/s]   69%|██████▉   | 12162/17525 [2:25:59<57:03,  1.57it/s] 69%|██████▉   | 12163/17525 [2:25:59<55:26,  1.61it/s] 69%|██████▉   | 12164/17525 [2:26:00<54:17,  1.65it/s] 69%|██████▉   | 12165/17525 [2:26:00<53:30,  1.67it/s] 69%|██████▉   | 12166/17525 [2:26:01<53:03,  1.68it/s] 69%|██████▉   | 12167/17525 [2:26:02<52:32,  1.70it/s] 69%|██████▉   | 12168/17525 [2:26:02<52:12,  1.71it/s] 69%|██████▉   | 12169/17525 [2:26:03<51:57,  1.72it/s] 69%|██████▉   | 12170/17525 [2:26:03<51:47,  1.72it/s]                                                       {'loss': 0.2915, 'grad_norm': 7.2758002281188965, 'learning_rate': 4.288149416398636e-06, 'epoch': 17.36}
 69%|██████▉   | 12170/17525 [2:26:03<51:47,  1.72it/s] 69%|██████▉   | 12171/17525 [2:26:04<51:46,  1.72it/s] 69%|██████▉   | 12172/17525 [2:26:05<51:36,  1.73it/s] 69%|██████▉   | 12173/17525 [2:26:05<51:34,  1.73it/s] 69%|██████▉   | 12174/17525 [2:26:06<51:32,  1.73it/s] 69%|██████▉   | 12175/17525 [2:26:06<51:21,  1.74it/s] 69%|██████▉   | 12176/17525 [2:26:07<51:21,  1.74it/s] 69%|██████▉   | 12177/17525 [2:26:07<51:20,  1.74it/s] 69%|██████▉   | 12178/17525 [2:26:08<51:19,  1.74it/s] 69%|██████▉   | 12179/17525 [2:26:09<51:26,  1.73it/s] 70%|██████▉   | 12180/17525 [2:26:09<51:25,  1.73it/s]                                                       {'loss': 0.4189, 'grad_norm': 23.09644889831543, 'learning_rate': 4.27342748204788e-06, 'epoch': 17.38}
 70%|██████▉   | 12180/17525 [2:26:09<51:25,  1.73it/s] 70%|██████▉   | 12181/17525 [2:26:10<51:26,  1.73it/s] 70%|██████▉   | 12182/17525 [2:26:10<55:22,  1.61it/s] 70%|██████▉   | 12183/17525 [2:26:11<54:09,  1.64it/s] 70%|██████▉   | 12184/17525 [2:26:12<53:12,  1.67it/s] 70%|██████▉   | 12185/17525 [2:26:12<52:37,  1.69it/s] 70%|██████▉   | 12186/17525 [2:26:13<52:17,  1.70it/s] 70%|██████▉   | 12187/17525 [2:26:13<51:59,  1.71it/s] 70%|██████▉   | 12188/17525 [2:26:14<51:49,  1.72it/s] 70%|██████▉   | 12189/17525 [2:26:14<51:37,  1.72it/s] 70%|██████▉   | 12190/17525 [2:26:16<1:19:38,  1.12it/s]                                                         {'loss': 0.3479, 'grad_norm': 8.527490615844727, 'learning_rate': 4.25872399233628e-06, 'epoch': 17.39}
 70%|██████▉   | 12190/17525 [2:26:16<1:19:38,  1.12it/s] 70%|██████▉   | 12191/17525 [2:26:18<1:39:01,  1.11s/it] 70%|██████▉   | 12192/17525 [2:26:18<1:24:44,  1.05it/s] 70%|██████▉   | 12193/17525 [2:26:19<1:14:40,  1.19it/s] 70%|██████▉   | 12194/17525 [2:26:19<1:07:40,  1.31it/s] 70%|██████▉   | 12195/17525 [2:26:20<1:02:39,  1.42it/s] 70%|██████▉   | 12196/17525 [2:26:21<59:16,  1.50it/s]   70%|██████▉   | 12197/17525 [2:26:21<56:54,  1.56it/s] 70%|██████▉   | 12198/17525 [2:26:22<55:20,  1.60it/s] 70%|██████▉   | 12199/17525 [2:26:22<54:05,  1.64it/s] 70%|██████▉   | 12200/17525 [2:26:23<53:12,  1.67it/s]                                                       {'loss': 0.4743, 'grad_norm': 20.484561920166016, 'learning_rate': 4.2440389946221094e-06, 'epoch': 17.4}
 70%|██████▉   | 12200/17525 [2:26:23<53:12,  1.67it/s][INFO|trainer.py:3512] 2024-06-25 04:29:44,825 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:29:44,825 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:29:44,825 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.105588436126709, 'eval_runtime': 4.5931, 'eval_samples_per_second': 96.449, 'eval_steps_per_second': 4.137, 'epoch': 17.4}
 70%|██████▉   | 12200/17525 [2:26:28<53:12,  1.67it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 70%|██████▉   | 12201/17525 [2:26:28<2:55:41,  1.98s/it] 70%|██████▉   | 12202/17525 [2:26:29<2:18:24,  1.56s/it] 70%|██████▉   | 12203/17525 [2:26:29<1:52:14,  1.27s/it] 70%|██████▉   | 12204/17525 [2:26:30<1:33:51,  1.06s/it] 70%|██████▉   | 12205/17525 [2:26:30<1:21:34,  1.09it/s] 70%|██████▉   | 12206/17525 [2:26:31<1:12:36,  1.22it/s] 70%|██████▉   | 12207/17525 [2:26:32<1:06:09,  1.34it/s] 70%|██████▉   | 12208/17525 [2:26:32<1:01:33,  1.44it/s] 70%|██████▉   | 12209/17525 [2:26:33<58:25,  1.52it/s]   70%|██████▉   | 12210/17525 [2:26:33<56:13,  1.58it/s]                                                       {'loss': 0.3971, 'grad_norm': 9.572179794311523, 'learning_rate': 4.229372536204075e-06, 'epoch': 17.42}
 70%|██████▉   | 12210/17525 [2:26:33<56:13,  1.58it/s] 70%|██████▉   | 12211/17525 [2:26:34<54:45,  1.62it/s] 70%|██████▉   | 12212/17525 [2:26:35<53:39,  1.65it/s] 70%|██████▉   | 12213/17525 [2:26:35<1:02:24,  1.42it/s] 70%|██████▉   | 12214/17525 [2:26:36<59:01,  1.50it/s]   70%|██████▉   | 12215/17525 [2:26:37<56:33,  1.56it/s] 70%|██████▉   | 12216/17525 [2:26:37<54:50,  1.61it/s] 70%|██████▉   | 12217/17525 [2:26:38<53:43,  1.65it/s] 70%|██████▉   | 12218/17525 [2:26:38<53:16,  1.66it/s] 70%|██████▉   | 12219/17525 [2:26:39<1:02:06,  1.42it/s] 70%|██████▉   | 12220/17525 [2:26:40<58:46,  1.50it/s]                                                         {'loss': 0.452, 'grad_norm': 15.279966354370117, 'learning_rate': 4.214724664321174e-06, 'epoch': 17.43}
 70%|██████▉   | 12220/17525 [2:26:40<58:46,  1.50it/s] 70%|██████▉   | 12221/17525 [2:26:40<56:29,  1.56it/s] 70%|██████▉   | 12222/17525 [2:26:41<54:43,  1.61it/s] 70%|██████▉   | 12223/17525 [2:26:42<53:36,  1.65it/s] 70%|██████▉   | 12224/17525 [2:26:42<52:48,  1.67it/s] 70%|██████▉   | 12225/17525 [2:26:43<52:52,  1.67it/s] 70%|██████▉   | 12226/17525 [2:26:43<52:15,  1.69it/s] 70%|██████▉   | 12227/17525 [2:26:44<51:47,  1.70it/s] 70%|██████▉   | 12228/17525 [2:26:44<51:35,  1.71it/s] 70%|██████▉   | 12229/17525 [2:26:45<51:21,  1.72it/s] 70%|██████▉   | 12230/17525 [2:26:46<51:15,  1.72it/s]                                                       {'loss': 0.2791, 'grad_norm': 6.147093296051025, 'learning_rate': 4.20009542615254e-06, 'epoch': 17.45}
 70%|██████▉   | 12230/17525 [2:26:46<51:15,  1.72it/s] 70%|██████▉   | 12231/17525 [2:26:46<51:10,  1.72it/s] 70%|██████▉   | 12232/17525 [2:26:47<51:02,  1.73it/s] 70%|██████▉   | 12233/17525 [2:26:47<50:58,  1.73it/s] 70%|██████▉   | 12234/17525 [2:26:48<50:59,  1.73it/s] 70%|██████▉   | 12235/17525 [2:26:49<50:55,  1.73it/s] 70%|██████▉   | 12236/17525 [2:26:49<51:00,  1.73it/s] 70%|██████▉   | 12237/17525 [2:26:50<50:53,  1.73it/s] 70%|██████▉   | 12238/17525 [2:26:50<50:48,  1.73it/s] 70%|██████▉   | 12239/17525 [2:26:51<50:47,  1.73it/s] 70%|██████▉   | 12240/17525 [2:26:52<59:10,  1.49it/s]                                                       {'loss': 0.3449, 'grad_norm': 10.593514442443848, 'learning_rate': 4.185484868817275e-06, 'epoch': 17.46}
 70%|██████▉   | 12240/17525 [2:26:52<59:10,  1.49it/s] 70%|██████▉   | 12241/17525 [2:26:52<57:17,  1.54it/s] 70%|██████▉   | 12242/17525 [2:26:53<55:25,  1.59it/s] 70%|██████▉   | 12243/17525 [2:26:53<53:58,  1.63it/s] 70%|██████▉   | 12244/17525 [2:26:54<52:55,  1.66it/s] 70%|██████▉   | 12245/17525 [2:26:55<52:16,  1.68it/s] 70%|██████▉   | 12246/17525 [2:26:55<51:44,  1.70it/s] 70%|██████▉   | 12247/17525 [2:26:56<51:19,  1.71it/s] 70%|██████▉   | 12248/17525 [2:26:56<51:06,  1.72it/s] 70%|██████▉   | 12249/17525 [2:26:57<50:51,  1.73it/s] 70%|██████▉   | 12250/17525 [2:26:58<50:53,  1.73it/s]                                                       {'loss': 0.4081, 'grad_norm': 13.219289779663086, 'learning_rate': 4.170893039374336e-06, 'epoch': 17.48}
 70%|██████▉   | 12250/17525 [2:26:58<50:53,  1.73it/s] 70%|██████▉   | 12251/17525 [2:26:58<50:54,  1.73it/s] 70%|██████▉   | 12252/17525 [2:26:59<1:01:56,  1.42it/s] 70%|██████▉   | 12253/17525 [2:27:00<58:34,  1.50it/s]   70%|██████▉   | 12254/17525 [2:27:00<56:08,  1.56it/s] 70%|██████▉   | 12255/17525 [2:27:01<54:21,  1.62it/s] 70%|██████▉   | 12256/17525 [2:27:01<53:11,  1.65it/s] 70%|██████▉   | 12257/17525 [2:27:02<52:47,  1.66it/s] 70%|██████▉   | 12258/17525 [2:27:03<52:02,  1.69it/s] 70%|██████▉   | 12259/17525 [2:27:03<51:36,  1.70it/s] 70%|██████▉   | 12260/17525 [2:27:04<52:28,  1.67it/s]                                                       {'loss': 0.3191, 'grad_norm': 15.012534141540527, 'learning_rate': 4.15631998482234e-06, 'epoch': 17.49}
 70%|██████▉   | 12260/17525 [2:27:04<52:28,  1.67it/s] 70%|██████▉   | 12261/17525 [2:27:04<51:54,  1.69it/s] 70%|██████▉   | 12262/17525 [2:27:05<51:26,  1.71it/s] 70%|██████▉   | 12263/17525 [2:27:05<51:04,  1.72it/s] 70%|██████▉   | 12264/17525 [2:27:06<50:44,  1.73it/s] 70%|██████▉   | 12265/17525 [2:27:07<50:38,  1.73it/s] 70%|██████▉   | 12266/17525 [2:27:07<50:28,  1.74it/s] 70%|██████▉   | 12267/17525 [2:27:08<50:23,  1.74it/s] 70%|███████   | 12268/17525 [2:27:08<50:17,  1.74it/s] 70%|███████   | 12269/17525 [2:27:09<50:18,  1.74it/s] 70%|███████   | 12270/17525 [2:27:09<50:17,  1.74it/s]                                                       {'loss': 0.4153, 'grad_norm': 27.364469528198242, 'learning_rate': 4.14176575209944e-06, 'epoch': 17.5}
 70%|███████   | 12270/17525 [2:27:09<50:17,  1.74it/s] 70%|███████   | 12271/17525 [2:27:10<50:18,  1.74it/s] 70%|███████   | 12272/17525 [2:27:11<50:13,  1.74it/s] 70%|███████   | 12273/17525 [2:27:11<50:12,  1.74it/s] 70%|███████   | 12274/17525 [2:27:12<59:51,  1.46it/s] 70%|███████   | 12275/17525 [2:27:13<57:04,  1.53it/s] 70%|███████   | 12276/17525 [2:27:13<55:03,  1.59it/s] 70%|███████   | 12277/17525 [2:27:14<53:34,  1.63it/s] 70%|███████   | 12278/17525 [2:27:14<52:34,  1.66it/s] 70%|███████   | 12279/17525 [2:27:15<51:55,  1.68it/s] 70%|███████   | 12280/17525 [2:27:16<51:24,  1.70it/s]                                                       {'loss': 0.331, 'grad_norm': 8.28639030456543, 'learning_rate': 4.127230388083167e-06, 'epoch': 17.52}
 70%|███████   | 12280/17525 [2:27:16<51:24,  1.70it/s] 70%|███████   | 12281/17525 [2:27:16<51:00,  1.71it/s] 70%|███████   | 12282/17525 [2:27:17<50:39,  1.73it/s] 70%|███████   | 12283/17525 [2:27:17<50:23,  1.73it/s] 70%|███████   | 12284/17525 [2:27:18<50:19,  1.74it/s] 70%|███████   | 12285/17525 [2:27:18<50:14,  1.74it/s] 70%|███████   | 12286/17525 [2:27:19<50:15,  1.74it/s] 70%|███████   | 12287/17525 [2:27:20<54:06,  1.61it/s] 70%|███████   | 12288/17525 [2:27:20<52:59,  1.65it/s] 70%|███████   | 12289/17525 [2:27:21<52:08,  1.67it/s] 70%|███████   | 12290/17525 [2:27:21<51:27,  1.70it/s]                                                       {'loss': 0.397, 'grad_norm': 10.546883583068848, 'learning_rate': 4.112713939590276e-06, 'epoch': 17.53}
 70%|███████   | 12290/17525 [2:27:21<51:27,  1.70it/s] 70%|███████   | 12291/17525 [2:27:22<51:05,  1.71it/s] 70%|███████   | 12292/17525 [2:27:23<50:42,  1.72it/s] 70%|███████   | 12293/17525 [2:27:23<50:33,  1.72it/s] 70%|███████   | 12294/17525 [2:27:24<50:25,  1.73it/s] 70%|███████   | 12295/17525 [2:27:24<50:14,  1.73it/s] 70%|███████   | 12296/17525 [2:27:25<50:38,  1.72it/s] 70%|███████   | 12297/17525 [2:27:26<50:23,  1.73it/s] 70%|███████   | 12298/17525 [2:27:26<51:04,  1.71it/s] 70%|███████   | 12299/17525 [2:27:27<50:40,  1.72it/s] 70%|███████   | 12300/17525 [2:27:27<50:34,  1.72it/s]                                                       {'loss': 0.3096, 'grad_norm': 3.0552752017974854, 'learning_rate': 4.098216453376597e-06, 'epoch': 17.55}
 70%|███████   | 12300/17525 [2:27:27<50:34,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 04:30:49,168 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:30:49,168 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:30:49,168 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1100234985351562, 'eval_runtime': 4.6015, 'eval_samples_per_second': 96.272, 'eval_steps_per_second': 4.129, 'epoch': 17.55}
 70%|███████   | 12300/17525 [2:27:32<50:34,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:30:53,774 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b0d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f4d9e5a5-050f-4ea7-987c-35a9c671ccdc)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:31:03,829 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:31:03,831 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 70%|███████   | 12301/17525 [2:27:43<7:21:23,  5.07s/it] 70%|███████   | 12302/17525 [2:27:44<5:33:00,  3.83s/it] 70%|███████   | 12303/17525 [2:27:44<4:08:03,  2.85s/it] 70%|███████   | 12304/17525 [2:27:45<3:08:31,  2.17s/it] 70%|███████   | 12305/17525 [2:27:45<2:27:01,  1.69s/it] 70%|███████   | 12306/17525 [2:27:46<1:57:52,  1.36s/it] 70%|███████   | 12307/17525 [2:27:47<1:37:26,  1.12s/it] 70%|███████   | 12308/17525 [2:27:47<1:23:06,  1.05it/s] 70%|███████   | 12309/17525 [2:27:48<1:13:14,  1.19it/s] 70%|███████   | 12310/17525 [2:27:48<1:06:16,  1.31it/s]                                                         {'loss': 0.3347, 'grad_norm': 9.60672378540039, 'learning_rate': 4.083737976136888e-06, 'epoch': 17.56}
 70%|███████   | 12310/17525 [2:27:48<1:06:16,  1.31it/s] 70%|███████   | 12311/17525 [2:27:49<1:02:20,  1.39it/s] 70%|███████   | 12312/17525 [2:27:50<58:34,  1.48it/s]   70%|███████   | 12313/17525 [2:27:50<55:55,  1.55it/s] 70%|███████   | 12314/17525 [2:27:51<53:58,  1.61it/s] 70%|███████   | 12315/17525 [2:27:51<52:47,  1.65it/s] 70%|███████   | 12316/17525 [2:27:52<51:54,  1.67it/s] 70%|███████   | 12317/17525 [2:27:52<51:13,  1.69it/s] 70%|███████   | 12318/17525 [2:27:53<50:47,  1.71it/s] 70%|███████   | 12319/17525 [2:27:54<50:29,  1.72it/s] 70%|███████   | 12320/17525 [2:27:54<50:16,  1.73it/s]                                                       {'loss': 0.3586, 'grad_norm': 21.174713134765625, 'learning_rate': 4.069278554504673e-06, 'epoch': 17.57}
 70%|███████   | 12320/17525 [2:27:54<50:16,  1.73it/s] 70%|███████   | 12321/17525 [2:27:55<50:14,  1.73it/s] 70%|███████   | 12322/17525 [2:27:55<49:56,  1.74it/s] 70%|███████   | 12323/17525 [2:27:56<49:54,  1.74it/s] 70%|███████   | 12324/17525 [2:27:56<49:45,  1.74it/s] 70%|███████   | 12325/17525 [2:27:57<49:41,  1.74it/s] 70%|███████   | 12326/17525 [2:27:58<49:45,  1.74it/s] 70%|███████   | 12327/17525 [2:27:58<49:53,  1.74it/s] 70%|███████   | 12328/17525 [2:27:59<49:47,  1.74it/s] 70%|███████   | 12329/17525 [2:27:59<49:45,  1.74it/s] 70%|███████   | 12330/17525 [2:28:00<49:46,  1.74it/s]                                                       {'loss': 0.3455, 'grad_norm': 11.652462005615234, 'learning_rate': 4.054838235052109e-06, 'epoch': 17.59}
 70%|███████   | 12330/17525 [2:28:00<49:46,  1.74it/s] 70%|███████   | 12331/17525 [2:28:00<49:46,  1.74it/s] 70%|███████   | 12332/17525 [2:28:01<49:40,  1.74it/s] 70%|███████   | 12333/17525 [2:28:02<49:40,  1.74it/s] 70%|███████   | 12334/17525 [2:28:02<49:42,  1.74it/s] 70%|███████   | 12335/17525 [2:28:03<49:43,  1.74it/s] 70%|███████   | 12336/17525 [2:28:03<50:10,  1.72it/s] 70%|███████   | 12337/17525 [2:28:04<49:56,  1.73it/s] 70%|███████   | 12338/17525 [2:28:04<49:46,  1.74it/s] 70%|███████   | 12339/17525 [2:28:05<49:41,  1.74it/s] 70%|███████   | 12340/17525 [2:28:06<49:39,  1.74it/s]                                                       {'loss': 0.3755, 'grad_norm': 9.882598876953125, 'learning_rate': 4.040417064289822e-06, 'epoch': 17.6}
 70%|███████   | 12340/17525 [2:28:06<49:39,  1.74it/s] 70%|███████   | 12341/17525 [2:28:06<49:42,  1.74it/s] 70%|███████   | 12342/17525 [2:28:07<50:35,  1.71it/s] 70%|███████   | 12343/17525 [2:28:07<50:17,  1.72it/s] 70%|███████   | 12344/17525 [2:28:08<50:07,  1.72it/s] 70%|███████   | 12345/17525 [2:28:09<49:57,  1.73it/s] 70%|███████   | 12346/17525 [2:28:09<49:48,  1.73it/s] 70%|███████   | 12347/17525 [2:28:10<49:39,  1.74it/s] 70%|███████   | 12348/17525 [2:28:10<49:33,  1.74it/s] 70%|███████   | 12349/17525 [2:28:11<49:31,  1.74it/s] 70%|███████   | 12350/17525 [2:28:11<49:35,  1.74it/s]                                                       {'loss': 0.3519, 'grad_norm': 16.648012161254883, 'learning_rate': 4.026015088666765e-06, 'epoch': 17.62}
 70%|███████   | 12350/17525 [2:28:11<49:35,  1.74it/s] 70%|███████   | 12351/17525 [2:28:12<49:34,  1.74it/s] 70%|███████   | 12352/17525 [2:28:13<49:38,  1.74it/s] 70%|███████   | 12353/17525 [2:28:13<49:29,  1.74it/s] 70%|███████   | 12354/17525 [2:28:14<58:56,  1.46it/s] 70%|███████   | 12355/17525 [2:28:15<1:00:30,  1.42it/s] 71%|███████   | 12356/17525 [2:28:15<57:14,  1.50it/s]   71%|███████   | 12357/17525 [2:28:16<54:54,  1.57it/s] 71%|███████   | 12358/17525 [2:28:17<53:15,  1.62it/s] 71%|███████   | 12359/17525 [2:28:17<52:11,  1.65it/s] 71%|███████   | 12360/17525 [2:28:18<51:17,  1.68it/s]                                                       {'loss': 0.4017, 'grad_norm': 35.441490173339844, 'learning_rate': 4.011632354570068e-06, 'epoch': 17.63}
 71%|███████   | 12360/17525 [2:28:18<51:17,  1.68it/s] 71%|███████   | 12361/17525 [2:28:18<50:45,  1.70it/s] 71%|███████   | 12362/17525 [2:28:19<50:19,  1.71it/s] 71%|███████   | 12363/17525 [2:28:19<50:01,  1.72it/s] 71%|███████   | 12364/17525 [2:28:20<49:46,  1.73it/s] 71%|███████   | 12365/17525 [2:28:21<50:12,  1.71it/s] 71%|███████   | 12366/17525 [2:28:21<49:59,  1.72it/s] 71%|███████   | 12367/17525 [2:28:22<49:43,  1.73it/s] 71%|███████   | 12368/17525 [2:28:22<49:31,  1.74it/s] 71%|███████   | 12369/17525 [2:28:23<49:27,  1.74it/s] 71%|███████   | 12370/17525 [2:28:23<49:22,  1.74it/s]                                                       {'loss': 0.3694, 'grad_norm': 14.561299324035645, 'learning_rate': 3.99726890832487e-06, 'epoch': 17.65}
 71%|███████   | 12370/17525 [2:28:23<49:22,  1.74it/s] 71%|███████   | 12371/17525 [2:28:25<1:09:16,  1.24it/s] 71%|███████   | 12372/17525 [2:28:25<1:03:16,  1.36it/s] 71%|███████   | 12373/17525 [2:28:26<59:18,  1.45it/s]   71%|███████   | 12374/17525 [2:28:26<56:17,  1.53it/s] 71%|███████   | 12375/17525 [2:28:27<54:10,  1.58it/s] 71%|███████   | 12376/17525 [2:28:28<52:45,  1.63it/s] 71%|███████   | 12377/17525 [2:28:28<51:45,  1.66it/s] 71%|███████   | 12378/17525 [2:28:29<51:00,  1.68it/s] 71%|███████   | 12379/17525 [2:28:29<50:28,  1.70it/s] 71%|███████   | 12380/17525 [2:28:30<50:04,  1.71it/s]                                                       {'loss': 0.3644, 'grad_norm': 3.5848939418792725, 'learning_rate': 3.982924796194217e-06, 'epoch': 17.66}
 71%|███████   | 12380/17525 [2:28:30<50:04,  1.71it/s] 71%|███████   | 12381/17525 [2:28:31<49:50,  1.72it/s] 71%|███████   | 12382/17525 [2:28:31<49:38,  1.73it/s] 71%|███████   | 12383/17525 [2:28:32<58:16,  1.47it/s] 71%|███████   | 12384/17525 [2:28:33<56:04,  1.53it/s] 71%|███████   | 12385/17525 [2:28:33<53:57,  1.59it/s] 71%|███████   | 12386/17525 [2:28:34<52:33,  1.63it/s] 71%|███████   | 12387/17525 [2:28:34<51:36,  1.66it/s] 71%|███████   | 12388/17525 [2:28:35<50:47,  1.69it/s] 71%|███████   | 12389/17525 [2:28:35<50:20,  1.70it/s] 71%|███████   | 12390/17525 [2:28:36<49:53,  1.72it/s]                                                       {'loss': 0.449, 'grad_norm': 15.35571575164795, 'learning_rate': 3.9686000643788505e-06, 'epoch': 17.67}
 71%|███████   | 12390/17525 [2:28:36<49:53,  1.72it/s] 71%|███████   | 12391/17525 [2:28:37<49:35,  1.73it/s] 71%|███████   | 12392/17525 [2:28:37<49:22,  1.73it/s] 71%|███████   | 12393/17525 [2:28:38<49:17,  1.73it/s] 71%|███████   | 12394/17525 [2:28:38<49:16,  1.74it/s] 71%|███████   | 12395/17525 [2:28:39<49:09,  1.74it/s] 71%|███████   | 12396/17525 [2:28:40<49:45,  1.72it/s] 71%|███████   | 12397/17525 [2:28:40<49:34,  1.72it/s] 71%|███████   | 12398/17525 [2:28:41<49:22,  1.73it/s] 71%|███████   | 12399/17525 [2:28:41<49:13,  1.74it/s] 71%|███████   | 12400/17525 [2:28:42<49:06,  1.74it/s]                                                       {'loss': 0.3474, 'grad_norm': 7.657159805297852, 'learning_rate': 3.954294759017106e-06, 'epoch': 17.69}
 71%|███████   | 12400/17525 [2:28:42<49:06,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:32:03,703 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:32:03,703 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:32:03,703 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1269443035125732, 'eval_runtime': 4.6008, 'eval_samples_per_second': 96.288, 'eval_steps_per_second': 4.13, 'epoch': 17.69}
 71%|███████   | 12400/17525 [2:28:46<49:06,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 71%|███████   | 12401/17525 [2:28:47<2:47:09,  1.96s/it] 71%|███████   | 12402/17525 [2:28:48<2:11:36,  1.54s/it] 71%|███████   | 12403/17525 [2:28:48<1:46:49,  1.25s/it] 71%|███████   | 12404/17525 [2:28:49<1:29:28,  1.05s/it] 71%|███████   | 12405/17525 [2:28:49<1:17:17,  1.10it/s] 71%|███████   | 12406/17525 [2:28:50<1:08:40,  1.24it/s] 71%|███████   | 12407/17525 [2:28:50<1:02:47,  1.36it/s] 71%|███████   | 12408/17525 [2:28:51<58:42,  1.45it/s]   71%|███████   | 12409/17525 [2:28:52<55:50,  1.53it/s] 71%|███████   | 12410/17525 [2:28:52<53:51,  1.58it/s]                                                       {'loss': 0.4424, 'grad_norm': 14.444601058959961, 'learning_rate': 3.940008926184749e-06, 'epoch': 17.7}
 71%|███████   | 12410/17525 [2:28:52<53:51,  1.58it/s] 71%|███████   | 12411/17525 [2:28:53<52:27,  1.62it/s] 71%|███████   | 12412/17525 [2:28:53<51:29,  1.66it/s] 71%|███████   | 12413/17525 [2:28:54<50:39,  1.68it/s] 71%|███████   | 12414/17525 [2:28:54<50:04,  1.70it/s] 71%|███████   | 12415/17525 [2:28:55<49:43,  1.71it/s] 71%|███████   | 12416/17525 [2:28:56<49:49,  1.71it/s] 71%|███████   | 12417/17525 [2:28:56<49:31,  1.72it/s] 71%|███████   | 12418/17525 [2:28:57<58:28,  1.46it/s] 71%|███████   | 12419/17525 [2:28:58<55:31,  1.53it/s] 71%|███████   | 12420/17525 [2:28:58<53:28,  1.59it/s]                                                       {'loss': 0.3763, 'grad_norm': 6.6880927085876465, 'learning_rate': 3.925742611894821e-06, 'epoch': 17.72}
 71%|███████   | 12420/17525 [2:28:58<53:28,  1.59it/s] 71%|███████   | 12421/17525 [2:28:59<52:11,  1.63it/s] 71%|███████   | 12422/17525 [2:28:59<51:12,  1.66it/s] 71%|███████   | 12423/17525 [2:29:00<50:30,  1.68it/s] 71%|███████   | 12424/17525 [2:29:01<50:00,  1.70it/s] 71%|███████   | 12425/17525 [2:29:01<49:41,  1.71it/s] 71%|███████   | 12426/17525 [2:29:02<49:27,  1.72it/s] 71%|███████   | 12427/17525 [2:29:02<49:16,  1.72it/s] 71%|███████   | 12428/17525 [2:29:03<49:08,  1.73it/s] 71%|███████   | 12429/17525 [2:29:03<48:59,  1.73it/s] 71%|███████   | 12430/17525 [2:29:04<48:53,  1.74it/s]                                                       {'loss': 0.3931, 'grad_norm': 15.16952133178711, 'learning_rate': 3.911495862097499e-06, 'epoch': 17.73}
 71%|███████   | 12430/17525 [2:29:04<48:53,  1.74it/s] 71%|███████   | 12431/17525 [2:29:05<48:52,  1.74it/s] 71%|███████   | 12432/17525 [2:29:05<48:49,  1.74it/s] 71%|███████   | 12433/17525 [2:29:06<48:47,  1.74it/s] 71%|███████   | 12434/17525 [2:29:06<48:48,  1.74it/s] 71%|███████   | 12435/17525 [2:29:07<48:44,  1.74it/s] 71%|███████   | 12436/17525 [2:29:07<48:37,  1.74it/s] 71%|███████   | 12437/17525 [2:29:08<48:40,  1.74it/s] 71%|███████   | 12438/17525 [2:29:09<48:39,  1.74it/s] 71%|███████   | 12439/17525 [2:29:09<48:39,  1.74it/s] 71%|███████   | 12440/17525 [2:29:10<48:35,  1.74it/s]                                                       {'loss': 0.3847, 'grad_norm': 11.255563735961914, 'learning_rate': 3.897268722679948e-06, 'epoch': 17.75}
 71%|███████   | 12440/17525 [2:29:10<48:35,  1.74it/s] 71%|███████   | 12441/17525 [2:29:10<48:43,  1.74it/s] 71%|███████   | 12442/17525 [2:29:12<1:08:28,  1.24it/s] 71%|███████   | 12443/17525 [2:29:12<1:02:32,  1.35it/s] 71%|███████   | 12444/17525 [2:29:13<58:25,  1.45it/s]   71%|███████   | 12445/17525 [2:29:13<55:30,  1.53it/s] 71%|███████   | 12446/17525 [2:29:14<53:23,  1.59it/s] 71%|███████   | 12447/17525 [2:29:15<52:30,  1.61it/s] 71%|███████   | 12448/17525 [2:29:15<51:20,  1.65it/s] 71%|███████   | 12449/17525 [2:29:16<50:31,  1.67it/s] 71%|███████   | 12450/17525 [2:29:16<50:22,  1.68it/s]                                                       {'loss': 0.4256, 'grad_norm': 16.51803970336914, 'learning_rate': 3.88306123946616e-06, 'epoch': 17.76}
 71%|███████   | 12450/17525 [2:29:16<50:22,  1.68it/s][INFO|trainer.py:3203] 2024-06-25 04:32:38,229 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b8cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 35ed5edd-5a4a-4f77-9010-a3c6f61110ba)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:32:48,340 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:32:48,342 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 71%|███████   | 12451/17525 [2:29:27<5:09:57,  3.67s/it] 71%|███████   | 12452/17525 [2:29:28<3:51:42,  2.74s/it] 71%|███████   | 12453/17525 [2:29:28<2:56:40,  2.09s/it] 71%|███████   | 12454/17525 [2:29:29<2:18:14,  1.64s/it] 71%|███████   | 12455/17525 [2:29:29<1:51:19,  1.32s/it] 71%|███████   | 12456/17525 [2:29:30<1:32:26,  1.09s/it] 71%|███████   | 12457/17525 [2:29:31<1:19:11,  1.07it/s] 71%|███████   | 12458/17525 [2:29:31<1:09:57,  1.21it/s] 71%|███████   | 12459/17525 [2:29:32<1:03:35,  1.33it/s] 71%|███████   | 12460/17525 [2:29:32<59:41,  1.41it/s]                                                         {'loss': 0.3219, 'grad_norm': 15.439550399780273, 'learning_rate': 3.868873458216829e-06, 'epoch': 17.77}
 71%|███████   | 12460/17525 [2:29:32<59:41,  1.41it/s] 71%|███████   | 12461/17525 [2:29:33<56:28,  1.49it/s] 71%|███████   | 12462/17525 [2:29:34<54:04,  1.56it/s] 71%|███████   | 12463/17525 [2:29:34<52:35,  1.60it/s] 71%|███████   | 12464/17525 [2:29:35<51:17,  1.64it/s] 71%|███████   | 12465/17525 [2:29:35<50:29,  1.67it/s] 71%|███████   | 12466/17525 [2:29:36<49:54,  1.69it/s] 71%|███████   | 12467/17525 [2:29:36<49:27,  1.70it/s] 71%|███████   | 12468/17525 [2:29:37<49:07,  1.72it/s] 71%|███████   | 12469/17525 [2:29:38<49:19,  1.71it/s] 71%|███████   | 12470/17525 [2:29:38<49:00,  1.72it/s]                                                       {'loss': 0.3867, 'grad_norm': 15.159719467163086, 'learning_rate': 3.854705424629183e-06, 'epoch': 17.79}
 71%|███████   | 12470/17525 [2:29:38<49:00,  1.72it/s] 71%|███████   | 12471/17525 [2:29:39<49:00,  1.72it/s] 71%|███████   | 12472/17525 [2:29:39<48:51,  1.72it/s] 71%|███████   | 12473/17525 [2:29:40<48:41,  1.73it/s] 71%|███████   | 12474/17525 [2:29:40<48:31,  1.73it/s] 71%|███████   | 12475/17525 [2:29:41<48:22,  1.74it/s] 71%|███████   | 12476/17525 [2:29:42<48:18,  1.74it/s] 71%|███████   | 12477/17525 [2:29:42<48:32,  1.73it/s] 71%|███████   | 12478/17525 [2:29:43<48:26,  1.74it/s] 71%|███████   | 12479/17525 [2:29:43<48:17,  1.74it/s] 71%|███████   | 12480/17525 [2:29:44<48:17,  1.74it/s]                                                       {'loss': 0.4611, 'grad_norm': 8.589774131774902, 'learning_rate': 3.8405571843368496e-06, 'epoch': 17.8}
 71%|███████   | 12480/17525 [2:29:44<48:17,  1.74it/s] 71%|███████   | 12481/17525 [2:29:44<48:18,  1.74it/s] 71%|███████   | 12482/17525 [2:29:45<48:16,  1.74it/s] 71%|███████   | 12483/17525 [2:29:46<48:12,  1.74it/s] 71%|███████   | 12484/17525 [2:29:46<48:08,  1.75it/s] 71%|███████   | 12485/17525 [2:29:47<48:10,  1.74it/s] 71%|███████   | 12486/17525 [2:29:47<48:06,  1.75it/s] 71%|███████▏  | 12487/17525 [2:29:48<48:05,  1.75it/s] 71%|███████▏  | 12488/17525 [2:29:49<48:48,  1.72it/s] 71%|███████▏  | 12489/17525 [2:29:49<48:38,  1.73it/s] 71%|███████▏  | 12490/17525 [2:29:50<48:30,  1.73it/s]                                                       {'loss': 0.2599, 'grad_norm': 10.195941925048828, 'learning_rate': 3.826428782909705e-06, 'epoch': 17.82}
 71%|███████▏  | 12490/17525 [2:29:50<48:30,  1.73it/s] 71%|███████▏  | 12491/17525 [2:29:50<48:26,  1.73it/s] 71%|███████▏  | 12492/17525 [2:29:51<48:17,  1.74it/s] 71%|███████▏  | 12493/17525 [2:29:51<48:08,  1.74it/s] 71%|███████▏  | 12494/17525 [2:29:52<48:05,  1.74it/s] 71%|███████▏  | 12495/17525 [2:29:53<48:07,  1.74it/s] 71%|███████▏  | 12496/17525 [2:29:53<48:11,  1.74it/s] 71%|███████▏  | 12497/17525 [2:29:54<48:10,  1.74it/s] 71%|███████▏  | 12498/17525 [2:29:54<48:09,  1.74it/s] 71%|███████▏  | 12499/17525 [2:29:55<58:53,  1.42it/s] 71%|███████▏  | 12500/17525 [2:29:56<55:46,  1.50it/s]                                                       {'loss': 0.3279, 'grad_norm': 12.50914478302002, 'learning_rate': 3.812320265853714e-06, 'epoch': 17.83}
 71%|███████▏  | 12500/17525 [2:29:56<55:46,  1.50it/s][INFO|trainer.py:3512] 2024-06-25 04:33:17,722 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:33:17,722 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:33:17,722 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.59it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                       
                                               [A{'eval_loss': 1.1220881938934326, 'eval_runtime': 4.6028, 'eval_samples_per_second': 96.246, 'eval_steps_per_second': 4.128, 'epoch': 17.83}
 71%|███████▏  | 12500/17525 [2:30:00<55:46,  1.50it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A 71%|███████▏  | 12501/17525 [2:30:01<2:49:16,  2.02s/it] 71%|███████▏  | 12502/17525 [2:30:02<2:12:57,  1.59s/it] 71%|███████▏  | 12503/17525 [2:30:02<1:47:35,  1.29s/it] 71%|███████▏  | 12504/17525 [2:30:03<1:45:23,  1.26s/it] 71%|███████▏  | 12505/17525 [2:30:05<1:47:35,  1.29s/it] 71%|███████▏  | 12506/17525 [2:30:05<1:29:58,  1.08s/it] 71%|███████▏  | 12507/17525 [2:30:06<1:17:33,  1.08it/s] 71%|███████▏  | 12508/17525 [2:30:06<1:08:42,  1.22it/s] 71%|███████▏  | 12509/17525 [2:30:07<1:02:24,  1.34it/s] 71%|███████▏  | 12510/17525 [2:30:08<57:58,  1.44it/s]                                                         {'loss': 0.4015, 'grad_norm': 18.243322372436523, 'learning_rate': 3.79823167861082e-06, 'epoch': 17.85}
 71%|███████▏  | 12510/17525 [2:30:08<57:58,  1.44it/s] 71%|███████▏  | 12511/17525 [2:30:08<55:05,  1.52it/s] 71%|███████▏  | 12512/17525 [2:30:09<52:54,  1.58it/s] 71%|███████▏  | 12513/17525 [2:30:09<51:27,  1.62it/s] 71%|███████▏  | 12514/17525 [2:30:10<50:17,  1.66it/s] 71%|███████▏  | 12515/17525 [2:30:10<49:27,  1.69it/s] 71%|███████▏  | 12516/17525 [2:30:11<48:57,  1.71it/s] 71%|███████▏  | 12517/17525 [2:30:12<48:38,  1.72it/s] 71%|███████▏  | 12518/17525 [2:30:12<48:21,  1.73it/s] 71%|███████▏  | 12519/17525 [2:30:13<48:10,  1.73it/s] 71%|███████▏  | 12520/17525 [2:30:13<48:02,  1.74it/s]                                                       {'loss': 0.4232, 'grad_norm': 15.022582054138184, 'learning_rate': 3.784163066558748e-06, 'epoch': 17.86}
 71%|███████▏  | 12520/17525 [2:30:13<48:02,  1.74it/s] 71%|███████▏  | 12521/17525 [2:30:14<48:00,  1.74it/s] 71%|███████▏  | 12522/17525 [2:30:14<47:57,  1.74it/s] 71%|███████▏  | 12523/17525 [2:30:15<48:30,  1.72it/s] 71%|███████▏  | 12524/17525 [2:30:16<48:22,  1.72it/s] 71%|███████▏  | 12525/17525 [2:30:16<48:06,  1.73it/s] 71%|███████▏  | 12526/17525 [2:30:17<47:57,  1.74it/s] 71%|███████▏  | 12527/17525 [2:30:17<47:56,  1.74it/s] 71%|███████▏  | 12528/17525 [2:30:18<47:54,  1.74it/s] 71%|███████▏  | 12529/17525 [2:30:19<47:49,  1.74it/s] 71%|███████▏  | 12530/17525 [2:30:19<47:50,  1.74it/s]                                                       {'loss': 0.3291, 'grad_norm': 10.989006996154785, 'learning_rate': 3.770114475010912e-06, 'epoch': 17.87}
 71%|███████▏  | 12530/17525 [2:30:19<47:50,  1.74it/s] 72%|███████▏  | 12531/17525 [2:30:20<47:49,  1.74it/s] 72%|███████▏  | 12532/17525 [2:30:20<47:46,  1.74it/s] 72%|███████▏  | 12533/17525 [2:30:21<47:45,  1.74it/s] 72%|███████▏  | 12534/17525 [2:30:22<56:29,  1.47it/s] 72%|███████▏  | 12535/17525 [2:30:22<53:53,  1.54it/s] 72%|███████▏  | 12536/17525 [2:30:23<52:03,  1.60it/s] 72%|███████▏  | 12537/17525 [2:30:23<51:42,  1.61it/s] 72%|███████▏  | 12538/17525 [2:30:24<50:29,  1.65it/s] 72%|███████▏  | 12539/17525 [2:30:25<49:37,  1.67it/s] 72%|███████▏  | 12540/17525 [2:30:25<49:06,  1.69it/s]                                                       {'loss': 0.3228, 'grad_norm': 6.9426350593566895, 'learning_rate': 3.7560859492162184e-06, 'epoch': 17.89}
 72%|███████▏  | 12540/17525 [2:30:25<49:06,  1.69it/s] 72%|███████▏  | 12541/17525 [2:30:26<48:42,  1.71it/s] 72%|███████▏  | 12542/17525 [2:30:26<48:23,  1.72it/s] 72%|███████▏  | 12543/17525 [2:30:27<48:09,  1.72it/s] 72%|███████▏  | 12544/17525 [2:30:28<48:06,  1.73it/s] 72%|███████▏  | 12545/17525 [2:30:28<48:01,  1.73it/s] 72%|███████▏  | 12546/17525 [2:30:29<47:55,  1.73it/s] 72%|███████▏  | 12547/17525 [2:30:29<47:52,  1.73it/s] 72%|███████▏  | 12548/17525 [2:30:30<47:48,  1.74it/s] 72%|███████▏  | 12549/17525 [2:30:30<47:39,  1.74it/s] 72%|███████▏  | 12550/17525 [2:30:31<47:40,  1.74it/s]                                                       {'loss': 0.3741, 'grad_norm': 69.57910919189453, 'learning_rate': 3.7420775343589566e-06, 'epoch': 17.9}
 72%|███████▏  | 12550/17525 [2:30:31<47:40,  1.74it/s] 72%|███████▏  | 12551/17525 [2:30:32<47:37,  1.74it/s] 72%|███████▏  | 12552/17525 [2:30:32<47:36,  1.74it/s] 72%|███████▏  | 12553/17525 [2:30:33<47:34,  1.74it/s] 72%|███████▏  | 12554/17525 [2:30:33<47:32,  1.74it/s] 72%|███████▏  | 12555/17525 [2:30:34<47:37,  1.74it/s] 72%|███████▏  | 12556/17525 [2:30:34<47:44,  1.73it/s] 72%|███████▏  | 12557/17525 [2:30:35<48:38,  1.70it/s] 72%|███████▏  | 12558/17525 [2:30:36<51:42,  1.60it/s] 72%|███████▏  | 12559/17525 [2:30:36<50:22,  1.64it/s] 72%|███████▏  | 12560/17525 [2:30:38<1:09:00,  1.20it/s]                                                         {'loss': 0.3808, 'grad_norm': 4.589175701141357, 'learning_rate': 3.7280892755586395e-06, 'epoch': 17.92}
 72%|███████▏  | 12560/17525 [2:30:38<1:09:00,  1.20it/s] 72%|███████▏  | 12561/17525 [2:30:38<1:02:30,  1.32it/s] 72%|███████▏  | 12562/17525 [2:30:39<58:00,  1.43it/s]   72%|███████▏  | 12563/17525 [2:30:39<54:47,  1.51it/s] 72%|███████▏  | 12564/17525 [2:30:40<52:28,  1.58it/s] 72%|███████▏  | 12565/17525 [2:30:41<50:59,  1.62it/s] 72%|███████▏  | 12566/17525 [2:30:41<49:56,  1.65it/s] 72%|███████▏  | 12567/17525 [2:30:42<49:12,  1.68it/s] 72%|███████▏  | 12568/17525 [2:30:42<48:36,  1.70it/s] 72%|███████▏  | 12569/17525 [2:30:43<48:21,  1.71it/s] 72%|███████▏  | 12570/17525 [2:30:43<47:56,  1.72it/s]                                                       {'loss': 0.3444, 'grad_norm': 8.288731575012207, 'learning_rate': 3.7141212178698583e-06, 'epoch': 17.93}
 72%|███████▏  | 12570/17525 [2:30:43<47:56,  1.72it/s] 72%|███████▏  | 12571/17525 [2:30:44<47:47,  1.73it/s] 72%|███████▏  | 12572/17525 [2:30:45<47:38,  1.73it/s] 72%|███████▏  | 12573/17525 [2:30:45<47:30,  1.74it/s] 72%|███████▏  | 12574/17525 [2:30:46<47:25,  1.74it/s] 72%|███████▏  | 12575/17525 [2:30:46<47:22,  1.74it/s] 72%|███████▏  | 12576/17525 [2:30:47<47:22,  1.74it/s] 72%|███████▏  | 12577/17525 [2:30:47<47:28,  1.74it/s] 72%|███████▏  | 12578/17525 [2:30:48<47:27,  1.74it/s] 72%|███████▏  | 12579/17525 [2:30:49<47:28,  1.74it/s] 72%|███████▏  | 12580/17525 [2:30:49<47:19,  1.74it/s]                                                       {'loss': 0.4149, 'grad_norm': 8.442567825317383, 'learning_rate': 3.7001734062821425e-06, 'epoch': 17.95}
 72%|███████▏  | 12580/17525 [2:30:49<47:19,  1.74it/s] 72%|███████▏  | 12581/17525 [2:30:50<47:28,  1.74it/s] 72%|███████▏  | 12582/17525 [2:30:50<47:22,  1.74it/s] 72%|███████▏  | 12583/17525 [2:30:51<47:21,  1.74it/s] 72%|███████▏  | 12584/17525 [2:30:51<47:17,  1.74it/s] 72%|███████▏  | 12585/17525 [2:30:52<47:12,  1.74it/s] 72%|███████▏  | 12586/17525 [2:30:53<47:15,  1.74it/s] 72%|███████▏  | 12587/17525 [2:30:53<47:12,  1.74it/s] 72%|███████▏  | 12588/17525 [2:30:54<47:10,  1.74it/s] 72%|███████▏  | 12589/17525 [2:30:54<47:14,  1.74it/s] 72%|███████▏  | 12590/17525 [2:30:55<47:16,  1.74it/s]                                                       {'loss': 0.3751, 'grad_norm': 25.16867446899414, 'learning_rate': 3.6862458857198013e-06, 'epoch': 17.96}
 72%|███████▏  | 12590/17525 [2:30:55<47:16,  1.74it/s] 72%|███████▏  | 12591/17525 [2:30:55<47:12,  1.74it/s] 72%|███████▏  | 12592/17525 [2:30:56<47:11,  1.74it/s] 72%|███████▏  | 12593/17525 [2:30:57<47:12,  1.74it/s] 72%|███████▏  | 12594/17525 [2:30:57<47:13,  1.74it/s] 72%|███████▏  | 12595/17525 [2:30:58<47:18,  1.74it/s] 72%|███████▏  | 12596/17525 [2:30:58<47:09,  1.74it/s] 72%|███████▏  | 12597/17525 [2:30:59<47:06,  1.74it/s] 72%|███████▏  | 12598/17525 [2:30:59<47:01,  1.75it/s] 72%|███████▏  | 12599/17525 [2:31:00<47:09,  1.74it/s] 72%|███████▏  | 12600/17525 [2:31:01<47:04,  1.74it/s]                                                       {'loss': 0.3675, 'grad_norm': 14.563796997070312, 'learning_rate': 3.6723387010417986e-06, 'epoch': 17.97}
 72%|███████▏  | 12600/17525 [2:31:01<47:04,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:34:22,533 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:34:22,533 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:34:22,533 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1226677894592285, 'eval_runtime': 4.6027, 'eval_samples_per_second': 96.248, 'eval_steps_per_second': 4.128, 'epoch': 17.97}
 72%|███████▏  | 12600/17525 [2:31:05<47:04,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:34:27,140 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b54ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 9540c119-2bab-4ecd-94b7-28c9a02bd944)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:34:37,197 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:34:37,200 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 72%|███████▏  | 12601/17525 [2:31:16<6:52:40,  5.03s/it] 72%|███████▏  | 12602/17525 [2:31:17<5:03:01,  3.69s/it] 72%|███████▏  | 12603/17525 [2:31:17<3:46:18,  2.76s/it] 72%|███████▏  | 12604/17525 [2:31:18<2:52:34,  2.10s/it] 72%|███████▏  | 12605/17525 [2:31:18<2:15:03,  1.65s/it] 72%|███████▏  | 12606/17525 [2:31:19<1:48:41,  1.33s/it] 72%|███████▏  | 12607/17525 [2:31:20<1:30:11,  1.10s/it] 72%|███████▏  | 12608/17525 [2:31:20<1:17:10,  1.06it/s] 72%|███████▏  | 12609/17525 [2:31:21<1:08:09,  1.20it/s] 72%|███████▏  | 12610/17525 [2:31:21<1:01:47,  1.33it/s]                                                         {'loss': 0.3573, 'grad_norm': 14.090112686157227, 'learning_rate': 3.658451897041596e-06, 'epoch': 17.99}
 72%|███████▏  | 12610/17525 [2:31:21<1:01:47,  1.33it/s] 72%|███████▏  | 12611/17525 [2:31:22<57:28,  1.42it/s]   72%|███████▏  | 12612/17525 [2:31:22<54:21,  1.51it/s] 72%|███████▏  | 12613/17525 [2:31:23<52:14,  1.57it/s] 72%|███████▏  | 12614/17525 [2:31:24<50:34,  1.62it/s] 72%|███████▏  | 12615/17525 [2:31:24<49:37,  1.65it/s] 72%|███████▏  | 12616/17525 [2:31:25<48:50,  1.68it/s] 72%|███████▏  | 12617/17525 [2:31:25<48:17,  1.69it/s] 72%|███████▏  | 12618/17525 [2:31:26<47:55,  1.71it/s] 72%|███████▏  | 12619/17525 [2:31:26<47:36,  1.72it/s] 72%|███████▏  | 12620/17525 [2:31:27<47:27,  1.72it/s]                                                       {'loss': 0.3876, 'grad_norm': 10.19796085357666, 'learning_rate': 3.6445855184470094e-06, 'epoch': 18.0}
 72%|███████▏  | 12620/17525 [2:31:27<47:27,  1.72it/s] 72%|███████▏  | 12621/17525 [2:31:28<47:20,  1.73it/s] 72%|███████▏  | 12622/17525 [2:31:28<47:13,  1.73it/s] 72%|███████▏  | 12623/17525 [2:31:29<47:05,  1.73it/s] 72%|███████▏  | 12624/17525 [2:31:29<47:04,  1.74it/s] 72%|███████▏  | 12625/17525 [2:31:30<46:56,  1.74it/s] 72%|███████▏  | 12626/17525 [2:31:31<55:47,  1.46it/s] 72%|███████▏  | 12627/17525 [2:31:31<53:06,  1.54it/s] 72%|███████▏  | 12628/17525 [2:31:32<51:14,  1.59it/s] 72%|███████▏  | 12629/17525 [2:31:33<49:53,  1.64it/s] 72%|███████▏  | 12630/17525 [2:31:33<49:03,  1.66it/s]                                                       {'loss': 0.3876, 'grad_norm': 9.793731689453125, 'learning_rate': 3.6307396099200686e-06, 'epoch': 18.02}
 72%|███████▏  | 12630/17525 [2:31:33<49:03,  1.66it/s] 72%|███████▏  | 12631/17525 [2:31:34<57:07,  1.43it/s] 72%|███████▏  | 12632/17525 [2:31:35<53:57,  1.51it/s] 72%|███████▏  | 12633/17525 [2:31:35<51:47,  1.57it/s] 72%|███████▏  | 12634/17525 [2:31:36<50:12,  1.62it/s] 72%|███████▏  | 12635/17525 [2:31:36<49:10,  1.66it/s] 72%|███████▏  | 12636/17525 [2:31:37<48:23,  1.68it/s] 72%|███████▏  | 12637/17525 [2:31:38<58:10,  1.40it/s] 72%|███████▏  | 12638/17525 [2:31:38<54:40,  1.49it/s] 72%|███████▏  | 12639/17525 [2:31:39<52:11,  1.56it/s] 72%|███████▏  | 12640/17525 [2:31:40<50:31,  1.61it/s]                                                       {'loss': 0.3177, 'grad_norm': 24.22579574584961, 'learning_rate': 3.616914216056875e-06, 'epoch': 18.03}
 72%|███████▏  | 12640/17525 [2:31:40<50:31,  1.61it/s] 72%|███████▏  | 12641/17525 [2:31:40<49:26,  1.65it/s] 72%|███████▏  | 12642/17525 [2:31:41<48:34,  1.68it/s] 72%|███████▏  | 12643/17525 [2:31:41<47:57,  1.70it/s] 72%|███████▏  | 12644/17525 [2:31:42<47:34,  1.71it/s] 72%|███████▏  | 12645/17525 [2:31:42<47:23,  1.72it/s] 72%|███████▏  | 12646/17525 [2:31:43<47:13,  1.72it/s] 72%|███████▏  | 12647/17525 [2:31:44<47:04,  1.73it/s] 72%|███████▏  | 12648/17525 [2:31:44<46:53,  1.73it/s] 72%|███████▏  | 12649/17525 [2:31:45<46:47,  1.74it/s] 72%|███████▏  | 12650/17525 [2:31:45<46:45,  1.74it/s]                                                       {'loss': 0.3774, 'grad_norm': 4.218006134033203, 'learning_rate': 3.603109381387441e-06, 'epoch': 18.05}
 72%|███████▏  | 12650/17525 [2:31:45<46:45,  1.74it/s] 72%|███████▏  | 12651/17525 [2:31:46<46:39,  1.74it/s] 72%|███████▏  | 12652/17525 [2:31:47<47:01,  1.73it/s] 72%|███████▏  | 12653/17525 [2:31:48<1:02:10,  1.31it/s] 72%|███████▏  | 12654/17525 [2:31:48<57:26,  1.41it/s]   72%|███████▏  | 12655/17525 [2:31:49<54:07,  1.50it/s] 72%|███████▏  | 12656/17525 [2:31:49<51:45,  1.57it/s] 72%|███████▏  | 12657/17525 [2:31:50<50:11,  1.62it/s] 72%|███████▏  | 12658/17525 [2:31:51<59:35,  1.36it/s] 72%|███████▏  | 12659/17525 [2:31:52<56:04,  1.45it/s] 72%|███████▏  | 12660/17525 [2:31:52<53:11,  1.52it/s]                                                       {'loss': 0.371, 'grad_norm': 8.562386512756348, 'learning_rate': 3.589325150375582e-06, 'epoch': 18.06}
 72%|███████▏  | 12660/17525 [2:31:52<53:11,  1.52it/s] 72%|███████▏  | 12661/17525 [2:31:53<51:10,  1.58it/s] 72%|███████▏  | 12662/17525 [2:31:53<49:43,  1.63it/s] 72%|███████▏  | 12663/17525 [2:31:54<49:20,  1.64it/s] 72%|███████▏  | 12664/17525 [2:31:54<48:30,  1.67it/s] 72%|███████▏  | 12665/17525 [2:31:55<48:19,  1.68it/s] 72%|███████▏  | 12666/17525 [2:31:56<47:54,  1.69it/s] 72%|███████▏  | 12667/17525 [2:31:56<47:28,  1.71it/s] 72%|███████▏  | 12668/17525 [2:31:57<47:08,  1.72it/s] 72%|███████▏  | 12669/17525 [2:31:57<46:59,  1.72it/s] 72%|███████▏  | 12670/17525 [2:31:58<46:50,  1.73it/s]                                                       {'loss': 0.3725, 'grad_norm': 8.20960521697998, 'learning_rate': 3.5755615674187305e-06, 'epoch': 18.07}
 72%|███████▏  | 12670/17525 [2:31:58<46:50,  1.73it/s] 72%|███████▏  | 12671/17525 [2:31:59<46:59,  1.72it/s] 72%|███████▏  | 12672/17525 [2:31:59<46:45,  1.73it/s] 72%|███████▏  | 12673/17525 [2:32:00<46:35,  1.74it/s] 72%|███████▏  | 12674/17525 [2:32:00<46:32,  1.74it/s] 72%|███████▏  | 12675/17525 [2:32:01<46:34,  1.74it/s] 72%|███████▏  | 12676/17525 [2:32:01<46:32,  1.74it/s] 72%|███████▏  | 12677/17525 [2:32:02<46:31,  1.74it/s] 72%|███████▏  | 12678/17525 [2:32:03<46:26,  1.74it/s] 72%|███████▏  | 12679/17525 [2:32:03<46:21,  1.74it/s] 72%|███████▏  | 12680/17525 [2:32:04<46:20,  1.74it/s]                                                       {'loss': 0.3721, 'grad_norm': 7.052158355712891, 'learning_rate': 3.5618186768478257e-06, 'epoch': 18.09}
 72%|███████▏  | 12680/17525 [2:32:04<46:20,  1.74it/s] 72%|███████▏  | 12681/17525 [2:32:04<47:00,  1.72it/s] 72%|███████▏  | 12682/17525 [2:32:05<46:46,  1.73it/s] 72%|███████▏  | 12683/17525 [2:32:05<46:41,  1.73it/s] 72%|███████▏  | 12684/17525 [2:32:06<46:38,  1.73it/s] 72%|███████▏  | 12685/17525 [2:32:07<46:35,  1.73it/s] 72%|███████▏  | 12686/17525 [2:32:07<46:32,  1.73it/s] 72%|███████▏  | 12687/17525 [2:32:08<46:30,  1.73it/s] 72%|███████▏  | 12688/17525 [2:32:08<46:23,  1.74it/s] 72%|███████▏  | 12689/17525 [2:32:09<46:20,  1.74it/s] 72%|███████▏  | 12690/17525 [2:32:09<46:20,  1.74it/s]                                                       {'loss': 0.3644, 'grad_norm': 16.57678985595703, 'learning_rate': 3.5480965229271545e-06, 'epoch': 18.1}
 72%|███████▏  | 12690/17525 [2:32:09<46:20,  1.74it/s] 72%|███████▏  | 12691/17525 [2:32:10<46:19,  1.74it/s] 72%|███████▏  | 12692/17525 [2:32:11<46:15,  1.74it/s] 72%|███████▏  | 12693/17525 [2:32:11<46:13,  1.74it/s] 72%|███████▏  | 12694/17525 [2:32:12<46:16,  1.74it/s] 72%|███████▏  | 12695/17525 [2:32:13<1:05:15,  1.23it/s] 72%|███████▏  | 12696/17525 [2:32:14<59:29,  1.35it/s]   72%|███████▏  | 12697/17525 [2:32:14<55:25,  1.45it/s] 72%|███████▏  | 12698/17525 [2:32:15<52:34,  1.53it/s] 72%|███████▏  | 12699/17525 [2:32:15<50:58,  1.58it/s] 72%|███████▏  | 12700/17525 [2:32:16<49:34,  1.62it/s]                                                       {'loss': 0.455, 'grad_norm': 15.67172622680664, 'learning_rate': 3.5343951498542184e-06, 'epoch': 18.12}
 72%|███████▏  | 12700/17525 [2:32:16<49:34,  1.62it/s][INFO|trainer.py:3512] 2024-06-25 04:35:37,927 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:35:37,927 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:35:37,927 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1429555416107178, 'eval_runtime': 4.597, 'eval_samples_per_second': 96.368, 'eval_steps_per_second': 4.133, 'epoch': 18.12}
 72%|███████▏  | 12700/17525 [2:32:21<49:34,  1.62it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 72%|███████▏  | 12701/17525 [2:32:21<2:43:08,  2.03s/it] 72%|███████▏  | 12702/17525 [2:32:22<2:08:04,  1.59s/it] 72%|███████▏  | 12703/17525 [2:32:23<1:43:30,  1.29s/it] 72%|███████▏  | 12704/17525 [2:32:23<1:26:19,  1.07s/it] 72%|███████▏  | 12705/17525 [2:32:24<1:14:17,  1.08it/s] 73%|███████▎  | 12706/17525 [2:32:24<1:05:54,  1.22it/s] 73%|███████▎  | 12707/17525 [2:32:25<59:55,  1.34it/s]   73%|███████▎  | 12708/17525 [2:32:25<55:41,  1.44it/s] 73%|███████▎  | 12709/17525 [2:32:26<52:51,  1.52it/s] 73%|███████▎  | 12710/17525 [2:32:27<50:54,  1.58it/s]                                                       {'loss': 0.4093, 'grad_norm': 12.554574012756348, 'learning_rate': 3.5207146017595827e-06, 'epoch': 18.13}
 73%|███████▎  | 12710/17525 [2:32:27<50:54,  1.58it/s] 73%|███████▎  | 12711/17525 [2:32:27<49:36,  1.62it/s] 73%|███████▎  | 12712/17525 [2:32:28<48:42,  1.65it/s] 73%|███████▎  | 12713/17525 [2:32:28<47:52,  1.68it/s] 73%|███████▎  | 12714/17525 [2:32:29<47:14,  1.70it/s] 73%|███████▎  | 12715/17525 [2:32:29<46:52,  1.71it/s] 73%|███████▎  | 12716/17525 [2:32:30<46:37,  1.72it/s] 73%|███████▎  | 12717/17525 [2:32:31<46:27,  1.72it/s] 73%|███████▎  | 12718/17525 [2:32:31<46:23,  1.73it/s] 73%|███████▎  | 12719/17525 [2:32:32<1:01:17,  1.31it/s] 73%|███████▎  | 12720/17525 [2:32:33<56:46,  1.41it/s]                                                         {'loss': 0.3257, 'grad_norm': 7.403234004974365, 'learning_rate': 3.507054922706733e-06, 'epoch': 18.15}
 73%|███████▎  | 12720/17525 [2:32:33<56:46,  1.41it/s] 73%|███████▎  | 12721/17525 [2:32:34<54:03,  1.48it/s] 73%|███████▎  | 12722/17525 [2:32:34<56:08,  1.43it/s] 73%|███████▎  | 12723/17525 [2:32:35<53:00,  1.51it/s] 73%|███████▎  | 12724/17525 [2:32:35<50:51,  1.57it/s] 73%|███████▎  | 12725/17525 [2:32:36<58:10,  1.38it/s] 73%|███████▎  | 12726/17525 [2:32:37<54:28,  1.47it/s] 73%|███████▎  | 12727/17525 [2:32:38<51:53,  1.54it/s] 73%|███████▎  | 12728/17525 [2:32:38<50:04,  1.60it/s] 73%|███████▎  | 12729/17525 [2:32:39<48:46,  1.64it/s] 73%|███████▎  | 12730/17525 [2:32:40<1:06:21,  1.20it/s]                                                         {'loss': 0.3088, 'grad_norm': 11.033349990844727, 'learning_rate': 3.4934161566919446e-06, 'epoch': 18.16}
 73%|███████▎  | 12730/17525 [2:32:40<1:06:21,  1.20it/s] 73%|███████▎  | 12731/17525 [2:32:41<1:00:16,  1.33it/s] 73%|███████▎  | 12732/17525 [2:32:41<56:00,  1.43it/s]   73%|███████▎  | 12733/17525 [2:32:42<53:03,  1.51it/s] 73%|███████▎  | 12734/17525 [2:32:42<50:58,  1.57it/s] 73%|███████▎  | 12735/17525 [2:32:43<49:24,  1.62it/s] 73%|███████▎  | 12736/17525 [2:32:43<48:22,  1.65it/s] 73%|███████▎  | 12737/17525 [2:32:44<48:08,  1.66it/s] 73%|███████▎  | 12738/17525 [2:32:45<47:28,  1.68it/s] 73%|███████▎  | 12739/17525 [2:32:45<46:54,  1.70it/s] 73%|███████▎  | 12740/17525 [2:32:46<46:32,  1.71it/s]                                                       {'loss': 0.4274, 'grad_norm': 7.849467754364014, 'learning_rate': 3.4797983476441344e-06, 'epoch': 18.17}
 73%|███████▎  | 12740/17525 [2:32:46<46:32,  1.71it/s] 73%|███████▎  | 12741/17525 [2:32:46<46:22,  1.72it/s] 73%|███████▎  | 12742/17525 [2:32:47<46:10,  1.73it/s] 73%|███████▎  | 12743/17525 [2:32:48<46:04,  1.73it/s] 73%|███████▎  | 12744/17525 [2:32:48<45:59,  1.73it/s] 73%|███████▎  | 12745/17525 [2:32:49<45:55,  1.73it/s] 73%|███████▎  | 12746/17525 [2:32:49<45:50,  1.74it/s] 73%|███████▎  | 12747/17525 [2:32:50<45:48,  1.74it/s] 73%|███████▎  | 12748/17525 [2:32:50<45:49,  1.74it/s] 73%|███████▎  | 12749/17525 [2:32:51<45:50,  1.74it/s] 73%|███████▎  | 12750/17525 [2:32:52<45:51,  1.74it/s]                                                       {'loss': 0.2968, 'grad_norm': 11.398503303527832, 'learning_rate': 3.466201539424716e-06, 'epoch': 18.19}
 73%|███████▎  | 12750/17525 [2:32:52<45:51,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 04:36:13,429 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bdd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 95499c29-e924-4df8-8d88-4ddfe90e4240)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:36:23,485 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:36:23,487 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 73%|███████▎  | 12751/17525 [2:33:02<4:49:23,  3.64s/it] 73%|███████▎  | 12752/17525 [2:33:03<3:36:22,  2.72s/it] 73%|███████▎  | 12753/17525 [2:33:03<2:45:08,  2.08s/it] 73%|███████▎  | 12754/17525 [2:33:04<2:09:21,  1.63s/it] 73%|███████▎  | 12755/17525 [2:33:05<1:52:52,  1.42s/it] 73%|███████▎  | 12756/17525 [2:33:06<1:32:46,  1.17s/it] 73%|███████▎  | 12757/17525 [2:33:06<1:18:37,  1.01it/s] 73%|███████▎  | 12758/17525 [2:33:07<1:08:40,  1.16it/s] 73%|███████▎  | 12759/17525 [2:33:07<1:01:43,  1.29it/s] 73%|███████▎  | 12760/17525 [2:33:08<56:53,  1.40it/s]                                                         {'loss': 0.4237, 'grad_norm': 10.1559476852417, 'learning_rate': 3.452625775827464e-06, 'epoch': 18.2}
 73%|███████▎  | 12760/17525 [2:33:08<56:53,  1.40it/s] 73%|███████▎  | 12761/17525 [2:33:08<53:33,  1.48it/s] 73%|███████▎  | 12762/17525 [2:33:09<51:12,  1.55it/s] 73%|███████▎  | 12763/17525 [2:33:10<49:31,  1.60it/s] 73%|███████▎  | 12764/17525 [2:33:10<48:23,  1.64it/s] 73%|███████▎  | 12765/17525 [2:33:11<47:29,  1.67it/s] 73%|███████▎  | 12766/17525 [2:33:11<46:52,  1.69it/s] 73%|███████▎  | 12767/17525 [2:33:12<46:25,  1.71it/s] 73%|███████▎  | 12768/17525 [2:33:12<46:12,  1.72it/s] 73%|███████▎  | 12769/17525 [2:33:13<45:59,  1.72it/s] 73%|███████▎  | 12770/17525 [2:33:14<46:27,  1.71it/s]                                                       {'loss': 0.4166, 'grad_norm': 10.051349639892578, 'learning_rate': 3.439071100578374e-06, 'epoch': 18.22}
 73%|███████▎  | 12770/17525 [2:33:14<46:27,  1.71it/s] 73%|███████▎  | 12771/17525 [2:33:14<46:14,  1.71it/s] 73%|███████▎  | 12772/17525 [2:33:15<46:05,  1.72it/s] 73%|███████▎  | 12773/17525 [2:33:15<45:50,  1.73it/s] 73%|███████▎  | 12774/17525 [2:33:16<45:42,  1.73it/s] 73%|███████▎  | 12775/17525 [2:33:17<45:34,  1.74it/s] 73%|███████▎  | 12776/17525 [2:33:17<45:39,  1.73it/s] 73%|███████▎  | 12777/17525 [2:33:18<45:40,  1.73it/s] 73%|███████▎  | 12778/17525 [2:33:18<45:40,  1.73it/s] 73%|███████▎  | 12779/17525 [2:33:19<45:35,  1.74it/s] 73%|███████▎  | 12780/17525 [2:33:20<54:10,  1.46it/s]                                                       {'loss': 0.4107, 'grad_norm': 13.458704948425293, 'learning_rate': 3.425537557335502e-06, 'epoch': 18.23}
 73%|███████▎  | 12780/17525 [2:33:20<54:10,  1.46it/s] 73%|███████▎  | 12781/17525 [2:33:20<51:37,  1.53it/s] 73%|███████▎  | 12782/17525 [2:33:21<49:48,  1.59it/s] 73%|███████▎  | 12783/17525 [2:33:21<48:31,  1.63it/s] 73%|███████▎  | 12784/17525 [2:33:22<47:40,  1.66it/s] 73%|███████▎  | 12785/17525 [2:33:23<47:02,  1.68it/s] 73%|███████▎  | 12786/17525 [2:33:23<46:35,  1.70it/s] 73%|███████▎  | 12787/17525 [2:33:24<46:12,  1.71it/s] 73%|███████▎  | 12788/17525 [2:33:24<45:52,  1.72it/s] 73%|███████▎  | 12789/17525 [2:33:25<46:24,  1.70it/s] 73%|███████▎  | 12790/17525 [2:33:26<46:48,  1.69it/s]                                                       {'loss': 0.3307, 'grad_norm': 25.645263671875, 'learning_rate': 3.412025189688867e-06, 'epoch': 18.25}
 73%|███████▎  | 12790/17525 [2:33:26<46:48,  1.69it/s] 73%|███████▎  | 12791/17525 [2:33:26<46:28,  1.70it/s] 73%|███████▎  | 12792/17525 [2:33:27<46:04,  1.71it/s] 73%|███████▎  | 12793/17525 [2:33:27<45:46,  1.72it/s] 73%|███████▎  | 12794/17525 [2:33:28<45:41,  1.73it/s] 73%|███████▎  | 12795/17525 [2:33:28<45:34,  1.73it/s] 73%|███████▎  | 12796/17525 [2:33:29<45:27,  1.73it/s] 73%|███████▎  | 12797/17525 [2:33:30<45:23,  1.74it/s] 73%|███████▎  | 12798/17525 [2:33:30<45:22,  1.74it/s] 73%|███████▎  | 12799/17525 [2:33:31<45:22,  1.74it/s] 73%|███████▎  | 12800/17525 [2:33:31<45:17,  1.74it/s]                                                       {'loss': 0.4355, 'grad_norm': 5.4244608879089355, 'learning_rate': 3.3985340411602598e-06, 'epoch': 18.26}
 73%|███████▎  | 12800/17525 [2:33:31<45:17,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:36:53,214 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:36:53,214 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:36:53,214 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.150707483291626, 'eval_runtime': 4.5925, 'eval_samples_per_second': 96.462, 'eval_steps_per_second': 4.137, 'epoch': 18.26}
 73%|███████▎  | 12800/17525 [2:33:36<45:17,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 73%|███████▎  | 12801/17525 [2:33:36<2:34:02,  1.96s/it] 73%|███████▎  | 12802/17525 [2:33:37<2:01:28,  1.54s/it] 73%|███████▎  | 12803/17525 [2:33:38<1:38:38,  1.25s/it] 73%|███████▎  | 12804/17525 [2:33:38<1:22:33,  1.05s/it] 73%|███████▎  | 12805/17525 [2:33:39<1:11:23,  1.10it/s] 73%|███████▎  | 12806/17525 [2:33:39<1:03:33,  1.24it/s] 73%|███████▎  | 12807/17525 [2:33:40<58:00,  1.36it/s]   73%|███████▎  | 12808/17525 [2:33:41<54:12,  1.45it/s] 73%|███████▎  | 12809/17525 [2:33:41<51:34,  1.52it/s] 73%|███████▎  | 12810/17525 [2:33:42<49:40,  1.58it/s]                                                       {'loss': 0.4139, 'grad_norm': 7.145071506500244, 'learning_rate': 3.385064155203138e-06, 'epoch': 18.27}
 73%|███████▎  | 12810/17525 [2:33:42<49:40,  1.58it/s] 73%|███████▎  | 12811/17525 [2:33:42<48:20,  1.63it/s] 73%|███████▎  | 12812/17525 [2:33:43<47:22,  1.66it/s] 73%|███████▎  | 12813/17525 [2:33:43<46:43,  1.68it/s] 73%|███████▎  | 12814/17525 [2:33:44<46:14,  1.70it/s] 73%|███████▎  | 12815/17525 [2:33:45<45:54,  1.71it/s] 73%|███████▎  | 12816/17525 [2:33:45<45:40,  1.72it/s] 73%|███████▎  | 12817/17525 [2:33:46<45:32,  1.72it/s] 73%|███████▎  | 12818/17525 [2:33:46<45:24,  1.73it/s] 73%|███████▎  | 12819/17525 [2:33:47<45:21,  1.73it/s] 73%|███████▎  | 12820/17525 [2:33:47<45:16,  1.73it/s]                                                       {'loss': 0.334, 'grad_norm': 9.17310619354248, 'learning_rate': 3.371615575202476e-06, 'epoch': 18.29}
 73%|███████▎  | 12820/17525 [2:33:47<45:16,  1.73it/s] 73%|███████▎  | 12821/17525 [2:33:48<45:20,  1.73it/s] 73%|███████▎  | 12822/17525 [2:33:49<45:16,  1.73it/s] 73%|███████▎  | 12823/17525 [2:33:50<1:03:39,  1.23it/s] 73%|███████▎  | 12824/17525 [2:33:51<58:08,  1.35it/s]   73%|███████▎  | 12825/17525 [2:33:51<54:10,  1.45it/s] 73%|███████▎  | 12826/17525 [2:33:52<51:23,  1.52it/s] 73%|███████▎  | 12827/17525 [2:33:52<49:31,  1.58it/s] 73%|███████▎  | 12828/17525 [2:33:53<48:08,  1.63it/s] 73%|███████▎  | 12829/17525 [2:33:53<47:07,  1.66it/s] 73%|███████▎  | 12830/17525 [2:33:54<46:26,  1.68it/s]                                                       {'loss': 0.4007, 'grad_norm': 4.544300079345703, 'learning_rate': 3.3581883444746188e-06, 'epoch': 18.3}
 73%|███████▎  | 12830/17525 [2:33:54<46:26,  1.68it/s] 73%|███████▎  | 12831/17525 [2:33:55<46:05,  1.70it/s] 73%|███████▎  | 12832/17525 [2:33:55<45:45,  1.71it/s] 73%|███████▎  | 12833/17525 [2:33:56<45:31,  1.72it/s] 73%|███████▎  | 12834/17525 [2:33:56<45:21,  1.72it/s] 73%|███████▎  | 12835/17525 [2:33:57<53:22,  1.46it/s] 73%|███████▎  | 12836/17525 [2:33:58<50:57,  1.53it/s] 73%|███████▎  | 12837/17525 [2:33:58<49:09,  1.59it/s] 73%|███████▎  | 12838/17525 [2:33:59<47:58,  1.63it/s] 73%|███████▎  | 12839/17525 [2:34:00<47:01,  1.66it/s] 73%|███████▎  | 12840/17525 [2:34:00<46:21,  1.68it/s]                                                       {'loss': 0.3734, 'grad_norm': 8.868156433105469, 'learning_rate': 3.3447825062671546e-06, 'epoch': 18.32}
 73%|███████▎  | 12840/17525 [2:34:00<46:21,  1.68it/s] 73%|███████▎  | 12841/17525 [2:34:02<1:10:54,  1.10it/s] 73%|███████▎  | 12842/17525 [2:34:02<1:03:09,  1.24it/s] 73%|███████▎  | 12843/17525 [2:34:03<57:40,  1.35it/s]   73%|███████▎  | 12844/17525 [2:34:04<57:11,  1.36it/s] 73%|███████▎  | 12845/17525 [2:34:04<53:27,  1.46it/s] 73%|███████▎  | 12846/17525 [2:34:05<50:46,  1.54it/s] 73%|███████▎  | 12847/17525 [2:34:05<49:04,  1.59it/s] 73%|███████▎  | 12848/17525 [2:34:06<47:51,  1.63it/s] 73%|███████▎  | 12849/17525 [2:34:06<46:57,  1.66it/s] 73%|███████▎  | 12850/17525 [2:34:07<46:18,  1.68it/s]                                                       {'loss': 0.4338, 'grad_norm': 5.541911602020264, 'learning_rate': 3.331398103758754e-06, 'epoch': 18.33}
 73%|███████▎  | 12850/17525 [2:34:07<46:18,  1.68it/s] 73%|███████▎  | 12851/17525 [2:34:08<45:56,  1.70it/s] 73%|███████▎  | 12852/17525 [2:34:08<45:33,  1.71it/s] 73%|███████▎  | 12853/17525 [2:34:09<45:19,  1.72it/s] 73%|███████▎  | 12854/17525 [2:34:09<45:09,  1.72it/s] 73%|███████▎  | 12855/17525 [2:34:10<44:59,  1.73it/s] 73%|███████▎  | 12856/17525 [2:34:11<44:53,  1.73it/s] 73%|███████▎  | 12857/17525 [2:34:11<45:18,  1.72it/s] 73%|███████▎  | 12858/17525 [2:34:12<45:08,  1.72it/s] 73%|███████▎  | 12859/17525 [2:34:13<55:57,  1.39it/s] 73%|███████▎  | 12860/17525 [2:34:13<52:35,  1.48it/s]                                                       {'loss': 0.3371, 'grad_norm': 3.123119592666626, 'learning_rate': 3.3180351800590703e-06, 'epoch': 18.35}
 73%|███████▎  | 12860/17525 [2:34:13<52:35,  1.48it/s] 73%|███████▎  | 12861/17525 [2:34:14<50:13,  1.55it/s] 73%|███████▎  | 12862/17525 [2:34:14<48:35,  1.60it/s] 73%|███████▎  | 12863/17525 [2:34:15<47:53,  1.62it/s] 73%|███████▎  | 12864/17525 [2:34:16<46:55,  1.66it/s] 73%|███████▎  | 12865/17525 [2:34:16<46:13,  1.68it/s] 73%|███████▎  | 12866/17525 [2:34:17<54:10,  1.43it/s] 73%|███████▎  | 12867/17525 [2:34:18<51:18,  1.51it/s] 73%|███████▎  | 12868/17525 [2:34:18<49:16,  1.58it/s] 73%|███████▎  | 12869/17525 [2:34:19<47:51,  1.62it/s] 73%|███████▎  | 12870/17525 [2:34:19<46:47,  1.66it/s]                                                       {'loss': 0.3196, 'grad_norm': 7.650304794311523, 'learning_rate': 3.304693778208551e-06, 'epoch': 18.36}
 73%|███████▎  | 12870/17525 [2:34:19<46:47,  1.66it/s] 73%|███████▎  | 12871/17525 [2:34:20<56:18,  1.38it/s] 73%|███████▎  | 12872/17525 [2:34:21<57:17,  1.35it/s] 73%|███████▎  | 12873/17525 [2:34:22<53:24,  1.45it/s] 73%|███████▎  | 12874/17525 [2:34:22<50:48,  1.53it/s] 73%|███████▎  | 12875/17525 [2:34:23<48:54,  1.58it/s] 73%|███████▎  | 12876/17525 [2:34:24<47:36,  1.63it/s] 73%|███████▎  | 12877/17525 [2:34:24<46:37,  1.66it/s] 73%|███████▎  | 12878/17525 [2:34:25<45:57,  1.69it/s] 73%|███████▎  | 12879/17525 [2:34:25<45:31,  1.70it/s] 73%|███████▎  | 12880/17525 [2:34:26<45:13,  1.71it/s]                                                       {'loss': 0.3363, 'grad_norm': 9.281447410583496, 'learning_rate': 3.2913739411783387e-06, 'epoch': 18.37}
 73%|███████▎  | 12880/17525 [2:34:26<45:13,  1.71it/s] 74%|███████▎  | 12881/17525 [2:34:26<45:00,  1.72it/s] 74%|███████▎  | 12882/17525 [2:34:27<44:52,  1.72it/s] 74%|███████▎  | 12883/17525 [2:34:28<44:49,  1.73it/s] 74%|███████▎  | 12884/17525 [2:34:28<44:37,  1.73it/s] 74%|███████▎  | 12885/17525 [2:34:29<44:27,  1.74it/s] 74%|███████▎  | 12886/17525 [2:34:30<52:01,  1.49it/s] 74%|███████▎  | 12887/17525 [2:34:30<49:46,  1.55it/s] 74%|███████▎  | 12888/17525 [2:34:31<48:05,  1.61it/s] 74%|███████▎  | 12889/17525 [2:34:31<46:56,  1.65it/s] 74%|███████▎  | 12890/17525 [2:34:32<46:10,  1.67it/s]                                                       {'loss': 0.3655, 'grad_norm': 8.685683250427246, 'learning_rate': 3.2780757118701147e-06, 'epoch': 18.39}
 74%|███████▎  | 12890/17525 [2:34:32<46:10,  1.67it/s] 74%|███████▎  | 12891/17525 [2:34:32<45:37,  1.69it/s] 74%|███████▎  | 12892/17525 [2:34:33<45:14,  1.71it/s] 74%|███████▎  | 12893/17525 [2:34:34<45:03,  1.71it/s] 74%|███████▎  | 12894/17525 [2:34:34<44:49,  1.72it/s] 74%|███████▎  | 12895/17525 [2:34:35<44:41,  1.73it/s] 74%|███████▎  | 12896/17525 [2:34:35<44:41,  1.73it/s] 74%|███████▎  | 12897/17525 [2:34:36<47:54,  1.61it/s] 74%|███████▎  | 12898/17525 [2:34:37<46:48,  1.65it/s] 74%|███████▎  | 12899/17525 [2:34:37<46:06,  1.67it/s] 74%|███████▎  | 12900/17525 [2:34:38<45:32,  1.69it/s]                                                       {'loss': 0.3359, 'grad_norm': 7.149446487426758, 'learning_rate': 3.2647991331159632e-06, 'epoch': 18.4}
 74%|███████▎  | 12900/17525 [2:34:38<45:32,  1.69it/s][INFO|trainer.py:3512] 2024-06-25 04:37:59,672 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:37:59,672 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:37:59,672 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1515412330627441, 'eval_runtime': 4.5975, 'eval_samples_per_second': 96.357, 'eval_steps_per_second': 4.133, 'epoch': 18.4}
 74%|███████▎  | 12900/17525 [2:34:42<45:32,  1.69it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:38:04,273 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b0d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 130eca36-e3a3-48dd-ad05-745fb3a51fd1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:38:14,329 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:38:14,331 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-12900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 74%|███████▎  | 12901/17525 [2:34:53<6:27:22,  5.03s/it] 74%|███████▎  | 12902/17525 [2:34:54<4:44:23,  3.69s/it] 74%|███████▎  | 12903/17525 [2:34:54<3:32:15,  2.76s/it] 74%|███████▎  | 12904/17525 [2:34:55<2:41:50,  2.10s/it] 74%|███████▎  | 12905/17525 [2:34:55<2:06:25,  1.64s/it] 74%|███████▎  | 12906/17525 [2:34:56<1:41:46,  1.32s/it] 74%|███████▎  | 12907/17525 [2:34:57<1:24:26,  1.10s/it] 74%|███████▎  | 12908/17525 [2:34:57<1:12:23,  1.06it/s] 74%|███████▎  | 12909/17525 [2:34:58<1:04:03,  1.20it/s] 74%|███████▎  | 12910/17525 [2:34:58<58:03,  1.32it/s]                                                         {'loss': 0.3771, 'grad_norm': 18.218324661254883, 'learning_rate': 3.2515442476782364e-06, 'epoch': 18.42}
 74%|███████▎  | 12910/17525 [2:34:58<58:03,  1.32it/s] 74%|███████▎  | 12911/17525 [2:34:59<53:56,  1.43it/s] 74%|███████▎  | 12912/17525 [2:34:59<50:59,  1.51it/s] 74%|███████▎  | 12913/17525 [2:35:00<49:17,  1.56it/s] 74%|███████▎  | 12914/17525 [2:35:01<47:43,  1.61it/s] 74%|███████▎  | 12915/17525 [2:35:01<46:32,  1.65it/s] 74%|███████▎  | 12916/17525 [2:35:02<45:45,  1.68it/s] 74%|███████▎  | 12917/17525 [2:35:02<45:15,  1.70it/s] 74%|███████▎  | 12918/17525 [2:35:03<44:55,  1.71it/s] 74%|███████▎  | 12919/17525 [2:35:04<44:39,  1.72it/s] 74%|███████▎  | 12920/17525 [2:35:04<44:26,  1.73it/s]                                                       {'loss': 0.3865, 'grad_norm': 15.901348114013672, 'learning_rate': 3.238311098249417e-06, 'epoch': 18.43}
 74%|███████▎  | 12920/17525 [2:35:04<44:26,  1.73it/s] 74%|███████▎  | 12921/17525 [2:35:05<44:31,  1.72it/s] 74%|███████▎  | 12922/17525 [2:35:05<44:22,  1.73it/s] 74%|███████▎  | 12923/17525 [2:35:06<44:15,  1.73it/s] 74%|███████▎  | 12924/17525 [2:35:07<48:37,  1.58it/s] 74%|███████▍  | 12925/17525 [2:35:07<47:18,  1.62it/s] 74%|███████▍  | 12926/17525 [2:35:08<46:20,  1.65it/s] 74%|███████▍  | 12927/17525 [2:35:08<45:33,  1.68it/s] 74%|███████▍  | 12928/17525 [2:35:09<45:03,  1.70it/s] 74%|███████▍  | 12929/17525 [2:35:09<44:43,  1.71it/s] 74%|███████▍  | 12930/17525 [2:35:10<44:31,  1.72it/s]                                                       {'loss': 0.3451, 'grad_norm': 17.404150009155273, 'learning_rate': 3.225099727451967e-06, 'epoch': 18.45}
 74%|███████▍  | 12930/17525 [2:35:10<44:31,  1.72it/s] 74%|███████▍  | 12931/17525 [2:35:11<44:26,  1.72it/s] 74%|███████▍  | 12932/17525 [2:35:11<44:14,  1.73it/s] 74%|███████▍  | 12933/17525 [2:35:12<44:04,  1.74it/s] 74%|███████▍  | 12934/17525 [2:35:12<44:03,  1.74it/s] 74%|███████▍  | 12935/17525 [2:35:13<44:01,  1.74it/s] 74%|███████▍  | 12936/17525 [2:35:13<44:02,  1.74it/s] 74%|███████▍  | 12937/17525 [2:35:14<44:01,  1.74it/s] 74%|███████▍  | 12938/17525 [2:35:15<44:00,  1.74it/s] 74%|███████▍  | 12939/17525 [2:35:15<44:00,  1.74it/s] 74%|███████▍  | 12940/17525 [2:35:16<53:24,  1.43it/s]                                                       {'loss': 0.353, 'grad_norm': 8.656377792358398, 'learning_rate': 3.2119101778382146e-06, 'epoch': 18.46}
 74%|███████▍  | 12940/17525 [2:35:16<53:24,  1.43it/s] 74%|███████▍  | 12941/17525 [2:35:17<50:38,  1.51it/s] 74%|███████▍  | 12942/17525 [2:35:17<48:39,  1.57it/s] 74%|███████▍  | 12943/17525 [2:35:18<47:13,  1.62it/s] 74%|███████▍  | 12944/17525 [2:35:18<46:16,  1.65it/s] 74%|███████▍  | 12945/17525 [2:35:19<49:39,  1.54it/s] 74%|███████▍  | 12946/17525 [2:35:20<47:53,  1.59it/s] 74%|███████▍  | 12947/17525 [2:35:20<46:46,  1.63it/s] 74%|███████▍  | 12948/17525 [2:35:21<56:54,  1.34it/s] 74%|███████▍  | 12949/17525 [2:35:22<53:03,  1.44it/s] 74%|███████▍  | 12950/17525 [2:35:23<50:49,  1.50it/s]                                                       {'loss': 0.3101, 'grad_norm': 7.179765224456787, 'learning_rate': 3.1987424918902e-06, 'epoch': 18.47}
 74%|███████▍  | 12950/17525 [2:35:23<50:49,  1.50it/s] 74%|███████▍  | 12951/17525 [2:35:23<48:47,  1.56it/s] 74%|███████▍  | 12952/17525 [2:35:24<50:47,  1.50it/s] 74%|███████▍  | 12953/17525 [2:35:25<49:25,  1.54it/s] 74%|███████▍  | 12954/17525 [2:35:25<47:47,  1.59it/s] 74%|███████▍  | 12955/17525 [2:35:26<46:37,  1.63it/s] 74%|███████▍  | 12956/17525 [2:35:26<45:45,  1.66it/s] 74%|███████▍  | 12957/17525 [2:35:27<45:08,  1.69it/s] 74%|███████▍  | 12958/17525 [2:35:27<45:01,  1.69it/s] 74%|███████▍  | 12959/17525 [2:35:28<44:40,  1.70it/s] 74%|███████▍  | 12960/17525 [2:35:29<44:26,  1.71it/s]                                                       {'loss': 0.3324, 'grad_norm': 8.83052921295166, 'learning_rate': 3.185596712019542e-06, 'epoch': 18.49}
 74%|███████▍  | 12960/17525 [2:35:29<44:26,  1.71it/s] 74%|███████▍  | 12961/17525 [2:35:29<44:17,  1.72it/s] 74%|███████▍  | 12962/17525 [2:35:30<44:07,  1.72it/s] 74%|███████▍  | 12963/17525 [2:35:30<43:56,  1.73it/s] 74%|███████▍  | 12964/17525 [2:35:31<43:51,  1.73it/s] 74%|███████▍  | 12965/17525 [2:35:31<43:46,  1.74it/s] 74%|███████▍  | 12966/17525 [2:35:32<43:44,  1.74it/s] 74%|███████▍  | 12967/17525 [2:35:33<43:43,  1.74it/s] 74%|███████▍  | 12968/17525 [2:35:33<43:42,  1.74it/s] 74%|███████▍  | 12969/17525 [2:35:34<44:16,  1.72it/s] 74%|███████▍  | 12970/17525 [2:35:34<44:02,  1.72it/s]                                                       {'loss': 0.3714, 'grad_norm': 5.4689555168151855, 'learning_rate': 3.1724728805673067e-06, 'epoch': 18.5}
 74%|███████▍  | 12970/17525 [2:35:34<44:02,  1.72it/s] 74%|███████▍  | 12971/17525 [2:35:35<43:52,  1.73it/s] 74%|███████▍  | 12972/17525 [2:35:36<43:45,  1.73it/s] 74%|███████▍  | 12973/17525 [2:35:36<43:42,  1.74it/s] 74%|███████▍  | 12974/17525 [2:35:37<43:36,  1.74it/s] 74%|███████▍  | 12975/17525 [2:35:37<43:35,  1.74it/s] 74%|███████▍  | 12976/17525 [2:35:38<43:37,  1.74it/s] 74%|███████▍  | 12977/17525 [2:35:38<43:36,  1.74it/s] 74%|███████▍  | 12978/17525 [2:35:39<43:32,  1.74it/s] 74%|███████▍  | 12979/17525 [2:35:40<43:32,  1.74it/s] 74%|███████▍  | 12980/17525 [2:35:40<43:30,  1.74it/s]                                                       {'loss': 0.4036, 'grad_norm': 8.315781593322754, 'learning_rate': 3.1593710398038544e-06, 'epoch': 18.52}
 74%|███████▍  | 12980/17525 [2:35:40<43:30,  1.74it/s] 74%|███████▍  | 12981/17525 [2:35:41<43:36,  1.74it/s] 74%|███████▍  | 12982/17525 [2:35:41<43:29,  1.74it/s] 74%|███████▍  | 12983/17525 [2:35:42<43:38,  1.73it/s] 74%|███████▍  | 12984/17525 [2:35:42<43:30,  1.74it/s] 74%|███████▍  | 12985/17525 [2:35:43<43:32,  1.74it/s] 74%|███████▍  | 12986/17525 [2:35:44<43:28,  1.74it/s] 74%|███████▍  | 12987/17525 [2:35:44<43:26,  1.74it/s] 74%|███████▍  | 12988/17525 [2:35:45<43:25,  1.74it/s] 74%|███████▍  | 12989/17525 [2:35:45<43:20,  1.74it/s] 74%|███████▍  | 12990/17525 [2:35:46<43:19,  1.74it/s]                                                       {'loss': 0.3241, 'grad_norm': 13.261701583862305, 'learning_rate': 3.1462912319287376e-06, 'epoch': 18.53}
 74%|███████▍  | 12990/17525 [2:35:46<43:19,  1.74it/s] 74%|███████▍  | 12991/17525 [2:35:46<43:23,  1.74it/s] 74%|███████▍  | 12992/17525 [2:35:47<43:27,  1.74it/s] 74%|███████▍  | 12993/17525 [2:35:48<43:23,  1.74it/s] 74%|███████▍  | 12994/17525 [2:35:48<43:22,  1.74it/s] 74%|███████▍  | 12995/17525 [2:35:49<43:20,  1.74it/s] 74%|███████▍  | 12996/17525 [2:35:49<43:20,  1.74it/s] 74%|███████▍  | 12997/17525 [2:35:50<43:18,  1.74it/s] 74%|███████▍  | 12998/17525 [2:35:50<43:23,  1.74it/s] 74%|███████▍  | 12999/17525 [2:35:51<43:21,  1.74it/s] 74%|███████▍  | 13000/17525 [2:35:52<43:19,  1.74it/s]                                                       {'loss': 0.2865, 'grad_norm': 8.339980125427246, 'learning_rate': 3.133233499070518e-06, 'epoch': 18.54}
 74%|███████▍  | 13000/17525 [2:35:52<43:19,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:39:13,543 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:39:13,543 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:39:13,543 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1498054265975952, 'eval_runtime': 4.595, 'eval_samples_per_second': 96.409, 'eval_steps_per_second': 4.135, 'epoch': 18.54}
 74%|███████▍  | 13000/17525 [2:35:56<43:19,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 74%|███████▍  | 13001/17525 [2:35:57<2:28:35,  1.97s/it] 74%|███████▍  | 13002/17525 [2:35:57<1:57:03,  1.55s/it] 74%|███████▍  | 13003/17525 [2:35:58<1:34:53,  1.26s/it] 74%|███████▍  | 13004/17525 [2:35:59<1:19:18,  1.05s/it] 74%|███████▍  | 13005/17525 [2:35:59<1:08:31,  1.10it/s] 74%|███████▍  | 13006/17525 [2:36:00<1:00:57,  1.24it/s] 74%|███████▍  | 13007/17525 [2:36:00<55:35,  1.35it/s]   74%|███████▍  | 13008/17525 [2:36:01<51:52,  1.45it/s] 74%|███████▍  | 13009/17525 [2:36:01<49:20,  1.53it/s] 74%|███████▍  | 13010/17525 [2:36:02<48:08,  1.56it/s]                                                       {'loss': 0.3775, 'grad_norm': 6.547909259796143, 'learning_rate': 3.1201978832866807e-06, 'epoch': 18.56}
 74%|███████▍  | 13010/17525 [2:36:02<48:08,  1.56it/s] 74%|███████▍  | 13011/17525 [2:36:03<46:43,  1.61it/s] 74%|███████▍  | 13012/17525 [2:36:03<45:40,  1.65it/s] 74%|███████▍  | 13013/17525 [2:36:04<44:57,  1.67it/s] 74%|███████▍  | 13014/17525 [2:36:04<44:19,  1.70it/s] 74%|███████▍  | 13015/17525 [2:36:05<43:55,  1.71it/s] 74%|███████▍  | 13016/17525 [2:36:05<43:43,  1.72it/s] 74%|███████▍  | 13017/17525 [2:36:06<44:10,  1.70it/s] 74%|███████▍  | 13018/17525 [2:36:07<43:48,  1.71it/s] 74%|███████▍  | 13019/17525 [2:36:08<51:44,  1.45it/s] 74%|███████▍  | 13020/17525 [2:36:08<49:16,  1.52it/s]                                                       {'loss': 0.2729, 'grad_norm': 12.337807655334473, 'learning_rate': 3.1071844265634553e-06, 'epoch': 18.57}
 74%|███████▍  | 13020/17525 [2:36:08<49:16,  1.52it/s] 74%|███████▍  | 13021/17525 [2:36:09<47:26,  1.58it/s] 74%|███████▍  | 13022/17525 [2:36:09<46:05,  1.63it/s] 74%|███████▍  | 13023/17525 [2:36:10<45:12,  1.66it/s] 74%|███████▍  | 13024/17525 [2:36:10<44:34,  1.68it/s] 74%|███████▍  | 13025/17525 [2:36:11<44:05,  1.70it/s] 74%|███████▍  | 13026/17525 [2:36:12<43:48,  1.71it/s] 74%|███████▍  | 13027/17525 [2:36:12<43:35,  1.72it/s] 74%|███████▍  | 13028/17525 [2:36:13<43:32,  1.72it/s] 74%|███████▍  | 13029/17525 [2:36:13<43:24,  1.73it/s] 74%|███████▍  | 13030/17525 [2:36:14<43:19,  1.73it/s]                                                       {'loss': 0.352, 'grad_norm': 10.641185760498047, 'learning_rate': 3.094193170815707e-06, 'epoch': 18.59}
 74%|███████▍  | 13030/17525 [2:36:14<43:19,  1.73it/s] 74%|███████▍  | 13031/17525 [2:36:14<43:18,  1.73it/s] 74%|███████▍  | 13032/17525 [2:36:15<43:08,  1.74it/s] 74%|███████▍  | 13033/17525 [2:36:16<43:09,  1.73it/s] 74%|███████▍  | 13034/17525 [2:36:16<43:39,  1.71it/s] 74%|███████▍  | 13035/17525 [2:36:17<43:22,  1.73it/s] 74%|███████▍  | 13036/17525 [2:36:17<43:10,  1.73it/s] 74%|███████▍  | 13037/17525 [2:36:18<43:43,  1.71it/s] 74%|███████▍  | 13038/17525 [2:36:19<43:22,  1.72it/s] 74%|███████▍  | 13039/17525 [2:36:19<43:16,  1.73it/s] 74%|███████▍  | 13040/17525 [2:36:20<43:06,  1.73it/s]                                                       {'loss': 0.4721, 'grad_norm': 10.92690658569336, 'learning_rate': 3.081224157886796e-06, 'epoch': 18.6}
 74%|███████▍  | 13040/17525 [2:36:20<43:06,  1.73it/s] 74%|███████▍  | 13041/17525 [2:36:20<43:53,  1.70it/s] 74%|███████▍  | 13042/17525 [2:36:21<43:30,  1.72it/s] 74%|███████▍  | 13043/17525 [2:36:21<43:14,  1.73it/s] 74%|███████▍  | 13044/17525 [2:36:22<43:05,  1.73it/s] 74%|███████▍  | 13045/17525 [2:36:23<43:01,  1.74it/s] 74%|███████▍  | 13046/17525 [2:36:23<42:54,  1.74it/s] 74%|███████▍  | 13047/17525 [2:36:24<42:48,  1.74it/s] 74%|███████▍  | 13048/17525 [2:36:24<42:45,  1.75it/s] 74%|███████▍  | 13049/17525 [2:36:25<42:45,  1.74it/s] 74%|███████▍  | 13050/17525 [2:36:26<50:27,  1.48it/s]                                                       {'loss': 0.3992, 'grad_norm': 8.997119903564453, 'learning_rate': 3.068277429548441e-06, 'epoch': 18.62}
 74%|███████▍  | 13050/17525 [2:36:26<50:27,  1.48it/s][INFO|trainer.py:3203] 2024-06-25 04:39:47,705 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b85990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a2c2a4f0-45dc-49d2-8e1e-6ede868d49ee)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:39:57,824 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:39:57,827 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 74%|███████▍  | 13051/17525 [2:36:37<4:37:44,  3.72s/it] 74%|███████▍  | 13052/17525 [2:36:37<3:27:10,  2.78s/it] 74%|███████▍  | 13053/17525 [2:36:38<2:37:49,  2.12s/it] 74%|███████▍  | 13054/17525 [2:36:38<2:03:13,  1.65s/it] 74%|███████▍  | 13055/17525 [2:36:39<1:39:06,  1.33s/it] 74%|███████▍  | 13056/17525 [2:36:40<1:22:08,  1.10s/it] 75%|███████▍  | 13057/17525 [2:36:40<1:10:16,  1.06it/s] 75%|███████▍  | 13058/17525 [2:36:41<1:01:58,  1.20it/s] 75%|███████▍  | 13059/17525 [2:36:41<56:55,  1.31it/s]   75%|███████▍  | 13060/17525 [2:36:42<52:35,  1.41it/s]                                                       {'loss': 0.3757, 'grad_norm': 6.12310266494751, 'learning_rate': 3.055353027500575e-06, 'epoch': 18.63}
 75%|███████▍  | 13060/17525 [2:36:42<52:35,  1.41it/s] 75%|███████▍  | 13061/17525 [2:36:42<49:39,  1.50it/s] 75%|███████▍  | 13062/17525 [2:36:43<47:41,  1.56it/s] 75%|███████▍  | 13063/17525 [2:36:44<46:15,  1.61it/s] 75%|███████▍  | 13064/17525 [2:36:44<45:11,  1.65it/s] 75%|███████▍  | 13065/17525 [2:36:45<44:28,  1.67it/s] 75%|███████▍  | 13066/17525 [2:36:45<43:57,  1.69it/s] 75%|███████▍  | 13067/17525 [2:36:46<43:34,  1.71it/s] 75%|███████▍  | 13068/17525 [2:36:46<43:15,  1.72it/s] 75%|███████▍  | 13069/17525 [2:36:47<43:04,  1.72it/s] 75%|███████▍  | 13070/17525 [2:36:48<42:58,  1.73it/s]                                                       {'loss': 0.3442, 'grad_norm': 6.305213928222656, 'learning_rate': 3.042450993371233e-06, 'epoch': 18.64}
 75%|███████▍  | 13070/17525 [2:36:48<42:58,  1.73it/s] 75%|███████▍  | 13071/17525 [2:36:48<42:55,  1.73it/s] 75%|███████▍  | 13072/17525 [2:36:49<42:51,  1.73it/s] 75%|███████▍  | 13073/17525 [2:36:49<42:46,  1.73it/s] 75%|███████▍  | 13074/17525 [2:36:50<42:39,  1.74it/s] 75%|███████▍  | 13075/17525 [2:36:50<42:37,  1.74it/s] 75%|███████▍  | 13076/17525 [2:36:51<42:54,  1.73it/s] 75%|███████▍  | 13077/17525 [2:36:52<42:45,  1.73it/s] 75%|███████▍  | 13078/17525 [2:36:52<42:41,  1.74it/s] 75%|███████▍  | 13079/17525 [2:36:53<42:42,  1.74it/s] 75%|███████▍  | 13080/17525 [2:36:53<42:36,  1.74it/s]                                                       {'loss': 0.3737, 'grad_norm': 8.851213455200195, 'learning_rate': 3.0295713687164006e-06, 'epoch': 18.66}
 75%|███████▍  | 13080/17525 [2:36:53<42:36,  1.74it/s] 75%|███████▍  | 13081/17525 [2:36:54<42:35,  1.74it/s] 75%|███████▍  | 13082/17525 [2:36:55<46:36,  1.59it/s] 75%|███████▍  | 13083/17525 [2:36:55<45:20,  1.63it/s] 75%|███████▍  | 13084/17525 [2:36:56<44:25,  1.67it/s] 75%|███████▍  | 13085/17525 [2:36:56<43:48,  1.69it/s] 75%|███████▍  | 13086/17525 [2:36:57<43:22,  1.71it/s] 75%|███████▍  | 13087/17525 [2:36:58<43:44,  1.69it/s] 75%|███████▍  | 13088/17525 [2:36:58<43:23,  1.70it/s] 75%|███████▍  | 13089/17525 [2:36:59<43:06,  1.71it/s] 75%|███████▍  | 13090/17525 [2:36:59<42:52,  1.72it/s]                                                       {'loss': 0.2893, 'grad_norm': 12.356863021850586, 'learning_rate': 3.016714195019883e-06, 'epoch': 18.67}
 75%|███████▍  | 13090/17525 [2:36:59<42:52,  1.72it/s] 75%|███████▍  | 13091/17525 [2:37:00<42:39,  1.73it/s] 75%|███████▍  | 13092/17525 [2:37:00<42:29,  1.74it/s] 75%|███████▍  | 13093/17525 [2:37:01<42:21,  1.74it/s] 75%|███████▍  | 13094/17525 [2:37:02<42:22,  1.74it/s] 75%|███████▍  | 13095/17525 [2:37:02<42:23,  1.74it/s] 75%|███████▍  | 13096/17525 [2:37:03<42:25,  1.74it/s] 75%|███████▍  | 13097/17525 [2:37:03<42:33,  1.73it/s] 75%|███████▍  | 13098/17525 [2:37:04<42:27,  1.74it/s] 75%|███████▍  | 13099/17525 [2:37:04<42:40,  1.73it/s] 75%|███████▍  | 13100/17525 [2:37:05<42:36,  1.73it/s]                                                       {'loss': 0.3724, 'grad_norm': 14.423343658447266, 'learning_rate': 3.00387951369318e-06, 'epoch': 18.69}
 75%|███████▍  | 13100/17525 [2:37:05<42:36,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:40:26,944 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:40:26,945 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:40:26,945 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.149944543838501, 'eval_runtime': 4.5949, 'eval_samples_per_second': 96.41, 'eval_steps_per_second': 4.135, 'epoch': 18.69}
 75%|███████▍  | 13100/17525 [2:37:10<42:36,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 75%|███████▍  | 13101/17525 [2:37:10<2:24:27,  1.96s/it] 75%|███████▍  | 13102/17525 [2:37:11<1:53:53,  1.54s/it] 75%|███████▍  | 13103/17525 [2:37:11<1:32:18,  1.25s/it] 75%|███████▍  | 13104/17525 [2:37:12<1:17:21,  1.05s/it] 75%|███████▍  | 13105/17525 [2:37:13<1:06:50,  1.10it/s] 75%|███████▍  | 13106/17525 [2:37:13<59:25,  1.24it/s]   75%|███████▍  | 13107/17525 [2:37:14<54:18,  1.36it/s] 75%|███████▍  | 13108/17525 [2:37:14<50:38,  1.45it/s] 75%|███████▍  | 13109/17525 [2:37:15<48:06,  1.53it/s] 75%|███████▍  | 13110/17525 [2:37:15<46:19,  1.59it/s]                                                       {'loss': 0.3502, 'grad_norm': 14.066388130187988, 'learning_rate': 2.9910673660753296e-06, 'epoch': 18.7}
 75%|███████▍  | 13110/17525 [2:37:15<46:19,  1.59it/s] 75%|███████▍  | 13111/17525 [2:37:16<45:11,  1.63it/s] 75%|███████▍  | 13112/17525 [2:37:17<44:15,  1.66it/s] 75%|███████▍  | 13113/17525 [2:37:17<43:41,  1.68it/s] 75%|███████▍  | 13114/17525 [2:37:18<43:16,  1.70it/s] 75%|███████▍  | 13115/17525 [2:37:18<42:54,  1.71it/s] 75%|███████▍  | 13116/17525 [2:37:19<42:38,  1.72it/s] 75%|███████▍  | 13117/17525 [2:37:19<42:27,  1.73it/s] 75%|███████▍  | 13118/17525 [2:37:20<42:48,  1.72it/s] 75%|███████▍  | 13119/17525 [2:37:21<42:35,  1.72it/s] 75%|███████▍  | 13120/17525 [2:37:21<42:29,  1.73it/s]                                                       {'loss': 0.3241, 'grad_norm': 36.41071701049805, 'learning_rate': 2.9782777934328187e-06, 'epoch': 18.72}
 75%|███████▍  | 13120/17525 [2:37:21<42:29,  1.73it/s] 75%|███████▍  | 13121/17525 [2:37:22<42:27,  1.73it/s] 75%|███████▍  | 13122/17525 [2:37:22<42:21,  1.73it/s] 75%|███████▍  | 13123/17525 [2:37:23<42:45,  1.72it/s] 75%|███████▍  | 13124/17525 [2:37:23<42:33,  1.72it/s] 75%|███████▍  | 13125/17525 [2:37:24<42:26,  1.73it/s] 75%|███████▍  | 13126/17525 [2:37:26<1:05:26,  1.12it/s] 75%|███████▍  | 13127/17525 [2:37:26<58:28,  1.25it/s]   75%|███████▍  | 13128/17525 [2:37:27<53:27,  1.37it/s] 75%|███████▍  | 13129/17525 [2:37:27<49:59,  1.47it/s] 75%|███████▍  | 13130/17525 [2:37:28<47:38,  1.54it/s]                                                       {'loss': 0.454, 'grad_norm': 14.907692909240723, 'learning_rate': 2.965510836959392e-06, 'epoch': 18.73}
 75%|███████▍  | 13130/17525 [2:37:28<47:38,  1.54it/s] 75%|███████▍  | 13131/17525 [2:37:29<45:56,  1.59it/s] 75%|███████▍  | 13132/17525 [2:37:29<44:47,  1.63it/s] 75%|███████▍  | 13133/17525 [2:37:30<43:51,  1.67it/s] 75%|███████▍  | 13134/17525 [2:37:30<43:12,  1.69it/s] 75%|███████▍  | 13135/17525 [2:37:31<42:47,  1.71it/s] 75%|███████▍  | 13136/17525 [2:37:31<42:29,  1.72it/s] 75%|███████▍  | 13137/17525 [2:37:32<42:21,  1.73it/s] 75%|███████▍  | 13138/17525 [2:37:33<42:11,  1.73it/s] 75%|███████▍  | 13139/17525 [2:37:33<42:09,  1.73it/s] 75%|███████▍  | 13140/17525 [2:37:34<41:58,  1.74it/s]                                                       {'loss': 0.351, 'grad_norm': 21.83550262451172, 'learning_rate': 2.9527665377759783e-06, 'epoch': 18.74}
 75%|███████▍  | 13140/17525 [2:37:34<41:58,  1.74it/s] 75%|███████▍  | 13141/17525 [2:37:34<41:55,  1.74it/s] 75%|███████▍  | 13142/17525 [2:37:35<41:54,  1.74it/s] 75%|███████▍  | 13143/17525 [2:37:35<42:30,  1.72it/s] 75%|███████▌  | 13144/17525 [2:37:36<42:23,  1.72it/s] 75%|███████▌  | 13145/17525 [2:37:37<42:15,  1.73it/s] 75%|███████▌  | 13146/17525 [2:37:37<42:09,  1.73it/s] 75%|███████▌  | 13147/17525 [2:37:38<42:03,  1.74it/s] 75%|███████▌  | 13148/17525 [2:37:38<41:58,  1.74it/s] 75%|███████▌  | 13149/17525 [2:37:39<42:42,  1.71it/s] 75%|███████▌  | 13150/17525 [2:37:40<42:24,  1.72it/s]                                                       {'loss': 0.3297, 'grad_norm': 19.708213806152344, 'learning_rate': 2.9400449369305082e-06, 'epoch': 18.76}
 75%|███████▌  | 13150/17525 [2:37:40<42:24,  1.72it/s] 75%|███████▌  | 13151/17525 [2:37:40<42:16,  1.72it/s] 75%|███████▌  | 13152/17525 [2:37:41<42:05,  1.73it/s] 75%|███████▌  | 13153/17525 [2:37:41<41:58,  1.74it/s] 75%|███████▌  | 13154/17525 [2:37:42<41:59,  1.74it/s] 75%|███████▌  | 13155/17525 [2:37:42<42:01,  1.73it/s] 75%|███████▌  | 13156/17525 [2:37:43<42:05,  1.73it/s] 75%|███████▌  | 13157/17525 [2:37:44<41:56,  1.74it/s] 75%|███████▌  | 13158/17525 [2:37:44<41:47,  1.74it/s] 75%|███████▌  | 13159/17525 [2:37:45<41:47,  1.74it/s] 75%|███████▌  | 13160/17525 [2:37:45<44:53,  1.62it/s]                                                       {'loss': 0.3603, 'grad_norm': 5.511297702789307, 'learning_rate': 2.9273460753978144e-06, 'epoch': 18.77}
 75%|███████▌  | 13160/17525 [2:37:45<44:53,  1.62it/s] 75%|███████▌  | 13161/17525 [2:37:46<43:57,  1.65it/s] 75%|███████▌  | 13162/17525 [2:37:47<43:16,  1.68it/s] 75%|███████▌  | 13163/17525 [2:37:47<42:44,  1.70it/s] 75%|███████▌  | 13164/17525 [2:37:48<42:27,  1.71it/s] 75%|███████▌  | 13165/17525 [2:37:48<42:17,  1.72it/s] 75%|███████▌  | 13166/17525 [2:37:49<42:31,  1.71it/s] 75%|███████▌  | 13167/17525 [2:37:49<42:15,  1.72it/s] 75%|███████▌  | 13168/17525 [2:37:50<42:31,  1.71it/s] 75%|███████▌  | 13169/17525 [2:37:51<42:15,  1.72it/s] 75%|███████▌  | 13170/17525 [2:37:51<42:07,  1.72it/s]                                                       {'loss': 0.3375, 'grad_norm': 9.6900634765625, 'learning_rate': 2.9146699940794864e-06, 'epoch': 18.79}
 75%|███████▌  | 13170/17525 [2:37:51<42:07,  1.72it/s] 75%|███████▌  | 13171/17525 [2:37:52<42:01,  1.73it/s] 75%|███████▌  | 13172/17525 [2:37:52<41:50,  1.73it/s] 75%|███████▌  | 13173/17525 [2:37:53<41:46,  1.74it/s] 75%|███████▌  | 13174/17525 [2:37:53<41:41,  1.74it/s] 75%|███████▌  | 13175/17525 [2:37:54<41:43,  1.74it/s] 75%|███████▌  | 13176/17525 [2:37:55<41:44,  1.74it/s] 75%|███████▌  | 13177/17525 [2:37:55<41:41,  1.74it/s] 75%|███████▌  | 13178/17525 [2:37:56<41:37,  1.74it/s] 75%|███████▌  | 13179/17525 [2:37:56<41:33,  1.74it/s] 75%|███████▌  | 13180/17525 [2:37:57<41:36,  1.74it/s]                                                       {'loss': 0.4386, 'grad_norm': 14.385008811950684, 'learning_rate': 2.902016733803741e-06, 'epoch': 18.8}
 75%|███████▌  | 13180/17525 [2:37:57<41:36,  1.74it/s] 75%|███████▌  | 13181/17525 [2:37:58<49:33,  1.46it/s] 75%|███████▌  | 13182/17525 [2:37:58<47:08,  1.54it/s] 75%|███████▌  | 13183/17525 [2:37:59<45:26,  1.59it/s] 75%|███████▌  | 13184/17525 [2:38:00<44:16,  1.63it/s] 75%|███████▌  | 13185/17525 [2:38:00<43:28,  1.66it/s] 75%|███████▌  | 13186/17525 [2:38:01<42:56,  1.68it/s] 75%|███████▌  | 13187/17525 [2:38:01<42:31,  1.70it/s] 75%|███████▌  | 13188/17525 [2:38:02<42:06,  1.72it/s] 75%|███████▌  | 13189/17525 [2:38:02<42:14,  1.71it/s] 75%|███████▌  | 13190/17525 [2:38:03<41:53,  1.72it/s]                                                       {'loss': 0.2887, 'grad_norm': 7.559331893920898, 'learning_rate': 2.889386335325295e-06, 'epoch': 18.82}
 75%|███████▌  | 13190/17525 [2:38:03<41:53,  1.72it/s] 75%|███████▌  | 13191/17525 [2:38:04<41:49,  1.73it/s] 75%|███████▌  | 13192/17525 [2:38:04<41:42,  1.73it/s] 75%|███████▌  | 13193/17525 [2:38:05<41:35,  1.74it/s] 75%|███████▌  | 13194/17525 [2:38:05<41:30,  1.74it/s] 75%|███████▌  | 13195/17525 [2:38:06<41:33,  1.74it/s] 75%|███████▌  | 13196/17525 [2:38:06<41:29,  1.74it/s] 75%|███████▌  | 13197/17525 [2:38:07<41:30,  1.74it/s] 75%|███████▌  | 13198/17525 [2:38:08<41:31,  1.74it/s] 75%|███████▌  | 13199/17525 [2:38:08<41:28,  1.74it/s] 75%|███████▌  | 13200/17525 [2:38:09<41:24,  1.74it/s]                                                       {'loss': 0.2918, 'grad_norm': 10.002057075500488, 'learning_rate': 2.8767788393252193e-06, 'epoch': 18.83}
 75%|███████▌  | 13200/17525 [2:38:09<41:24,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:41:30,682 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:41:30,682 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:41:30,682 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1446497440338135, 'eval_runtime': 4.6033, 'eval_samples_per_second': 96.234, 'eval_steps_per_second': 4.127, 'epoch': 18.83}
 75%|███████▌  | 13200/17525 [2:38:13<41:24,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:41:35,289 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bfd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7a5a1057-9c6f-4b82-9271-5f21f7383920)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:41:45,347 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:41:45,349 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 75%|███████▌  | 13201/17525 [2:38:24<6:01:37,  5.02s/it] 75%|███████▌  | 13202/17525 [2:38:25<4:25:29,  3.68s/it] 75%|███████▌  | 13203/17525 [2:38:25<3:18:14,  2.75s/it] 75%|███████▌  | 13204/17525 [2:38:26<2:31:12,  2.10s/it] 75%|███████▌  | 13205/17525 [2:38:26<1:58:17,  1.64s/it] 75%|███████▌  | 13206/17525 [2:38:27<1:35:11,  1.32s/it] 75%|███████▌  | 13207/17525 [2:38:28<1:19:03,  1.10s/it] 75%|███████▌  | 13208/17525 [2:38:28<1:07:42,  1.06it/s] 75%|███████▌  | 13209/17525 [2:38:29<59:52,  1.20it/s]   75%|███████▌  | 13210/17525 [2:38:29<54:14,  1.33it/s]                                                       {'loss': 0.3066, 'grad_norm': 23.10572624206543, 'learning_rate': 2.8641942864108295e-06, 'epoch': 18.84}
 75%|███████▌  | 13210/17525 [2:38:29<54:14,  1.33it/s] 75%|███████▌  | 13211/17525 [2:38:30<50:25,  1.43it/s] 75%|███████▌  | 13212/17525 [2:38:31<47:36,  1.51it/s] 75%|███████▌  | 13213/17525 [2:38:31<45:41,  1.57it/s] 75%|███████▌  | 13214/17525 [2:38:32<44:18,  1.62it/s] 75%|███████▌  | 13215/17525 [2:38:32<43:19,  1.66it/s] 75%|███████▌  | 13216/17525 [2:38:33<42:35,  1.69it/s] 75%|███████▌  | 13217/17525 [2:38:33<42:06,  1.70it/s] 75%|███████▌  | 13218/17525 [2:38:34<41:51,  1.71it/s] 75%|███████▌  | 13219/17525 [2:38:35<41:31,  1.73it/s] 75%|███████▌  | 13220/17525 [2:38:35<41:22,  1.73it/s]                                                       {'loss': 0.3538, 'grad_norm': 12.30656623840332, 'learning_rate': 2.851632717115539e-06, 'epoch': 18.86}
 75%|███████▌  | 13220/17525 [2:38:35<41:22,  1.73it/s] 75%|███████▌  | 13221/17525 [2:38:36<41:15,  1.74it/s] 75%|███████▌  | 13222/17525 [2:38:36<41:10,  1.74it/s] 75%|███████▌  | 13223/17525 [2:38:37<41:06,  1.74it/s] 75%|███████▌  | 13224/17525 [2:38:37<41:02,  1.75it/s] 75%|███████▌  | 13225/17525 [2:38:38<40:57,  1.75it/s] 75%|███████▌  | 13226/17525 [2:38:38<40:51,  1.75it/s] 75%|███████▌  | 13227/17525 [2:38:39<40:50,  1.75it/s] 75%|███████▌  | 13228/17525 [2:38:40<40:53,  1.75it/s] 75%|███████▌  | 13229/17525 [2:38:40<41:00,  1.75it/s] 75%|███████▌  | 13230/17525 [2:38:41<41:26,  1.73it/s]                                                       {'loss': 0.3087, 'grad_norm': 11.898590087890625, 'learning_rate': 2.8390941718987365e-06, 'epoch': 18.87}
 75%|███████▌  | 13230/17525 [2:38:41<41:26,  1.73it/s] 75%|███████▌  | 13231/17525 [2:38:41<41:22,  1.73it/s] 76%|███████▌  | 13232/17525 [2:38:42<41:13,  1.74it/s] 76%|███████▌  | 13233/17525 [2:38:43<41:13,  1.73it/s] 76%|███████▌  | 13234/17525 [2:38:43<41:07,  1.74it/s] 76%|███████▌  | 13235/17525 [2:38:44<41:04,  1.74it/s] 76%|███████▌  | 13236/17525 [2:38:44<40:59,  1.74it/s] 76%|███████▌  | 13237/17525 [2:38:45<40:54,  1.75it/s] 76%|███████▌  | 13238/17525 [2:38:45<40:51,  1.75it/s] 76%|███████▌  | 13239/17525 [2:38:46<40:46,  1.75it/s] 76%|███████▌  | 13240/17525 [2:38:47<40:51,  1.75it/s]                                                       {'loss': 0.3462, 'grad_norm': 8.3519926071167, 'learning_rate': 2.8265786911456482e-06, 'epoch': 18.89}
 76%|███████▌  | 13240/17525 [2:38:47<40:51,  1.75it/s] 76%|███████▌  | 13241/17525 [2:38:47<40:57,  1.74it/s] 76%|███████▌  | 13242/17525 [2:38:48<48:35,  1.47it/s] 76%|███████▌  | 13243/17525 [2:38:49<46:17,  1.54it/s] 76%|███████▌  | 13244/17525 [2:38:49<44:37,  1.60it/s] 76%|███████▌  | 13245/17525 [2:38:50<43:31,  1.64it/s] 76%|███████▌  | 13246/17525 [2:38:50<42:46,  1.67it/s] 76%|███████▌  | 13247/17525 [2:38:51<42:14,  1.69it/s] 76%|███████▌  | 13248/17525 [2:38:51<41:46,  1.71it/s] 76%|███████▌  | 13249/17525 [2:38:52<41:29,  1.72it/s] 76%|███████▌  | 13250/17525 [2:38:53<41:20,  1.72it/s]                                                       {'loss': 0.3343, 'grad_norm': 11.253073692321777, 'learning_rate': 2.8140863151672203e-06, 'epoch': 18.9}
 76%|███████▌  | 13250/17525 [2:38:53<41:20,  1.72it/s] 76%|███████▌  | 13251/17525 [2:38:53<41:13,  1.73it/s] 76%|███████▌  | 13252/17525 [2:38:54<41:10,  1.73it/s] 76%|███████▌  | 13253/17525 [2:38:54<41:03,  1.73it/s] 76%|███████▌  | 13254/17525 [2:38:55<41:00,  1.74it/s] 76%|███████▌  | 13255/17525 [2:38:56<40:55,  1.74it/s] 76%|███████▌  | 13256/17525 [2:38:56<40:54,  1.74it/s] 76%|███████▌  | 13257/17525 [2:38:57<40:53,  1.74it/s] 76%|███████▌  | 13258/17525 [2:38:57<40:53,  1.74it/s] 76%|███████▌  | 13259/17525 [2:38:58<40:52,  1.74it/s] 76%|███████▌  | 13260/17525 [2:38:59<57:17,  1.24it/s]                                                       {'loss': 0.4204, 'grad_norm': 11.477594375610352, 'learning_rate': 2.801617084199967e-06, 'epoch': 18.92}
 76%|███████▌  | 13260/17525 [2:38:59<57:17,  1.24it/s] 76%|███████▌  | 13261/17525 [2:39:00<52:22,  1.36it/s] 76%|███████▌  | 13262/17525 [2:39:00<48:57,  1.45it/s] 76%|███████▌  | 13263/17525 [2:39:01<46:23,  1.53it/s] 76%|███████▌  | 13264/17525 [2:39:01<44:35,  1.59it/s] 76%|███████▌  | 13265/17525 [2:39:02<43:24,  1.64it/s] 76%|███████▌  | 13266/17525 [2:39:03<42:38,  1.66it/s] 76%|███████▌  | 13267/17525 [2:39:03<42:02,  1.69it/s] 76%|███████▌  | 13268/17525 [2:39:04<41:37,  1.70it/s] 76%|███████▌  | 13269/17525 [2:39:04<41:17,  1.72it/s] 76%|███████▌  | 13270/17525 [2:39:05<41:04,  1.73it/s]                                                       {'loss': 0.4115, 'grad_norm': 10.28475284576416, 'learning_rate': 2.7891710384058733e-06, 'epoch': 18.93}
 76%|███████▌  | 13270/17525 [2:39:05<41:04,  1.73it/s] 76%|███████▌  | 13271/17525 [2:39:05<40:58,  1.73it/s] 76%|███████▌  | 13272/17525 [2:39:06<40:49,  1.74it/s] 76%|███████▌  | 13273/17525 [2:39:07<40:43,  1.74it/s] 76%|███████▌  | 13274/17525 [2:39:07<40:41,  1.74it/s] 76%|███████▌  | 13275/17525 [2:39:08<40:44,  1.74it/s] 76%|███████▌  | 13276/17525 [2:39:08<40:42,  1.74it/s] 76%|███████▌  | 13277/17525 [2:39:09<40:44,  1.74it/s] 76%|███████▌  | 13278/17525 [2:39:09<40:38,  1.74it/s] 76%|███████▌  | 13279/17525 [2:39:10<40:35,  1.74it/s] 76%|███████▌  | 13280/17525 [2:39:11<40:36,  1.74it/s]                                                       {'loss': 0.3519, 'grad_norm': 8.322064399719238, 'learning_rate': 2.7767482178722325e-06, 'epoch': 18.94}
 76%|███████▌  | 13280/17525 [2:39:11<40:36,  1.74it/s] 76%|███████▌  | 13281/17525 [2:39:11<40:41,  1.74it/s] 76%|███████▌  | 13282/17525 [2:39:12<40:36,  1.74it/s] 76%|███████▌  | 13283/17525 [2:39:12<40:37,  1.74it/s] 76%|███████▌  | 13284/17525 [2:39:13<40:41,  1.74it/s] 76%|███████▌  | 13285/17525 [2:39:13<40:34,  1.74it/s] 76%|███████▌  | 13286/17525 [2:39:14<40:27,  1.75it/s] 76%|███████▌  | 13287/17525 [2:39:15<40:29,  1.74it/s] 76%|███████▌  | 13288/17525 [2:39:15<41:19,  1.71it/s] 76%|███████▌  | 13289/17525 [2:39:16<41:01,  1.72it/s] 76%|███████▌  | 13290/17525 [2:39:17<44:47,  1.58it/s]                                                       {'loss': 0.4002, 'grad_norm': 9.946760177612305, 'learning_rate': 2.764348662611538e-06, 'epoch': 18.96}
 76%|███████▌  | 13290/17525 [2:39:17<44:47,  1.58it/s] 76%|███████▌  | 13291/17525 [2:39:17<44:07,  1.60it/s] 76%|███████▌  | 13292/17525 [2:39:18<49:34,  1.42it/s] 76%|███████▌  | 13293/17525 [2:39:19<46:48,  1.51it/s] 76%|███████▌  | 13294/17525 [2:39:19<44:51,  1.57it/s] 76%|███████▌  | 13295/17525 [2:39:20<43:28,  1.62it/s] 76%|███████▌  | 13296/17525 [2:39:20<42:32,  1.66it/s] 76%|███████▌  | 13297/17525 [2:39:21<45:24,  1.55it/s] 76%|███████▌  | 13298/17525 [2:39:22<43:50,  1.61it/s] 76%|███████▌  | 13299/17525 [2:39:22<42:46,  1.65it/s] 76%|███████▌  | 13300/17525 [2:39:23<42:06,  1.67it/s]                                                       {'loss': 0.3673, 'grad_norm': 8.317363739013672, 'learning_rate': 2.7519724125613477e-06, 'epoch': 18.97}
 76%|███████▌  | 13300/17525 [2:39:23<42:06,  1.67it/s][INFO|trainer.py:3512] 2024-06-25 04:42:44,711 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:42:44,711 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:42:44,711 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1274231672286987, 'eval_runtime': 4.6004, 'eval_samples_per_second': 96.295, 'eval_steps_per_second': 4.13, 'epoch': 18.97}
 76%|███████▌  | 13300/17525 [2:39:27<42:06,  1.67it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 76%|███████▌  | 13301/17525 [2:39:28<2:18:55,  1.97s/it] 76%|███████▌  | 13302/17525 [2:39:29<1:49:20,  1.55s/it] 76%|███████▌  | 13303/17525 [2:39:29<1:28:38,  1.26s/it] 76%|███████▌  | 13304/17525 [2:39:30<1:14:06,  1.05s/it] 76%|███████▌  | 13305/17525 [2:39:30<1:03:57,  1.10it/s] 76%|███████▌  | 13306/17525 [2:39:31<56:52,  1.24it/s]   76%|███████▌  | 13307/17525 [2:39:31<51:52,  1.36it/s] 76%|███████▌  | 13308/17525 [2:39:32<48:22,  1.45it/s] 76%|███████▌  | 13309/17525 [2:39:33<45:56,  1.53it/s] 76%|███████▌  | 13310/17525 [2:39:33<44:17,  1.59it/s]                                                       {'loss': 0.3829, 'grad_norm': 14.194260597229004, 'learning_rate': 2.739619507584158e-06, 'epoch': 18.99}
 76%|███████▌  | 13310/17525 [2:39:33<44:17,  1.59it/s] 76%|███████▌  | 13311/17525 [2:39:34<43:12,  1.63it/s] 76%|███████▌  | 13312/17525 [2:39:34<42:16,  1.66it/s] 76%|███████▌  | 13313/17525 [2:39:35<41:41,  1.68it/s] 76%|███████▌  | 13314/17525 [2:39:35<41:18,  1.70it/s] 76%|███████▌  | 13315/17525 [2:39:36<40:55,  1.71it/s] 76%|███████▌  | 13316/17525 [2:39:37<40:40,  1.72it/s] 76%|███████▌  | 13317/17525 [2:39:37<40:35,  1.73it/s] 76%|███████▌  | 13318/17525 [2:39:38<43:40,  1.61it/s] 76%|███████▌  | 13319/17525 [2:39:38<42:35,  1.65it/s] 76%|███████▌  | 13320/17525 [2:39:39<41:56,  1.67it/s]                                                       {'loss': 0.3119, 'grad_norm': 13.34398078918457, 'learning_rate': 2.727289987467274e-06, 'epoch': 19.0}
 76%|███████▌  | 13320/17525 [2:39:39<41:56,  1.67it/s] 76%|███████▌  | 13321/17525 [2:39:40<41:23,  1.69it/s] 76%|███████▌  | 13322/17525 [2:39:40<41:05,  1.70it/s] 76%|███████▌  | 13323/17525 [2:39:41<40:45,  1.72it/s] 76%|███████▌  | 13324/17525 [2:39:41<40:51,  1.71it/s] 76%|███████▌  | 13325/17525 [2:39:42<40:40,  1.72it/s] 76%|███████▌  | 13326/17525 [2:39:43<40:34,  1.73it/s] 76%|███████▌  | 13327/17525 [2:39:43<40:27,  1.73it/s] 76%|███████▌  | 13328/17525 [2:39:44<40:15,  1.74it/s] 76%|███████▌  | 13329/17525 [2:39:44<43:59,  1.59it/s] 76%|███████▌  | 13330/17525 [2:39:45<42:50,  1.63it/s]                                                       {'loss': 0.3633, 'grad_norm': 9.721860885620117, 'learning_rate': 2.714983891922672e-06, 'epoch': 19.02}
 76%|███████▌  | 13330/17525 [2:39:45<42:50,  1.63it/s] 76%|███████▌  | 13331/17525 [2:39:46<42:03,  1.66it/s] 76%|███████▌  | 13332/17525 [2:39:46<41:28,  1.69it/s] 76%|███████▌  | 13333/17525 [2:39:47<41:01,  1.70it/s] 76%|███████▌  | 13334/17525 [2:39:48<48:20,  1.44it/s] 76%|███████▌  | 13335/17525 [2:39:48<45:52,  1.52it/s] 76%|███████▌  | 13336/17525 [2:39:49<44:11,  1.58it/s] 76%|███████▌  | 13337/17525 [2:39:49<42:57,  1.62it/s] 76%|███████▌  | 13338/17525 [2:39:50<42:03,  1.66it/s] 76%|███████▌  | 13339/17525 [2:39:51<41:31,  1.68it/s] 76%|███████▌  | 13340/17525 [2:39:51<41:10,  1.69it/s]                                                       {'loss': 0.3355, 'grad_norm': 9.27225399017334, 'learning_rate': 2.7027012605868895e-06, 'epoch': 19.03}
 76%|███████▌  | 13340/17525 [2:39:51<41:10,  1.69it/s] 76%|███████▌  | 13341/17525 [2:39:52<40:59,  1.70it/s] 76%|███████▌  | 13342/17525 [2:39:52<40:46,  1.71it/s] 76%|███████▌  | 13343/17525 [2:39:53<40:40,  1.71it/s] 76%|███████▌  | 13344/17525 [2:39:53<40:25,  1.72it/s] 76%|███████▌  | 13345/17525 [2:39:54<40:14,  1.73it/s] 76%|███████▌  | 13346/17525 [2:39:55<40:10,  1.73it/s] 76%|███████▌  | 13347/17525 [2:39:55<40:05,  1.74it/s] 76%|███████▌  | 13348/17525 [2:39:56<40:00,  1.74it/s] 76%|███████▌  | 13349/17525 [2:39:56<40:00,  1.74it/s] 76%|███████▌  | 13350/17525 [2:39:57<39:56,  1.74it/s]                                                       {'loss': 0.3948, 'grad_norm': 8.083416938781738, 'learning_rate': 2.6904421330208886e-06, 'epoch': 19.04}
 76%|███████▌  | 13350/17525 [2:39:57<39:56,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 04:43:18,752 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bfd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e55c3068-e548-4ac8-af5c-f96051584264)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:43:28,872 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:43:28,875 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 76%|███████▌  | 13351/17525 [2:40:08<4:14:14,  3.65s/it] 76%|███████▌  | 13352/17525 [2:40:08<3:10:00,  2.73s/it] 76%|███████▌  | 13353/17525 [2:40:09<2:25:00,  2.09s/it] 76%|███████▌  | 13354/17525 [2:40:09<1:53:30,  1.63s/it] 76%|███████▌  | 13355/17525 [2:40:10<1:31:23,  1.31s/it] 76%|███████▌  | 13356/17525 [2:40:11<1:15:56,  1.09s/it] 76%|███████▌  | 13357/17525 [2:40:12<1:13:49,  1.06s/it] 76%|███████▌  | 13358/17525 [2:40:12<1:03:39,  1.09it/s] 76%|███████▌  | 13359/17525 [2:40:13<56:35,  1.23it/s]   76%|███████▌  | 13360/17525 [2:40:13<51:28,  1.35it/s]                                                       {'loss': 0.3338, 'grad_norm': 7.582174777984619, 'learning_rate': 2.678206548709923e-06, 'epoch': 19.06}
 76%|███████▌  | 13360/17525 [2:40:13<51:28,  1.35it/s] 76%|███████▌  | 13361/17525 [2:40:14<51:08,  1.36it/s] 76%|███████▌  | 13362/17525 [2:40:15<47:47,  1.45it/s] 76%|███████▋  | 13363/17525 [2:40:15<45:20,  1.53it/s] 76%|███████▋  | 13364/17525 [2:40:16<43:38,  1.59it/s] 76%|███████▋  | 13365/17525 [2:40:16<45:14,  1.53it/s] 76%|███████▋  | 13366/17525 [2:40:17<43:38,  1.59it/s] 76%|███████▋  | 13367/17525 [2:40:18<50:01,  1.39it/s] 76%|███████▋  | 13368/17525 [2:40:19<46:58,  1.47it/s] 76%|███████▋  | 13369/17525 [2:40:19<44:50,  1.54it/s] 76%|███████▋  | 13370/17525 [2:40:20<43:20,  1.60it/s]                                                       {'loss': 0.3631, 'grad_norm': 9.730387687683105, 'learning_rate': 2.6659945470634197e-06, 'epoch': 19.07}
 76%|███████▋  | 13370/17525 [2:40:20<43:20,  1.60it/s] 76%|███████▋  | 13371/17525 [2:40:20<42:17,  1.64it/s] 76%|███████▋  | 13372/17525 [2:40:21<41:28,  1.67it/s] 76%|███████▋  | 13373/17525 [2:40:21<40:54,  1.69it/s] 76%|███████▋  | 13374/17525 [2:40:22<40:29,  1.71it/s] 76%|███████▋  | 13375/17525 [2:40:23<40:14,  1.72it/s] 76%|███████▋  | 13376/17525 [2:40:23<40:00,  1.73it/s] 76%|███████▋  | 13377/17525 [2:40:24<39:51,  1.73it/s] 76%|███████▋  | 13378/17525 [2:40:25<46:32,  1.49it/s] 76%|███████▋  | 13379/17525 [2:40:25<44:26,  1.55it/s] 76%|███████▋  | 13380/17525 [2:40:26<42:57,  1.61it/s]                                                       {'loss': 0.326, 'grad_norm': 15.152776718139648, 'learning_rate': 2.653806167414851e-06, 'epoch': 19.09}
 76%|███████▋  | 13380/17525 [2:40:26<42:57,  1.61it/s] 76%|███████▋  | 13381/17525 [2:40:26<42:04,  1.64it/s] 76%|███████▋  | 13382/17525 [2:40:27<41:14,  1.67it/s] 76%|███████▋  | 13383/17525 [2:40:27<40:46,  1.69it/s] 76%|███████▋  | 13384/17525 [2:40:28<40:25,  1.71it/s] 76%|███████▋  | 13385/17525 [2:40:29<40:11,  1.72it/s] 76%|███████▋  | 13386/17525 [2:40:29<39:59,  1.72it/s] 76%|███████▋  | 13387/17525 [2:40:30<39:49,  1.73it/s] 76%|███████▋  | 13388/17525 [2:40:30<39:46,  1.73it/s] 76%|███████▋  | 13389/17525 [2:40:31<46:56,  1.47it/s] 76%|███████▋  | 13390/17525 [2:40:32<44:48,  1.54it/s]                                                       {'loss': 0.3791, 'grad_norm': 5.2430949211120605, 'learning_rate': 2.6416414490215923e-06, 'epoch': 19.1}
 76%|███████▋  | 13390/17525 [2:40:32<44:48,  1.54it/s] 76%|███████▋  | 13391/17525 [2:40:32<43:17,  1.59it/s] 76%|███████▋  | 13392/17525 [2:40:33<42:10,  1.63it/s] 76%|███████▋  | 13393/17525 [2:40:34<41:23,  1.66it/s] 76%|███████▋  | 13394/17525 [2:40:34<40:47,  1.69it/s] 76%|███████▋  | 13395/17525 [2:40:35<40:27,  1.70it/s] 76%|███████▋  | 13396/17525 [2:40:35<40:13,  1.71it/s] 76%|███████▋  | 13397/17525 [2:40:36<39:57,  1.72it/s] 76%|███████▋  | 13398/17525 [2:40:36<39:45,  1.73it/s] 76%|███████▋  | 13399/17525 [2:40:37<39:48,  1.73it/s] 76%|███████▋  | 13400/17525 [2:40:38<46:56,  1.46it/s]                                                       {'loss': 0.3476, 'grad_norm': 10.36697006225586, 'learning_rate': 2.6295004310648344e-06, 'epoch': 19.12}
 76%|███████▋  | 13400/17525 [2:40:38<46:56,  1.46it/s][INFO|trainer.py:3512] 2024-06-25 04:43:59,838 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:43:59,838 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:43:59,838 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1606618165969849, 'eval_runtime': 4.5964, 'eval_samples_per_second': 96.38, 'eval_steps_per_second': 4.134, 'epoch': 19.12}
 76%|███████▋  | 13400/17525 [2:40:43<46:56,  1.46it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 76%|███████▋  | 13401/17525 [2:40:43<2:19:40,  2.03s/it] 76%|███████▋  | 13402/17525 [2:40:44<1:49:33,  1.59s/it] 76%|███████▋  | 13403/17525 [2:40:45<1:35:47,  1.39s/it] 76%|███████▋  | 13404/17525 [2:40:45<1:18:49,  1.15s/it] 76%|███████▋  | 13405/17525 [2:40:46<1:14:21,  1.08s/it] 76%|███████▋  | 13406/17525 [2:40:47<1:03:54,  1.07it/s] 77%|███████▋  | 13407/17525 [2:40:47<56:31,  1.21it/s]   77%|███████▋  | 13408/17525 [2:40:48<51:18,  1.34it/s] 77%|███████▋  | 13409/17525 [2:40:48<47:44,  1.44it/s] 77%|███████▋  | 13410/17525 [2:40:49<45:11,  1.52it/s]                                                       {'loss': 0.3141, 'grad_norm': 10.66978645324707, 'learning_rate': 2.6173831526494032e-06, 'epoch': 19.13}
 77%|███████▋  | 13410/17525 [2:40:49<45:11,  1.52it/s] 77%|███████▋  | 13411/17525 [2:40:50<43:26,  1.58it/s] 77%|███████▋  | 13412/17525 [2:40:50<42:12,  1.62it/s] 77%|███████▋  | 13413/17525 [2:40:51<48:34,  1.41it/s] 77%|███████▋  | 13414/17525 [2:40:52<45:49,  1.50it/s] 77%|███████▋  | 13415/17525 [2:40:52<43:52,  1.56it/s] 77%|███████▋  | 13416/17525 [2:40:53<42:28,  1.61it/s] 77%|███████▋  | 13417/17525 [2:40:53<41:31,  1.65it/s] 77%|███████▋  | 13418/17525 [2:40:54<40:50,  1.68it/s] 77%|███████▋  | 13419/17525 [2:40:55<40:21,  1.70it/s] 77%|███████▋  | 13420/17525 [2:40:55<40:01,  1.71it/s]                                                       {'loss': 0.3772, 'grad_norm': 10.08940315246582, 'learning_rate': 2.6052896528036797e-06, 'epoch': 19.14}
 77%|███████▋  | 13420/17525 [2:40:55<40:01,  1.71it/s] 77%|███████▋  | 13421/17525 [2:40:56<39:52,  1.72it/s] 77%|███████▋  | 13422/17525 [2:40:56<39:45,  1.72it/s] 77%|███████▋  | 13423/17525 [2:40:57<46:49,  1.46it/s] 77%|███████▋  | 13424/17525 [2:40:58<44:36,  1.53it/s] 77%|███████▋  | 13425/17525 [2:40:59<53:17,  1.28it/s] 77%|███████▋  | 13426/17525 [2:40:59<49:10,  1.39it/s] 77%|███████▋  | 13427/17525 [2:41:00<46:11,  1.48it/s] 77%|███████▋  | 13428/17525 [2:41:01<44:09,  1.55it/s] 77%|███████▋  | 13429/17525 [2:41:01<42:37,  1.60it/s] 77%|███████▋  | 13430/17525 [2:41:02<41:58,  1.63it/s]                                                       {'loss': 0.3378, 'grad_norm': 9.218966484069824, 'learning_rate': 2.5932199704794514e-06, 'epoch': 19.16}
 77%|███████▋  | 13430/17525 [2:41:02<41:58,  1.63it/s] 77%|███████▋  | 13431/17525 [2:41:02<41:10,  1.66it/s] 77%|███████▋  | 13432/17525 [2:41:03<40:30,  1.68it/s] 77%|███████▋  | 13433/17525 [2:41:03<40:07,  1.70it/s] 77%|███████▋  | 13434/17525 [2:41:04<39:47,  1.71it/s] 77%|███████▋  | 13435/17525 [2:41:05<39:37,  1.72it/s] 77%|███████▋  | 13436/17525 [2:41:05<39:30,  1.72it/s] 77%|███████▋  | 13437/17525 [2:41:06<39:28,  1.73it/s] 77%|███████▋  | 13438/17525 [2:41:06<39:22,  1.73it/s] 77%|███████▋  | 13439/17525 [2:41:07<39:17,  1.73it/s] 77%|███████▋  | 13440/17525 [2:41:07<39:13,  1.74it/s]                                                       {'loss': 0.347, 'grad_norm': 19.238807678222656, 'learning_rate': 2.5811741445517947e-06, 'epoch': 19.17}
 77%|███████▋  | 13440/17525 [2:41:07<39:13,  1.74it/s] 77%|███████▋  | 13441/17525 [2:41:08<39:15,  1.73it/s] 77%|███████▋  | 13442/17525 [2:41:09<39:13,  1.74it/s] 77%|███████▋  | 13443/17525 [2:41:09<42:11,  1.61it/s] 77%|███████▋  | 13444/17525 [2:41:10<41:13,  1.65it/s] 77%|███████▋  | 13445/17525 [2:41:10<40:32,  1.68it/s] 77%|███████▋  | 13446/17525 [2:41:11<40:06,  1.70it/s] 77%|███████▋  | 13447/17525 [2:41:12<39:47,  1.71it/s] 77%|███████▋  | 13448/17525 [2:41:12<39:32,  1.72it/s] 77%|███████▋  | 13449/17525 [2:41:13<39:23,  1.72it/s] 77%|███████▋  | 13450/17525 [2:41:14<43:02,  1.58it/s]                                                       {'loss': 0.3403, 'grad_norm': 31.71845245361328, 'learning_rate': 2.5691522138189484e-06, 'epoch': 19.19}
 77%|███████▋  | 13450/17525 [2:41:14<43:02,  1.58it/s] 77%|███████▋  | 13451/17525 [2:41:14<41:54,  1.62it/s] 77%|███████▋  | 13452/17525 [2:41:15<41:00,  1.66it/s] 77%|███████▋  | 13453/17525 [2:41:15<40:21,  1.68it/s] 77%|███████▋  | 13454/17525 [2:41:16<39:54,  1.70it/s] 77%|███████▋  | 13455/17525 [2:41:16<39:38,  1.71it/s] 77%|███████▋  | 13456/17525 [2:41:17<39:26,  1.72it/s] 77%|███████▋  | 13457/17525 [2:41:18<39:17,  1.73it/s] 77%|███████▋  | 13458/17525 [2:41:18<39:47,  1.70it/s] 77%|███████▋  | 13459/17525 [2:41:19<43:10,  1.57it/s] 77%|███████▋  | 13460/17525 [2:41:20<41:56,  1.62it/s]                                                       {'loss': 0.4463, 'grad_norm': 9.325209617614746, 'learning_rate': 2.5571542170021744e-06, 'epoch': 19.2}
 77%|███████▋  | 13460/17525 [2:41:20<41:56,  1.62it/s] 77%|███████▋  | 13461/17525 [2:41:20<41:04,  1.65it/s] 77%|███████▋  | 13462/17525 [2:41:21<56:39,  1.20it/s] 77%|███████▋  | 13463/17525 [2:41:22<51:21,  1.32it/s] 77%|███████▋  | 13464/17525 [2:41:23<47:42,  1.42it/s] 77%|███████▋  | 13465/17525 [2:41:23<45:08,  1.50it/s] 77%|███████▋  | 13466/17525 [2:41:24<43:45,  1.55it/s] 77%|███████▋  | 13467/17525 [2:41:24<42:21,  1.60it/s] 77%|███████▋  | 13468/17525 [2:41:25<41:19,  1.64it/s] 77%|███████▋  | 13469/17525 [2:41:26<40:34,  1.67it/s] 77%|███████▋  | 13470/17525 [2:41:26<40:48,  1.66it/s]                                                       {'loss': 0.279, 'grad_norm': 11.013577461242676, 'learning_rate': 2.5451801927456697e-06, 'epoch': 19.22}
 77%|███████▋  | 13470/17525 [2:41:26<40:48,  1.66it/s] 77%|███████▋  | 13471/17525 [2:41:27<40:16,  1.68it/s] 77%|███████▋  | 13472/17525 [2:41:27<39:51,  1.70it/s] 77%|███████▋  | 13473/17525 [2:41:28<39:31,  1.71it/s] 77%|███████▋  | 13474/17525 [2:41:28<39:46,  1.70it/s] 77%|███████▋  | 13475/17525 [2:41:29<39:26,  1.71it/s] 77%|███████▋  | 13476/17525 [2:41:30<39:08,  1.72it/s] 77%|███████▋  | 13477/17525 [2:41:30<38:57,  1.73it/s] 77%|███████▋  | 13478/17525 [2:41:32<54:21,  1.24it/s] 77%|███████▋  | 13479/17525 [2:41:32<49:42,  1.36it/s] 77%|███████▋  | 13480/17525 [2:41:33<46:22,  1.45it/s]                                                       {'loss': 0.3569, 'grad_norm': 13.819117546081543, 'learning_rate': 2.5332301796163974e-06, 'epoch': 19.23}
 77%|███████▋  | 13480/17525 [2:41:33<46:22,  1.45it/s] 77%|███████▋  | 13481/17525 [2:41:33<44:07,  1.53it/s] 77%|███████▋  | 13482/17525 [2:41:34<42:31,  1.58it/s] 77%|███████▋  | 13483/17525 [2:41:34<41:21,  1.63it/s] 77%|███████▋  | 13484/17525 [2:41:35<40:32,  1.66it/s] 77%|███████▋  | 13485/17525 [2:41:36<40:03,  1.68it/s] 77%|███████▋  | 13486/17525 [2:41:36<39:40,  1.70it/s] 77%|███████▋  | 13487/17525 [2:41:37<39:21,  1.71it/s] 77%|███████▋  | 13488/17525 [2:41:37<39:11,  1.72it/s] 77%|███████▋  | 13489/17525 [2:41:38<39:02,  1.72it/s] 77%|███████▋  | 13490/17525 [2:41:38<38:51,  1.73it/s]                                                       {'loss': 0.4471, 'grad_norm': 10.717461585998535, 'learning_rate': 2.5213042161039923e-06, 'epoch': 19.24}
 77%|███████▋  | 13490/17525 [2:41:38<38:51,  1.73it/s] 77%|███████▋  | 13491/17525 [2:41:39<38:54,  1.73it/s] 77%|███████▋  | 13492/17525 [2:41:40<38:49,  1.73it/s] 77%|███████▋  | 13493/17525 [2:41:40<38:40,  1.74it/s] 77%|███████▋  | 13494/17525 [2:41:41<38:40,  1.74it/s] 77%|███████▋  | 13495/17525 [2:41:41<38:37,  1.74it/s] 77%|███████▋  | 13496/17525 [2:41:42<38:32,  1.74it/s] 77%|███████▋  | 13497/17525 [2:41:42<38:34,  1.74it/s] 77%|███████▋  | 13498/17525 [2:41:43<47:13,  1.42it/s] 77%|███████▋  | 13499/17525 [2:41:44<44:39,  1.50it/s] 77%|███████▋  | 13500/17525 [2:41:45<42:50,  1.57it/s]                                                       {'loss': 0.3339, 'grad_norm': 4.541258335113525, 'learning_rate': 2.509402340620629e-06, 'epoch': 19.26}
 77%|███████▋  | 13500/17525 [2:41:45<42:50,  1.57it/s][INFO|trainer.py:3512] 2024-06-25 04:45:06,499 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:45:06,499 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:45:06,499 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1629161834716797, 'eval_runtime': 4.5972, 'eval_samples_per_second': 96.363, 'eval_steps_per_second': 4.133, 'epoch': 19.26}
 77%|███████▋  | 13500/17525 [2:41:49<42:50,  1.57it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:45:11,100 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b85990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 57cc1c07-eff1-42a7-b87e-fb143c5200d5)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:45:21,157 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:45:21,159 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 77%|███████▋  | 13501/17525 [2:42:00<5:39:25,  5.06s/it] 77%|███████▋  | 13502/17525 [2:42:01<4:09:08,  3.72s/it] 77%|███████▋  | 13503/17525 [2:42:01<3:05:54,  2.77s/it] 77%|███████▋  | 13504/17525 [2:42:02<2:21:36,  2.11s/it] 77%|███████▋  | 13505/17525 [2:42:02<1:53:30,  1.69s/it] 77%|███████▋  | 13506/17525 [2:42:03<1:31:02,  1.36s/it] 77%|███████▋  | 13507/17525 [2:42:04<1:15:15,  1.12s/it] 77%|███████▋  | 13508/17525 [2:42:04<1:04:10,  1.04it/s] 77%|███████▋  | 13509/17525 [2:42:05<56:25,  1.19it/s]   77%|███████▋  | 13510/17525 [2:42:05<51:02,  1.31it/s]                                                       {'loss': 0.3393, 'grad_norm': 14.91318416595459, 'learning_rate': 2.497524591500895e-06, 'epoch': 19.27}
 77%|███████▋  | 13510/17525 [2:42:05<51:02,  1.31it/s] 77%|███████▋  | 13511/17525 [2:42:06<47:17,  1.41it/s] 77%|███████▋  | 13512/17525 [2:42:06<44:37,  1.50it/s] 77%|███████▋  | 13513/17525 [2:42:07<42:40,  1.57it/s] 77%|███████▋  | 13514/17525 [2:42:08<41:58,  1.59it/s] 77%|███████▋  | 13515/17525 [2:42:08<41:11,  1.62it/s] 77%|███████▋  | 13516/17525 [2:42:09<40:19,  1.66it/s] 77%|███████▋  | 13517/17525 [2:42:09<39:41,  1.68it/s] 77%|███████▋  | 13518/17525 [2:42:10<39:17,  1.70it/s] 77%|███████▋  | 13519/17525 [2:42:11<38:55,  1.72it/s] 77%|███████▋  | 13520/17525 [2:42:11<38:44,  1.72it/s]                                                       {'loss': 0.3377, 'grad_norm': 9.00289535522461, 'learning_rate': 2.4856710070016697e-06, 'epoch': 19.29}
 77%|███████▋  | 13520/17525 [2:42:11<38:44,  1.72it/s] 77%|███████▋  | 13521/17525 [2:42:12<38:35,  1.73it/s] 77%|███████▋  | 13522/17525 [2:42:12<38:27,  1.73it/s] 77%|███████▋  | 13523/17525 [2:42:13<38:28,  1.73it/s] 77%|███████▋  | 13524/17525 [2:42:14<47:02,  1.42it/s] 77%|███████▋  | 13525/17525 [2:42:14<44:22,  1.50it/s] 77%|███████▋  | 13526/17525 [2:42:15<42:33,  1.57it/s] 77%|███████▋  | 13527/17525 [2:42:16<41:14,  1.62it/s] 77%|███████▋  | 13528/17525 [2:42:16<40:20,  1.65it/s] 77%|███████▋  | 13529/17525 [2:42:17<39:38,  1.68it/s] 77%|███████▋  | 13530/17525 [2:42:17<39:12,  1.70it/s]                                                       {'loss': 0.3568, 'grad_norm': 8.909634590148926, 'learning_rate': 2.473841625302006e-06, 'epoch': 19.3}
 77%|███████▋  | 13530/17525 [2:42:17<39:12,  1.70it/s] 77%|███████▋  | 13531/17525 [2:42:18<38:56,  1.71it/s] 77%|███████▋  | 13532/17525 [2:42:18<38:41,  1.72it/s] 77%|███████▋  | 13533/17525 [2:42:19<38:32,  1.73it/s] 77%|███████▋  | 13534/17525 [2:42:20<38:23,  1.73it/s] 77%|███████▋  | 13535/17525 [2:42:20<38:18,  1.74it/s] 77%|███████▋  | 13536/17525 [2:42:21<38:21,  1.73it/s] 77%|███████▋  | 13537/17525 [2:42:21<38:23,  1.73it/s] 77%|███████▋  | 13538/17525 [2:42:22<38:23,  1.73it/s] 77%|███████▋  | 13539/17525 [2:42:22<38:21,  1.73it/s] 77%|███████▋  | 13540/17525 [2:42:23<38:18,  1.73it/s]                                                       {'loss': 0.2989, 'grad_norm': 8.311395645141602, 'learning_rate': 2.4620364845029886e-06, 'epoch': 19.32}
 77%|███████▋  | 13540/17525 [2:42:23<38:18,  1.73it/s] 77%|███████▋  | 13541/17525 [2:42:24<38:19,  1.73it/s] 77%|███████▋  | 13542/17525 [2:42:24<38:13,  1.74it/s] 77%|███████▋  | 13543/17525 [2:42:25<38:15,  1.73it/s] 77%|███████▋  | 13544/17525 [2:42:25<38:13,  1.74it/s] 77%|███████▋  | 13545/17525 [2:42:26<38:13,  1.74it/s] 77%|███████▋  | 13546/17525 [2:42:26<38:08,  1.74it/s] 77%|███████▋  | 13547/17525 [2:42:27<38:09,  1.74it/s] 77%|███████▋  | 13548/17525 [2:42:28<38:08,  1.74it/s] 77%|███████▋  | 13549/17525 [2:42:28<38:10,  1.74it/s] 77%|███████▋  | 13550/17525 [2:42:29<38:09,  1.74it/s]                                                       {'loss': 0.3289, 'grad_norm': 15.061673164367676, 'learning_rate': 2.4502556226276406e-06, 'epoch': 19.33}
 77%|███████▋  | 13550/17525 [2:42:29<38:09,  1.74it/s] 77%|███████▋  | 13551/17525 [2:42:29<38:08,  1.74it/s] 77%|███████▋  | 13552/17525 [2:42:30<38:06,  1.74it/s] 77%|███████▋  | 13553/17525 [2:42:30<38:11,  1.73it/s] 77%|███████▋  | 13554/17525 [2:42:31<38:06,  1.74it/s] 77%|███████▋  | 13555/17525 [2:42:32<38:04,  1.74it/s] 77%|███████▋  | 13556/17525 [2:42:32<38:02,  1.74it/s] 77%|███████▋  | 13557/17525 [2:42:33<38:02,  1.74it/s] 77%|███████▋  | 13558/17525 [2:42:33<37:55,  1.74it/s] 77%|███████▋  | 13559/17525 [2:42:34<37:54,  1.74it/s] 77%|███████▋  | 13560/17525 [2:42:35<37:54,  1.74it/s]                                                       {'loss': 0.2783, 'grad_norm': 3.1774110794067383, 'learning_rate': 2.4384990776207773e-06, 'epoch': 19.34}
 77%|███████▋  | 13560/17525 [2:42:35<37:54,  1.74it/s] 77%|███████▋  | 13561/17525 [2:42:35<38:00,  1.74it/s] 77%|███████▋  | 13562/17525 [2:42:36<37:58,  1.74it/s] 77%|███████▋  | 13563/17525 [2:42:36<38:00,  1.74it/s] 77%|███████▋  | 13564/17525 [2:42:37<38:06,  1.73it/s] 77%|███████▋  | 13565/17525 [2:42:37<37:58,  1.74it/s] 77%|███████▋  | 13566/17525 [2:42:38<37:55,  1.74it/s] 77%|███████▋  | 13567/17525 [2:42:39<37:51,  1.74it/s] 77%|███████▋  | 13568/17525 [2:42:39<37:51,  1.74it/s] 77%|███████▋  | 13569/17525 [2:42:40<37:47,  1.74it/s] 77%|███████▋  | 13570/17525 [2:42:40<37:50,  1.74it/s]                                                       {'loss': 0.3846, 'grad_norm': 14.820223808288574, 'learning_rate': 2.4267668873488938e-06, 'epoch': 19.36}
 77%|███████▋  | 13570/17525 [2:42:40<37:50,  1.74it/s] 77%|███████▋  | 13571/17525 [2:42:41<38:30,  1.71it/s] 77%|███████▋  | 13572/17525 [2:42:41<38:26,  1.71it/s] 77%|███████▋  | 13573/17525 [2:42:42<38:14,  1.72it/s] 77%|███████▋  | 13574/17525 [2:42:43<38:06,  1.73it/s] 77%|███████▋  | 13575/17525 [2:42:43<38:03,  1.73it/s] 77%|███████▋  | 13576/17525 [2:42:44<38:03,  1.73it/s] 77%|███████▋  | 13577/17525 [2:42:44<38:03,  1.73it/s] 77%|███████▋  | 13578/17525 [2:42:45<38:02,  1.73it/s] 77%|███████▋  | 13579/17525 [2:42:45<37:52,  1.74it/s] 77%|███████▋  | 13580/17525 [2:42:46<37:49,  1.74it/s]                                                       {'loss': 0.3248, 'grad_norm': 27.38963508605957, 'learning_rate': 2.4150590896000446e-06, 'epoch': 19.37}
 77%|███████▋  | 13580/17525 [2:42:46<37:49,  1.74it/s] 77%|███████▋  | 13581/17525 [2:42:47<37:49,  1.74it/s] 78%|███████▊  | 13582/17525 [2:42:47<37:50,  1.74it/s] 78%|███████▊  | 13583/17525 [2:42:48<37:50,  1.74it/s] 78%|███████▊  | 13584/17525 [2:42:48<37:47,  1.74it/s] 78%|███████▊  | 13585/17525 [2:42:49<37:48,  1.74it/s] 78%|███████▊  | 13586/17525 [2:42:50<37:47,  1.74it/s] 78%|███████▊  | 13587/17525 [2:42:50<37:48,  1.74it/s] 78%|███████▊  | 13588/17525 [2:42:51<38:09,  1.72it/s] 78%|███████▊  | 13589/17525 [2:42:51<38:31,  1.70it/s] 78%|███████▊  | 13590/17525 [2:42:52<38:10,  1.72it/s]                                                       {'loss': 0.3349, 'grad_norm': 6.54591178894043, 'learning_rate': 2.403375722083707e-06, 'epoch': 19.39}
 78%|███████▊  | 13590/17525 [2:42:52<38:10,  1.72it/s] 78%|███████▊  | 13591/17525 [2:42:52<38:03,  1.72it/s] 78%|███████▊  | 13592/17525 [2:42:53<37:52,  1.73it/s] 78%|███████▊  | 13593/17525 [2:42:54<37:46,  1.73it/s] 78%|███████▊  | 13594/17525 [2:42:54<37:48,  1.73it/s] 78%|███████▊  | 13595/17525 [2:42:55<37:46,  1.73it/s] 78%|███████▊  | 13596/17525 [2:42:55<37:41,  1.74it/s] 78%|███████▊  | 13597/17525 [2:42:56<37:34,  1.74it/s] 78%|███████▊  | 13598/17525 [2:42:56<37:34,  1.74it/s] 78%|███████▊  | 13599/17525 [2:42:57<37:31,  1.74it/s] 78%|███████▊  | 13600/17525 [2:42:58<37:33,  1.74it/s]                                                       {'loss': 0.4144, 'grad_norm': 13.047161102294922, 'learning_rate': 2.391716822430691e-06, 'epoch': 19.4}
 78%|███████▊  | 13600/17525 [2:42:58<37:33,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:46:19,485 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:46:19,486 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:46:19,486 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.162134051322937, 'eval_runtime': 4.6003, 'eval_samples_per_second': 96.299, 'eval_steps_per_second': 4.13, 'epoch': 19.4}
 78%|███████▊  | 13600/17525 [2:43:02<37:33,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 78%|███████▊  | 13601/17525 [2:43:03<2:08:02,  1.96s/it] 78%|███████▊  | 13602/17525 [2:43:03<1:40:55,  1.54s/it] 78%|███████▊  | 13603/17525 [2:43:04<1:21:56,  1.25s/it] 78%|███████▊  | 13604/17525 [2:43:05<1:08:36,  1.05s/it] 78%|███████▊  | 13605/17525 [2:43:05<59:19,  1.10it/s]   78%|███████▊  | 13606/17525 [2:43:06<52:54,  1.23it/s] 78%|███████▊  | 13607/17525 [2:43:06<48:19,  1.35it/s] 78%|███████▊  | 13608/17525 [2:43:07<45:07,  1.45it/s] 78%|███████▊  | 13609/17525 [2:43:07<42:46,  1.53it/s] 78%|███████▊  | 13610/17525 [2:43:08<41:09,  1.59it/s]                                                       {'loss': 0.344, 'grad_norm': 12.27396011352539, 'learning_rate': 2.380082428192976e-06, 'epoch': 19.42}
 78%|███████▊  | 13610/17525 [2:43:08<41:09,  1.59it/s] 78%|███████▊  | 13611/17525 [2:43:09<40:03,  1.63it/s] 78%|███████▊  | 13612/17525 [2:43:09<39:16,  1.66it/s] 78%|███████▊  | 13613/17525 [2:43:10<38:43,  1.68it/s] 78%|███████▊  | 13614/17525 [2:43:10<38:17,  1.70it/s] 78%|███████▊  | 13615/17525 [2:43:11<38:00,  1.71it/s] 78%|███████▊  | 13616/17525 [2:43:11<37:50,  1.72it/s] 78%|███████▊  | 13617/17525 [2:43:12<37:40,  1.73it/s] 78%|███████▊  | 13618/17525 [2:43:13<37:42,  1.73it/s] 78%|███████▊  | 13619/17525 [2:43:13<37:36,  1.73it/s] 78%|███████▊  | 13620/17525 [2:43:14<37:27,  1.74it/s]                                                       {'loss': 0.4168, 'grad_norm': 11.065496444702148, 'learning_rate': 2.3684725768436333e-06, 'epoch': 19.43}
 78%|███████▊  | 13620/17525 [2:43:14<37:27,  1.74it/s] 78%|███████▊  | 13621/17525 [2:43:14<37:30,  1.73it/s] 78%|███████▊  | 13622/17525 [2:43:15<37:27,  1.74it/s] 78%|███████▊  | 13623/17525 [2:43:15<37:43,  1.72it/s] 78%|███████▊  | 13624/17525 [2:43:16<37:38,  1.73it/s] 78%|███████▊  | 13625/17525 [2:43:17<37:30,  1.73it/s] 78%|███████▊  | 13626/17525 [2:43:17<37:24,  1.74it/s] 78%|███████▊  | 13627/17525 [2:43:18<44:07,  1.47it/s] 78%|███████▊  | 13628/17525 [2:43:19<45:52,  1.42it/s] 78%|███████▊  | 13629/17525 [2:43:19<43:21,  1.50it/s] 78%|███████▊  | 13630/17525 [2:43:20<44:16,  1.47it/s]                                                       {'loss': 0.4168, 'grad_norm': 10.352195739746094, 'learning_rate': 2.3568873057766685e-06, 'epoch': 19.44}
 78%|███████▊  | 13630/17525 [2:43:20<44:16,  1.47it/s] 78%|███████▊  | 13631/17525 [2:43:21<42:14,  1.54it/s] 78%|███████▊  | 13632/17525 [2:43:21<40:44,  1.59it/s] 78%|███████▊  | 13633/17525 [2:43:22<39:38,  1.64it/s] 78%|███████▊  | 13634/17525 [2:43:22<38:55,  1.67it/s] 78%|███████▊  | 13635/17525 [2:43:23<38:22,  1.69it/s] 78%|███████▊  | 13636/17525 [2:43:24<37:58,  1.71it/s] 78%|███████▊  | 13637/17525 [2:43:24<37:40,  1.72it/s] 78%|███████▊  | 13638/17525 [2:43:25<37:34,  1.72it/s] 78%|███████▊  | 13639/17525 [2:43:25<37:50,  1.71it/s] 78%|███████▊  | 13640/17525 [2:43:26<37:41,  1.72it/s]                                                       {'loss': 0.3286, 'grad_norm': 14.76219367980957, 'learning_rate': 2.345326652306924e-06, 'epoch': 19.46}
 78%|███████▊  | 13640/17525 [2:43:26<37:41,  1.72it/s] 78%|███████▊  | 13641/17525 [2:43:26<37:36,  1.72it/s] 78%|███████▊  | 13642/17525 [2:43:27<37:27,  1.73it/s] 78%|███████▊  | 13643/17525 [2:43:28<37:25,  1.73it/s] 78%|███████▊  | 13644/17525 [2:43:28<37:21,  1.73it/s] 78%|███████▊  | 13645/17525 [2:43:29<37:19,  1.73it/s] 78%|███████▊  | 13646/17525 [2:43:29<37:18,  1.73it/s] 78%|███████▊  | 13647/17525 [2:43:30<37:15,  1.73it/s] 78%|███████▊  | 13648/17525 [2:43:31<46:38,  1.39it/s] 78%|███████▊  | 13649/17525 [2:43:32<43:44,  1.48it/s] 78%|███████▊  | 13650/17525 [2:43:32<41:44,  1.55it/s]                                                       {'loss': 0.3199, 'grad_norm': 24.649919509887695, 'learning_rate': 2.3337906536699504e-06, 'epoch': 19.47}
 78%|███████▊  | 13650/17525 [2:43:32<41:44,  1.55it/s][INFO|trainer.py:3203] 2024-06-25 04:46:54,053 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bfd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 43008af3-71f6-43eb-a999-fe5c202998ae)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:47:04,110 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:47:04,112 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 78%|███████▊  | 13651/17525 [2:43:43<3:59:17,  3.71s/it] 78%|███████▊  | 13652/17525 [2:43:44<2:58:38,  2.77s/it] 78%|███████▊  | 13653/17525 [2:43:44<2:16:06,  2.11s/it] 78%|███████▊  | 13654/17525 [2:43:45<1:46:53,  1.66s/it] 78%|███████▊  | 13655/17525 [2:43:45<1:26:13,  1.34s/it] 78%|███████▊  | 13656/17525 [2:43:46<1:11:23,  1.11s/it] 78%|███████▊  | 13657/17525 [2:43:46<1:01:00,  1.06it/s] 78%|███████▊  | 13658/17525 [2:43:47<53:48,  1.20it/s]   78%|███████▊  | 13659/17525 [2:43:48<48:42,  1.32it/s] 78%|███████▊  | 13660/17525 [2:43:48<45:10,  1.43it/s]                                                       {'loss': 0.2569, 'grad_norm': 4.934114456176758, 'learning_rate': 2.322279347021892e-06, 'epoch': 19.49}
 78%|███████▊  | 13660/17525 [2:43:48<45:10,  1.43it/s] 78%|███████▊  | 13661/17525 [2:43:49<42:45,  1.51it/s] 78%|███████▊  | 13662/17525 [2:43:49<40:59,  1.57it/s] 78%|███████▊  | 13663/17525 [2:43:50<39:46,  1.62it/s] 78%|███████▊  | 13664/17525 [2:43:51<38:58,  1.65it/s] 78%|███████▊  | 13665/17525 [2:43:51<38:15,  1.68it/s] 78%|███████▊  | 13666/17525 [2:43:52<37:51,  1.70it/s] 78%|███████▊  | 13667/17525 [2:43:52<37:32,  1.71it/s] 78%|███████▊  | 13668/17525 [2:43:53<37:26,  1.72it/s] 78%|███████▊  | 13669/17525 [2:43:53<37:15,  1.72it/s] 78%|███████▊  | 13670/17525 [2:43:54<37:14,  1.73it/s]                                                       {'loss': 0.3386, 'grad_norm': 12.843905448913574, 'learning_rate': 2.310792769439353e-06, 'epoch': 19.5}
 78%|███████▊  | 13670/17525 [2:43:54<37:14,  1.73it/s] 78%|███████▊  | 13671/17525 [2:43:55<37:10,  1.73it/s] 78%|███████▊  | 13672/17525 [2:43:55<37:03,  1.73it/s] 78%|███████▊  | 13673/17525 [2:43:56<37:04,  1.73it/s] 78%|███████▊  | 13674/17525 [2:43:56<36:57,  1.74it/s] 78%|███████▊  | 13675/17525 [2:43:57<36:51,  1.74it/s] 78%|███████▊  | 13676/17525 [2:43:57<36:50,  1.74it/s] 78%|███████▊  | 13677/17525 [2:43:58<36:48,  1.74it/s] 78%|███████▊  | 13678/17525 [2:43:59<36:50,  1.74it/s] 78%|███████▊  | 13679/17525 [2:43:59<36:48,  1.74it/s] 78%|███████▊  | 13680/17525 [2:44:00<36:52,  1.74it/s]                                                       {'loss': 0.3905, 'grad_norm': 18.978378295898438, 'learning_rate': 2.299330957919297e-06, 'epoch': 19.51}
 78%|███████▊  | 13680/17525 [2:44:00<36:52,  1.74it/s] 78%|███████▊  | 13681/17525 [2:44:00<36:57,  1.73it/s] 78%|███████▊  | 13682/17525 [2:44:01<36:53,  1.74it/s] 78%|███████▊  | 13683/17525 [2:44:01<36:53,  1.74it/s] 78%|███████▊  | 13684/17525 [2:44:02<36:52,  1.74it/s] 78%|███████▊  | 13685/17525 [2:44:03<39:32,  1.62it/s] 78%|███████▊  | 13686/17525 [2:44:03<38:39,  1.65it/s] 78%|███████▊  | 13687/17525 [2:44:04<38:08,  1.68it/s] 78%|███████▊  | 13688/17525 [2:44:04<37:44,  1.69it/s] 78%|███████▊  | 13689/17525 [2:44:05<37:26,  1.71it/s] 78%|███████▊  | 13690/17525 [2:44:06<37:10,  1.72it/s]                                                       {'loss': 0.2989, 'grad_norm': 11.721565246582031, 'learning_rate': 2.2878939493789144e-06, 'epoch': 19.53}
 78%|███████▊  | 13690/17525 [2:44:06<37:10,  1.72it/s] 78%|███████▊  | 13691/17525 [2:44:06<37:06,  1.72it/s] 78%|███████▊  | 13692/17525 [2:44:07<36:59,  1.73it/s] 78%|███████▊  | 13693/17525 [2:44:07<36:54,  1.73it/s] 78%|███████▊  | 13694/17525 [2:44:08<36:48,  1.73it/s] 78%|███████▊  | 13695/17525 [2:44:08<36:42,  1.74it/s] 78%|███████▊  | 13696/17525 [2:44:09<36:39,  1.74it/s] 78%|███████▊  | 13697/17525 [2:44:10<36:42,  1.74it/s] 78%|███████▊  | 13698/17525 [2:44:10<36:38,  1.74it/s] 78%|███████▊  | 13699/17525 [2:44:11<36:54,  1.73it/s] 78%|███████▊  | 13700/17525 [2:44:11<36:48,  1.73it/s]                                                       {'loss': 0.3261, 'grad_norm': 10.33765983581543, 'learning_rate': 2.2764817806555117e-06, 'epoch': 19.54}
 78%|███████▊  | 13700/17525 [2:44:11<36:48,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 04:47:33,259 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:47:33,259 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:47:33,259 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1572375297546387, 'eval_runtime': 4.5951, 'eval_samples_per_second': 96.406, 'eval_steps_per_second': 4.135, 'epoch': 19.54}
 78%|███████▊  | 13700/17525 [2:44:16<36:48,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 78%|███████▊  | 13701/17525 [2:44:17<2:04:49,  1.96s/it] 78%|███████▊  | 13702/17525 [2:44:17<1:38:22,  1.54s/it] 78%|███████▊  | 13703/17525 [2:44:18<1:19:54,  1.25s/it] 78%|███████▊  | 13704/17525 [2:44:19<1:26:38,  1.36s/it] 78%|███████▊  | 13705/17525 [2:44:21<1:23:46,  1.32s/it] 78%|███████▊  | 13706/17525 [2:44:21<1:09:35,  1.09s/it] 78%|███████▊  | 13707/17525 [2:44:22<59:41,  1.07it/s]   78%|███████▊  | 13708/17525 [2:44:22<52:44,  1.21it/s] 78%|███████▊  | 13709/17525 [2:44:23<47:58,  1.33it/s] 78%|███████▊  | 13710/17525 [2:44:23<44:32,  1.43it/s]                                                       {'loss': 0.3982, 'grad_norm': 14.18801498413086, 'learning_rate': 2.26509448850639e-06, 'epoch': 19.56}
 78%|███████▊  | 13710/17525 [2:44:23<44:32,  1.43it/s] 78%|███████▊  | 13711/17525 [2:44:24<42:10,  1.51it/s] 78%|███████▊  | 13712/17525 [2:44:25<40:26,  1.57it/s] 78%|███████▊  | 13713/17525 [2:44:25<39:12,  1.62it/s] 78%|███████▊  | 13714/17525 [2:44:26<38:21,  1.66it/s] 78%|███████▊  | 13715/17525 [2:44:26<37:43,  1.68it/s] 78%|███████▊  | 13716/17525 [2:44:27<37:16,  1.70it/s] 78%|███████▊  | 13717/17525 [2:44:27<37:03,  1.71it/s] 78%|███████▊  | 13718/17525 [2:44:28<36:52,  1.72it/s] 78%|███████▊  | 13719/17525 [2:44:29<36:45,  1.73it/s] 78%|███████▊  | 13720/17525 [2:44:29<36:39,  1.73it/s]                                                       {'loss': 0.3482, 'grad_norm': 12.843523979187012, 'learning_rate': 2.253732109608714e-06, 'epoch': 19.57}
 78%|███████▊  | 13720/17525 [2:44:29<36:39,  1.73it/s] 78%|███████▊  | 13721/17525 [2:44:30<36:32,  1.73it/s] 78%|███████▊  | 13722/17525 [2:44:30<36:29,  1.74it/s] 78%|███████▊  | 13723/17525 [2:44:31<36:51,  1.72it/s] 78%|███████▊  | 13724/17525 [2:44:31<36:41,  1.73it/s] 78%|███████▊  | 13725/17525 [2:44:32<36:33,  1.73it/s] 78%|███████▊  | 13726/17525 [2:44:33<36:26,  1.74it/s] 78%|███████▊  | 13727/17525 [2:44:33<36:22,  1.74it/s] 78%|███████▊  | 13728/17525 [2:44:34<36:22,  1.74it/s] 78%|███████▊  | 13729/17525 [2:44:34<36:22,  1.74it/s] 78%|███████▊  | 13730/17525 [2:44:35<39:59,  1.58it/s]                                                       {'loss': 0.371, 'grad_norm': 12.007278442382812, 'learning_rate': 2.2423946805594255e-06, 'epoch': 19.59}
 78%|███████▊  | 13730/17525 [2:44:35<39:59,  1.58it/s] 78%|███████▊  | 13731/17525 [2:44:36<42:18,  1.49it/s] 78%|███████▊  | 13732/17525 [2:44:36<40:39,  1.55it/s] 78%|███████▊  | 13733/17525 [2:44:37<39:26,  1.60it/s] 78%|███████▊  | 13734/17525 [2:44:38<38:29,  1.64it/s] 78%|███████▊  | 13735/17525 [2:44:38<37:52,  1.67it/s] 78%|███████▊  | 13736/17525 [2:44:39<37:28,  1.69it/s] 78%|███████▊  | 13737/17525 [2:44:39<37:11,  1.70it/s] 78%|███████▊  | 13738/17525 [2:44:40<36:59,  1.71it/s] 78%|███████▊  | 13739/17525 [2:44:40<36:45,  1.72it/s] 78%|███████▊  | 13740/17525 [2:44:41<36:32,  1.73it/s]                                                       {'loss': 0.3553, 'grad_norm': 25.249631881713867, 'learning_rate': 2.231082237875084e-06, 'epoch': 19.6}
 78%|███████▊  | 13740/17525 [2:44:41<36:32,  1.73it/s] 78%|███████▊  | 13741/17525 [2:44:42<36:27,  1.73it/s] 78%|███████▊  | 13742/17525 [2:44:42<36:22,  1.73it/s] 78%|███████▊  | 13743/17525 [2:44:43<36:20,  1.73it/s] 78%|███████▊  | 13744/17525 [2:44:43<36:14,  1.74it/s] 78%|███████▊  | 13745/17525 [2:44:44<36:16,  1.74it/s] 78%|███████▊  | 13746/17525 [2:44:44<36:11,  1.74it/s] 78%|███████▊  | 13747/17525 [2:44:45<36:11,  1.74it/s] 78%|███████▊  | 13748/17525 [2:44:46<36:09,  1.74it/s] 78%|███████▊  | 13749/17525 [2:44:46<36:06,  1.74it/s] 78%|███████▊  | 13750/17525 [2:44:47<36:04,  1.74it/s]                                                       {'loss': 0.326, 'grad_norm': 11.479042053222656, 'learning_rate': 2.2197948179917926e-06, 'epoch': 19.61}
 78%|███████▊  | 13750/17525 [2:44:47<36:04,  1.74it/s] 78%|███████▊  | 13751/17525 [2:44:47<36:05,  1.74it/s] 78%|███████▊  | 13752/17525 [2:44:48<35:59,  1.75it/s] 78%|███████▊  | 13753/17525 [2:44:48<35:58,  1.75it/s] 78%|███████▊  | 13754/17525 [2:44:49<35:55,  1.75it/s] 78%|███████▊  | 13755/17525 [2:44:50<35:58,  1.75it/s] 78%|███████▊  | 13756/17525 [2:44:50<36:02,  1.74it/s] 78%|███████▊  | 13757/17525 [2:44:51<36:00,  1.74it/s] 79%|███████▊  | 13758/17525 [2:44:51<36:00,  1.74it/s] 79%|███████▊  | 13759/17525 [2:44:52<35:58,  1.74it/s] 79%|███████▊  | 13760/17525 [2:44:52<35:53,  1.75it/s]                                                       {'loss': 0.3644, 'grad_norm': 19.025299072265625, 'learning_rate': 2.208532457265039e-06, 'epoch': 19.63}
 79%|███████▊  | 13760/17525 [2:44:53<35:53,  1.75it/s] 79%|███████▊  | 13761/17525 [2:44:53<35:55,  1.75it/s] 79%|███████▊  | 13762/17525 [2:44:54<35:58,  1.74it/s] 79%|███████▊  | 13763/17525 [2:44:54<35:55,  1.75it/s] 79%|███████▊  | 13764/17525 [2:44:55<35:55,  1.74it/s] 79%|███████▊  | 13765/17525 [2:44:55<35:57,  1.74it/s] 79%|███████▊  | 13766/17525 [2:44:56<35:59,  1.74it/s] 79%|███████▊  | 13767/17525 [2:44:57<36:00,  1.74it/s] 79%|███████▊  | 13768/17525 [2:44:57<35:58,  1.74it/s] 79%|███████▊  | 13769/17525 [2:44:58<36:00,  1.74it/s] 79%|███████▊  | 13770/17525 [2:44:58<35:57,  1.74it/s]                                                       {'loss': 0.2831, 'grad_norm': 9.516271591186523, 'learning_rate': 2.1972951919696106e-06, 'epoch': 19.64}
 79%|███████▊  | 13770/17525 [2:44:58<35:57,  1.74it/s] 79%|███████▊  | 13771/17525 [2:44:59<35:58,  1.74it/s] 79%|███████▊  | 13772/17525 [2:45:00<44:03,  1.42it/s] 79%|███████▊  | 13773/17525 [2:45:00<41:45,  1.50it/s] 79%|███████▊  | 13774/17525 [2:45:01<40:05,  1.56it/s] 79%|███████▊  | 13775/17525 [2:45:02<38:48,  1.61it/s] 79%|███████▊  | 13776/17525 [2:45:02<37:57,  1.65it/s] 79%|███████▊  | 13777/17525 [2:45:03<37:50,  1.65it/s] 79%|███████▊  | 13778/17525 [2:45:03<37:14,  1.68it/s] 79%|███████▊  | 13779/17525 [2:45:04<36:47,  1.70it/s] 79%|███████▊  | 13780/17525 [2:45:04<36:28,  1.71it/s]                                                       {'loss': 0.348, 'grad_norm': 4.895562171936035, 'learning_rate': 2.1860830582994607e-06, 'epoch': 19.66}
 79%|███████▊  | 13780/17525 [2:45:04<36:28,  1.71it/s] 79%|███████▊  | 13781/17525 [2:45:05<36:19,  1.72it/s] 79%|███████▊  | 13782/17525 [2:45:06<36:12,  1.72it/s] 79%|███████▊  | 13783/17525 [2:45:06<36:06,  1.73it/s] 79%|███████▊  | 13784/17525 [2:45:07<35:56,  1.73it/s] 79%|███████▊  | 13785/17525 [2:45:07<35:50,  1.74it/s] 79%|███████▊  | 13786/17525 [2:45:08<35:48,  1.74it/s] 79%|███████▊  | 13787/17525 [2:45:08<35:45,  1.74it/s] 79%|███████▊  | 13788/17525 [2:45:09<35:45,  1.74it/s] 79%|███████▊  | 13789/17525 [2:45:10<36:09,  1.72it/s] 79%|███████▊  | 13790/17525 [2:45:10<36:00,  1.73it/s]                                                       {'loss': 0.351, 'grad_norm': 15.018529891967773, 'learning_rate': 2.174896092367598e-06, 'epoch': 19.67}
 79%|███████▊  | 13790/17525 [2:45:10<36:00,  1.73it/s] 79%|███████▊  | 13791/17525 [2:45:11<35:57,  1.73it/s] 79%|███████▊  | 13792/17525 [2:45:11<35:55,  1.73it/s] 79%|███████▊  | 13793/17525 [2:45:12<35:50,  1.74it/s] 79%|███████▊  | 13794/17525 [2:45:13<35:48,  1.74it/s] 79%|███████▊  | 13795/17525 [2:45:13<35:59,  1.73it/s] 79%|███████▊  | 13796/17525 [2:45:14<35:51,  1.73it/s] 79%|███████▊  | 13797/17525 [2:45:14<35:45,  1.74it/s] 79%|███████▊  | 13798/17525 [2:45:15<35:44,  1.74it/s] 79%|███████▊  | 13799/17525 [2:45:15<35:38,  1.74it/s] 79%|███████▊  | 13800/17525 [2:45:16<35:40,  1.74it/s]                                                       {'loss': 0.3877, 'grad_norm': 10.705799102783203, 'learning_rate': 2.163734330205971e-06, 'epoch': 19.69}
 79%|███████▊  | 13800/17525 [2:45:16<35:40,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:48:37,870 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:48:37,870 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:48:37,870 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1619913578033447, 'eval_runtime': 4.602, 'eval_samples_per_second': 96.262, 'eval_steps_per_second': 4.129, 'epoch': 19.69}
 79%|███████▊  | 13800/17525 [2:45:21<35:40,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:48:42,476 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c55990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ad8c48a3-8b0f-4d2e-8c0d-d78536a6159e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:48:52,532 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:48:52,535 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 79%|███████▉  | 13801/17525 [2:45:31<5:11:28,  5.02s/it] 79%|███████▉  | 13802/17525 [2:45:32<3:48:47,  3.69s/it] 79%|███████▉  | 13803/17525 [2:45:33<2:50:55,  2.76s/it] 79%|███████▉  | 13804/17525 [2:45:33<2:10:19,  2.10s/it] 79%|███████▉  | 13805/17525 [2:45:34<1:41:53,  1.64s/it] 79%|███████▉  | 13806/17525 [2:45:34<1:22:00,  1.32s/it] 79%|███████▉  | 13807/17525 [2:45:35<1:08:05,  1.10s/it] 79%|███████▉  | 13808/17525 [2:45:35<58:21,  1.06it/s]   79%|███████▉  | 13809/17525 [2:45:36<54:51,  1.13it/s] 79%|███████▉  | 13810/17525 [2:45:37<49:02,  1.26it/s]                                                       {'loss': 0.4298, 'grad_norm': 17.00798225402832, 'learning_rate': 2.152597807765341e-06, 'epoch': 19.7}
 79%|███████▉  | 13810/17525 [2:45:37<49:02,  1.26it/s] 79%|███████▉  | 13811/17525 [2:45:37<44:59,  1.38it/s] 79%|███████▉  | 13812/17525 [2:45:38<42:08,  1.47it/s] 79%|███████▉  | 13813/17525 [2:45:38<40:09,  1.54it/s] 79%|███████▉  | 13814/17525 [2:45:39<38:46,  1.60it/s] 79%|███████▉  | 13815/17525 [2:45:40<37:46,  1.64it/s] 79%|███████▉  | 13816/17525 [2:45:40<37:04,  1.67it/s] 79%|███████▉  | 13817/17525 [2:45:41<36:31,  1.69it/s] 79%|███████▉  | 13818/17525 [2:45:41<36:20,  1.70it/s] 79%|███████▉  | 13819/17525 [2:45:42<36:02,  1.71it/s] 79%|███████▉  | 13820/17525 [2:45:42<35:51,  1.72it/s]                                                       {'loss': 0.3375, 'grad_norm': 8.475714683532715, 'learning_rate': 2.1414865609151836e-06, 'epoch': 19.71}
 79%|███████▉  | 13820/17525 [2:45:42<35:51,  1.72it/s] 79%|███████▉  | 13821/17525 [2:45:43<35:43,  1.73it/s] 79%|███████▉  | 13822/17525 [2:45:44<35:39,  1.73it/s] 79%|███████▉  | 13823/17525 [2:45:44<35:34,  1.73it/s] 79%|███████▉  | 13824/17525 [2:45:45<35:30,  1.74it/s] 79%|███████▉  | 13825/17525 [2:45:45<35:27,  1.74it/s] 79%|███████▉  | 13826/17525 [2:45:46<35:48,  1.72it/s] 79%|███████▉  | 13827/17525 [2:45:47<35:35,  1.73it/s] 79%|███████▉  | 13828/17525 [2:45:47<35:27,  1.74it/s] 79%|███████▉  | 13829/17525 [2:45:48<35:23,  1.74it/s] 79%|███████▉  | 13830/17525 [2:45:48<35:23,  1.74it/s]                                                       {'loss': 0.3602, 'grad_norm': 10.32249927520752, 'learning_rate': 2.1304006254435615e-06, 'epoch': 19.73}
 79%|███████▉  | 13830/17525 [2:45:48<35:23,  1.74it/s] 79%|███████▉  | 13831/17525 [2:45:49<35:28,  1.74it/s] 79%|███████▉  | 13832/17525 [2:45:49<35:23,  1.74it/s] 79%|███████▉  | 13833/17525 [2:45:50<35:20,  1.74it/s] 79%|███████▉  | 13834/17525 [2:45:51<35:25,  1.74it/s] 79%|███████▉  | 13835/17525 [2:45:51<35:23,  1.74it/s] 79%|███████▉  | 13836/17525 [2:45:52<35:21,  1.74it/s] 79%|███████▉  | 13837/17525 [2:45:52<35:19,  1.74it/s] 79%|███████▉  | 13838/17525 [2:45:53<35:16,  1.74it/s] 79%|███████▉  | 13839/17525 [2:45:53<35:16,  1.74it/s] 79%|███████▉  | 13840/17525 [2:45:54<41:52,  1.47it/s]                                                       {'loss': 0.4149, 'grad_norm': 16.781328201293945, 'learning_rate': 2.119340037057015e-06, 'epoch': 19.74}
 79%|███████▉  | 13840/17525 [2:45:54<41:52,  1.47it/s] 79%|███████▉  | 13841/17525 [2:45:55<39:55,  1.54it/s] 79%|███████▉  | 13842/17525 [2:45:56<39:11,  1.57it/s] 79%|███████▉  | 13843/17525 [2:45:56<38:00,  1.61it/s] 79%|███████▉  | 13844/17525 [2:45:57<37:14,  1.65it/s] 79%|███████▉  | 13845/17525 [2:45:57<36:36,  1.68it/s] 79%|███████▉  | 13846/17525 [2:45:58<36:15,  1.69it/s] 79%|███████▉  | 13847/17525 [2:45:58<36:37,  1.67it/s] 79%|███████▉  | 13848/17525 [2:45:59<36:16,  1.69it/s] 79%|███████▉  | 13849/17525 [2:46:00<35:59,  1.70it/s] 79%|███████▉  | 13850/17525 [2:46:00<35:45,  1.71it/s]                                                       {'loss': 0.3691, 'grad_norm': 15.584612846374512, 'learning_rate': 2.108304831380439e-06, 'epoch': 19.76}
 79%|███████▉  | 13850/17525 [2:46:00<35:45,  1.71it/s] 79%|███████▉  | 13851/17525 [2:46:01<35:35,  1.72it/s] 79%|███████▉  | 13852/17525 [2:46:01<35:28,  1.73it/s] 79%|███████▉  | 13853/17525 [2:46:02<35:21,  1.73it/s] 79%|███████▉  | 13854/17525 [2:46:02<35:14,  1.74it/s] 79%|███████▉  | 13855/17525 [2:46:03<35:05,  1.74it/s] 79%|███████▉  | 13856/17525 [2:46:04<35:07,  1.74it/s] 79%|███████▉  | 13857/17525 [2:46:04<35:14,  1.74it/s] 79%|███████▉  | 13858/17525 [2:46:05<35:12,  1.74it/s] 79%|███████▉  | 13859/17525 [2:46:05<35:38,  1.71it/s] 79%|███████▉  | 13860/17525 [2:46:06<35:24,  1.72it/s]                                                       {'loss': 0.3823, 'grad_norm': 12.961126327514648, 'learning_rate': 2.0972950439569818e-06, 'epoch': 19.77}
 79%|███████▉  | 13860/17525 [2:46:06<35:24,  1.72it/s] 79%|███████▉  | 13861/17525 [2:46:07<35:23,  1.73it/s] 79%|███████▉  | 13862/17525 [2:46:07<35:18,  1.73it/s] 79%|███████▉  | 13863/17525 [2:46:08<35:08,  1.74it/s] 79%|███████▉  | 13864/17525 [2:46:08<35:04,  1.74it/s] 79%|███████▉  | 13865/17525 [2:46:09<35:00,  1.74it/s] 79%|███████▉  | 13866/17525 [2:46:09<34:59,  1.74it/s] 79%|███████▉  | 13867/17525 [2:46:10<34:56,  1.74it/s] 79%|███████▉  | 13868/17525 [2:46:11<35:02,  1.74it/s] 79%|███████▉  | 13869/17525 [2:46:11<35:01,  1.74it/s] 79%|███████▉  | 13870/17525 [2:46:12<35:01,  1.74it/s]                                                       {'loss': 0.3769, 'grad_norm': 7.52579402923584, 'learning_rate': 2.0863107102479074e-06, 'epoch': 19.79}
 79%|███████▉  | 13870/17525 [2:46:12<35:01,  1.74it/s] 79%|███████▉  | 13871/17525 [2:46:12<35:06,  1.74it/s] 79%|███████▉  | 13872/17525 [2:46:13<35:03,  1.74it/s] 79%|███████▉  | 13873/17525 [2:46:14<41:03,  1.48it/s] 79%|███████▉  | 13874/17525 [2:46:14<39:14,  1.55it/s] 79%|███████▉  | 13875/17525 [2:46:15<37:57,  1.60it/s] 79%|███████▉  | 13876/17525 [2:46:15<37:04,  1.64it/s] 79%|███████▉  | 13877/17525 [2:46:16<38:49,  1.57it/s] 79%|███████▉  | 13878/17525 [2:46:17<37:37,  1.62it/s] 79%|███████▉  | 13879/17525 [2:46:17<36:47,  1.65it/s] 79%|███████▉  | 13880/17525 [2:46:18<36:13,  1.68it/s]                                                       {'loss': 0.415, 'grad_norm': 7.020823001861572, 'learning_rate': 2.075351865632518e-06, 'epoch': 19.8}
 79%|███████▉  | 13880/17525 [2:46:18<36:13,  1.68it/s] 79%|███████▉  | 13881/17525 [2:46:18<35:46,  1.70it/s] 79%|███████▉  | 13882/17525 [2:46:19<35:29,  1.71it/s] 79%|███████▉  | 13883/17525 [2:46:20<35:17,  1.72it/s] 79%|███████▉  | 13884/17525 [2:46:20<35:09,  1.73it/s] 79%|███████▉  | 13885/17525 [2:46:21<35:03,  1.73it/s] 79%|███████▉  | 13886/17525 [2:46:21<34:57,  1.74it/s] 79%|███████▉  | 13887/17525 [2:46:22<34:50,  1.74it/s] 79%|███████▉  | 13888/17525 [2:46:22<34:48,  1.74it/s] 79%|███████▉  | 13889/17525 [2:46:23<35:11,  1.72it/s] 79%|███████▉  | 13890/17525 [2:46:24<34:58,  1.73it/s]                                                       {'loss': 0.3358, 'grad_norm': 7.327383995056152, 'learning_rate': 2.064418545407998e-06, 'epoch': 19.81}
 79%|███████▉  | 13890/17525 [2:46:24<34:58,  1.73it/s] 79%|███████▉  | 13891/17525 [2:46:24<34:59,  1.73it/s] 79%|███████▉  | 13892/17525 [2:46:25<34:50,  1.74it/s] 79%|███████▉  | 13893/17525 [2:46:25<34:43,  1.74it/s] 79%|███████▉  | 13894/17525 [2:46:26<34:42,  1.74it/s] 79%|███████▉  | 13895/17525 [2:46:27<34:42,  1.74it/s] 79%|███████▉  | 13896/17525 [2:46:27<34:44,  1.74it/s] 79%|███████▉  | 13897/17525 [2:46:28<34:44,  1.74it/s] 79%|███████▉  | 13898/17525 [2:46:28<34:41,  1.74it/s] 79%|███████▉  | 13899/17525 [2:46:29<34:41,  1.74it/s] 79%|███████▉  | 13900/17525 [2:46:29<34:45,  1.74it/s]                                                       {'loss': 0.3335, 'grad_norm': 12.124690055847168, 'learning_rate': 2.0535107847893323e-06, 'epoch': 19.83}
 79%|███████▉  | 13900/17525 [2:46:29<34:45,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:49:51,283 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:49:51,283 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:49:51,283 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1691319942474365, 'eval_runtime': 4.596, 'eval_samples_per_second': 96.388, 'eval_steps_per_second': 4.134, 'epoch': 19.83}
 79%|███████▉  | 13900/17525 [2:46:34<34:45,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 79%|███████▉  | 13901/17525 [2:46:35<1:58:11,  1.96s/it] 79%|███████▉  | 13902/17525 [2:46:35<1:33:09,  1.54s/it] 79%|███████▉  | 13903/17525 [2:46:36<1:15:35,  1.25s/it] 79%|███████▉  | 13904/17525 [2:46:36<1:03:14,  1.05s/it] 79%|███████▉  | 13905/17525 [2:46:37<54:42,  1.10it/s]   79%|███████▉  | 13906/17525 [2:46:37<48:38,  1.24it/s] 79%|███████▉  | 13907/17525 [2:46:38<44:35,  1.35it/s] 79%|███████▉  | 13908/17525 [2:46:39<41:37,  1.45it/s] 79%|███████▉  | 13909/17525 [2:46:39<39:35,  1.52it/s] 79%|███████▉  | 13910/17525 [2:46:40<38:04,  1.58it/s]                                                       {'loss': 0.418, 'grad_norm': 18.53354835510254, 'learning_rate': 2.042628618909177e-06, 'epoch': 19.84}
 79%|███████▉  | 13910/17525 [2:46:40<38:04,  1.58it/s] 79%|███████▉  | 13911/17525 [2:46:40<37:08,  1.62it/s] 79%|███████▉  | 13912/17525 [2:46:41<36:22,  1.66it/s] 79%|███████▉  | 13913/17525 [2:46:41<35:53,  1.68it/s] 79%|███████▉  | 13914/17525 [2:46:42<35:33,  1.69it/s] 79%|███████▉  | 13915/17525 [2:46:43<35:16,  1.71it/s] 79%|███████▉  | 13916/17525 [2:46:43<35:30,  1.69it/s] 79%|███████▉  | 13917/17525 [2:46:44<35:27,  1.70it/s] 79%|███████▉  | 13918/17525 [2:46:44<35:09,  1.71it/s] 79%|███████▉  | 13919/17525 [2:46:45<34:58,  1.72it/s] 79%|███████▉  | 13920/17525 [2:46:46<34:51,  1.72it/s]                                                       {'loss': 0.352, 'grad_norm': 6.370828628540039, 'learning_rate': 2.031772082817752e-06, 'epoch': 19.86}
 79%|███████▉  | 13920/17525 [2:46:46<34:51,  1.72it/s] 79%|███████▉  | 13921/17525 [2:46:46<34:45,  1.73it/s] 79%|███████▉  | 13922/17525 [2:46:47<34:41,  1.73it/s] 79%|███████▉  | 13923/17525 [2:46:47<34:38,  1.73it/s] 79%|███████▉  | 13924/17525 [2:46:48<34:33,  1.74it/s] 79%|███████▉  | 13925/17525 [2:46:48<34:33,  1.74it/s] 79%|███████▉  | 13926/17525 [2:46:49<34:35,  1.73it/s] 79%|███████▉  | 13927/17525 [2:46:50<34:30,  1.74it/s] 79%|███████▉  | 13928/17525 [2:46:50<34:26,  1.74it/s] 79%|███████▉  | 13929/17525 [2:46:51<34:25,  1.74it/s] 79%|███████▉  | 13930/17525 [2:46:51<34:31,  1.74it/s]                                                       {'loss': 0.3768, 'grad_norm': 10.178182601928711, 'learning_rate': 2.0209412114827297e-06, 'epoch': 19.87}
 79%|███████▉  | 13930/17525 [2:46:51<34:31,  1.74it/s] 79%|███████▉  | 13931/17525 [2:46:52<35:10,  1.70it/s] 79%|███████▉  | 13932/17525 [2:46:52<35:01,  1.71it/s] 80%|███████▉  | 13933/17525 [2:46:53<35:11,  1.70it/s] 80%|███████▉  | 13934/17525 [2:46:54<35:04,  1.71it/s] 80%|███████▉  | 13935/17525 [2:46:54<35:11,  1.70it/s] 80%|███████▉  | 13936/17525 [2:46:56<49:01,  1.22it/s] 80%|███████▉  | 13937/17525 [2:46:56<44:44,  1.34it/s] 80%|███████▉  | 13938/17525 [2:46:57<41:43,  1.43it/s] 80%|███████▉  | 13939/17525 [2:46:57<39:40,  1.51it/s] 80%|███████▉  | 13940/17525 [2:46:58<38:21,  1.56it/s]                                                       {'loss': 0.4178, 'grad_norm': 10.347912788391113, 'learning_rate': 2.0101360397891056e-06, 'epoch': 19.89}
 80%|███████▉  | 13940/17525 [2:46:58<38:21,  1.56it/s] 80%|███████▉  | 13941/17525 [2:46:59<37:19,  1.60it/s] 80%|███████▉  | 13942/17525 [2:47:00<47:36,  1.25it/s] 80%|███████▉  | 13943/17525 [2:47:00<43:40,  1.37it/s] 80%|███████▉  | 13944/17525 [2:47:01<40:52,  1.46it/s] 80%|███████▉  | 13945/17525 [2:47:02<45:24,  1.31it/s] 80%|███████▉  | 13946/17525 [2:47:02<42:06,  1.42it/s] 80%|███████▉  | 13947/17525 [2:47:03<40:07,  1.49it/s] 80%|███████▉  | 13948/17525 [2:47:04<38:32,  1.55it/s] 80%|███████▉  | 13949/17525 [2:47:04<37:20,  1.60it/s] 80%|███████▉  | 13950/17525 [2:47:05<36:44,  1.62it/s]                                                       {'loss': 0.3708, 'grad_norm': 7.260988235473633, 'learning_rate': 1.999356602539121e-06, 'epoch': 19.9}
 80%|███████▉  | 13950/17525 [2:47:05<36:44,  1.62it/s][INFO|trainer.py:3203] 2024-06-25 04:50:26,671 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c55990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 04d1eff0-c5f4-4152-8cfc-deaac1035410)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:50:36,728 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:50:36,730 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-13950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 80%|███████▉  | 13951/17525 [2:47:16<3:38:25,  3.67s/it] 80%|███████▉  | 13952/17525 [2:47:16<2:43:12,  2.74s/it] 80%|███████▉  | 13953/17525 [2:47:17<2:04:30,  2.09s/it] 80%|███████▉  | 13954/17525 [2:47:17<1:37:37,  1.64s/it] 80%|███████▉  | 13955/17525 [2:47:18<1:18:34,  1.32s/it] 80%|███████▉  | 13956/17525 [2:47:18<1:05:13,  1.10s/it] 80%|███████▉  | 13957/17525 [2:47:19<55:57,  1.06it/s]   80%|███████▉  | 13958/17525 [2:47:20<49:23,  1.20it/s] 80%|███████▉  | 13959/17525 [2:47:20<44:45,  1.33it/s] 80%|███████▉  | 13960/17525 [2:47:21<41:29,  1.43it/s]                                                       {'loss': 0.3878, 'grad_norm': 11.098207473754883, 'learning_rate': 1.9886029344521108e-06, 'epoch': 19.91}
 80%|███████▉  | 13960/17525 [2:47:21<41:29,  1.43it/s] 80%|███████▉  | 13961/17525 [2:47:21<39:19,  1.51it/s] 80%|███████▉  | 13962/17525 [2:47:22<37:42,  1.57it/s] 80%|███████▉  | 13963/17525 [2:47:22<36:34,  1.62it/s] 80%|███████▉  | 13964/17525 [2:47:23<35:49,  1.66it/s] 80%|███████▉  | 13965/17525 [2:47:24<35:21,  1.68it/s] 80%|███████▉  | 13966/17525 [2:47:24<34:59,  1.70it/s] 80%|███████▉  | 13967/17525 [2:47:25<34:38,  1.71it/s] 80%|███████▉  | 13968/17525 [2:47:25<34:29,  1.72it/s] 80%|███████▉  | 13969/17525 [2:47:26<34:27,  1.72it/s] 80%|███████▉  | 13970/17525 [2:47:26<34:21,  1.72it/s]                                                       {'loss': 0.2963, 'grad_norm': 10.574097633361816, 'learning_rate': 1.977875070164419e-06, 'epoch': 19.93}
 80%|███████▉  | 13970/17525 [2:47:26<34:21,  1.72it/s] 80%|███████▉  | 13971/17525 [2:47:27<34:15,  1.73it/s] 80%|███████▉  | 13972/17525 [2:47:28<34:12,  1.73it/s] 80%|███████▉  | 13973/17525 [2:47:28<34:04,  1.74it/s] 80%|███████▉  | 13974/17525 [2:47:30<52:34,  1.13it/s] 80%|███████▉  | 13975/17525 [2:47:30<47:02,  1.26it/s] 80%|███████▉  | 13976/17525 [2:47:31<43:08,  1.37it/s] 80%|███████▉  | 13977/17525 [2:47:32<40:24,  1.46it/s] 80%|███████▉  | 13978/17525 [2:47:32<38:29,  1.54it/s] 80%|███████▉  | 13979/17525 [2:47:33<37:12,  1.59it/s] 80%|███████▉  | 13980/17525 [2:47:33<36:10,  1.63it/s]                                                       {'loss': 0.3473, 'grad_norm': 6.150959014892578, 'learning_rate': 1.967173044229278e-06, 'epoch': 19.94}
 80%|███████▉  | 13980/17525 [2:47:33<36:10,  1.63it/s] 80%|███████▉  | 13981/17525 [2:47:34<35:36,  1.66it/s] 80%|███████▉  | 13982/17525 [2:47:34<35:00,  1.69it/s] 80%|███████▉  | 13983/17525 [2:47:35<34:37,  1.70it/s] 80%|███████▉  | 13984/17525 [2:47:36<34:27,  1.71it/s] 80%|███████▉  | 13985/17525 [2:47:37<40:33,  1.45it/s] 80%|███████▉  | 13986/17525 [2:47:37<38:33,  1.53it/s] 80%|███████▉  | 13987/17525 [2:47:38<37:11,  1.59it/s] 80%|███████▉  | 13988/17525 [2:47:38<36:07,  1.63it/s] 80%|███████▉  | 13989/17525 [2:47:40<49:11,  1.20it/s] 80%|███████▉  | 13990/17525 [2:47:40<44:29,  1.32it/s]                                                       {'loss': 0.3097, 'grad_norm': 33.14719772338867, 'learning_rate': 1.956496891116699e-06, 'epoch': 19.96}
 80%|███████▉  | 13990/17525 [2:47:40<44:29,  1.32it/s] 80%|███████▉  | 13991/17525 [2:47:41<41:19,  1.43it/s] 80%|███████▉  | 13992/17525 [2:47:41<39:06,  1.51it/s] 80%|███████▉  | 13993/17525 [2:47:42<37:31,  1.57it/s] 80%|███████▉  | 13994/17525 [2:47:42<36:24,  1.62it/s] 80%|███████▉  | 13995/17525 [2:47:43<35:36,  1.65it/s] 80%|███████▉  | 13996/17525 [2:47:44<35:03,  1.68it/s] 80%|███████▉  | 13997/17525 [2:47:44<34:43,  1.69it/s] 80%|███████▉  | 13998/17525 [2:47:45<34:25,  1.71it/s] 80%|███████▉  | 13999/17525 [2:47:45<34:12,  1.72it/s] 80%|███████▉  | 14000/17525 [2:47:46<34:04,  1.72it/s]                                                       {'loss': 0.4036, 'grad_norm': 33.09016418457031, 'learning_rate': 1.945846645213351e-06, 'epoch': 19.97}
 80%|███████▉  | 14000/17525 [2:47:46<34:04,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 04:51:07,816 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:51:07,816 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:51:07,816 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.65it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.05it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.169737458229065, 'eval_runtime': 4.5895, 'eval_samples_per_second': 96.525, 'eval_steps_per_second': 4.14, 'epoch': 19.97}
 80%|███████▉  | 14000/17525 [2:47:51<34:04,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 80%|███████▉  | 14001/17525 [2:47:51<1:54:57,  1.96s/it] 80%|███████▉  | 14002/17525 [2:47:52<1:30:35,  1.54s/it] 80%|███████▉  | 14003/17525 [2:47:52<1:13:36,  1.25s/it] 80%|███████▉  | 14004/17525 [2:47:53<1:01:41,  1.05s/it] 80%|███████▉  | 14005/17525 [2:47:53<53:21,  1.10it/s]   80%|███████▉  | 14006/17525 [2:47:54<47:25,  1.24it/s] 80%|███████▉  | 14007/17525 [2:47:55<43:58,  1.33it/s] 80%|███████▉  | 14008/17525 [2:47:55<40:50,  1.44it/s] 80%|███████▉  | 14009/17525 [2:47:56<38:45,  1.51it/s] 80%|███████▉  | 14010/17525 [2:47:56<37:10,  1.58it/s]                                                       {'loss': 0.3117, 'grad_norm': 13.028891563415527, 'learning_rate': 1.9352223408224735e-06, 'epoch': 19.99}
 80%|███████▉  | 14010/17525 [2:47:56<37:10,  1.58it/s] 80%|███████▉  | 14011/17525 [2:47:57<36:09,  1.62it/s] 80%|███████▉  | 14012/17525 [2:47:57<35:24,  1.65it/s] 80%|███████▉  | 14013/17525 [2:47:58<34:49,  1.68it/s] 80%|███████▉  | 14014/17525 [2:47:59<34:39,  1.69it/s] 80%|███████▉  | 14015/17525 [2:47:59<34:21,  1.70it/s] 80%|███████▉  | 14016/17525 [2:48:00<34:08,  1.71it/s] 80%|███████▉  | 14017/17525 [2:48:00<34:00,  1.72it/s] 80%|███████▉  | 14018/17525 [2:48:01<33:49,  1.73it/s] 80%|███████▉  | 14019/17525 [2:48:01<33:44,  1.73it/s] 80%|████████  | 14020/17525 [2:48:02<33:35,  1.74it/s]                                                       {'loss': 0.4063, 'grad_norm': 14.034104347229004, 'learning_rate': 1.924624012163737e-06, 'epoch': 20.0}
 80%|████████  | 14020/17525 [2:48:02<33:35,  1.74it/s] 80%|████████  | 14021/17525 [2:48:03<33:40,  1.73it/s] 80%|████████  | 14022/17525 [2:48:03<33:58,  1.72it/s] 80%|████████  | 14023/17525 [2:48:04<33:49,  1.73it/s] 80%|████████  | 14024/17525 [2:48:05<37:00,  1.58it/s] 80%|████████  | 14025/17525 [2:48:05<36:01,  1.62it/s] 80%|████████  | 14026/17525 [2:48:06<35:16,  1.65it/s] 80%|████████  | 14027/17525 [2:48:06<34:42,  1.68it/s] 80%|████████  | 14028/17525 [2:48:07<34:18,  1.70it/s] 80%|████████  | 14029/17525 [2:48:07<34:02,  1.71it/s] 80%|████████  | 14030/17525 [2:48:08<33:52,  1.72it/s]                                                       {'loss': 0.3473, 'grad_norm': 5.847207069396973, 'learning_rate': 1.9140516933731566e-06, 'epoch': 20.01}
 80%|████████  | 14030/17525 [2:48:08<33:52,  1.72it/s] 80%|████████  | 14031/17525 [2:48:09<33:44,  1.73it/s] 80%|████████  | 14032/17525 [2:48:09<33:39,  1.73it/s] 80%|████████  | 14033/17525 [2:48:10<33:34,  1.73it/s] 80%|████████  | 14034/17525 [2:48:10<33:30,  1.74it/s] 80%|████████  | 14035/17525 [2:48:11<33:29,  1.74it/s] 80%|████████  | 14036/17525 [2:48:11<33:28,  1.74it/s] 80%|████████  | 14037/17525 [2:48:12<33:26,  1.74it/s] 80%|████████  | 14038/17525 [2:48:13<33:29,  1.74it/s] 80%|████████  | 14039/17525 [2:48:13<33:29,  1.73it/s] 80%|████████  | 14040/17525 [2:48:14<33:28,  1.74it/s]                                                       {'loss': 0.4193, 'grad_norm': 9.035436630249023, 'learning_rate': 1.9035054185029688e-06, 'epoch': 20.03}
 80%|████████  | 14040/17525 [2:48:14<33:28,  1.74it/s] 80%|████████  | 14041/17525 [2:48:14<33:29,  1.73it/s] 80%|████████  | 14042/17525 [2:48:15<33:29,  1.73it/s] 80%|████████  | 14043/17525 [2:48:16<33:33,  1.73it/s] 80%|████████  | 14044/17525 [2:48:16<33:32,  1.73it/s] 80%|████████  | 14045/17525 [2:48:17<33:27,  1.73it/s] 80%|████████  | 14046/17525 [2:48:17<33:22,  1.74it/s] 80%|████████  | 14047/17525 [2:48:18<33:22,  1.74it/s] 80%|████████  | 14048/17525 [2:48:18<33:18,  1.74it/s] 80%|████████  | 14049/17525 [2:48:19<33:13,  1.74it/s] 80%|████████  | 14050/17525 [2:48:20<33:13,  1.74it/s]                                                       {'loss': 0.3482, 'grad_norm': 10.461803436279297, 'learning_rate': 1.892985221521526e-06, 'epoch': 20.04}
 80%|████████  | 14050/17525 [2:48:20<33:13,  1.74it/s] 80%|████████  | 14051/17525 [2:48:20<33:18,  1.74it/s] 80%|████████  | 14052/17525 [2:48:21<33:18,  1.74it/s] 80%|████████  | 14053/17525 [2:48:21<33:17,  1.74it/s] 80%|████████  | 14054/17525 [2:48:22<33:15,  1.74it/s] 80%|████████  | 14055/17525 [2:48:22<33:15,  1.74it/s] 80%|████████  | 14056/17525 [2:48:23<33:16,  1.74it/s] 80%|████████  | 14057/17525 [2:48:24<33:16,  1.74it/s] 80%|████████  | 14058/17525 [2:48:24<33:21,  1.73it/s] 80%|████████  | 14059/17525 [2:48:25<33:25,  1.73it/s] 80%|████████  | 14060/17525 [2:48:25<33:16,  1.74it/s]                                                       {'loss': 0.3881, 'grad_norm': 6.609043598175049, 'learning_rate': 1.8824911363131892e-06, 'epoch': 20.06}
 80%|████████  | 14060/17525 [2:48:25<33:16,  1.74it/s] 80%|████████  | 14061/17525 [2:48:26<33:21,  1.73it/s] 80%|████████  | 14062/17525 [2:48:26<33:46,  1.71it/s] 80%|████████  | 14063/17525 [2:48:27<34:06,  1.69it/s] 80%|████████  | 14064/17525 [2:48:28<33:48,  1.71it/s] 80%|████████  | 14065/17525 [2:48:28<33:30,  1.72it/s] 80%|████████  | 14066/17525 [2:48:29<33:21,  1.73it/s] 80%|████████  | 14067/17525 [2:48:29<33:16,  1.73it/s] 80%|████████  | 14068/17525 [2:48:30<33:12,  1.74it/s] 80%|████████  | 14069/17525 [2:48:31<33:07,  1.74it/s] 80%|████████  | 14070/17525 [2:48:31<36:31,  1.58it/s]                                                       {'loss': 0.3633, 'grad_norm': 5.3363752365112305, 'learning_rate': 1.8720231966782065e-06, 'epoch': 20.07}
 80%|████████  | 14070/17525 [2:48:31<36:31,  1.58it/s] 80%|████████  | 14071/17525 [2:48:32<35:35,  1.62it/s] 80%|████████  | 14072/17525 [2:48:32<34:49,  1.65it/s] 80%|████████  | 14073/17525 [2:48:33<34:20,  1.68it/s] 80%|████████  | 14074/17525 [2:48:34<33:56,  1.69it/s] 80%|████████  | 14075/17525 [2:48:34<33:44,  1.70it/s] 80%|████████  | 14076/17525 [2:48:35<33:32,  1.71it/s] 80%|████████  | 14077/17525 [2:48:35<33:26,  1.72it/s] 80%|████████  | 14078/17525 [2:48:36<33:16,  1.73it/s] 80%|████████  | 14079/17525 [2:48:36<33:11,  1.73it/s] 80%|████████  | 14080/17525 [2:48:37<33:10,  1.73it/s]                                                       {'loss': 0.3201, 'grad_norm': 11.977761268615723, 'learning_rate': 1.8615814363326323e-06, 'epoch': 20.09}
 80%|████████  | 14080/17525 [2:48:37<33:10,  1.73it/s] 80%|████████  | 14081/17525 [2:48:38<33:06,  1.73it/s] 80%|████████  | 14082/17525 [2:48:38<33:05,  1.73it/s] 80%|████████  | 14083/17525 [2:48:39<33:03,  1.74it/s] 80%|████████  | 14084/17525 [2:48:39<33:11,  1.73it/s] 80%|████████  | 14085/17525 [2:48:40<33:07,  1.73it/s] 80%|████████  | 14086/17525 [2:48:41<33:01,  1.74it/s] 80%|████████  | 14087/17525 [2:48:41<32:55,  1.74it/s] 80%|████████  | 14088/17525 [2:48:42<32:54,  1.74it/s] 80%|████████  | 14089/17525 [2:48:42<32:59,  1.74it/s] 80%|████████  | 14090/17525 [2:48:43<33:00,  1.73it/s]                                                       {'loss': 0.3188, 'grad_norm': 8.53881549835205, 'learning_rate': 1.8511658889081829e-06, 'epoch': 20.1}
 80%|████████  | 14090/17525 [2:48:43<33:00,  1.73it/s] 80%|████████  | 14091/17525 [2:48:43<33:01,  1.73it/s] 80%|████████  | 14092/17525 [2:48:44<32:56,  1.74it/s] 80%|████████  | 14093/17525 [2:48:45<32:56,  1.74it/s] 80%|████████  | 14094/17525 [2:48:45<32:52,  1.74it/s] 80%|████████  | 14095/17525 [2:48:46<32:54,  1.74it/s] 80%|████████  | 14096/17525 [2:48:46<33:09,  1.72it/s] 80%|████████  | 14097/17525 [2:48:47<33:18,  1.72it/s] 80%|████████  | 14098/17525 [2:48:47<33:10,  1.72it/s] 80%|████████  | 14099/17525 [2:48:48<33:05,  1.73it/s] 80%|████████  | 14100/17525 [2:48:49<43:37,  1.31it/s]                                                       {'loss': 0.3223, 'grad_norm': 5.1986403465271, 'learning_rate': 1.8407765879521532e-06, 'epoch': 20.11}
 80%|████████  | 14100/17525 [2:48:49<43:37,  1.31it/s][INFO|trainer.py:3512] 2024-06-25 04:52:11,130 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:52:11,130 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:52:11,130 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.00it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.34it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.60it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.84it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.32it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.58it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.73it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1794008016586304, 'eval_runtime': 4.6111, 'eval_samples_per_second': 96.072, 'eval_steps_per_second': 4.12, 'epoch': 20.11}
 80%|████████  | 14100/17525 [2:48:54<43:37,  1.31it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:52:15,746 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b7d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: b371e967-985a-4bb2-ad23-c4e1b79be73e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:52:25,872 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:52:25,874 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 80%|████████  | 14101/17525 [2:49:05<4:55:16,  5.17s/it] 80%|████████  | 14102/17525 [2:49:05<3:36:34,  3.80s/it] 80%|████████  | 14103/17525 [2:49:06<2:41:27,  2.83s/it] 80%|████████  | 14104/17525 [2:49:06<2:02:51,  2.15s/it] 80%|████████  | 14105/17525 [2:49:07<1:35:52,  1.68s/it] 80%|████████  | 14106/17525 [2:49:08<1:16:54,  1.35s/it] 80%|████████  | 14107/17525 [2:49:08<1:03:40,  1.12s/it] 81%|████████  | 14108/17525 [2:49:09<54:33,  1.04it/s]   81%|████████  | 14109/17525 [2:49:09<47:58,  1.19it/s] 81%|████████  | 14110/17525 [2:49:10<43:20,  1.31it/s]                                                       {'loss': 0.2612, 'grad_norm': 8.44549560546875, 'learning_rate': 1.8304135669273016e-06, 'epoch': 20.13}
 81%|████████  | 14110/17525 [2:49:10<43:20,  1.31it/s] 81%|████████  | 14111/17525 [2:49:10<40:10,  1.42it/s] 81%|████████  | 14112/17525 [2:49:11<37:49,  1.50it/s] 81%|████████  | 14113/17525 [2:49:12<36:14,  1.57it/s] 81%|████████  | 14114/17525 [2:49:12<35:09,  1.62it/s] 81%|████████  | 14115/17525 [2:49:13<34:28,  1.65it/s] 81%|████████  | 14116/17525 [2:49:14<40:01,  1.42it/s] 81%|████████  | 14117/17525 [2:49:14<37:46,  1.50it/s] 81%|████████  | 14118/17525 [2:49:15<36:13,  1.57it/s] 81%|████████  | 14119/17525 [2:49:15<35:09,  1.61it/s] 81%|████████  | 14120/17525 [2:49:16<34:20,  1.65it/s]                                                       {'loss': 0.2838, 'grad_norm': 9.636758804321289, 'learning_rate': 1.8200768592117413e-06, 'epoch': 20.14}
 81%|████████  | 14120/17525 [2:49:16<34:20,  1.65it/s] 81%|████████  | 14121/17525 [2:49:17<33:51,  1.68it/s] 81%|████████  | 14122/17525 [2:49:17<33:27,  1.70it/s] 81%|████████  | 14123/17525 [2:49:18<33:10,  1.71it/s] 81%|████████  | 14124/17525 [2:49:18<32:58,  1.72it/s] 81%|████████  | 14125/17525 [2:49:19<32:46,  1.73it/s] 81%|████████  | 14126/17525 [2:49:19<32:45,  1.73it/s] 81%|████████  | 14127/17525 [2:49:20<32:43,  1.73it/s] 81%|████████  | 14128/17525 [2:49:21<32:35,  1.74it/s] 81%|████████  | 14129/17525 [2:49:21<35:41,  1.59it/s] 81%|████████  | 14130/17525 [2:49:22<37:36,  1.50it/s]                                                       {'loss': 0.3415, 'grad_norm': 14.334916114807129, 'learning_rate': 1.8097664980988316e-06, 'epoch': 20.16}
 81%|████████  | 14130/17525 [2:49:22<37:36,  1.50it/s] 81%|████████  | 14131/17525 [2:49:23<42:15,  1.34it/s] 81%|████████  | 14132/17525 [2:49:24<39:18,  1.44it/s] 81%|████████  | 14133/17525 [2:49:24<37:14,  1.52it/s] 81%|████████  | 14134/17525 [2:49:25<35:46,  1.58it/s] 81%|████████  | 14135/17525 [2:49:25<34:41,  1.63it/s] 81%|████████  | 14136/17525 [2:49:26<34:02,  1.66it/s] 81%|████████  | 14137/17525 [2:49:26<34:00,  1.66it/s] 81%|████████  | 14138/17525 [2:49:27<33:57,  1.66it/s] 81%|████████  | 14139/17525 [2:49:28<33:37,  1.68it/s] 81%|████████  | 14140/17525 [2:49:28<33:22,  1.69it/s]                                                       {'loss': 0.3519, 'grad_norm': 17.098474502563477, 'learning_rate': 1.7994825167970787e-06, 'epoch': 20.17}
 81%|████████  | 14140/17525 [2:49:28<33:22,  1.69it/s] 81%|████████  | 14141/17525 [2:49:29<33:05,  1.70it/s] 81%|████████  | 14142/17525 [2:49:29<32:52,  1.72it/s] 81%|████████  | 14143/17525 [2:49:30<32:41,  1.72it/s] 81%|████████  | 14144/17525 [2:49:31<32:33,  1.73it/s] 81%|████████  | 14145/17525 [2:49:31<32:29,  1.73it/s] 81%|████████  | 14146/17525 [2:49:32<32:25,  1.74it/s] 81%|████████  | 14147/17525 [2:49:32<32:23,  1.74it/s] 81%|████████  | 14148/17525 [2:49:33<32:21,  1.74it/s] 81%|████████  | 14149/17525 [2:49:33<32:22,  1.74it/s] 81%|████████  | 14150/17525 [2:49:34<32:21,  1.74it/s]                                                       {'loss': 0.3721, 'grad_norm': 9.567728042602539, 'learning_rate': 1.7892249484300094e-06, 'epoch': 20.19}
 81%|████████  | 14150/17525 [2:49:34<32:21,  1.74it/s] 81%|████████  | 14151/17525 [2:49:35<32:20,  1.74it/s] 81%|████████  | 14152/17525 [2:49:35<32:18,  1.74it/s] 81%|████████  | 14153/17525 [2:49:36<32:16,  1.74it/s] 81%|████████  | 14154/17525 [2:49:36<32:19,  1.74it/s] 81%|████████  | 14155/17525 [2:49:37<32:19,  1.74it/s] 81%|████████  | 14156/17525 [2:49:37<32:20,  1.74it/s] 81%|████████  | 14157/17525 [2:49:38<32:18,  1.74it/s] 81%|████████  | 14158/17525 [2:49:39<32:19,  1.74it/s] 81%|████████  | 14159/17525 [2:49:39<32:19,  1.74it/s] 81%|████████  | 14160/17525 [2:49:40<32:20,  1.73it/s]                                                       {'loss': 0.382, 'grad_norm': 7.026895523071289, 'learning_rate': 1.7789938260360907e-06, 'epoch': 20.2}
 81%|████████  | 14160/17525 [2:49:40<32:20,  1.73it/s] 81%|████████  | 14161/17525 [2:49:40<32:20,  1.73it/s] 81%|████████  | 14162/17525 [2:49:41<32:16,  1.74it/s] 81%|████████  | 14163/17525 [2:49:41<32:17,  1.74it/s] 81%|████████  | 14164/17525 [2:49:42<38:21,  1.46it/s] 81%|████████  | 14165/17525 [2:49:43<36:28,  1.54it/s] 81%|████████  | 14166/17525 [2:49:44<35:08,  1.59it/s] 81%|████████  | 14167/17525 [2:49:45<47:19,  1.18it/s] 81%|████████  | 14168/17525 [2:49:46<42:49,  1.31it/s] 81%|████████  | 14169/17525 [2:49:46<39:35,  1.41it/s] 81%|████████  | 14170/17525 [2:49:47<37:21,  1.50it/s]                                                       {'loss': 0.3594, 'grad_norm': 6.08875036239624, 'learning_rate': 1.7687891825686033e-06, 'epoch': 20.21}
 81%|████████  | 14170/17525 [2:49:47<37:21,  1.50it/s] 81%|████████  | 14171/17525 [2:49:47<35:46,  1.56it/s] 81%|████████  | 14172/17525 [2:49:48<34:36,  1.61it/s] 81%|████████  | 14173/17525 [2:49:48<34:03,  1.64it/s] 81%|████████  | 14174/17525 [2:49:49<33:30,  1.67it/s] 81%|████████  | 14175/17525 [2:49:50<33:04,  1.69it/s] 81%|████████  | 14176/17525 [2:49:50<32:48,  1.70it/s] 81%|████████  | 14177/17525 [2:49:51<32:37,  1.71it/s] 81%|████████  | 14178/17525 [2:49:51<32:30,  1.72it/s] 81%|████████  | 14179/17525 [2:49:52<32:23,  1.72it/s] 81%|████████  | 14180/17525 [2:49:52<32:26,  1.72it/s]                                                       {'loss': 0.3228, 'grad_norm': 8.999069213867188, 'learning_rate': 1.7586110508955434e-06, 'epoch': 20.23}
 81%|████████  | 14180/17525 [2:49:52<32:26,  1.72it/s] 81%|████████  | 14181/17525 [2:49:53<32:25,  1.72it/s] 81%|████████  | 14182/17525 [2:49:54<32:20,  1.72it/s] 81%|████████  | 14183/17525 [2:49:54<32:13,  1.73it/s] 81%|████████  | 14184/17525 [2:49:55<32:08,  1.73it/s] 81%|████████  | 14185/17525 [2:49:55<32:04,  1.74it/s] 81%|████████  | 14186/17525 [2:49:56<32:06,  1.73it/s] 81%|████████  | 14187/17525 [2:49:56<32:06,  1.73it/s] 81%|████████  | 14188/17525 [2:49:57<32:02,  1.74it/s] 81%|████████  | 14189/17525 [2:49:58<31:57,  1.74it/s] 81%|████████  | 14190/17525 [2:49:58<31:57,  1.74it/s]                                                       {'loss': 0.3281, 'grad_norm': 7.555751800537109, 'learning_rate': 1.748459463799521e-06, 'epoch': 20.24}
 81%|████████  | 14190/17525 [2:49:58<31:57,  1.74it/s] 81%|████████  | 14191/17525 [2:49:59<32:02,  1.73it/s] 81%|████████  | 14192/17525 [2:49:59<32:03,  1.73it/s] 81%|████████  | 14193/17525 [2:50:00<32:03,  1.73it/s] 81%|████████  | 14194/17525 [2:50:01<31:58,  1.74it/s] 81%|████████  | 14195/17525 [2:50:01<31:56,  1.74it/s] 81%|████████  | 14196/17525 [2:50:02<31:56,  1.74it/s] 81%|████████  | 14197/17525 [2:50:02<31:52,  1.74it/s] 81%|████████  | 14198/17525 [2:50:03<31:52,  1.74it/s] 81%|████████  | 14199/17525 [2:50:03<31:53,  1.74it/s] 81%|████████  | 14200/17525 [2:50:04<31:52,  1.74it/s]                                                       {'loss': 0.355, 'grad_norm': 17.289793014526367, 'learning_rate': 1.7383344539776337e-06, 'epoch': 20.26}
 81%|████████  | 14200/17525 [2:50:04<31:52,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:53:25,850 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:53:25,850 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:53:25,850 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1810343265533447, 'eval_runtime': 4.6009, 'eval_samples_per_second': 96.285, 'eval_steps_per_second': 4.13, 'epoch': 20.26}
 81%|████████  | 14200/17525 [2:50:09<31:52,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 81%|████████  | 14201/17525 [2:50:09<1:48:31,  1.96s/it] 81%|████████  | 14202/17525 [2:50:10<1:25:32,  1.54s/it] 81%|████████  | 14203/17525 [2:50:10<1:09:26,  1.25s/it] 81%|████████  | 14204/17525 [2:50:11<1:03:32,  1.15s/it] 81%|████████  | 14205/17525 [2:50:12<54:00,  1.02it/s]   81%|████████  | 14206/17525 [2:50:12<47:20,  1.17it/s] 81%|████████  | 14207/17525 [2:50:13<48:40,  1.14it/s] 81%|████████  | 14208/17525 [2:50:14<53:39,  1.03it/s] 81%|████████  | 14209/17525 [2:50:15<47:16,  1.17it/s] 81%|████████  | 14210/17525 [2:50:16<50:00,  1.10it/s]                                                       {'loss': 0.3426, 'grad_norm': 7.447105884552002, 'learning_rate': 1.7282360540414e-06, 'epoch': 20.27}
 81%|████████  | 14210/17525 [2:50:16<50:00,  1.10it/s] 81%|████████  | 14211/17525 [2:50:17<44:40,  1.24it/s] 81%|████████  | 14212/17525 [2:50:17<40:47,  1.35it/s] 81%|████████  | 14213/17525 [2:50:18<38:05,  1.45it/s] 81%|████████  | 14214/17525 [2:50:18<36:09,  1.53it/s] 81%|████████  | 14215/17525 [2:50:19<34:50,  1.58it/s] 81%|████████  | 14216/17525 [2:50:20<33:55,  1.63it/s] 81%|████████  | 14217/17525 [2:50:20<33:15,  1.66it/s] 81%|████████  | 14218/17525 [2:50:21<32:46,  1.68it/s] 81%|████████  | 14219/17525 [2:50:22<38:20,  1.44it/s] 81%|████████  | 14220/17525 [2:50:22<36:21,  1.52it/s]                                                       {'loss': 0.3265, 'grad_norm': 7.707095623016357, 'learning_rate': 1.7181642965166069e-06, 'epoch': 20.29}
 81%|████████  | 14220/17525 [2:50:22<36:21,  1.52it/s] 81%|████████  | 14221/17525 [2:50:23<35:04,  1.57it/s] 81%|████████  | 14222/17525 [2:50:23<34:01,  1.62it/s] 81%|████████  | 14223/17525 [2:50:24<33:20,  1.65it/s] 81%|████████  | 14224/17525 [2:50:25<32:51,  1.67it/s] 81%|████████  | 14225/17525 [2:50:25<38:14,  1.44it/s] 81%|████████  | 14226/17525 [2:50:26<36:17,  1.52it/s] 81%|████████  | 14227/17525 [2:50:27<34:49,  1.58it/s] 81%|████████  | 14228/17525 [2:50:27<36:11,  1.52it/s] 81%|████████  | 14229/17525 [2:50:28<34:51,  1.58it/s] 81%|████████  | 14230/17525 [2:50:28<33:57,  1.62it/s]                                                       {'loss': 0.3528, 'grad_norm': 8.126075744628906, 'learning_rate': 1.70811921384325e-06, 'epoch': 20.3}
 81%|████████  | 14230/17525 [2:50:28<33:57,  1.62it/s] 81%|████████  | 14231/17525 [2:50:29<33:16,  1.65it/s] 81%|████████  | 14232/17525 [2:50:30<33:05,  1.66it/s] 81%|████████  | 14233/17525 [2:50:30<32:38,  1.68it/s] 81%|████████  | 14234/17525 [2:50:31<32:21,  1.70it/s] 81%|████████  | 14235/17525 [2:50:31<32:22,  1.69it/s] 81%|████████  | 14236/17525 [2:50:32<32:12,  1.70it/s] 81%|████████  | 14237/17525 [2:50:33<32:02,  1.71it/s] 81%|████████  | 14238/17525 [2:50:33<31:51,  1.72it/s] 81%|████████  | 14239/17525 [2:50:34<32:00,  1.71it/s] 81%|████████▏ | 14240/17525 [2:50:34<31:50,  1.72it/s]                                                       {'loss': 0.3762, 'grad_norm': 10.807252883911133, 'learning_rate': 1.6981008383753927e-06, 'epoch': 20.31}
 81%|████████▏ | 14240/17525 [2:50:34<31:50,  1.72it/s] 81%|████████▏ | 14241/17525 [2:50:35<31:46,  1.72it/s] 81%|████████▏ | 14242/17525 [2:50:35<31:48,  1.72it/s] 81%|████████▏ | 14243/17525 [2:50:36<32:21,  1.69it/s] 81%|████████▏ | 14244/17525 [2:50:37<32:09,  1.70it/s] 81%|████████▏ | 14245/17525 [2:50:37<31:57,  1.71it/s] 81%|████████▏ | 14246/17525 [2:50:38<31:52,  1.71it/s] 81%|████████▏ | 14247/17525 [2:50:38<31:49,  1.72it/s] 81%|████████▏ | 14248/17525 [2:50:39<36:55,  1.48it/s] 81%|████████▏ | 14249/17525 [2:50:40<35:37,  1.53it/s] 81%|████████▏ | 14250/17525 [2:50:40<34:23,  1.59it/s]                                                       {'loss': 0.3683, 'grad_norm': 12.521492958068848, 'learning_rate': 1.6881092023810853e-06, 'epoch': 20.33}
 81%|████████▏ | 14250/17525 [2:50:40<34:23,  1.59it/s][INFO|trainer.py:3203] 2024-06-25 04:54:02,335 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c55990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: aa121198-7164-4454-a4d2-6fbd16cf566f)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:54:12,392 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:54:12,394 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 81%|████████▏ | 14251/17525 [2:50:51<3:20:52,  3.68s/it] 81%|████████▏ | 14252/17525 [2:50:52<2:30:07,  2.75s/it] 81%|████████▏ | 14253/17525 [2:50:52<1:54:32,  2.10s/it] 81%|████████▏ | 14254/17525 [2:50:53<1:29:38,  1.64s/it] 81%|████████▏ | 14255/17525 [2:50:54<1:12:12,  1.32s/it] 81%|████████▏ | 14256/17525 [2:50:54<59:58,  1.10s/it]   81%|████████▏ | 14257/17525 [2:50:55<51:19,  1.06it/s] 81%|████████▏ | 14258/17525 [2:50:55<45:15,  1.20it/s] 81%|████████▏ | 14259/17525 [2:50:56<41:06,  1.32it/s] 81%|████████▏ | 14260/17525 [2:50:56<38:11,  1.42it/s]                                                       {'loss': 0.3401, 'grad_norm': 14.022276878356934, 'learning_rate': 1.6781443380422513e-06, 'epoch': 20.34}
 81%|████████▏ | 14260/17525 [2:50:56<38:11,  1.42it/s] 81%|████████▏ | 14261/17525 [2:50:57<36:11,  1.50it/s] 81%|████████▏ | 14262/17525 [2:50:58<34:39,  1.57it/s] 81%|████████▏ | 14263/17525 [2:50:58<33:35,  1.62it/s] 81%|████████▏ | 14264/17525 [2:50:59<32:52,  1.65it/s] 81%|████████▏ | 14265/17525 [2:50:59<32:22,  1.68it/s] 81%|████████▏ | 14266/17525 [2:51:00<32:00,  1.70it/s] 81%|████████▏ | 14267/17525 [2:51:00<31:43,  1.71it/s] 81%|████████▏ | 14268/17525 [2:51:01<31:32,  1.72it/s] 81%|████████▏ | 14269/17525 [2:51:02<31:22,  1.73it/s] 81%|████████▏ | 14270/17525 [2:51:02<31:20,  1.73it/s]                                                       {'loss': 0.3232, 'grad_norm': 7.955234527587891, 'learning_rate': 1.6682062774545892e-06, 'epoch': 20.36}
 81%|████████▏ | 14270/17525 [2:51:02<31:20,  1.73it/s] 81%|████████▏ | 14271/17525 [2:51:03<31:22,  1.73it/s] 81%|████████▏ | 14272/17525 [2:51:04<38:18,  1.42it/s] 81%|████████▏ | 14273/17525 [2:51:04<36:14,  1.50it/s] 81%|████████▏ | 14274/17525 [2:51:05<34:40,  1.56it/s] 81%|████████▏ | 14275/17525 [2:51:06<33:40,  1.61it/s] 81%|████████▏ | 14276/17525 [2:51:06<32:53,  1.65it/s] 81%|████████▏ | 14277/17525 [2:51:07<32:20,  1.67it/s] 81%|████████▏ | 14278/17525 [2:51:07<31:58,  1.69it/s] 81%|████████▏ | 14279/17525 [2:51:08<31:42,  1.71it/s] 81%|████████▏ | 14280/17525 [2:51:08<31:31,  1.72it/s]                                                       {'loss': 0.3265, 'grad_norm': 8.037973403930664, 'learning_rate': 1.6582950526274578e-06, 'epoch': 20.37}
 81%|████████▏ | 14280/17525 [2:51:08<31:31,  1.72it/s] 81%|████████▏ | 14281/17525 [2:51:09<31:26,  1.72it/s] 81%|████████▏ | 14282/17525 [2:51:10<31:20,  1.72it/s] 82%|████████▏ | 14283/17525 [2:51:10<31:14,  1.73it/s] 82%|████████▏ | 14284/17525 [2:51:11<31:08,  1.73it/s] 82%|████████▏ | 14285/17525 [2:51:11<31:05,  1.74it/s] 82%|████████▏ | 14286/17525 [2:51:12<31:04,  1.74it/s] 82%|████████▏ | 14287/17525 [2:51:12<31:04,  1.74it/s] 82%|████████▏ | 14288/17525 [2:51:13<30:59,  1.74it/s] 82%|████████▏ | 14289/17525 [2:51:14<30:59,  1.74it/s] 82%|████████▏ | 14290/17525 [2:51:14<31:01,  1.74it/s]                                                       {'loss': 0.3006, 'grad_norm': 7.677862644195557, 'learning_rate': 1.6484106954837874e-06, 'epoch': 20.39}
 82%|████████▏ | 14290/17525 [2:51:14<31:01,  1.74it/s] 82%|████████▏ | 14291/17525 [2:51:15<31:05,  1.73it/s] 82%|████████▏ | 14292/17525 [2:51:15<31:06,  1.73it/s] 82%|████████▏ | 14293/17525 [2:51:16<31:07,  1.73it/s] 82%|████████▏ | 14294/17525 [2:51:16<31:09,  1.73it/s] 82%|████████▏ | 14295/17525 [2:51:17<31:05,  1.73it/s] 82%|████████▏ | 14296/17525 [2:51:18<30:58,  1.74it/s] 82%|████████▏ | 14297/17525 [2:51:18<30:56,  1.74it/s] 82%|████████▏ | 14298/17525 [2:51:19<31:16,  1.72it/s] 82%|████████▏ | 14299/17525 [2:51:19<31:08,  1.73it/s] 82%|████████▏ | 14300/17525 [2:51:20<31:14,  1.72it/s]                                                       {'loss': 0.308, 'grad_norm': 6.266178131103516, 'learning_rate': 1.63855323785997e-06, 'epoch': 20.4}
 82%|████████▏ | 14300/17525 [2:51:20<31:14,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 04:54:41,816 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:54:41,816 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:54:41,816 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1771012544631958, 'eval_runtime': 4.5935, 'eval_samples_per_second': 96.441, 'eval_steps_per_second': 4.136, 'epoch': 20.4}
 82%|████████▏ | 14300/17525 [2:51:25<31:14,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 82%|████████▏ | 14301/17525 [2:51:25<1:45:22,  1.96s/it] 82%|████████▏ | 14302/17525 [2:51:26<1:23:06,  1.55s/it] 82%|████████▏ | 14303/17525 [2:51:26<1:07:25,  1.26s/it] 82%|████████▏ | 14304/17525 [2:51:27<56:23,  1.05s/it]   82%|████████▏ | 14305/17525 [2:51:27<48:48,  1.10it/s] 82%|████████▏ | 14306/17525 [2:51:28<43:30,  1.23it/s] 82%|████████▏ | 14307/17525 [2:51:29<40:19,  1.33it/s] 82%|████████▏ | 14308/17525 [2:51:29<39:56,  1.34it/s] 82%|████████▏ | 14309/17525 [2:51:30<37:14,  1.44it/s] 82%|████████▏ | 14310/17525 [2:51:30<35:18,  1.52it/s]                                                       {'loss': 0.399, 'grad_norm': 11.23763656616211, 'learning_rate': 1.6287227115057548e-06, 'epoch': 20.41}
 82%|████████▏ | 14310/17525 [2:51:30<35:18,  1.52it/s] 82%|████████▏ | 14311/17525 [2:51:31<39:18,  1.36it/s] 82%|████████▏ | 14312/17525 [2:51:32<36:47,  1.46it/s] 82%|████████▏ | 14313/17525 [2:51:33<34:59,  1.53it/s] 82%|████████▏ | 14314/17525 [2:51:33<33:42,  1.59it/s] 82%|████████▏ | 14315/17525 [2:51:34<32:48,  1.63it/s] 82%|████████▏ | 14316/17525 [2:51:34<32:11,  1.66it/s] 82%|████████▏ | 14317/17525 [2:51:35<31:44,  1.68it/s] 82%|████████▏ | 14318/17525 [2:51:35<31:28,  1.70it/s] 82%|████████▏ | 14319/17525 [2:51:36<31:14,  1.71it/s] 82%|████████▏ | 14320/17525 [2:51:37<30:58,  1.72it/s]                                                       {'loss': 0.3753, 'grad_norm': 12.434346199035645, 'learning_rate': 1.6189191480841526e-06, 'epoch': 20.43}
 82%|████████▏ | 14320/17525 [2:51:37<30:58,  1.72it/s] 82%|████████▏ | 14321/17525 [2:51:37<30:52,  1.73it/s] 82%|████████▏ | 14322/17525 [2:51:38<30:49,  1.73it/s] 82%|████████▏ | 14323/17525 [2:51:38<30:48,  1.73it/s] 82%|████████▏ | 14324/17525 [2:51:39<30:42,  1.74it/s] 82%|████████▏ | 14325/17525 [2:51:40<36:30,  1.46it/s] 82%|████████▏ | 14326/17525 [2:51:40<34:44,  1.53it/s] 82%|████████▏ | 14327/17525 [2:51:41<33:25,  1.59it/s] 82%|████████▏ | 14328/17525 [2:51:42<32:31,  1.64it/s] 82%|████████▏ | 14329/17525 [2:51:42<31:59,  1.66it/s] 82%|████████▏ | 14330/17525 [2:51:43<31:42,  1.68it/s]                                                       {'loss': 0.3376, 'grad_norm': 12.528658866882324, 'learning_rate': 1.60914257917132e-06, 'epoch': 20.44}
 82%|████████▏ | 14330/17525 [2:51:43<31:42,  1.68it/s] 82%|████████▏ | 14331/17525 [2:51:43<31:46,  1.68it/s] 82%|████████▏ | 14332/17525 [2:51:44<31:27,  1.69it/s] 82%|████████▏ | 14333/17525 [2:51:44<31:13,  1.70it/s] 82%|████████▏ | 14334/17525 [2:51:45<31:01,  1.71it/s] 82%|████████▏ | 14335/17525 [2:51:46<30:51,  1.72it/s] 82%|████████▏ | 14336/17525 [2:51:46<30:46,  1.73it/s] 82%|████████▏ | 14337/17525 [2:51:47<31:09,  1.70it/s] 82%|████████▏ | 14338/17525 [2:51:47<30:59,  1.71it/s] 82%|████████▏ | 14339/17525 [2:51:48<30:45,  1.73it/s] 82%|████████▏ | 14340/17525 [2:51:48<30:39,  1.73it/s]                                                       {'loss': 0.3234, 'grad_norm': 13.152320861816406, 'learning_rate': 1.5993930362564835e-06, 'epoch': 20.46}
 82%|████████▏ | 14340/17525 [2:51:48<30:39,  1.73it/s] 82%|████████▏ | 14341/17525 [2:51:49<30:40,  1.73it/s] 82%|████████▏ | 14342/17525 [2:51:50<30:36,  1.73it/s] 82%|████████▏ | 14343/17525 [2:51:50<30:33,  1.74it/s] 82%|████████▏ | 14344/17525 [2:51:51<30:33,  1.74it/s] 82%|████████▏ | 14345/17525 [2:51:51<30:32,  1.74it/s] 82%|████████▏ | 14346/17525 [2:51:52<30:28,  1.74it/s] 82%|████████▏ | 14347/17525 [2:51:53<30:26,  1.74it/s] 82%|████████▏ | 14348/17525 [2:51:53<30:27,  1.74it/s] 82%|████████▏ | 14349/17525 [2:51:54<36:12,  1.46it/s] 82%|████████▏ | 14350/17525 [2:51:55<34:49,  1.52it/s]                                                       {'loss': 0.2876, 'grad_norm': 11.359338760375977, 'learning_rate': 1.5896705507418032e-06, 'epoch': 20.47}
 82%|████████▏ | 14350/17525 [2:51:55<34:49,  1.52it/s] 82%|████████▏ | 14351/17525 [2:51:55<33:30,  1.58it/s] 82%|████████▏ | 14352/17525 [2:51:56<32:36,  1.62it/s] 82%|████████▏ | 14353/17525 [2:51:56<32:16,  1.64it/s] 82%|████████▏ | 14354/17525 [2:51:57<31:44,  1.67it/s] 82%|████████▏ | 14355/17525 [2:51:58<31:21,  1.69it/s] 82%|████████▏ | 14356/17525 [2:51:58<31:06,  1.70it/s] 82%|████████▏ | 14357/17525 [2:51:59<30:50,  1.71it/s] 82%|████████▏ | 14358/17525 [2:51:59<33:48,  1.56it/s] 82%|████████▏ | 14359/17525 [2:52:00<32:45,  1.61it/s] 82%|████████▏ | 14360/17525 [2:52:01<32:00,  1.65it/s]                                                       {'loss': 0.3785, 'grad_norm': 12.401975631713867, 'learning_rate': 1.5799751539423092e-06, 'epoch': 20.49}
 82%|████████▏ | 14360/17525 [2:52:01<32:00,  1.65it/s] 82%|████████▏ | 14361/17525 [2:52:01<31:29,  1.67it/s] 82%|████████▏ | 14362/17525 [2:52:02<31:06,  1.69it/s] 82%|████████▏ | 14363/17525 [2:52:02<30:47,  1.71it/s] 82%|████████▏ | 14364/17525 [2:52:03<30:37,  1.72it/s] 82%|████████▏ | 14365/17525 [2:52:03<30:30,  1.73it/s] 82%|████████▏ | 14366/17525 [2:52:04<30:30,  1.73it/s] 82%|████████▏ | 14367/17525 [2:52:05<30:23,  1.73it/s] 82%|████████▏ | 14368/17525 [2:52:05<30:23,  1.73it/s] 82%|████████▏ | 14369/17525 [2:52:06<30:23,  1.73it/s] 82%|████████▏ | 14370/17525 [2:52:06<30:21,  1.73it/s]                                                       {'loss': 0.3645, 'grad_norm': 14.361092567443848, 'learning_rate': 1.5703068770857643e-06, 'epoch': 20.5}
 82%|████████▏ | 14370/17525 [2:52:06<30:21,  1.73it/s] 82%|████████▏ | 14371/17525 [2:52:07<30:24,  1.73it/s] 82%|████████▏ | 14372/17525 [2:52:08<30:39,  1.71it/s] 82%|████████▏ | 14373/17525 [2:52:08<30:52,  1.70it/s] 82%|████████▏ | 14374/17525 [2:52:09<30:43,  1.71it/s] 82%|████████▏ | 14375/17525 [2:52:09<30:35,  1.72it/s] 82%|████████▏ | 14376/17525 [2:52:10<30:28,  1.72it/s] 82%|████████▏ | 14377/17525 [2:52:10<30:22,  1.73it/s] 82%|████████▏ | 14378/17525 [2:52:11<30:15,  1.73it/s] 82%|████████▏ | 14379/17525 [2:52:12<30:12,  1.74it/s] 82%|████████▏ | 14380/17525 [2:52:12<30:08,  1.74it/s]                                                       {'loss': 0.3547, 'grad_norm': 8.298408508300781, 'learning_rate': 1.5606657513125944e-06, 'epoch': 20.51}
 82%|████████▏ | 14380/17525 [2:52:12<30:08,  1.74it/s] 82%|████████▏ | 14381/17525 [2:52:13<30:09,  1.74it/s] 82%|████████▏ | 14382/17525 [2:52:13<30:07,  1.74it/s] 82%|████████▏ | 14383/17525 [2:52:14<30:08,  1.74it/s] 82%|████████▏ | 14384/17525 [2:52:14<30:14,  1.73it/s] 82%|████████▏ | 14385/17525 [2:52:15<30:16,  1.73it/s] 82%|████████▏ | 14386/17525 [2:52:16<30:18,  1.73it/s] 82%|████████▏ | 14387/17525 [2:52:16<30:15,  1.73it/s] 82%|████████▏ | 14388/17525 [2:52:17<30:14,  1.73it/s] 82%|████████▏ | 14389/17525 [2:52:17<30:14,  1.73it/s] 82%|████████▏ | 14390/17525 [2:52:18<30:42,  1.70it/s]                                                       {'loss': 0.3512, 'grad_norm': 6.74215841293335, 'learning_rate': 1.5510518076757674e-06, 'epoch': 20.53}
 82%|████████▏ | 14390/17525 [2:52:18<30:42,  1.70it/s] 82%|████████▏ | 14391/17525 [2:52:19<30:31,  1.71it/s] 82%|████████▏ | 14392/17525 [2:52:19<30:47,  1.70it/s] 82%|████████▏ | 14393/17525 [2:52:20<30:31,  1.71it/s] 82%|████████▏ | 14394/17525 [2:52:20<30:21,  1.72it/s] 82%|████████▏ | 14395/17525 [2:52:21<30:15,  1.72it/s] 82%|████████▏ | 14396/17525 [2:52:21<30:12,  1.73it/s] 82%|████████▏ | 14397/17525 [2:52:22<30:07,  1.73it/s] 82%|████████▏ | 14398/17525 [2:52:23<30:00,  1.74it/s] 82%|████████▏ | 14399/17525 [2:52:23<29:59,  1.74it/s] 82%|████████▏ | 14400/17525 [2:52:24<29:57,  1.74it/s]                                                       {'loss': 0.4216, 'grad_norm': 11.725940704345703, 'learning_rate': 1.5414650771407047e-06, 'epoch': 20.54}
 82%|████████▏ | 14400/17525 [2:52:24<29:57,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 04:55:45,639 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:55:45,639 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:55:45,639 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.76it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.82it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.38it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.62it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1818993091583252, 'eval_runtime': 4.6043, 'eval_samples_per_second': 96.214, 'eval_steps_per_second': 4.127, 'epoch': 20.54}
 82%|████████▏ | 14400/17525 [2:52:28<29:57,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:55:50,247 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c64ad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 10937ba7-82f1-4624-acb6-5cf1721e63c0)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:56:00,304 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:56:00,307 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 82%|████████▏ | 14401/17525 [2:52:39<4:21:19,  5.02s/it] 82%|████████▏ | 14402/17525 [2:52:40<3:11:48,  3.69s/it] 82%|████████▏ | 14403/17525 [2:52:40<2:23:09,  2.75s/it] 82%|████████▏ | 14404/17525 [2:52:41<1:49:11,  2.10s/it] 82%|████████▏ | 14405/17525 [2:52:41<1:25:25,  1.64s/it] 82%|████████▏ | 14406/17525 [2:52:42<1:08:43,  1.32s/it] 82%|████████▏ | 14407/17525 [2:52:43<57:01,  1.10s/it]   82%|████████▏ | 14408/17525 [2:52:43<48:50,  1.06it/s] 82%|████████▏ | 14409/17525 [2:52:44<43:08,  1.20it/s] 82%|████████▏ | 14410/17525 [2:52:44<39:06,  1.33it/s]                                                       {'loss': 0.3717, 'grad_norm': 10.640888214111328, 'learning_rate': 1.5319055905851766e-06, 'epoch': 20.56}
 82%|████████▏ | 14410/17525 [2:52:44<39:06,  1.33it/s] 82%|████████▏ | 14411/17525 [2:52:45<36:26,  1.42it/s] 82%|████████▏ | 14412/17525 [2:52:45<34:23,  1.51it/s] 82%|████████▏ | 14413/17525 [2:52:46<33:00,  1.57it/s] 82%|████████▏ | 14414/17525 [2:52:47<32:01,  1.62it/s] 82%|████████▏ | 14415/17525 [2:52:47<31:20,  1.65it/s] 82%|████████▏ | 14416/17525 [2:52:48<30:48,  1.68it/s] 82%|████████▏ | 14417/17525 [2:52:48<30:27,  1.70it/s] 82%|████████▏ | 14418/17525 [2:52:49<30:12,  1.71it/s] 82%|████████▏ | 14419/17525 [2:52:49<30:05,  1.72it/s] 82%|████████▏ | 14420/17525 [2:52:50<30:00,  1.72it/s]                                                       {'loss': 0.4245, 'grad_norm': 6.481602191925049, 'learning_rate': 1.5223733787991978e-06, 'epoch': 20.57}
 82%|████████▏ | 14420/17525 [2:52:50<30:00,  1.72it/s] 82%|████████▏ | 14421/17525 [2:52:51<29:56,  1.73it/s] 82%|████████▏ | 14422/17525 [2:52:51<29:48,  1.74it/s] 82%|████████▏ | 14423/17525 [2:52:52<35:28,  1.46it/s] 82%|████████▏ | 14424/17525 [2:52:53<33:46,  1.53it/s] 82%|████████▏ | 14425/17525 [2:52:53<34:39,  1.49it/s] 82%|████████▏ | 14426/17525 [2:52:54<33:09,  1.56it/s] 82%|████████▏ | 14427/17525 [2:52:55<32:07,  1.61it/s] 82%|████████▏ | 14428/17525 [2:52:55<31:20,  1.65it/s] 82%|████████▏ | 14429/17525 [2:52:56<30:53,  1.67it/s] 82%|████████▏ | 14430/17525 [2:52:56<30:26,  1.69it/s]                                                       {'loss': 0.3769, 'grad_norm': 7.747342109680176, 'learning_rate': 1.512868472484943e-06, 'epoch': 20.58}
 82%|████████▏ | 14430/17525 [2:52:56<30:26,  1.69it/s] 82%|████████▏ | 14431/17525 [2:52:57<30:14,  1.70it/s] 82%|████████▏ | 14432/17525 [2:52:58<42:15,  1.22it/s] 82%|████████▏ | 14433/17525 [2:52:59<38:48,  1.33it/s] 82%|████████▏ | 14434/17525 [2:52:59<36:01,  1.43it/s] 82%|████████▏ | 14435/17525 [2:53:00<34:09,  1.51it/s] 82%|████████▏ | 14436/17525 [2:53:01<32:51,  1.57it/s] 82%|████████▏ | 14437/17525 [2:53:01<31:52,  1.61it/s] 82%|████████▏ | 14438/17525 [2:53:02<31:14,  1.65it/s] 82%|████████▏ | 14439/17525 [2:53:02<30:47,  1.67it/s] 82%|████████▏ | 14440/17525 [2:53:03<30:27,  1.69it/s]                                                       {'loss': 0.3026, 'grad_norm': 16.807315826416016, 'learning_rate': 1.5033909022566329e-06, 'epoch': 20.6}
 82%|████████▏ | 14440/17525 [2:53:03<30:27,  1.69it/s] 82%|████████▏ | 14441/17525 [2:53:03<30:14,  1.70it/s] 82%|████████▏ | 14442/17525 [2:53:04<29:57,  1.72it/s] 82%|████████▏ | 14443/17525 [2:53:05<29:49,  1.72it/s] 82%|████████▏ | 14444/17525 [2:53:05<30:09,  1.70it/s] 82%|████████▏ | 14445/17525 [2:53:06<29:53,  1.72it/s] 82%|████████▏ | 14446/17525 [2:53:06<29:43,  1.73it/s] 82%|████████▏ | 14447/17525 [2:53:07<29:34,  1.73it/s] 82%|████████▏ | 14448/17525 [2:53:07<29:31,  1.74it/s] 82%|████████▏ | 14449/17525 [2:53:08<29:28,  1.74it/s] 82%|████████▏ | 14450/17525 [2:53:09<29:28,  1.74it/s]                                                       {'loss': 0.3753, 'grad_norm': 11.051215171813965, 'learning_rate': 1.4939406986404459e-06, 'epoch': 20.61}
 82%|████████▏ | 14450/17525 [2:53:09<29:28,  1.74it/s] 82%|████████▏ | 14451/17525 [2:53:09<29:31,  1.74it/s] 82%|████████▏ | 14452/17525 [2:53:10<29:34,  1.73it/s] 82%|████████▏ | 14453/17525 [2:53:10<29:29,  1.74it/s] 82%|████████▏ | 14454/17525 [2:53:11<35:57,  1.42it/s] 82%|████████▏ | 14455/17525 [2:53:12<34:02,  1.50it/s] 82%|████████▏ | 14456/17525 [2:53:13<32:40,  1.57it/s] 82%|████████▏ | 14457/17525 [2:53:13<31:47,  1.61it/s] 82%|████████▏ | 14458/17525 [2:53:14<31:08,  1.64it/s] 83%|████████▎ | 14459/17525 [2:53:14<30:43,  1.66it/s] 83%|████████▎ | 14460/17525 [2:53:15<30:14,  1.69it/s]                                                       {'loss': 0.3886, 'grad_norm': 9.3753023147583, 'learning_rate': 1.484517892074413e-06, 'epoch': 20.63}
 83%|████████▎ | 14460/17525 [2:53:15<30:14,  1.69it/s] 83%|████████▎ | 14461/17525 [2:53:15<30:00,  1.70it/s] 83%|████████▎ | 14462/17525 [2:53:16<29:48,  1.71it/s] 83%|████████▎ | 14463/17525 [2:53:17<29:41,  1.72it/s] 83%|████████▎ | 14464/17525 [2:53:17<29:35,  1.72it/s] 83%|████████▎ | 14465/17525 [2:53:18<29:31,  1.73it/s] 83%|████████▎ | 14466/17525 [2:53:18<29:27,  1.73it/s] 83%|████████▎ | 14467/17525 [2:53:19<29:25,  1.73it/s] 83%|████████▎ | 14468/17525 [2:53:20<31:30,  1.62it/s] 83%|████████▎ | 14469/17525 [2:53:20<31:11,  1.63it/s] 83%|████████▎ | 14470/17525 [2:53:21<30:36,  1.66it/s]                                                       {'loss': 0.3512, 'grad_norm': 8.00353717803955, 'learning_rate': 1.4751225129083247e-06, 'epoch': 20.64}
 83%|████████▎ | 14470/17525 [2:53:21<30:36,  1.66it/s] 83%|████████▎ | 14471/17525 [2:53:21<30:27,  1.67it/s] 83%|████████▎ | 14472/17525 [2:53:22<30:07,  1.69it/s] 83%|████████▎ | 14473/17525 [2:53:23<29:52,  1.70it/s] 83%|████████▎ | 14474/17525 [2:53:23<29:34,  1.72it/s] 83%|████████▎ | 14475/17525 [2:53:24<29:27,  1.73it/s] 83%|████████▎ | 14476/17525 [2:53:24<29:21,  1.73it/s] 83%|████████▎ | 14477/17525 [2:53:25<29:13,  1.74it/s] 83%|████████▎ | 14478/17525 [2:53:25<29:13,  1.74it/s] 83%|████████▎ | 14479/17525 [2:53:26<29:11,  1.74it/s] 83%|████████▎ | 14480/17525 [2:53:27<29:15,  1.73it/s]                                                       {'loss': 0.4086, 'grad_norm': 5.837514400482178, 'learning_rate': 1.465754591403623e-06, 'epoch': 20.66}
 83%|████████▎ | 14480/17525 [2:53:27<29:15,  1.73it/s] 83%|████████▎ | 14481/17525 [2:53:27<29:16,  1.73it/s] 83%|████████▎ | 14482/17525 [2:53:28<29:15,  1.73it/s] 83%|████████▎ | 14483/17525 [2:53:28<29:13,  1.73it/s] 83%|████████▎ | 14484/17525 [2:53:29<29:10,  1.74it/s] 83%|████████▎ | 14485/17525 [2:53:29<29:11,  1.74it/s] 83%|████████▎ | 14486/17525 [2:53:30<29:06,  1.74it/s] 83%|████████▎ | 14487/17525 [2:53:31<29:09,  1.74it/s] 83%|████████▎ | 14488/17525 [2:53:31<29:08,  1.74it/s] 83%|████████▎ | 14489/17525 [2:53:32<29:04,  1.74it/s] 83%|████████▎ | 14490/17525 [2:53:32<29:02,  1.74it/s]                                                       {'loss': 0.3604, 'grad_norm': 17.0487003326416, 'learning_rate': 1.456414157733328e-06, 'epoch': 20.67}
 83%|████████▎ | 14490/17525 [2:53:32<29:02,  1.74it/s] 83%|████████▎ | 14491/17525 [2:53:33<29:03,  1.74it/s] 83%|████████▎ | 14492/17525 [2:53:33<29:03,  1.74it/s] 83%|████████▎ | 14493/17525 [2:53:34<29:03,  1.74it/s] 83%|████████▎ | 14494/17525 [2:53:35<29:03,  1.74it/s] 83%|████████▎ | 14495/17525 [2:53:35<29:05,  1.74it/s] 83%|████████▎ | 14496/17525 [2:53:36<28:59,  1.74it/s] 83%|████████▎ | 14497/17525 [2:53:36<28:59,  1.74it/s] 83%|████████▎ | 14498/17525 [2:53:37<35:14,  1.43it/s] 83%|████████▎ | 14499/17525 [2:53:38<33:22,  1.51it/s] 83%|████████▎ | 14500/17525 [2:53:38<32:03,  1.57it/s]                                                       {'loss': 0.3247, 'grad_norm': 5.862185955047607, 'learning_rate': 1.4471012419819041e-06, 'epoch': 20.68}
 83%|████████▎ | 14500/17525 [2:53:38<32:03,  1.57it/s][INFO|trainer.py:3512] 2024-06-25 04:57:00,336 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:57:00,336 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:57:00,336 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1828174591064453, 'eval_runtime': 4.6015, 'eval_samples_per_second': 96.273, 'eval_steps_per_second': 4.129, 'epoch': 20.68}
 83%|████████▎ | 14500/17525 [2:53:43<32:03,  1.57it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 83%|████████▎ | 14501/17525 [2:53:44<1:40:51,  2.00s/it] 83%|████████▎ | 14502/17525 [2:53:44<1:19:19,  1.57s/it] 83%|████████▎ | 14503/17525 [2:53:45<1:04:14,  1.28s/it] 83%|████████▎ | 14504/17525 [2:53:45<53:37,  1.06s/it]   83%|████████▎ | 14505/17525 [2:53:46<46:09,  1.09it/s] 83%|████████▎ | 14506/17525 [2:53:47<40:58,  1.23it/s] 83%|████████▎ | 14507/17525 [2:53:47<37:49,  1.33it/s] 83%|████████▎ | 14508/17525 [2:53:48<35:29,  1.42it/s] 83%|████████▎ | 14509/17525 [2:53:48<33:31,  1.50it/s] 83%|████████▎ | 14510/17525 [2:53:49<32:08,  1.56it/s]                                                       {'loss': 0.2947, 'grad_norm': 5.41982364654541, 'learning_rate': 1.4378158741452054e-06, 'epoch': 20.7}
 83%|████████▎ | 14510/17525 [2:53:49<32:08,  1.56it/s] 83%|████████▎ | 14511/17525 [2:53:49<31:12,  1.61it/s] 83%|████████▎ | 14512/17525 [2:53:50<30:23,  1.65it/s] 83%|████████▎ | 14513/17525 [2:53:51<29:58,  1.68it/s] 83%|████████▎ | 14514/17525 [2:53:51<29:35,  1.70it/s] 83%|████████▎ | 14515/17525 [2:53:52<29:20,  1.71it/s] 83%|████████▎ | 14516/17525 [2:53:52<29:09,  1.72it/s] 83%|████████▎ | 14517/17525 [2:53:53<29:04,  1.72it/s] 83%|████████▎ | 14518/17525 [2:53:53<29:00,  1.73it/s] 83%|████████▎ | 14519/17525 [2:53:54<28:55,  1.73it/s] 83%|████████▎ | 14520/17525 [2:53:55<28:54,  1.73it/s]                                                       {'loss': 0.3096, 'grad_norm': 12.58060359954834, 'learning_rate': 1.4285580841303382e-06, 'epoch': 20.71}
 83%|████████▎ | 14520/17525 [2:53:55<28:54,  1.73it/s] 83%|████████▎ | 14521/17525 [2:53:55<28:52,  1.73it/s] 83%|████████▎ | 14522/17525 [2:53:56<28:53,  1.73it/s] 83%|████████▎ | 14523/17525 [2:53:56<28:53,  1.73it/s] 83%|████████▎ | 14524/17525 [2:53:57<28:52,  1.73it/s] 83%|████████▎ | 14525/17525 [2:53:58<29:11,  1.71it/s] 83%|████████▎ | 14526/17525 [2:53:58<29:05,  1.72it/s] 83%|████████▎ | 14527/17525 [2:53:59<28:56,  1.73it/s] 83%|████████▎ | 14528/17525 [2:53:59<28:51,  1.73it/s] 83%|████████▎ | 14529/17525 [2:54:00<28:44,  1.74it/s] 83%|████████▎ | 14530/17525 [2:54:00<28:40,  1.74it/s]                                                       {'loss': 0.3255, 'grad_norm': 17.835693359375, 'learning_rate': 1.4193279017555938e-06, 'epoch': 20.73}
 83%|████████▎ | 14530/17525 [2:54:00<28:40,  1.74it/s] 83%|████████▎ | 14531/17525 [2:54:01<28:40,  1.74it/s] 83%|████████▎ | 14532/17525 [2:54:02<28:36,  1.74it/s] 83%|████████▎ | 14533/17525 [2:54:02<28:37,  1.74it/s] 83%|████████▎ | 14534/17525 [2:54:03<28:37,  1.74it/s] 83%|████████▎ | 14535/17525 [2:54:03<28:39,  1.74it/s] 83%|████████▎ | 14536/17525 [2:54:04<28:39,  1.74it/s] 83%|████████▎ | 14537/17525 [2:54:04<28:37,  1.74it/s] 83%|████████▎ | 14538/17525 [2:54:05<28:36,  1.74it/s] 83%|████████▎ | 14539/17525 [2:54:06<28:37,  1.74it/s] 83%|████████▎ | 14540/17525 [2:54:06<28:37,  1.74it/s]                                                       {'loss': 0.4358, 'grad_norm': 7.2301249504089355, 'learning_rate': 1.4101253567503447e-06, 'epoch': 20.74}
 83%|████████▎ | 14540/17525 [2:54:06<28:37,  1.74it/s] 83%|████████▎ | 14541/17525 [2:54:07<28:35,  1.74it/s] 83%|████████▎ | 14542/17525 [2:54:08<35:52,  1.39it/s] 83%|████████▎ | 14543/17525 [2:54:08<33:39,  1.48it/s] 83%|████████▎ | 14544/17525 [2:54:09<32:04,  1.55it/s] 83%|████████▎ | 14545/17525 [2:54:09<31:01,  1.60it/s] 83%|████████▎ | 14546/17525 [2:54:10<30:19,  1.64it/s] 83%|████████▎ | 14547/17525 [2:54:11<30:04,  1.65it/s] 83%|████████▎ | 14548/17525 [2:54:11<29:33,  1.68it/s] 83%|████████▎ | 14549/17525 [2:54:12<29:11,  1.70it/s] 83%|████████▎ | 14550/17525 [2:54:12<28:59,  1.71it/s]                                                       {'loss': 0.2987, 'grad_norm': 8.966476440429688, 'learning_rate': 1.4009504787549333e-06, 'epoch': 20.76}
 83%|████████▎ | 14550/17525 [2:54:12<28:59,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 04:57:34,279 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14550
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bdd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 29a8cca8-0b7a-4455-93e9-5bd6445e1e0d)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:57:44,393 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:57:44,395 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14550/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 83%|████████▎ | 14551/17525 [2:54:23<3:01:32,  3.66s/it] 83%|████████▎ | 14552/17525 [2:54:24<2:15:39,  2.74s/it] 83%|████████▎ | 14553/17525 [2:54:24<1:43:32,  2.09s/it] 83%|████████▎ | 14554/17525 [2:54:25<1:20:57,  1.64s/it] 83%|████████▎ | 14555/17525 [2:54:26<1:05:11,  1.32s/it] 83%|████████▎ | 14556/17525 [2:54:26<54:10,  1.09s/it]   83%|████████▎ | 14557/17525 [2:54:27<46:27,  1.06it/s] 83%|████████▎ | 14558/17525 [2:54:27<41:21,  1.20it/s] 83%|████████▎ | 14559/17525 [2:54:28<37:26,  1.32it/s] 83%|████████▎ | 14560/17525 [2:54:28<34:42,  1.42it/s]                                                       {'loss': 0.3148, 'grad_norm': 10.679579734802246, 'learning_rate': 1.3918032973206087e-06, 'epoch': 20.77}
 83%|████████▎ | 14560/17525 [2:54:28<34:42,  1.42it/s] 83%|████████▎ | 14561/17525 [2:54:29<32:50,  1.50it/s] 83%|████████▎ | 14562/17525 [2:54:30<31:29,  1.57it/s] 83%|████████▎ | 14563/17525 [2:54:30<30:34,  1.61it/s] 83%|████████▎ | 14564/17525 [2:54:31<29:51,  1.65it/s] 83%|████████▎ | 14565/17525 [2:54:32<41:02,  1.20it/s] 83%|████████▎ | 14566/17525 [2:54:33<37:14,  1.32it/s] 83%|████████▎ | 14567/17525 [2:54:33<34:33,  1.43it/s] 83%|████████▎ | 14568/17525 [2:54:34<32:40,  1.51it/s] 83%|████████▎ | 14569/17525 [2:54:34<31:16,  1.58it/s] 83%|████████▎ | 14570/17525 [2:54:35<30:22,  1.62it/s]                                                       {'loss': 0.2869, 'grad_norm': 15.461793899536133, 'learning_rate': 1.3826838419093958e-06, 'epoch': 20.78}
 83%|████████▎ | 14570/17525 [2:54:35<30:22,  1.62it/s] 83%|████████▎ | 14571/17525 [2:54:36<29:50,  1.65it/s] 83%|████████▎ | 14572/17525 [2:54:36<29:43,  1.66it/s] 83%|████████▎ | 14573/17525 [2:54:37<29:13,  1.68it/s] 83%|████████▎ | 14574/17525 [2:54:37<28:54,  1.70it/s] 83%|████████▎ | 14575/17525 [2:54:38<28:39,  1.72it/s] 83%|████████▎ | 14576/17525 [2:54:38<28:30,  1.72it/s] 83%|████████▎ | 14577/17525 [2:54:39<28:22,  1.73it/s] 83%|████████▎ | 14578/17525 [2:54:40<28:16,  1.74it/s] 83%|████████▎ | 14579/17525 [2:54:40<28:13,  1.74it/s] 83%|████████▎ | 14580/17525 [2:54:41<28:13,  1.74it/s]                                                       {'loss': 0.3506, 'grad_norm': 6.660933017730713, 'learning_rate': 1.3735921418940268e-06, 'epoch': 20.8}
 83%|████████▎ | 14580/17525 [2:54:41<28:13,  1.74it/s] 83%|████████▎ | 14581/17525 [2:54:41<28:14,  1.74it/s] 83%|████████▎ | 14582/17525 [2:54:42<28:14,  1.74it/s] 83%|████████▎ | 14583/17525 [2:54:42<28:15,  1.74it/s] 83%|████████▎ | 14584/17525 [2:54:43<28:33,  1.72it/s] 83%|████████▎ | 14585/17525 [2:54:44<28:31,  1.72it/s] 83%|████████▎ | 14586/17525 [2:54:44<28:25,  1.72it/s] 83%|████████▎ | 14587/17525 [2:54:46<43:59,  1.11it/s] 83%|████████▎ | 14588/17525 [2:54:46<39:14,  1.25it/s] 83%|████████▎ | 14589/17525 [2:54:47<35:57,  1.36it/s] 83%|████████▎ | 14590/17525 [2:54:48<33:36,  1.46it/s]                                                       {'loss': 0.4283, 'grad_norm': 12.303263664245605, 'learning_rate': 1.364528226557833e-06, 'epoch': 20.81}
 83%|████████▎ | 14590/17525 [2:54:48<33:36,  1.46it/s] 83%|████████▎ | 14591/17525 [2:54:48<31:58,  1.53it/s] 83%|████████▎ | 14592/17525 [2:54:49<30:46,  1.59it/s] 83%|████████▎ | 14593/17525 [2:54:49<29:55,  1.63it/s] 83%|████████▎ | 14594/17525 [2:54:51<41:10,  1.19it/s] 83%|████████▎ | 14595/17525 [2:54:51<37:16,  1.31it/s] 83%|████████▎ | 14596/17525 [2:54:52<34:31,  1.41it/s] 83%|████████▎ | 14597/17525 [2:54:52<32:35,  1.50it/s] 83%|████████▎ | 14598/17525 [2:54:53<31:16,  1.56it/s] 83%|████████▎ | 14599/17525 [2:54:54<30:23,  1.60it/s] 83%|████████▎ | 14600/17525 [2:54:54<29:42,  1.64it/s]                                                       {'loss': 0.3435, 'grad_norm': 6.518451690673828, 'learning_rate': 1.3554921250946584e-06, 'epoch': 20.83}
 83%|████████▎ | 14600/17525 [2:54:54<29:42,  1.64it/s][INFO|trainer.py:3512] 2024-06-25 04:58:16,044 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:58:16,045 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:58:16,045 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.183892011642456, 'eval_runtime': 4.5937, 'eval_samples_per_second': 96.436, 'eval_steps_per_second': 4.136, 'epoch': 20.83}
 83%|████████▎ | 14600/17525 [2:54:59<29:42,  1.64it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 83%|████████▎ | 14601/17525 [2:54:59<1:36:31,  1.98s/it] 83%|████████▎ | 14602/17525 [2:55:00<1:15:58,  1.56s/it] 83%|████████▎ | 14603/17525 [2:55:00<1:01:34,  1.26s/it] 83%|████████▎ | 14604/17525 [2:55:01<51:26,  1.06s/it]   83%|████████▎ | 14605/17525 [2:55:02<44:23,  1.10it/s] 83%|████████▎ | 14606/17525 [2:55:02<39:29,  1.23it/s] 83%|████████▎ | 14607/17525 [2:55:03<35:59,  1.35it/s] 83%|████████▎ | 14608/17525 [2:55:03<33:31,  1.45it/s] 83%|████████▎ | 14609/17525 [2:55:04<31:52,  1.52it/s] 83%|████████▎ | 14610/17525 [2:55:05<31:06,  1.56it/s]                                                       {'loss': 0.3489, 'grad_norm': 7.786263465881348, 'learning_rate': 1.346483866608751e-06, 'epoch': 20.84}
 83%|████████▎ | 14610/17525 [2:55:05<31:06,  1.56it/s] 83%|████████▎ | 14611/17525 [2:55:05<30:12,  1.61it/s] 83%|████████▎ | 14612/17525 [2:55:06<29:33,  1.64it/s] 83%|████████▎ | 14613/17525 [2:55:06<29:08,  1.67it/s] 83%|████████▎ | 14614/17525 [2:55:07<28:49,  1.68it/s] 83%|████████▎ | 14615/17525 [2:55:08<35:30,  1.37it/s] 83%|████████▎ | 14616/17525 [2:55:08<33:13,  1.46it/s] 83%|████████▎ | 14617/17525 [2:55:09<31:39,  1.53it/s] 83%|████████▎ | 14618/17525 [2:55:10<30:32,  1.59it/s] 83%|████████▎ | 14619/17525 [2:55:10<29:45,  1.63it/s] 83%|████████▎ | 14620/17525 [2:55:11<29:12,  1.66it/s]                                                       {'loss': 0.3813, 'grad_norm': 18.480188369750977, 'learning_rate': 1.337503480114697e-06, 'epoch': 20.86}
 83%|████████▎ | 14620/17525 [2:55:11<29:12,  1.66it/s] 83%|████████▎ | 14621/17525 [2:55:11<28:57,  1.67it/s] 83%|████████▎ | 14622/17525 [2:55:12<28:36,  1.69it/s] 83%|████████▎ | 14623/17525 [2:55:13<28:23,  1.70it/s] 83%|████████▎ | 14624/17525 [2:55:13<28:16,  1.71it/s] 83%|████████▎ | 14625/17525 [2:55:14<28:08,  1.72it/s] 83%|████████▎ | 14626/17525 [2:55:14<28:01,  1.72it/s] 83%|████████▎ | 14627/17525 [2:55:15<27:56,  1.73it/s] 83%|████████▎ | 14628/17525 [2:55:15<27:56,  1.73it/s] 83%|████████▎ | 14629/17525 [2:55:16<27:54,  1.73it/s] 83%|████████▎ | 14630/17525 [2:55:17<27:49,  1.73it/s]                                                       {'loss': 0.3465, 'grad_norm': 8.536497116088867, 'learning_rate': 1.328550994537292e-06, 'epoch': 20.87}
 83%|████████▎ | 14630/17525 [2:55:17<27:49,  1.73it/s] 83%|████████▎ | 14631/17525 [2:55:17<27:57,  1.72it/s] 83%|████████▎ | 14632/17525 [2:55:18<28:07,  1.71it/s] 83%|████████▎ | 14633/17525 [2:55:18<27:58,  1.72it/s] 84%|████████▎ | 14634/17525 [2:55:19<27:52,  1.73it/s] 84%|████████▎ | 14635/17525 [2:55:20<30:02,  1.60it/s] 84%|████████▎ | 14636/17525 [2:55:20<29:21,  1.64it/s] 84%|████████▎ | 14637/17525 [2:55:21<28:51,  1.67it/s] 84%|████████▎ | 14638/17525 [2:55:21<28:30,  1.69it/s] 84%|████████▎ | 14639/17525 [2:55:22<28:16,  1.70it/s] 84%|████████▎ | 14640/17525 [2:55:22<28:03,  1.71it/s]                                                       {'loss': 0.3052, 'grad_norm': 16.582992553710938, 'learning_rate': 1.3196264387114831e-06, 'epoch': 20.88}
 84%|████████▎ | 14640/17525 [2:55:22<28:03,  1.71it/s] 84%|████████▎ | 14641/17525 [2:55:23<27:58,  1.72it/s] 84%|████████▎ | 14642/17525 [2:55:24<27:55,  1.72it/s] 84%|████████▎ | 14643/17525 [2:55:24<27:53,  1.72it/s] 84%|████████▎ | 14644/17525 [2:55:25<27:47,  1.73it/s] 84%|████████▎ | 14645/17525 [2:55:25<27:45,  1.73it/s] 84%|████████▎ | 14646/17525 [2:55:26<27:46,  1.73it/s] 84%|████████▎ | 14647/17525 [2:55:27<27:43,  1.73it/s] 84%|████████▎ | 14648/17525 [2:55:27<27:39,  1.73it/s] 84%|████████▎ | 14649/17525 [2:55:28<27:41,  1.73it/s] 84%|████████▎ | 14650/17525 [2:55:28<27:39,  1.73it/s]                                                       {'loss': 0.3773, 'grad_norm': 7.179162979125977, 'learning_rate': 1.3107298413822432e-06, 'epoch': 20.9}
 84%|████████▎ | 14650/17525 [2:55:28<27:39,  1.73it/s] 84%|████████▎ | 14651/17525 [2:55:29<27:37,  1.73it/s] 84%|████████▎ | 14652/17525 [2:55:29<27:41,  1.73it/s] 84%|████████▎ | 14653/17525 [2:55:30<27:45,  1.72it/s] 84%|████████▎ | 14654/17525 [2:55:31<27:46,  1.72it/s] 84%|████████▎ | 14655/17525 [2:55:31<27:43,  1.72it/s] 84%|████████▎ | 14656/17525 [2:55:32<27:39,  1.73it/s] 84%|████████▎ | 14657/17525 [2:55:32<27:38,  1.73it/s] 84%|████████▎ | 14658/17525 [2:55:33<27:36,  1.73it/s] 84%|████████▎ | 14659/17525 [2:55:33<27:36,  1.73it/s] 84%|████████▎ | 14660/17525 [2:55:34<27:34,  1.73it/s]                                                       {'loss': 0.4631, 'grad_norm': 13.720818519592285, 'learning_rate': 1.3018612312045043e-06, 'epoch': 20.91}
 84%|████████▎ | 14660/17525 [2:55:34<27:34,  1.73it/s] 84%|████████▎ | 14661/17525 [2:55:35<27:35,  1.73it/s] 84%|████████▎ | 14662/17525 [2:55:35<27:34,  1.73it/s] 84%|████████▎ | 14663/17525 [2:55:36<27:34,  1.73it/s] 84%|████████▎ | 14664/17525 [2:55:36<27:46,  1.72it/s] 84%|████████▎ | 14665/17525 [2:55:37<27:40,  1.72it/s] 84%|████████▎ | 14666/17525 [2:55:38<32:30,  1.47it/s] 84%|████████▎ | 14667/17525 [2:55:38<30:57,  1.54it/s] 84%|████████▎ | 14668/17525 [2:55:39<29:54,  1.59it/s] 84%|████████▎ | 14669/17525 [2:55:40<29:08,  1.63it/s] 84%|████████▎ | 14670/17525 [2:55:40<28:35,  1.66it/s]                                                       {'loss': 0.3815, 'grad_norm': 10.863384246826172, 'learning_rate': 1.293020636743052e-06, 'epoch': 20.93}
 84%|████████▎ | 14670/17525 [2:55:40<28:35,  1.66it/s] 84%|████████▎ | 14671/17525 [2:55:41<28:17,  1.68it/s] 84%|████████▎ | 14672/17525 [2:55:41<27:59,  1.70it/s] 84%|████████▎ | 14673/17525 [2:55:42<27:47,  1.71it/s] 84%|████████▎ | 14674/17525 [2:55:42<27:39,  1.72it/s] 84%|████████▎ | 14675/17525 [2:55:43<27:49,  1.71it/s] 84%|████████▎ | 14676/17525 [2:55:44<27:42,  1.71it/s] 84%|████████▎ | 14677/17525 [2:55:44<27:37,  1.72it/s] 84%|████████▍ | 14678/17525 [2:55:45<27:31,  1.72it/s] 84%|████████▍ | 14679/17525 [2:55:45<27:26,  1.73it/s] 84%|████████▍ | 14680/17525 [2:55:46<27:23,  1.73it/s]                                                       {'loss': 0.3338, 'grad_norm': 10.83187484741211, 'learning_rate': 1.2842080864724316e-06, 'epoch': 20.94}
 84%|████████▍ | 14680/17525 [2:55:46<27:23,  1.73it/s] 84%|████████▍ | 14681/17525 [2:55:47<27:21,  1.73it/s] 84%|████████▍ | 14682/17525 [2:55:47<27:18,  1.74it/s] 84%|████████▍ | 14683/17525 [2:55:48<27:17,  1.74it/s] 84%|████████▍ | 14684/17525 [2:55:48<27:22,  1.73it/s] 84%|████████▍ | 14685/17525 [2:55:49<27:30,  1.72it/s] 84%|████████▍ | 14686/17525 [2:55:49<27:37,  1.71it/s] 84%|████████▍ | 14687/17525 [2:55:50<29:34,  1.60it/s] 84%|████████▍ | 14688/17525 [2:55:51<29:01,  1.63it/s] 84%|████████▍ | 14689/17525 [2:55:52<43:11,  1.09it/s] 84%|████████▍ | 14690/17525 [2:55:53<38:25,  1.23it/s]                                                       {'loss': 0.3861, 'grad_norm': 11.375626564025879, 'learning_rate': 1.2754236087768723e-06, 'epoch': 20.96}
 84%|████████▍ | 14690/17525 [2:55:53<38:25,  1.23it/s] 84%|████████▍ | 14691/17525 [2:55:54<35:40,  1.32it/s] 84%|████████▍ | 14692/17525 [2:55:54<33:05,  1.43it/s] 84%|████████▍ | 14693/17525 [2:55:55<31:16,  1.51it/s] 84%|████████▍ | 14694/17525 [2:55:55<30:01,  1.57it/s] 84%|████████▍ | 14695/17525 [2:55:56<29:09,  1.62it/s] 84%|████████▍ | 14696/17525 [2:55:57<31:20,  1.50it/s] 84%|████████▍ | 14697/17525 [2:55:57<30:32,  1.54it/s] 84%|████████▍ | 14698/17525 [2:55:58<29:28,  1.60it/s] 84%|████████▍ | 14699/17525 [2:55:58<28:45,  1.64it/s] 84%|████████▍ | 14700/17525 [2:55:59<28:15,  1.67it/s]                                                       {'loss': 0.338, 'grad_norm': 11.269353866577148, 'learning_rate': 1.2666672319501737e-06, 'epoch': 20.97}
 84%|████████▍ | 14700/17525 [2:55:59<28:15,  1.67it/s][INFO|trainer.py:3512] 2024-06-25 04:59:20,876 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 04:59:20,876 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 04:59:20,876 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.13it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1714606285095215, 'eval_runtime': 4.5982, 'eval_samples_per_second': 96.343, 'eval_steps_per_second': 4.132, 'epoch': 20.97}
 84%|████████▍ | 14700/17525 [2:56:04<28:15,  1.67it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 04:59:25,478 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14700
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bdd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 8aaac41d-1e1d-4004-987a-9ec6162de241)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 04:59:35,533 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 04:59:35,536 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14700/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 84%|████████▍ | 14701/17525 [2:56:14<3:56:57,  5.03s/it] 84%|████████▍ | 14702/17525 [2:56:15<2:54:00,  3.70s/it] 84%|████████▍ | 14703/17525 [2:56:16<2:12:26,  2.82s/it] 84%|████████▍ | 14704/17525 [2:56:16<1:40:55,  2.15s/it] 84%|████████▍ | 14705/17525 [2:56:17<1:18:44,  1.68s/it] 84%|████████▍ | 14706/17525 [2:56:17<1:03:12,  1.35s/it] 84%|████████▍ | 14707/17525 [2:56:18<52:21,  1.11s/it]   84%|████████▍ | 14708/17525 [2:56:19<44:44,  1.05it/s] 84%|████████▍ | 14709/17525 [2:56:19<39:22,  1.19it/s] 84%|████████▍ | 14710/17525 [2:56:20<35:37,  1.32it/s]                                                       {'loss': 0.3014, 'grad_norm': 7.93023681640625, 'learning_rate': 1.2579389841956324e-06, 'epoch': 20.98}
 84%|████████▍ | 14710/17525 [2:56:20<35:37,  1.32it/s] 84%|████████▍ | 14711/17525 [2:56:20<33:03,  1.42it/s] 84%|████████▍ | 14712/17525 [2:56:21<31:14,  1.50it/s] 84%|████████▍ | 14713/17525 [2:56:21<29:55,  1.57it/s] 84%|████████▍ | 14714/17525 [2:56:22<28:59,  1.62it/s] 84%|████████▍ | 14715/17525 [2:56:23<28:18,  1.65it/s] 84%|████████▍ | 14716/17525 [2:56:23<27:53,  1.68it/s] 84%|████████▍ | 14717/17525 [2:56:24<27:34,  1.70it/s] 84%|████████▍ | 14718/17525 [2:56:24<27:25,  1.71it/s] 84%|████████▍ | 14719/17525 [2:56:25<27:14,  1.72it/s] 84%|████████▍ | 14720/17525 [2:56:25<27:07,  1.72it/s]                                                       {'loss': 0.3777, 'grad_norm': 6.533530235290527, 'learning_rate': 1.2492388936259415e-06, 'epoch': 21.0}
 84%|████████▍ | 14720/17525 [2:56:25<27:07,  1.72it/s] 84%|████████▍ | 14721/17525 [2:56:26<27:02,  1.73it/s] 84%|████████▍ | 14722/17525 [2:56:27<26:59,  1.73it/s] 84%|████████▍ | 14723/17525 [2:56:27<26:58,  1.73it/s] 84%|████████▍ | 14724/17525 [2:56:28<26:58,  1.73it/s] 84%|████████▍ | 14725/17525 [2:56:28<27:10,  1.72it/s] 84%|████████▍ | 14726/17525 [2:56:29<26:59,  1.73it/s] 84%|████████▍ | 14727/17525 [2:56:30<31:32,  1.48it/s] 84%|████████▍ | 14728/17525 [2:56:30<30:03,  1.55it/s] 84%|████████▍ | 14729/17525 [2:56:31<29:05,  1.60it/s] 84%|████████▍ | 14730/17525 [2:56:32<28:22,  1.64it/s]                                                       {'loss': 0.3695, 'grad_norm': 6.989031791687012, 'learning_rate': 1.2405669882631045e-06, 'epoch': 21.01}
 84%|████████▍ | 14730/17525 [2:56:32<28:22,  1.64it/s] 84%|████████▍ | 14731/17525 [2:56:33<34:19,  1.36it/s] 84%|████████▍ | 14732/17525 [2:56:33<32:03,  1.45it/s] 84%|████████▍ | 14733/17525 [2:56:34<30:26,  1.53it/s] 84%|████████▍ | 14734/17525 [2:56:35<35:52,  1.30it/s] 84%|████████▍ | 14735/17525 [2:56:35<33:20,  1.39it/s] 84%|████████▍ | 14736/17525 [2:56:36<31:28,  1.48it/s] 84%|████████▍ | 14737/17525 [2:56:37<30:17,  1.53it/s] 84%|████████▍ | 14738/17525 [2:56:37<29:16,  1.59it/s] 84%|████████▍ | 14739/17525 [2:56:38<28:31,  1.63it/s] 84%|████████▍ | 14740/17525 [2:56:38<27:56,  1.66it/s]                                                       {'loss': 0.3293, 'grad_norm': 5.477147102355957, 'learning_rate': 1.231923296038342e-06, 'epoch': 21.03}
 84%|████████▍ | 14740/17525 [2:56:38<27:56,  1.66it/s] 84%|████████▍ | 14741/17525 [2:56:39<27:35,  1.68it/s] 84%|████████▍ | 14742/17525 [2:56:39<27:19,  1.70it/s] 84%|████████▍ | 14743/17525 [2:56:40<27:06,  1.71it/s] 84%|████████▍ | 14744/17525 [2:56:41<26:55,  1.72it/s] 84%|████████▍ | 14745/17525 [2:56:41<26:47,  1.73it/s] 84%|████████▍ | 14746/17525 [2:56:42<26:44,  1.73it/s] 84%|████████▍ | 14747/17525 [2:56:42<26:41,  1.74it/s] 84%|████████▍ | 14748/17525 [2:56:43<27:04,  1.71it/s] 84%|████████▍ | 14749/17525 [2:56:44<26:52,  1.72it/s] 84%|████████▍ | 14750/17525 [2:56:44<26:45,  1.73it/s]                                                       {'loss': 0.3118, 'grad_norm': 11.484833717346191, 'learning_rate': 1.2233078447920055e-06, 'epoch': 21.04}
 84%|████████▍ | 14750/17525 [2:56:44<26:45,  1.73it/s] 84%|████████▍ | 14751/17525 [2:56:45<26:44,  1.73it/s] 84%|████████▍ | 14752/17525 [2:56:45<27:00,  1.71it/s] 84%|████████▍ | 14753/17525 [2:56:46<26:53,  1.72it/s] 84%|████████▍ | 14754/17525 [2:56:46<26:45,  1.73it/s] 84%|████████▍ | 14755/17525 [2:56:47<26:41,  1.73it/s] 84%|████████▍ | 14756/17525 [2:56:48<26:39,  1.73it/s] 84%|████████▍ | 14757/17525 [2:56:48<26:39,  1.73it/s] 84%|████████▍ | 14758/17525 [2:56:49<26:37,  1.73it/s] 84%|████████▍ | 14759/17525 [2:56:49<26:32,  1.74it/s] 84%|████████▍ | 14760/17525 [2:56:50<26:31,  1.74it/s]                                                       {'loss': 0.3338, 'grad_norm': 9.426265716552734, 'learning_rate': 1.214720662273483e-06, 'epoch': 21.06}
 84%|████████▍ | 14760/17525 [2:56:50<26:31,  1.74it/s] 84%|████████▍ | 14761/17525 [2:56:50<26:33,  1.73it/s] 84%|████████▍ | 14762/17525 [2:56:51<26:29,  1.74it/s] 84%|████████▍ | 14763/17525 [2:56:52<26:29,  1.74it/s] 84%|████████▍ | 14764/17525 [2:56:52<26:31,  1.74it/s] 84%|████████▍ | 14765/17525 [2:56:53<27:00,  1.70it/s] 84%|████████▍ | 14766/17525 [2:56:53<26:47,  1.72it/s] 84%|████████▍ | 14767/17525 [2:56:54<27:01,  1.70it/s] 84%|████████▍ | 14768/17525 [2:56:55<26:51,  1.71it/s] 84%|████████▍ | 14769/17525 [2:56:55<26:42,  1.72it/s] 84%|████████▍ | 14770/17525 [2:56:56<26:39,  1.72it/s]                                                       {'loss': 0.3033, 'grad_norm': 8.553755760192871, 'learning_rate': 1.2061617761411125e-06, 'epoch': 21.07}
 84%|████████▍ | 14770/17525 [2:56:56<26:39,  1.72it/s] 84%|████████▍ | 14771/17525 [2:56:56<26:37,  1.72it/s] 84%|████████▍ | 14772/17525 [2:56:57<26:29,  1.73it/s] 84%|████████▍ | 14773/17525 [2:56:57<26:29,  1.73it/s] 84%|████████▍ | 14774/17525 [2:56:58<26:25,  1.73it/s] 84%|████████▍ | 14775/17525 [2:56:59<26:26,  1.73it/s] 84%|████████▍ | 14776/17525 [2:56:59<26:23,  1.74it/s] 84%|████████▍ | 14777/17525 [2:57:00<26:26,  1.73it/s] 84%|████████▍ | 14778/17525 [2:57:00<26:22,  1.74it/s] 84%|████████▍ | 14779/17525 [2:57:01<26:21,  1.74it/s] 84%|████████▍ | 14780/17525 [2:57:01<26:20,  1.74it/s]                                                       {'loss': 0.2989, 'grad_norm': 9.148070335388184, 'learning_rate': 1.197631213962095e-06, 'epoch': 21.08}
 84%|████████▍ | 14780/17525 [2:57:01<26:20,  1.74it/s] 84%|████████▍ | 14781/17525 [2:57:02<26:21,  1.73it/s] 84%|████████▍ | 14782/17525 [2:57:03<26:19,  1.74it/s] 84%|████████▍ | 14783/17525 [2:57:03<26:18,  1.74it/s] 84%|████████▍ | 14784/17525 [2:57:04<26:17,  1.74it/s] 84%|████████▍ | 14785/17525 [2:57:04<26:36,  1.72it/s] 84%|████████▍ | 14786/17525 [2:57:05<26:26,  1.73it/s] 84%|████████▍ | 14787/17525 [2:57:05<26:22,  1.73it/s] 84%|████████▍ | 14788/17525 [2:57:06<26:17,  1.74it/s] 84%|████████▍ | 14789/17525 [2:57:07<26:14,  1.74it/s] 84%|████████▍ | 14790/17525 [2:57:07<26:10,  1.74it/s]                                                       {'loss': 0.3946, 'grad_norm': 5.389263153076172, 'learning_rate': 1.1891290032124003e-06, 'epoch': 21.1}
 84%|████████▍ | 14790/17525 [2:57:07<26:10,  1.74it/s] 84%|████████▍ | 14791/17525 [2:57:08<26:11,  1.74it/s] 84%|████████▍ | 14792/17525 [2:57:08<26:10,  1.74it/s] 84%|████████▍ | 14793/17525 [2:57:09<26:09,  1.74it/s] 84%|████████▍ | 14794/17525 [2:57:09<26:08,  1.74it/s] 84%|████████▍ | 14795/17525 [2:57:10<26:03,  1.75it/s] 84%|████████▍ | 14796/17525 [2:57:11<26:00,  1.75it/s] 84%|████████▍ | 14797/17525 [2:57:11<26:01,  1.75it/s] 84%|████████▍ | 14798/17525 [2:57:12<26:02,  1.75it/s] 84%|████████▍ | 14799/17525 [2:57:12<25:59,  1.75it/s] 84%|████████▍ | 14800/17525 [2:57:13<26:00,  1.75it/s]                                                       {'loss': 0.2868, 'grad_norm': 5.594916820526123, 'learning_rate': 1.1806551712766855e-06, 'epoch': 21.11}
 84%|████████▍ | 14800/17525 [2:57:13<26:00,  1.75it/s][INFO|trainer.py:3512] 2024-06-25 05:00:34,822 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:00:34,822 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:00:34,822 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1978291273117065, 'eval_runtime': 4.6003, 'eval_samples_per_second': 96.299, 'eval_steps_per_second': 4.13, 'epoch': 21.11}
 84%|████████▍ | 14800/17525 [2:57:18<26:00,  1.75it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 84%|████████▍ | 14801/17525 [2:57:18<1:28:53,  1.96s/it] 84%|████████▍ | 14802/17525 [2:57:19<1:10:04,  1.54s/it] 84%|████████▍ | 14803/17525 [2:57:19<58:44,  1.29s/it]   84%|████████▍ | 14804/17525 [2:57:20<48:52,  1.08s/it] 84%|████████▍ | 14805/17525 [2:57:21<42:02,  1.08it/s] 84%|████████▍ | 14806/17525 [2:57:21<37:13,  1.22it/s] 84%|████████▍ | 14807/17525 [2:57:22<33:49,  1.34it/s] 84%|████████▍ | 14808/17525 [2:57:22<31:27,  1.44it/s] 85%|████████▍ | 14809/17525 [2:57:23<29:46,  1.52it/s] 85%|████████▍ | 14810/17525 [2:57:23<28:37,  1.58it/s]                                                       {'loss': 0.3794, 'grad_norm': 15.749210357666016, 'learning_rate': 1.172209745448195e-06, 'epoch': 21.13}
 85%|████████▍ | 14810/17525 [2:57:23<28:37,  1.58it/s] 85%|████████▍ | 14811/17525 [2:57:24<27:51,  1.62it/s] 85%|████████▍ | 14812/17525 [2:57:25<27:16,  1.66it/s] 85%|████████▍ | 14813/17525 [2:57:25<26:52,  1.68it/s] 85%|████████▍ | 14814/17525 [2:57:26<26:34,  1.70it/s] 85%|████████▍ | 14815/17525 [2:57:26<26:23,  1.71it/s] 85%|████████▍ | 14816/17525 [2:57:27<26:14,  1.72it/s] 85%|████████▍ | 14817/17525 [2:57:27<26:10,  1.72it/s] 85%|████████▍ | 14818/17525 [2:57:28<26:02,  1.73it/s] 85%|████████▍ | 14819/17525 [2:57:29<26:00,  1.73it/s] 85%|████████▍ | 14820/17525 [2:57:29<25:58,  1.74it/s]                                                       {'loss': 0.4105, 'grad_norm': 8.889115333557129, 'learning_rate': 1.163792752928692e-06, 'epoch': 21.14}
 85%|████████▍ | 14820/17525 [2:57:29<25:58,  1.74it/s] 85%|████████▍ | 14821/17525 [2:57:30<25:59,  1.73it/s] 85%|████████▍ | 14822/17525 [2:57:30<25:56,  1.74it/s] 85%|████████▍ | 14823/17525 [2:57:31<25:57,  1.74it/s] 85%|████████▍ | 14824/17525 [2:57:32<28:17,  1.59it/s] 85%|████████▍ | 14825/17525 [2:57:32<27:33,  1.63it/s] 85%|████████▍ | 14826/17525 [2:57:33<27:02,  1.66it/s] 85%|████████▍ | 14827/17525 [2:57:33<26:40,  1.69it/s] 85%|████████▍ | 14828/17525 [2:57:34<26:25,  1.70it/s] 85%|████████▍ | 14829/17525 [2:57:35<26:15,  1.71it/s] 85%|████████▍ | 14830/17525 [2:57:35<26:05,  1.72it/s]                                                       {'loss': 0.341, 'grad_norm': 7.194930553436279, 'learning_rate': 1.1554042208283455e-06, 'epoch': 21.16}
 85%|████████▍ | 14830/17525 [2:57:35<26:05,  1.72it/s] 85%|████████▍ | 14831/17525 [2:57:36<26:00,  1.73it/s] 85%|████████▍ | 14832/17525 [2:57:36<25:56,  1.73it/s] 85%|████████▍ | 14833/17525 [2:57:37<25:52,  1.73it/s] 85%|████████▍ | 14834/17525 [2:57:38<36:38,  1.22it/s] 85%|████████▍ | 14835/17525 [2:57:39<33:24,  1.34it/s] 85%|████████▍ | 14836/17525 [2:57:39<31:05,  1.44it/s] 85%|████████▍ | 14837/17525 [2:57:40<29:31,  1.52it/s] 85%|████████▍ | 14838/17525 [2:57:41<28:37,  1.56it/s] 85%|████████▍ | 14839/17525 [2:57:41<27:45,  1.61it/s] 85%|████████▍ | 14840/17525 [2:57:42<27:09,  1.65it/s]                                                       {'loss': 0.3367, 'grad_norm': 7.624589920043945, 'learning_rate': 1.1470441761656715e-06, 'epoch': 21.17}
 85%|████████▍ | 14840/17525 [2:57:42<27:09,  1.65it/s] 85%|████████▍ | 14841/17525 [2:57:42<26:44,  1.67it/s] 85%|████████▍ | 14842/17525 [2:57:43<26:26,  1.69it/s] 85%|████████▍ | 14843/17525 [2:57:43<26:14,  1.70it/s] 85%|████████▍ | 14844/17525 [2:57:44<26:04,  1.71it/s] 85%|████████▍ | 14845/17525 [2:57:45<25:55,  1.72it/s] 85%|████████▍ | 14846/17525 [2:57:45<25:51,  1.73it/s] 85%|████████▍ | 14847/17525 [2:57:46<25:46,  1.73it/s] 85%|████████▍ | 14848/17525 [2:57:46<25:44,  1.73it/s] 85%|████████▍ | 14849/17525 [2:57:47<25:41,  1.74it/s] 85%|████████▍ | 14850/17525 [2:57:47<25:40,  1.74it/s]                                                       {'loss': 0.3611, 'grad_norm': 5.0961833000183105, 'learning_rate': 1.138712645867418e-06, 'epoch': 21.18}
 85%|████████▍ | 14850/17525 [2:57:47<25:40,  1.74it/s][INFO|trainer.py:3203] 2024-06-25 05:01:09,321 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14850
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7b7d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f070a595-e50c-48fb-a129-2a67ba608f03)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:01:19,379 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14850/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:01:19,381 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-14850/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 85%|████████▍ | 14851/17525 [2:57:58<2:42:12,  3.64s/it] 85%|████████▍ | 14852/17525 [2:57:59<2:01:12,  2.72s/it] 85%|████████▍ | 14853/17525 [2:57:59<1:32:29,  2.08s/it] 85%|████████▍ | 14854/17525 [2:58:00<1:12:24,  1.63s/it] 85%|████████▍ | 14855/17525 [2:58:01<58:21,  1.31s/it]   85%|████████▍ | 14856/17525 [2:58:01<48:33,  1.09s/it] 85%|████████▍ | 14857/17525 [2:58:02<41:36,  1.07it/s] 85%|████████▍ | 14858/17525 [2:58:02<36:47,  1.21it/s] 85%|████████▍ | 14859/17525 [2:58:03<33:25,  1.33it/s] 85%|████████▍ | 14860/17525 [2:58:04<41:36,  1.07it/s]                                                       {'loss': 0.3695, 'grad_norm': 10.772811889648438, 'learning_rate': 1.1304096567684985e-06, 'epoch': 21.2}
 85%|████████▍ | 14860/17525 [2:58:04<41:36,  1.07it/s] 85%|████████▍ | 14861/17525 [2:58:05<36:53,  1.20it/s] 85%|████████▍ | 14862/17525 [2:58:05<33:30,  1.32it/s] 85%|████████▍ | 14863/17525 [2:58:06<31:05,  1.43it/s] 85%|████████▍ | 14864/17525 [2:58:06<29:24,  1.51it/s] 85%|████████▍ | 14865/17525 [2:58:07<28:14,  1.57it/s] 85%|████████▍ | 14866/17525 [2:58:08<27:25,  1.62it/s] 85%|████████▍ | 14867/17525 [2:58:08<26:50,  1.65it/s] 85%|████████▍ | 14868/17525 [2:58:09<26:24,  1.68it/s] 85%|████████▍ | 14869/17525 [2:58:09<26:10,  1.69it/s] 85%|████████▍ | 14870/17525 [2:58:10<26:14,  1.69it/s]                                                       {'loss': 0.36, 'grad_norm': 9.883440971374512, 'learning_rate': 1.1221352356118975e-06, 'epoch': 21.21}
 85%|████████▍ | 14870/17525 [2:58:10<26:14,  1.69it/s] 85%|████████▍ | 14871/17525 [2:58:11<26:09,  1.69it/s] 85%|████████▍ | 14872/17525 [2:58:11<25:53,  1.71it/s] 85%|████████▍ | 14873/17525 [2:58:12<25:45,  1.72it/s] 85%|████████▍ | 14874/17525 [2:58:12<25:39,  1.72it/s] 85%|████████▍ | 14875/17525 [2:58:13<25:35,  1.73it/s] 85%|████████▍ | 14876/17525 [2:58:13<25:29,  1.73it/s] 85%|████████▍ | 14877/17525 [2:58:14<25:26,  1.74it/s] 85%|████████▍ | 14878/17525 [2:58:15<25:27,  1.73it/s] 85%|████████▍ | 14879/17525 [2:58:15<25:23,  1.74it/s] 85%|████████▍ | 14880/17525 [2:58:16<25:38,  1.72it/s]                                                       {'loss': 0.3555, 'grad_norm': 8.616554260253906, 'learning_rate': 1.1138894090485863e-06, 'epoch': 21.23}
 85%|████████▍ | 14880/17525 [2:58:16<25:38,  1.72it/s] 85%|████████▍ | 14881/17525 [2:58:16<25:31,  1.73it/s] 85%|████████▍ | 14882/17525 [2:58:17<25:25,  1.73it/s] 85%|████████▍ | 14883/17525 [2:58:18<25:51,  1.70it/s] 85%|████████▍ | 14884/17525 [2:58:18<25:39,  1.72it/s] 85%|████████▍ | 14885/17525 [2:58:19<25:34,  1.72it/s] 85%|████████▍ | 14886/17525 [2:58:19<25:28,  1.73it/s] 85%|████████▍ | 14887/17525 [2:58:20<25:24,  1.73it/s] 85%|████████▍ | 14888/17525 [2:58:20<25:41,  1.71it/s] 85%|████████▍ | 14889/17525 [2:58:21<25:35,  1.72it/s] 85%|████████▍ | 14890/17525 [2:58:22<25:31,  1.72it/s]                                                       {'loss': 0.4533, 'grad_norm': 10.29157543182373, 'learning_rate': 1.1056722036374322e-06, 'epoch': 21.24}
 85%|████████▍ | 14890/17525 [2:58:22<25:31,  1.72it/s] 85%|████████▍ | 14891/17525 [2:58:22<25:30,  1.72it/s] 85%|████████▍ | 14892/17525 [2:58:23<25:27,  1.72it/s] 85%|████████▍ | 14893/17525 [2:58:23<25:37,  1.71it/s] 85%|████████▍ | 14894/17525 [2:58:24<25:31,  1.72it/s] 85%|████████▍ | 14895/17525 [2:58:24<25:28,  1.72it/s] 85%|████████▍ | 14896/17525 [2:58:25<25:22,  1.73it/s] 85%|████████▌ | 14897/17525 [2:58:26<25:17,  1.73it/s] 85%|████████▌ | 14898/17525 [2:58:26<25:12,  1.74it/s] 85%|████████▌ | 14899/17525 [2:58:27<25:12,  1.74it/s] 85%|████████▌ | 14900/17525 [2:58:27<25:11,  1.74it/s]                                                       {'loss': 0.3314, 'grad_norm': 9.677377700805664, 'learning_rate': 1.0974836458451222e-06, 'epoch': 21.26}
 85%|████████▌ | 14900/17525 [2:58:27<25:11,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:01:49,246 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:01:49,246 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:01:49,246 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.189368486404419, 'eval_runtime': 4.5967, 'eval_samples_per_second': 96.373, 'eval_steps_per_second': 4.133, 'epoch': 21.26}
 85%|████████▌ | 14900/17525 [2:58:32<25:11,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 85%|████████▌ | 14901/17525 [2:58:33<1:25:37,  1.96s/it] 85%|████████▌ | 14902/17525 [2:58:33<1:07:26,  1.54s/it] 85%|████████▌ | 14903/17525 [2:58:34<54:51,  1.26s/it]   85%|████████▌ | 14904/17525 [2:58:35<51:34,  1.18s/it] 85%|████████▌ | 14905/17525 [2:58:35<43:41,  1.00s/it] 85%|████████▌ | 14906/17525 [2:58:36<38:07,  1.14it/s] 85%|████████▌ | 14907/17525 [2:58:36<34:11,  1.28it/s] 85%|████████▌ | 14908/17525 [2:58:37<31:26,  1.39it/s] 85%|████████▌ | 14909/17525 [2:58:38<29:31,  1.48it/s] 85%|████████▌ | 14910/17525 [2:58:38<28:13,  1.54it/s]                                                       {'loss': 0.3719, 'grad_norm': 11.505353927612305, 'learning_rate': 1.0893237620460683e-06, 'epoch': 21.27}
 85%|████████▌ | 14910/17525 [2:58:38<28:13,  1.54it/s] 85%|████████▌ | 14911/17525 [2:58:39<27:18,  1.60it/s] 85%|████████▌ | 14912/17525 [2:58:39<26:35,  1.64it/s] 85%|████████▌ | 14913/17525 [2:58:40<26:08,  1.67it/s] 85%|████████▌ | 14914/17525 [2:58:40<25:51,  1.68it/s] 85%|████████▌ | 14915/17525 [2:58:41<25:35,  1.70it/s] 85%|████████▌ | 14916/17525 [2:58:42<25:26,  1.71it/s] 85%|████████▌ | 14917/17525 [2:58:42<25:22,  1.71it/s] 85%|████████▌ | 14918/17525 [2:58:43<25:18,  1.72it/s] 85%|████████▌ | 14919/17525 [2:58:43<25:09,  1.73it/s] 85%|████████▌ | 14920/17525 [2:58:44<25:20,  1.71it/s]                                                       {'loss': 0.4012, 'grad_norm': 11.509947776794434, 'learning_rate': 1.0811925785223297e-06, 'epoch': 21.28}
 85%|████████▌ | 14920/17525 [2:58:44<25:20,  1.71it/s] 85%|████████▌ | 14921/17525 [2:58:45<25:27,  1.71it/s] 85%|████████▌ | 14922/17525 [2:58:45<25:17,  1.72it/s] 85%|████████▌ | 14923/17525 [2:58:46<25:07,  1.73it/s] 85%|████████▌ | 14924/17525 [2:58:46<25:02,  1.73it/s] 85%|████████▌ | 14925/17525 [2:58:47<24:57,  1.74it/s] 85%|████████▌ | 14926/17525 [2:58:47<24:55,  1.74it/s] 85%|████████▌ | 14927/17525 [2:58:48<24:55,  1.74it/s] 85%|████████▌ | 14928/17525 [2:58:49<24:57,  1.73it/s] 85%|████████▌ | 14929/17525 [2:58:49<24:55,  1.74it/s] 85%|████████▌ | 14930/17525 [2:58:50<25:13,  1.71it/s]                                                       {'loss': 0.3527, 'grad_norm': 8.229467391967773, 'learning_rate': 1.0730901214635259e-06, 'epoch': 21.3}
 85%|████████▌ | 14930/17525 [2:58:50<25:13,  1.71it/s] 85%|████████▌ | 14931/17525 [2:58:50<25:07,  1.72it/s] 85%|████████▌ | 14932/17525 [2:58:51<25:02,  1.73it/s] 85%|████████▌ | 14933/17525 [2:58:51<24:58,  1.73it/s] 85%|████████▌ | 14934/17525 [2:58:52<24:56,  1.73it/s] 85%|████████▌ | 14935/17525 [2:58:53<24:53,  1.73it/s] 85%|████████▌ | 14936/17525 [2:58:53<24:52,  1.74it/s] 85%|████████▌ | 14937/17525 [2:58:54<24:51,  1.73it/s] 85%|████████▌ | 14938/17525 [2:58:54<24:57,  1.73it/s] 85%|████████▌ | 14939/17525 [2:58:55<25:09,  1.71it/s] 85%|████████▌ | 14940/17525 [2:58:56<25:05,  1.72it/s]                                                       {'loss': 0.2659, 'grad_norm': 7.724128246307373, 'learning_rate': 1.0650164169667443e-06, 'epoch': 21.31}
 85%|████████▌ | 14940/17525 [2:58:56<25:05,  1.72it/s] 85%|████████▌ | 14941/17525 [2:58:56<25:03,  1.72it/s] 85%|████████▌ | 14942/17525 [2:58:57<24:57,  1.72it/s] 85%|████████▌ | 14943/17525 [2:58:57<24:52,  1.73it/s] 85%|████████▌ | 14944/17525 [2:58:58<24:50,  1.73it/s] 85%|████████▌ | 14945/17525 [2:58:58<24:50,  1.73it/s] 85%|████████▌ | 14946/17525 [2:58:59<24:48,  1.73it/s] 85%|████████▌ | 14947/17525 [2:59:00<24:48,  1.73it/s] 85%|████████▌ | 14948/17525 [2:59:00<24:47,  1.73it/s] 85%|████████▌ | 14949/17525 [2:59:01<24:49,  1.73it/s] 85%|████████▌ | 14950/17525 [2:59:01<24:49,  1.73it/s]                                                       {'loss': 0.3694, 'grad_norm': 6.717220783233643, 'learning_rate': 1.0569714910364781e-06, 'epoch': 21.33}
 85%|████████▌ | 14950/17525 [2:59:01<24:49,  1.73it/s] 85%|████████▌ | 14951/17525 [2:59:02<24:52,  1.72it/s] 85%|████████▌ | 14952/17525 [2:59:02<25:10,  1.70it/s] 85%|████████▌ | 14953/17525 [2:59:03<24:59,  1.72it/s] 85%|████████▌ | 14954/17525 [2:59:04<24:50,  1.72it/s] 85%|████████▌ | 14955/17525 [2:59:04<24:47,  1.73it/s] 85%|████████▌ | 14956/17525 [2:59:05<24:45,  1.73it/s] 85%|████████▌ | 14957/17525 [2:59:05<25:01,  1.71it/s] 85%|████████▌ | 14958/17525 [2:59:06<24:54,  1.72it/s] 85%|████████▌ | 14959/17525 [2:59:07<25:04,  1.71it/s] 85%|████████▌ | 14960/17525 [2:59:07<24:56,  1.71it/s]                                                       {'loss': 0.3288, 'grad_norm': 9.765990257263184, 'learning_rate': 1.0489553695845112e-06, 'epoch': 21.34}
 85%|████████▌ | 14960/17525 [2:59:07<24:56,  1.71it/s] 85%|████████▌ | 14961/17525 [2:59:08<24:51,  1.72it/s] 85%|████████▌ | 14962/17525 [2:59:08<24:45,  1.72it/s] 85%|████████▌ | 14963/17525 [2:59:09<24:41,  1.73it/s] 85%|████████▌ | 14964/17525 [2:59:09<24:37,  1.73it/s] 85%|████████▌ | 14965/17525 [2:59:10<24:36,  1.73it/s] 85%|████████▌ | 14966/17525 [2:59:11<24:51,  1.72it/s] 85%|████████▌ | 14967/17525 [2:59:12<30:12,  1.41it/s] 85%|████████▌ | 14968/17525 [2:59:12<28:32,  1.49it/s] 85%|████████▌ | 14969/17525 [2:59:13<27:22,  1.56it/s] 85%|████████▌ | 14970/17525 [2:59:13<26:32,  1.60it/s]                                                       {'loss': 0.2916, 'grad_norm': 20.290908813476562, 'learning_rate': 1.040968078429866e-06, 'epoch': 21.36}
 85%|████████▌ | 14970/17525 [2:59:13<26:32,  1.60it/s] 85%|████████▌ | 14971/17525 [2:59:14<25:57,  1.64it/s] 85%|████████▌ | 14972/17525 [2:59:15<29:59,  1.42it/s] 85%|████████▌ | 14973/17525 [2:59:15<28:24,  1.50it/s] 85%|████████▌ | 14974/17525 [2:59:16<27:13,  1.56it/s] 85%|████████▌ | 14975/17525 [2:59:17<26:25,  1.61it/s] 85%|████████▌ | 14976/17525 [2:59:17<25:48,  1.65it/s] 85%|████████▌ | 14977/17525 [2:59:18<25:22,  1.67it/s] 85%|████████▌ | 14978/17525 [2:59:18<25:04,  1.69it/s] 85%|████████▌ | 14979/17525 [2:59:19<30:20,  1.40it/s] 85%|████████▌ | 14980/17525 [2:59:20<28:34,  1.48it/s]                                                       {'loss': 0.4309, 'grad_norm': 8.403877258300781, 'learning_rate': 1.0330096432986948e-06, 'epoch': 21.37}
 85%|████████▌ | 14980/17525 [2:59:20<28:34,  1.48it/s] 85%|████████▌ | 14981/17525 [2:59:21<31:56,  1.33it/s] 85%|████████▌ | 14982/17525 [2:59:21<29:43,  1.43it/s] 85%|████████▌ | 14983/17525 [2:59:22<28:17,  1.50it/s] 86%|████████▌ | 14984/17525 [2:59:23<27:05,  1.56it/s] 86%|████████▌ | 14985/17525 [2:59:23<26:14,  1.61it/s] 86%|████████▌ | 14986/17525 [2:59:24<25:40,  1.65it/s] 86%|████████▌ | 14987/17525 [2:59:24<25:15,  1.67it/s] 86%|████████▌ | 14988/17525 [2:59:25<24:57,  1.69it/s] 86%|████████▌ | 14989/17525 [2:59:25<24:47,  1.70it/s] 86%|████████▌ | 14990/17525 [2:59:26<24:43,  1.71it/s]                                                       {'loss': 0.2965, 'grad_norm': 6.030170917510986, 'learning_rate': 1.0250800898242141e-06, 'epoch': 21.38}
 86%|████████▌ | 14990/17525 [2:59:26<24:43,  1.71it/s] 86%|████████▌ | 14991/17525 [2:59:27<29:13,  1.45it/s] 86%|████████▌ | 14992/17525 [2:59:28<27:48,  1.52it/s] 86%|████████▌ | 14993/17525 [2:59:28<26:44,  1.58it/s] 86%|████████▌ | 14994/17525 [2:59:29<26:00,  1.62it/s] 86%|████████▌ | 14995/17525 [2:59:29<25:32,  1.65it/s] 86%|████████▌ | 14996/17525 [2:59:30<25:11,  1.67it/s] 86%|████████▌ | 14997/17525 [2:59:30<24:53,  1.69it/s] 86%|████████▌ | 14998/17525 [2:59:31<24:44,  1.70it/s] 86%|████████▌ | 14999/17525 [2:59:32<24:33,  1.71it/s] 86%|████████▌ | 15000/17525 [2:59:32<24:28,  1.72it/s]                                                       {'loss': 0.3651, 'grad_norm': 7.331466197967529, 'learning_rate': 1.0171794435466154e-06, 'epoch': 21.4}
 86%|████████▌ | 15000/17525 [2:59:32<24:28,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:02:54,066 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:02:54,066 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:02:54,066 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.02it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.186659812927246, 'eval_runtime': 4.6017, 'eval_samples_per_second': 96.268, 'eval_steps_per_second': 4.129, 'epoch': 21.4}
 86%|████████▌ | 15000/17525 [2:59:37<24:28,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:02:58,671 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15000
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c0af10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 3f62ddce-d5e4-49c9-a481-a3e291b6f979)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:03:08,728 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:03:08,731 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15000/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 86%|████████▌ | 15001/17525 [2:59:48<3:31:23,  5.03s/it] 86%|████████▌ | 15002/17525 [2:59:48<2:35:10,  3.69s/it] 86%|████████▌ | 15003/17525 [2:59:49<1:55:48,  2.76s/it] 86%|████████▌ | 15004/17525 [2:59:49<1:28:17,  2.10s/it] 86%|████████▌ | 15005/17525 [2:59:50<1:09:01,  1.64s/it] 86%|████████▌ | 15006/17525 [2:59:50<55:33,  1.32s/it]   86%|████████▌ | 15007/17525 [2:59:51<46:09,  1.10s/it] 86%|████████▌ | 15008/17525 [2:59:52<39:31,  1.06it/s] 86%|████████▌ | 15009/17525 [2:59:52<34:54,  1.20it/s] 86%|████████▌ | 15010/17525 [2:59:53<33:55,  1.24it/s]                                                       {'loss': 0.3497, 'grad_norm': 9.36786937713623, 'learning_rate': 1.0093077299129806e-06, 'epoch': 21.41}
 86%|████████▌ | 15010/17525 [2:59:53<33:55,  1.24it/s] 86%|████████▌ | 15011/17525 [2:59:54<31:01,  1.35it/s] 86%|████████▌ | 15012/17525 [2:59:54<28:57,  1.45it/s] 86%|████████▌ | 15013/17525 [2:59:55<27:27,  1.52it/s] 86%|████████▌ | 15014/17525 [2:59:55<26:26,  1.58it/s] 86%|████████▌ | 15015/17525 [2:59:56<25:42,  1.63it/s] 86%|████████▌ | 15016/17525 [2:59:56<25:13,  1.66it/s] 86%|████████▌ | 15017/17525 [2:59:57<24:53,  1.68it/s] 86%|████████▌ | 15018/17525 [2:59:58<24:38,  1.70it/s] 86%|████████▌ | 15019/17525 [2:59:58<24:26,  1.71it/s] 86%|████████▌ | 15020/17525 [2:59:59<24:17,  1.72it/s]                                                       {'loss': 0.2988, 'grad_norm': 8.531266212463379, 'learning_rate': 1.0014649742772075e-06, 'epoch': 21.43}
 86%|████████▌ | 15020/17525 [2:59:59<24:17,  1.72it/s] 86%|████████▌ | 15021/17525 [2:59:59<24:15,  1.72it/s] 86%|████████▌ | 15022/17525 [3:00:00<24:09,  1.73it/s] 86%|████████▌ | 15023/17525 [3:00:00<24:04,  1.73it/s] 86%|████████▌ | 15024/17525 [3:00:01<24:00,  1.74it/s] 86%|████████▌ | 15025/17525 [3:00:02<23:55,  1.74it/s] 86%|████████▌ | 15026/17525 [3:00:02<23:58,  1.74it/s] 86%|████████▌ | 15027/17525 [3:00:03<23:57,  1.74it/s] 86%|████████▌ | 15028/17525 [3:00:03<23:55,  1.74it/s] 86%|████████▌ | 15029/17525 [3:00:04<23:57,  1.74it/s] 86%|████████▌ | 15030/17525 [3:00:04<23:56,  1.74it/s]                                                       {'loss': 0.4463, 'grad_norm': 7.515811920166016, 'learning_rate': 9.936512018999166e-07, 'epoch': 21.44}
 86%|████████▌ | 15030/17525 [3:00:04<23:56,  1.74it/s] 86%|████████▌ | 15031/17525 [3:00:05<23:58,  1.73it/s] 86%|████████▌ | 15032/17525 [3:00:06<24:04,  1.73it/s] 86%|████████▌ | 15033/17525 [3:00:06<24:08,  1.72it/s] 86%|████████▌ | 15034/17525 [3:00:07<24:05,  1.72it/s] 86%|████████▌ | 15035/17525 [3:00:07<24:05,  1.72it/s] 86%|████████▌ | 15036/17525 [3:00:08<24:02,  1.73it/s] 86%|████████▌ | 15037/17525 [3:00:08<24:01,  1.73it/s] 86%|████████▌ | 15038/17525 [3:00:09<23:59,  1.73it/s] 86%|████████▌ | 15039/17525 [3:00:10<23:55,  1.73it/s] 86%|████████▌ | 15040/17525 [3:00:10<23:52,  1.73it/s]                                                       {'loss': 0.2978, 'grad_norm': 7.3387980461120605, 'learning_rate': 9.858664379483818e-07, 'epoch': 21.46}
 86%|████████▌ | 15040/17525 [3:00:10<23:52,  1.73it/s] 86%|████████▌ | 15041/17525 [3:00:11<23:53,  1.73it/s] 86%|████████▌ | 15042/17525 [3:00:11<23:53,  1.73it/s] 86%|████████▌ | 15043/17525 [3:00:12<28:12,  1.47it/s] 86%|████████▌ | 15044/17525 [3:00:13<26:56,  1.53it/s] 86%|████████▌ | 15045/17525 [3:00:13<25:59,  1.59it/s] 86%|████████▌ | 15046/17525 [3:00:14<25:19,  1.63it/s] 86%|████████▌ | 15047/17525 [3:00:15<24:51,  1.66it/s] 86%|████████▌ | 15048/17525 [3:00:15<24:34,  1.68it/s] 86%|████████▌ | 15049/17525 [3:00:16<24:20,  1.70it/s] 86%|████████▌ | 15050/17525 [3:00:16<24:10,  1.71it/s]                                                       {'loss': 0.3092, 'grad_norm': 8.250752449035645, 'learning_rate': 9.781107074964447e-07, 'epoch': 21.47}
 86%|████████▌ | 15050/17525 [3:00:16<24:10,  1.71it/s] 86%|████████▌ | 15051/17525 [3:00:17<24:07,  1.71it/s] 86%|████████▌ | 15052/17525 [3:00:18<24:00,  1.72it/s] 86%|████████▌ | 15053/17525 [3:00:18<23:53,  1.72it/s] 86%|████████▌ | 15054/17525 [3:00:19<23:50,  1.73it/s] 86%|████████▌ | 15055/17525 [3:00:19<23:50,  1.73it/s] 86%|████████▌ | 15056/17525 [3:00:20<23:48,  1.73it/s] 86%|████████▌ | 15057/17525 [3:00:20<23:48,  1.73it/s] 86%|████████▌ | 15058/17525 [3:00:21<23:46,  1.73it/s] 86%|████████▌ | 15059/17525 [3:00:22<24:03,  1.71it/s] 86%|████████▌ | 15060/17525 [3:00:22<23:58,  1.71it/s]                                                       {'loss': 0.3539, 'grad_norm': 5.493757724761963, 'learning_rate': 9.703840355244287e-07, 'epoch': 21.48}
 86%|████████▌ | 15060/17525 [3:00:22<23:58,  1.71it/s] 86%|████████▌ | 15061/17525 [3:00:23<23:53,  1.72it/s] 86%|████████▌ | 15062/17525 [3:00:23<25:44,  1.59it/s] 86%|████████▌ | 15063/17525 [3:00:24<25:08,  1.63it/s] 86%|████████▌ | 15064/17525 [3:00:25<24:41,  1.66it/s] 86%|████████▌ | 15065/17525 [3:00:25<24:21,  1.68it/s] 86%|████████▌ | 15066/17525 [3:00:26<24:13,  1.69it/s] 86%|████████▌ | 15067/17525 [3:00:26<24:03,  1.70it/s] 86%|████████▌ | 15068/17525 [3:00:27<23:54,  1.71it/s] 86%|████████▌ | 15069/17525 [3:00:28<23:50,  1.72it/s] 86%|████████▌ | 15070/17525 [3:00:28<23:45,  1.72it/s]                                                       {'loss': 0.4039, 'grad_norm': 9.879440307617188, 'learning_rate': 9.62686446919069e-07, 'epoch': 21.5}
 86%|████████▌ | 15070/17525 [3:00:28<23:45,  1.72it/s] 86%|████████▌ | 15071/17525 [3:00:29<23:59,  1.70it/s] 86%|████████▌ | 15072/17525 [3:00:29<23:52,  1.71it/s] 86%|████████▌ | 15073/17525 [3:00:30<23:48,  1.72it/s] 86%|████████▌ | 15074/17525 [3:00:30<23:42,  1.72it/s] 86%|████████▌ | 15075/17525 [3:00:31<23:40,  1.72it/s] 86%|████████▌ | 15076/17525 [3:00:32<23:37,  1.73it/s] 86%|████████▌ | 15077/17525 [3:00:32<23:36,  1.73it/s] 86%|████████▌ | 15078/17525 [3:00:33<23:35,  1.73it/s] 86%|████████▌ | 15079/17525 [3:00:33<23:35,  1.73it/s] 86%|████████▌ | 15080/17525 [3:00:34<23:56,  1.70it/s]                                                       {'loss': 0.3359, 'grad_norm': 14.68562126159668, 'learning_rate': 9.550179664734227e-07, 'epoch': 21.51}
 86%|████████▌ | 15080/17525 [3:00:34<23:56,  1.70it/s] 86%|████████▌ | 15081/17525 [3:00:35<24:14,  1.68it/s] 86%|████████▌ | 15082/17525 [3:00:35<24:02,  1.69it/s] 86%|████████▌ | 15083/17525 [3:00:36<23:50,  1.71it/s] 86%|████████▌ | 15084/17525 [3:00:36<23:45,  1.71it/s] 86%|████████▌ | 15085/17525 [3:00:37<23:39,  1.72it/s] 86%|████████▌ | 15086/17525 [3:00:37<23:36,  1.72it/s] 86%|████████▌ | 15087/17525 [3:00:38<23:31,  1.73it/s] 86%|████████▌ | 15088/17525 [3:00:39<23:29,  1.73it/s] 86%|████████▌ | 15089/17525 [3:00:39<23:28,  1.73it/s] 86%|████████▌ | 15090/17525 [3:00:40<23:26,  1.73it/s]                                                       {'loss': 0.3002, 'grad_norm': 3.9083871841430664, 'learning_rate': 9.473786188867906e-07, 'epoch': 21.53}
 86%|████████▌ | 15090/17525 [3:00:40<23:26,  1.73it/s] 86%|████████▌ | 15091/17525 [3:00:40<23:27,  1.73it/s] 86%|████████▌ | 15092/17525 [3:00:41<23:24,  1.73it/s] 86%|████████▌ | 15093/17525 [3:00:41<23:22,  1.73it/s] 86%|████████▌ | 15094/17525 [3:00:42<23:21,  1.73it/s] 86%|████████▌ | 15095/17525 [3:00:43<23:24,  1.73it/s] 86%|████████▌ | 15096/17525 [3:00:43<23:20,  1.73it/s] 86%|████████▌ | 15097/17525 [3:00:44<23:21,  1.73it/s] 86%|████████▌ | 15098/17525 [3:00:44<23:22,  1.73it/s] 86%|████████▌ | 15099/17525 [3:00:45<23:22,  1.73it/s] 86%|████████▌ | 15100/17525 [3:00:46<23:22,  1.73it/s]                                                       {'loss': 0.3187, 'grad_norm': 7.068571090698242, 'learning_rate': 9.39768428764648e-07, 'epoch': 21.54}
 86%|████████▌ | 15100/17525 [3:00:46<23:22,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 05:04:07,404 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:04:07,404 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:04:07,404 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1854920387268066, 'eval_runtime': 4.5969, 'eval_samples_per_second': 96.369, 'eval_steps_per_second': 4.133, 'epoch': 21.54}
 86%|████████▌ | 15100/17525 [3:00:50<23:22,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 86%|████████▌ | 15101/17525 [3:00:51<1:19:10,  1.96s/it] 86%|████████▌ | 15102/17525 [3:00:52<1:11:56,  1.78s/it] 86%|████████▌ | 15103/17525 [3:00:53<57:23,  1.42s/it]   86%|████████▌ | 15104/17525 [3:00:53<47:12,  1.17s/it] 86%|████████▌ | 15105/17525 [3:00:54<40:01,  1.01it/s] 86%|████████▌ | 15106/17525 [3:00:54<34:59,  1.15it/s] 86%|████████▌ | 15107/17525 [3:00:55<31:26,  1.28it/s] 86%|████████▌ | 15108/17525 [3:00:56<28:56,  1.39it/s] 86%|████████▌ | 15109/17525 [3:00:56<27:14,  1.48it/s] 86%|████████▌ | 15110/17525 [3:00:57<26:01,  1.55it/s]                                                       {'loss': 0.2868, 'grad_norm': 9.492308616638184, 'learning_rate': 9.321874206185466e-07, 'epoch': 21.55}
 86%|████████▌ | 15110/17525 [3:00:57<26:01,  1.55it/s] 86%|████████▌ | 15111/17525 [3:00:57<25:12,  1.60it/s] 86%|████████▌ | 15112/17525 [3:00:58<24:34,  1.64it/s] 86%|████████▌ | 15113/17525 [3:00:58<24:12,  1.66it/s] 86%|████████▌ | 15114/17525 [3:00:59<23:51,  1.68it/s] 86%|████████▌ | 15115/17525 [3:01:00<23:59,  1.67it/s] 86%|████████▋ | 15116/17525 [3:01:00<23:47,  1.69it/s] 86%|████████▋ | 15117/17525 [3:01:01<23:33,  1.70it/s] 86%|████████▋ | 15118/17525 [3:01:01<23:26,  1.71it/s] 86%|████████▋ | 15119/17525 [3:01:02<23:21,  1.72it/s] 86%|████████▋ | 15120/17525 [3:01:02<23:16,  1.72it/s]                                                       {'loss': 0.3453, 'grad_norm': 24.183834075927734, 'learning_rate': 9.246356188660588e-07, 'epoch': 21.57}
 86%|████████▋ | 15120/17525 [3:01:02<23:16,  1.72it/s] 86%|████████▋ | 15121/17525 [3:01:03<23:15,  1.72it/s] 86%|████████▋ | 15122/17525 [3:01:04<23:14,  1.72it/s] 86%|████████▋ | 15123/17525 [3:01:04<23:11,  1.73it/s] 86%|████████▋ | 15124/17525 [3:01:05<27:24,  1.46it/s] 86%|████████▋ | 15125/17525 [3:01:06<26:11,  1.53it/s] 86%|████████▋ | 15126/17525 [3:01:06<25:18,  1.58it/s] 86%|████████▋ | 15127/17525 [3:01:07<24:38,  1.62it/s] 86%|████████▋ | 15128/17525 [3:01:07<24:11,  1.65it/s] 86%|████████▋ | 15129/17525 [3:01:08<24:09,  1.65it/s] 86%|████████▋ | 15130/17525 [3:01:09<23:47,  1.68it/s]                                                       {'loss': 0.3203, 'grad_norm': 4.505391597747803, 'learning_rate': 9.171130478306745e-07, 'epoch': 21.58}
 86%|████████▋ | 15130/17525 [3:01:09<23:47,  1.68it/s] 86%|████████▋ | 15131/17525 [3:01:09<23:37,  1.69it/s] 86%|████████▋ | 15132/17525 [3:01:10<23:26,  1.70it/s] 86%|████████▋ | 15133/17525 [3:01:10<23:17,  1.71it/s] 86%|████████▋ | 15134/17525 [3:01:11<23:11,  1.72it/s] 86%|████████▋ | 15135/17525 [3:01:12<23:07,  1.72it/s] 86%|████████▋ | 15136/17525 [3:01:12<23:02,  1.73it/s] 86%|████████▋ | 15137/17525 [3:01:13<23:01,  1.73it/s] 86%|████████▋ | 15138/17525 [3:01:13<24:39,  1.61it/s] 86%|████████▋ | 15139/17525 [3:01:14<24:08,  1.65it/s] 86%|████████▋ | 15140/17525 [3:01:15<27:55,  1.42it/s]                                                       {'loss': 0.2948, 'grad_norm': 8.58640193939209, 'learning_rate': 9.096197317417399e-07, 'epoch': 21.6}
 86%|████████▋ | 15140/17525 [3:01:15<27:55,  1.42it/s] 86%|████████▋ | 15141/17525 [3:01:15<26:25,  1.50it/s] 86%|████████▋ | 15142/17525 [3:01:16<25:18,  1.57it/s] 86%|████████▋ | 15143/17525 [3:01:17<24:51,  1.60it/s] 86%|████████▋ | 15144/17525 [3:01:17<24:14,  1.64it/s] 86%|████████▋ | 15145/17525 [3:01:18<23:48,  1.67it/s] 86%|████████▋ | 15146/17525 [3:01:18<23:29,  1.69it/s] 86%|████████▋ | 15147/17525 [3:01:19<23:17,  1.70it/s] 86%|████████▋ | 15148/17525 [3:01:20<23:09,  1.71it/s] 86%|████████▋ | 15149/17525 [3:01:20<23:03,  1.72it/s] 86%|████████▋ | 15150/17525 [3:01:21<23:02,  1.72it/s]                                                       {'loss': 0.3964, 'grad_norm': 26.517562866210938, 'learning_rate': 9.021556947343791e-07, 'epoch': 21.61}
 86%|████████▋ | 15150/17525 [3:01:21<23:02,  1.72it/s][INFO|trainer.py:3203] 2024-06-25 05:04:42,602 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15150
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c3af10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 3eb6a0ab-24d2-4c64-bcb4-97867f306ca4)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:04:52,666 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:04:52,669 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15150/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 86%|████████▋ | 15151/17525 [3:01:32<2:24:21,  3.65s/it] 86%|████████▋ | 15152/17525 [3:01:32<1:47:55,  2.73s/it] 86%|████████▋ | 15153/17525 [3:01:33<1:22:24,  2.08s/it] 86%|████████▋ | 15154/17525 [3:01:33<1:04:32,  1.63s/it] 86%|████████▋ | 15155/17525 [3:01:34<52:00,  1.32s/it]   86%|████████▋ | 15156/17525 [3:01:34<43:14,  1.10s/it] 86%|████████▋ | 15157/17525 [3:01:35<37:03,  1.07it/s] 86%|████████▋ | 15158/17525 [3:01:36<32:43,  1.21it/s] 86%|████████▋ | 15159/17525 [3:01:36<29:48,  1.32it/s] 87%|████████▋ | 15160/17525 [3:01:37<27:41,  1.42it/s]                                                       {'loss': 0.2848, 'grad_norm': 16.127321243286133, 'learning_rate': 8.947209608493989e-07, 'epoch': 21.63}
 87%|████████▋ | 15160/17525 [3:01:37<27:41,  1.42it/s] 87%|████████▋ | 15161/17525 [3:01:37<26:15,  1.50it/s] 87%|████████▋ | 15162/17525 [3:01:38<25:12,  1.56it/s] 87%|████████▋ | 15163/17525 [3:01:38<24:25,  1.61it/s] 87%|████████▋ | 15164/17525 [3:01:40<36:10,  1.09it/s] 87%|████████▋ | 15165/17525 [3:01:41<32:08,  1.22it/s] 87%|████████▋ | 15166/17525 [3:01:41<29:15,  1.34it/s] 87%|████████▋ | 15167/17525 [3:01:42<27:16,  1.44it/s] 87%|████████▋ | 15168/17525 [3:01:42<25:54,  1.52it/s] 87%|████████▋ | 15169/17525 [3:01:43<24:54,  1.58it/s] 87%|████████▋ | 15170/17525 [3:01:44<24:12,  1.62it/s]                                                       {'loss': 0.3462, 'grad_norm': 9.404557228088379, 'learning_rate': 8.873155540332401e-07, 'epoch': 21.64}
 87%|████████▋ | 15170/17525 [3:01:44<24:12,  1.62it/s] 87%|████████▋ | 15171/17525 [3:01:44<23:46,  1.65it/s] 87%|████████▋ | 15172/17525 [3:01:45<23:41,  1.66it/s] 87%|████████▋ | 15173/17525 [3:01:45<23:21,  1.68it/s] 87%|████████▋ | 15174/17525 [3:01:46<23:07,  1.69it/s] 87%|████████▋ | 15175/17525 [3:01:46<22:59,  1.70it/s] 87%|████████▋ | 15176/17525 [3:01:47<26:50,  1.46it/s] 87%|████████▋ | 15177/17525 [3:01:48<25:35,  1.53it/s] 87%|████████▋ | 15178/17525 [3:01:49<24:41,  1.58it/s] 87%|████████▋ | 15179/17525 [3:01:49<24:01,  1.63it/s] 87%|████████▋ | 15180/17525 [3:01:50<23:33,  1.66it/s]                                                       {'loss': 0.3321, 'grad_norm': 12.34916877746582, 'learning_rate': 8.799394981378717e-07, 'epoch': 21.65}
 87%|████████▋ | 15180/17525 [3:01:50<23:33,  1.66it/s] 87%|████████▋ | 15181/17525 [3:01:50<23:14,  1.68it/s] 87%|████████▋ | 15182/17525 [3:01:51<23:00,  1.70it/s] 87%|████████▋ | 15183/17525 [3:01:51<22:51,  1.71it/s] 87%|████████▋ | 15184/17525 [3:01:52<22:46,  1.71it/s] 87%|████████▋ | 15185/17525 [3:01:53<22:39,  1.72it/s] 87%|████████▋ | 15186/17525 [3:01:53<22:38,  1.72it/s] 87%|████████▋ | 15187/17525 [3:01:54<22:33,  1.73it/s] 87%|████████▋ | 15188/17525 [3:01:54<22:32,  1.73it/s] 87%|████████▋ | 15189/17525 [3:01:55<24:34,  1.58it/s] 87%|████████▋ | 15190/17525 [3:01:56<23:58,  1.62it/s]                                                       {'loss': 0.3002, 'grad_norm': 11.694767951965332, 'learning_rate': 8.725928169207332e-07, 'epoch': 21.67}
 87%|████████▋ | 15190/17525 [3:01:56<23:58,  1.62it/s] 87%|████████▋ | 15191/17525 [3:01:56<25:07,  1.55it/s] 87%|████████▋ | 15192/17525 [3:01:57<24:17,  1.60it/s] 87%|████████▋ | 15193/17525 [3:01:57<23:44,  1.64it/s] 87%|████████▋ | 15194/17525 [3:01:58<23:19,  1.67it/s] 87%|████████▋ | 15195/17525 [3:01:59<23:02,  1.69it/s] 87%|████████▋ | 15196/17525 [3:01:59<22:47,  1.70it/s] 87%|████████▋ | 15197/17525 [3:02:00<22:41,  1.71it/s] 87%|████████▋ | 15198/17525 [3:02:00<22:33,  1.72it/s] 87%|████████▋ | 15199/17525 [3:02:01<22:29,  1.72it/s] 87%|████████▋ | 15200/17525 [3:02:02<26:03,  1.49it/s]                                                       {'loss': 0.2802, 'grad_norm': 10.973758697509766, 'learning_rate': 8.652755340446484e-07, 'epoch': 21.68}
 87%|████████▋ | 15200/17525 [3:02:02<26:03,  1.49it/s][INFO|trainer.py:3512] 2024-06-25 05:05:23,732 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:05:23,732 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:05:23,732 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1913048028945923, 'eval_runtime': 4.5944, 'eval_samples_per_second': 96.423, 'eval_steps_per_second': 4.136, 'epoch': 21.68}
 87%|████████▋ | 15200/17525 [3:02:06<26:03,  1.49it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 87%|████████▋ | 15201/17525 [3:02:07<1:18:24,  2.02s/it] 87%|████████▋ | 15202/17525 [3:02:08<1:01:32,  1.59s/it] 87%|████████▋ | 15203/17525 [3:02:08<49:44,  1.29s/it]   87%|████████▋ | 15204/17525 [3:02:09<41:26,  1.07s/it] 87%|████████▋ | 15205/17525 [3:02:09<35:39,  1.08it/s] 87%|████████▋ | 15206/17525 [3:02:10<31:34,  1.22it/s] 87%|████████▋ | 15207/17525 [3:02:10<28:45,  1.34it/s] 87%|████████▋ | 15208/17525 [3:02:11<26:45,  1.44it/s] 87%|████████▋ | 15209/17525 [3:02:12<25:20,  1.52it/s] 87%|████████▋ | 15210/17525 [3:02:12<24:23,  1.58it/s]                                                       {'loss': 0.3228, 'grad_norm': 5.720457553863525, 'learning_rate': 8.579876730777559e-07, 'epoch': 21.7}
 87%|████████▋ | 15210/17525 [3:02:12<24:23,  1.58it/s] 87%|████████▋ | 15211/17525 [3:02:13<23:45,  1.62it/s] 87%|████████▋ | 15212/17525 [3:02:13<23:16,  1.66it/s] 87%|████████▋ | 15213/17525 [3:02:14<22:53,  1.68it/s] 87%|████████▋ | 15214/17525 [3:02:14<22:39,  1.70it/s] 87%|████████▋ | 15215/17525 [3:02:15<22:28,  1.71it/s] 87%|████████▋ | 15216/17525 [3:02:16<22:23,  1.72it/s] 87%|████████▋ | 15217/17525 [3:02:16<22:19,  1.72it/s] 87%|████████▋ | 15218/17525 [3:02:17<22:14,  1.73it/s] 87%|████████▋ | 15219/17525 [3:02:17<22:11,  1.73it/s] 87%|████████▋ | 15220/17525 [3:02:18<22:08,  1.74it/s]                                                       {'loss': 0.3515, 'grad_norm': 10.462164878845215, 'learning_rate': 8.507292574934223e-07, 'epoch': 21.71}
 87%|████████▋ | 15220/17525 [3:02:18<22:08,  1.74it/s] 87%|████████▋ | 15221/17525 [3:02:19<22:11,  1.73it/s] 87%|████████▋ | 15222/17525 [3:02:19<22:11,  1.73it/s] 87%|████████▋ | 15223/17525 [3:02:20<22:10,  1.73it/s] 87%|████████▋ | 15224/17525 [3:02:20<22:10,  1.73it/s] 87%|████████▋ | 15225/17525 [3:02:22<34:21,  1.12it/s] 87%|████████▋ | 15226/17525 [3:02:22<30:41,  1.25it/s] 87%|████████▋ | 15227/17525 [3:02:23<32:09,  1.19it/s] 87%|████████▋ | 15228/17525 [3:02:24<29:11,  1.31it/s] 87%|████████▋ | 15229/17525 [3:02:25<32:32,  1.18it/s] 87%|████████▋ | 15230/17525 [3:02:26<29:21,  1.30it/s]                                                       {'loss': 0.3554, 'grad_norm': 8.042037963867188, 'learning_rate': 8.435003106701867e-07, 'epoch': 21.73}
 87%|████████▋ | 15230/17525 [3:02:26<29:21,  1.30it/s] 87%|████████▋ | 15231/17525 [3:02:26<27:11,  1.41it/s] 87%|████████▋ | 15232/17525 [3:02:27<25:40,  1.49it/s] 87%|████████▋ | 15233/17525 [3:02:27<24:34,  1.55it/s] 87%|████████▋ | 15234/17525 [3:02:28<23:48,  1.60it/s] 87%|████████▋ | 15235/17525 [3:02:28<23:16,  1.64it/s] 87%|████████▋ | 15236/17525 [3:02:29<22:55,  1.66it/s] 87%|████████▋ | 15237/17525 [3:02:30<22:38,  1.68it/s] 87%|████████▋ | 15238/17525 [3:02:30<22:25,  1.70it/s] 87%|████████▋ | 15239/17525 [3:02:31<22:17,  1.71it/s] 87%|████████▋ | 15240/17525 [3:02:32<23:51,  1.60it/s]                                                       {'loss': 0.4027, 'grad_norm': 8.0097074508667, 'learning_rate': 8.363008558916575e-07, 'epoch': 21.74}
 87%|████████▋ | 15240/17525 [3:02:32<23:51,  1.60it/s] 87%|████████▋ | 15241/17525 [3:02:32<23:21,  1.63it/s] 87%|████████▋ | 15242/17525 [3:02:33<22:57,  1.66it/s] 87%|████████▋ | 15243/17525 [3:02:33<22:36,  1.68it/s] 87%|████████▋ | 15244/17525 [3:02:34<22:22,  1.70it/s] 87%|████████▋ | 15245/17525 [3:02:34<22:16,  1.71it/s] 87%|████████▋ | 15246/17525 [3:02:35<22:13,  1.71it/s] 87%|████████▋ | 15247/17525 [3:02:36<22:09,  1.71it/s] 87%|████████▋ | 15248/17525 [3:02:36<22:05,  1.72it/s] 87%|████████▋ | 15249/17525 [3:02:37<22:02,  1.72it/s] 87%|████████▋ | 15250/17525 [3:02:37<21:56,  1.73it/s]                                                       {'loss': 0.35, 'grad_norm': 13.332722663879395, 'learning_rate': 8.291309163464678e-07, 'epoch': 21.75}
 87%|████████▋ | 15250/17525 [3:02:37<21:56,  1.73it/s] 87%|████████▋ | 15251/17525 [3:02:38<21:55,  1.73it/s] 87%|████████▋ | 15252/17525 [3:02:38<21:55,  1.73it/s] 87%|████████▋ | 15253/17525 [3:02:39<21:50,  1.73it/s] 87%|████████▋ | 15254/17525 [3:02:40<25:58,  1.46it/s] 87%|████████▋ | 15255/17525 [3:02:41<24:41,  1.53it/s] 87%|████████▋ | 15256/17525 [3:02:41<23:47,  1.59it/s] 87%|████████▋ | 15257/17525 [3:02:42<23:09,  1.63it/s] 87%|████████▋ | 15258/17525 [3:02:42<22:43,  1.66it/s] 87%|████████▋ | 15259/17525 [3:02:43<22:26,  1.68it/s] 87%|████████▋ | 15260/17525 [3:02:43<22:12,  1.70it/s]                                                       {'loss': 0.3527, 'grad_norm': 14.312726974487305, 'learning_rate': 8.219905151281726e-07, 'epoch': 21.77}
 87%|████████▋ | 15260/17525 [3:02:43<22:12,  1.70it/s] 87%|████████▋ | 15261/17525 [3:02:44<22:05,  1.71it/s] 87%|████████▋ | 15262/17525 [3:02:45<21:58,  1.72it/s] 87%|████████▋ | 15263/17525 [3:02:45<21:52,  1.72it/s] 87%|████████▋ | 15264/17525 [3:02:46<21:48,  1.73it/s] 87%|████████▋ | 15265/17525 [3:02:46<21:45,  1.73it/s] 87%|████████▋ | 15266/17525 [3:02:47<21:42,  1.73it/s] 87%|████████▋ | 15267/17525 [3:02:47<21:41,  1.74it/s] 87%|████████▋ | 15268/17525 [3:02:48<21:37,  1.74it/s] 87%|████████▋ | 15269/17525 [3:02:49<25:39,  1.47it/s] 87%|████████▋ | 15270/17525 [3:02:50<24:24,  1.54it/s]                                                       {'loss': 0.3296, 'grad_norm': 10.830965995788574, 'learning_rate': 8.148796752351939e-07, 'epoch': 21.78}
 87%|████████▋ | 15270/17525 [3:02:50<24:24,  1.54it/s] 87%|████████▋ | 15271/17525 [3:02:50<23:34,  1.59it/s] 87%|████████▋ | 15272/17525 [3:02:51<22:57,  1.64it/s] 87%|████████▋ | 15273/17525 [3:02:51<22:34,  1.66it/s] 87%|████████▋ | 15274/17525 [3:02:52<22:17,  1.68it/s] 87%|████████▋ | 15275/17525 [3:02:52<22:06,  1.70it/s] 87%|████████▋ | 15276/17525 [3:02:53<21:56,  1.71it/s] 87%|████████▋ | 15277/17525 [3:02:54<30:36,  1.22it/s] 87%|████████▋ | 15278/17525 [3:02:55<27:55,  1.34it/s] 87%|████████▋ | 15279/17525 [3:02:56<26:03,  1.44it/s] 87%|████████▋ | 15280/17525 [3:02:56<24:42,  1.51it/s]                                                       {'loss': 0.3277, 'grad_norm': 7.803630352020264, 'learning_rate': 8.0779841957074e-07, 'epoch': 21.8}
 87%|████████▋ | 15280/17525 [3:02:56<24:42,  1.51it/s] 87%|████████▋ | 15281/17525 [3:02:57<23:48,  1.57it/s] 87%|████████▋ | 15282/17525 [3:02:57<23:05,  1.62it/s] 87%|████████▋ | 15283/17525 [3:02:58<22:53,  1.63it/s] 87%|████████▋ | 15284/17525 [3:02:58<22:48,  1.64it/s] 87%|████████▋ | 15285/17525 [3:02:59<22:24,  1.67it/s] 87%|████████▋ | 15286/17525 [3:03:00<22:10,  1.68it/s] 87%|████████▋ | 15287/17525 [3:03:00<21:57,  1.70it/s] 87%|████████▋ | 15288/17525 [3:03:01<21:48,  1.71it/s] 87%|████████▋ | 15289/17525 [3:03:01<21:43,  1.72it/s] 87%|████████▋ | 15290/17525 [3:03:02<21:37,  1.72it/s]                                                       {'loss': 0.311, 'grad_norm': 6.148188591003418, 'learning_rate': 8.007467709427263e-07, 'epoch': 21.81}
 87%|████████▋ | 15290/17525 [3:03:02<21:37,  1.72it/s] 87%|████████▋ | 15291/17525 [3:03:02<21:37,  1.72it/s] 87%|████████▋ | 15292/17525 [3:03:03<21:32,  1.73it/s] 87%|████████▋ | 15293/17525 [3:03:04<21:29,  1.73it/s] 87%|████████▋ | 15294/17525 [3:03:04<21:30,  1.73it/s] 87%|████████▋ | 15295/17525 [3:03:05<21:28,  1.73it/s] 87%|████████▋ | 15296/17525 [3:03:05<21:28,  1.73it/s] 87%|████████▋ | 15297/17525 [3:03:06<21:27,  1.73it/s] 87%|████████▋ | 15298/17525 [3:03:07<21:25,  1.73it/s] 87%|████████▋ | 15299/17525 [3:03:07<21:22,  1.74it/s] 87%|████████▋ | 15300/17525 [3:03:08<21:23,  1.73it/s]                                                       {'loss': 0.3679, 'grad_norm': 10.753777503967285, 'learning_rate': 7.937247520637192e-07, 'epoch': 21.83}
 87%|████████▋ | 15300/17525 [3:03:08<21:23,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 05:06:29,585 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:06:29,586 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:06:29,586 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1952348947525024, 'eval_runtime': 4.6005, 'eval_samples_per_second': 96.294, 'eval_steps_per_second': 4.13, 'epoch': 21.83}
 87%|████████▋ | 15300/17525 [3:03:12<21:23,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:06:34,189 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15300
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c7cad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2a3aa23f-4195-42b5-a7e9-3ddac42065f9)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:06:44,246 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:06:44,248 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15300/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 87%|████████▋ | 15301/17525 [3:03:23<3:06:03,  5.02s/it] 87%|████████▋ | 15302/17525 [3:03:24<2:16:36,  3.69s/it] 87%|████████▋ | 15303/17525 [3:03:24<1:44:07,  2.81s/it] 87%|████████▋ | 15304/17525 [3:03:25<1:19:13,  2.14s/it] 87%|████████▋ | 15305/17525 [3:03:26<1:01:49,  1.67s/it] 87%|████████▋ | 15306/17525 [3:03:26<49:38,  1.34s/it]   87%|████████▋ | 15307/17525 [3:03:27<41:08,  1.11s/it] 87%|████████▋ | 15308/17525 [3:03:27<35:13,  1.05it/s] 87%|████████▋ | 15309/17525 [3:03:28<32:51,  1.12it/s] 87%|████████▋ | 15310/17525 [3:03:29<29:23,  1.26it/s]                                                       {'loss': 0.3522, 'grad_norm': 10.217952728271484, 'learning_rate': 7.867323855508358e-07, 'epoch': 21.84}
 87%|████████▋ | 15310/17525 [3:03:29<29:23,  1.26it/s] 87%|████████▋ | 15311/17525 [3:03:29<27:00,  1.37it/s] 87%|████████▋ | 15312/17525 [3:03:30<25:17,  1.46it/s] 87%|████████▋ | 15313/17525 [3:03:31<31:08,  1.18it/s] 87%|████████▋ | 15314/17525 [3:03:32<28:10,  1.31it/s] 87%|████████▋ | 15315/17525 [3:03:32<26:06,  1.41it/s] 87%|████████▋ | 15316/17525 [3:03:33<24:37,  1.49it/s] 87%|████████▋ | 15317/17525 [3:03:33<23:33,  1.56it/s] 87%|████████▋ | 15318/17525 [3:03:34<22:49,  1.61it/s] 87%|████████▋ | 15319/17525 [3:03:34<22:18,  1.65it/s] 87%|████████▋ | 15320/17525 [3:03:35<21:58,  1.67it/s]                                                       {'loss': 0.3968, 'grad_norm': 4.660646915435791, 'learning_rate': 7.79769693925696e-07, 'epoch': 21.85}
 87%|████████▋ | 15320/17525 [3:03:35<21:58,  1.67it/s] 87%|████████▋ | 15321/17525 [3:03:36<21:43,  1.69it/s] 87%|████████▋ | 15322/17525 [3:03:36<21:33,  1.70it/s] 87%|████████▋ | 15323/17525 [3:03:37<21:25,  1.71it/s] 87%|████████▋ | 15324/17525 [3:03:37<21:19,  1.72it/s] 87%|████████▋ | 15325/17525 [3:03:38<21:13,  1.73it/s] 87%|████████▋ | 15326/17525 [3:03:38<21:09,  1.73it/s] 87%|████████▋ | 15327/17525 [3:03:39<21:07,  1.73it/s] 87%|████████▋ | 15328/17525 [3:03:40<21:05,  1.74it/s] 87%|████████▋ | 15329/17525 [3:03:40<21:04,  1.74it/s] 87%|████████▋ | 15330/17525 [3:03:41<21:02,  1.74it/s]                                                       {'loss': 0.4566, 'grad_norm': 7.6466383934021, 'learning_rate': 7.728366996143399e-07, 'epoch': 21.87}
 87%|████████▋ | 15330/17525 [3:03:41<21:02,  1.74it/s] 87%|████████▋ | 15331/17525 [3:03:41<21:02,  1.74it/s] 87%|████████▋ | 15332/17525 [3:03:42<21:01,  1.74it/s] 87%|████████▋ | 15333/17525 [3:03:43<21:00,  1.74it/s] 87%|████████▋ | 15334/17525 [3:03:43<24:53,  1.47it/s] 88%|████████▊ | 15335/17525 [3:03:44<23:43,  1.54it/s] 88%|████████▊ | 15336/17525 [3:03:45<22:55,  1.59it/s] 88%|████████▊ | 15337/17525 [3:03:45<22:21,  1.63it/s] 88%|████████▊ | 15338/17525 [3:03:46<25:46,  1.41it/s] 88%|████████▊ | 15339/17525 [3:03:47<25:51,  1.41it/s] 88%|████████▊ | 15340/17525 [3:03:47<24:21,  1.50it/s]                                                       {'loss': 0.4243, 'grad_norm': 15.92473316192627, 'learning_rate': 7.659334249471528e-07, 'epoch': 21.88}
 88%|████████▊ | 15340/17525 [3:03:47<24:21,  1.50it/s] 88%|████████▊ | 15341/17525 [3:03:48<23:20,  1.56it/s] 88%|████████▊ | 15342/17525 [3:03:49<22:37,  1.61it/s] 88%|████████▊ | 15343/17525 [3:03:49<23:31,  1.55it/s] 88%|████████▊ | 15344/17525 [3:03:50<22:43,  1.60it/s] 88%|████████▊ | 15345/17525 [3:03:50<22:09,  1.64it/s] 88%|████████▊ | 15346/17525 [3:03:52<28:23,  1.28it/s] 88%|████████▊ | 15347/17525 [3:03:52<26:07,  1.39it/s] 88%|████████▊ | 15348/17525 [3:03:53<24:34,  1.48it/s] 88%|████████▊ | 15349/17525 [3:03:53<23:27,  1.55it/s] 88%|████████▊ | 15350/17525 [3:03:54<22:41,  1.60it/s]                                                       {'loss': 0.334, 'grad_norm': 20.299428939819336, 'learning_rate': 7.590598921587988e-07, 'epoch': 21.9}
 88%|████████▊ | 15350/17525 [3:03:54<22:41,  1.60it/s] 88%|████████▊ | 15351/17525 [3:03:55<24:17,  1.49it/s] 88%|████████▊ | 15352/17525 [3:03:55<23:14,  1.56it/s] 88%|████████▊ | 15353/17525 [3:03:56<22:30,  1.61it/s] 88%|████████▊ | 15354/17525 [3:03:56<22:02,  1.64it/s] 88%|████████▊ | 15355/17525 [3:03:57<21:39,  1.67it/s] 88%|████████▊ | 15356/17525 [3:03:58<21:22,  1.69it/s] 88%|████████▊ | 15357/17525 [3:03:58<21:10,  1.71it/s] 88%|████████▊ | 15358/17525 [3:03:59<21:03,  1.71it/s] 88%|████████▊ | 15359/17525 [3:03:59<20:57,  1.72it/s] 88%|████████▊ | 15360/17525 [3:04:00<20:53,  1.73it/s]                                                       {'loss': 0.3498, 'grad_norm': 8.755730628967285, 'learning_rate': 7.522161233881453e-07, 'epoch': 21.91}
 88%|████████▊ | 15360/17525 [3:04:00<20:53,  1.73it/s] 88%|████████▊ | 15361/17525 [3:04:00<20:51,  1.73it/s] 88%|████████▊ | 15362/17525 [3:04:01<20:47,  1.73it/s] 88%|████████▊ | 15363/17525 [3:04:02<20:42,  1.74it/s] 88%|████████▊ | 15364/17525 [3:04:02<20:40,  1.74it/s] 88%|████████▊ | 15365/17525 [3:04:03<20:37,  1.75it/s] 88%|████████▊ | 15366/17525 [3:04:03<20:38,  1.74it/s] 88%|████████▊ | 15367/17525 [3:04:04<20:38,  1.74it/s] 88%|████████▊ | 15368/17525 [3:04:04<20:38,  1.74it/s] 88%|████████▊ | 15369/17525 [3:04:05<20:39,  1.74it/s] 88%|████████▊ | 15370/17525 [3:04:06<20:41,  1.74it/s]                                                       {'loss': 0.3057, 'grad_norm': 7.175840854644775, 'learning_rate': 7.454021406781908e-07, 'epoch': 21.93}
 88%|████████▊ | 15370/17525 [3:04:06<20:41,  1.74it/s] 88%|████████▊ | 15371/17525 [3:04:06<20:43,  1.73it/s] 88%|████████▊ | 15372/17525 [3:04:07<20:39,  1.74it/s] 88%|████████▊ | 15373/17525 [3:04:07<20:40,  1.73it/s] 88%|████████▊ | 15374/17525 [3:04:08<20:45,  1.73it/s] 88%|████████▊ | 15375/17525 [3:04:08<20:44,  1.73it/s] 88%|████████▊ | 15376/17525 [3:04:09<20:42,  1.73it/s] 88%|████████▊ | 15377/17525 [3:04:10<20:40,  1.73it/s] 88%|████████▊ | 15378/17525 [3:04:10<20:38,  1.73it/s] 88%|████████▊ | 15379/17525 [3:04:11<20:36,  1.74it/s] 88%|████████▊ | 15380/17525 [3:04:11<20:37,  1.73it/s]                                                       {'loss': 0.414, 'grad_norm': 8.937640190124512, 'learning_rate': 7.386179659760051e-07, 'epoch': 21.94}
 88%|████████▊ | 15380/17525 [3:04:11<20:37,  1.73it/s] 88%|████████▊ | 15381/17525 [3:04:12<20:37,  1.73it/s] 88%|████████▊ | 15382/17525 [3:04:13<20:36,  1.73it/s] 88%|████████▊ | 15383/17525 [3:04:13<20:36,  1.73it/s] 88%|████████▊ | 15384/17525 [3:04:14<20:34,  1.73it/s] 88%|████████▊ | 15385/17525 [3:04:14<20:41,  1.72it/s] 88%|████████▊ | 15386/17525 [3:04:15<20:44,  1.72it/s] 88%|████████▊ | 15387/17525 [3:04:15<20:42,  1.72it/s] 88%|████████▊ | 15388/17525 [3:04:16<20:37,  1.73it/s] 88%|████████▊ | 15389/17525 [3:04:17<20:36,  1.73it/s] 88%|████████▊ | 15390/17525 [3:04:17<20:35,  1.73it/s]                                                       {'loss': 0.3186, 'grad_norm': 5.303895950317383, 'learning_rate': 7.318636211326379e-07, 'epoch': 21.95}
 88%|████████▊ | 15390/17525 [3:04:17<20:35,  1.73it/s] 88%|████████▊ | 15391/17525 [3:04:18<20:33,  1.73it/s] 88%|████████▊ | 15392/17525 [3:04:18<20:31,  1.73it/s] 88%|████████▊ | 15393/17525 [3:04:19<20:30,  1.73it/s] 88%|████████▊ | 15394/17525 [3:04:19<20:27,  1.74it/s] 88%|████████▊ | 15395/17525 [3:04:20<20:26,  1.74it/s] 88%|████████▊ | 15396/17525 [3:04:21<20:29,  1.73it/s] 88%|████████▊ | 15397/17525 [3:04:21<20:28,  1.73it/s] 88%|████████▊ | 15398/17525 [3:04:22<20:25,  1.74it/s] 88%|████████▊ | 15399/17525 [3:04:22<20:24,  1.74it/s] 88%|████████▊ | 15400/17525 [3:04:23<22:18,  1.59it/s]                                                       {'loss': 0.3595, 'grad_norm': 15.0380859375, 'learning_rate': 7.251391279030684e-07, 'epoch': 21.97}
 88%|████████▊ | 15400/17525 [3:04:23<22:18,  1.59it/s][INFO|trainer.py:3512] 2024-06-25 05:07:44,980 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:07:44,980 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:07:44,980 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.00it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1838228702545166, 'eval_runtime': 4.6045, 'eval_samples_per_second': 96.209, 'eval_steps_per_second': 4.126, 'epoch': 21.97}
 88%|████████▊ | 15400/17525 [3:04:28<22:18,  1.59it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 88%|████████▊ | 15401/17525 [3:04:28<1:10:44,  2.00s/it] 88%|████████▊ | 15402/17525 [3:04:29<55:37,  1.57s/it]   88%|████████▊ | 15403/17525 [3:04:29<45:01,  1.27s/it] 88%|████████▊ | 15404/17525 [3:04:30<37:38,  1.06s/it] 88%|████████▊ | 15405/17525 [3:04:31<32:27,  1.09it/s] 88%|████████▊ | 15406/17525 [3:04:31<28:47,  1.23it/s] 88%|████████▊ | 15407/17525 [3:04:32<26:15,  1.34it/s] 88%|████████▊ | 15408/17525 [3:04:32<24:28,  1.44it/s] 88%|████████▊ | 15409/17525 [3:04:33<23:14,  1.52it/s] 88%|████████▊ | 15410/17525 [3:04:33<22:22,  1.58it/s]                                                       {'loss': 0.4312, 'grad_norm': 15.433320999145508, 'learning_rate': 7.184445079461267e-07, 'epoch': 21.98}
 88%|████████▊ | 15410/17525 [3:04:33<22:22,  1.58it/s] 88%|████████▊ | 15411/17525 [3:04:34<21:45,  1.62it/s] 88%|████████▊ | 15412/17525 [3:04:35<21:15,  1.66it/s] 88%|████████▊ | 15413/17525 [3:04:35<20:56,  1.68it/s] 88%|████████▊ | 15414/17525 [3:04:36<20:47,  1.69it/s] 88%|████████▊ | 15415/17525 [3:04:36<20:40,  1.70it/s] 88%|████████▊ | 15416/17525 [3:04:37<20:30,  1.71it/s] 88%|████████▊ | 15417/17525 [3:04:38<20:26,  1.72it/s] 88%|████████▊ | 15418/17525 [3:04:38<20:20,  1.73it/s] 88%|████████▊ | 15419/17525 [3:04:39<20:18,  1.73it/s] 88%|████████▊ | 15420/17525 [3:04:39<20:29,  1.71it/s]                                                       {'loss': 0.3328, 'grad_norm': 7.616556167602539, 'learning_rate': 7.117797828244177e-07, 'epoch': 22.0}
 88%|████████▊ | 15420/17525 [3:04:39<20:29,  1.71it/s] 88%|████████▊ | 15421/17525 [3:04:40<20:24,  1.72it/s] 88%|████████▊ | 15422/17525 [3:04:40<20:35,  1.70it/s] 88%|████████▊ | 15423/17525 [3:04:41<20:27,  1.71it/s] 88%|████████▊ | 15424/17525 [3:04:42<20:20,  1.72it/s] 88%|████████▊ | 15425/17525 [3:04:42<20:15,  1.73it/s] 88%|████████▊ | 15426/17525 [3:04:43<20:19,  1.72it/s] 88%|████████▊ | 15427/17525 [3:04:43<20:17,  1.72it/s] 88%|████████▊ | 15428/17525 [3:04:44<20:16,  1.72it/s] 88%|████████▊ | 15429/17525 [3:04:44<20:16,  1.72it/s] 88%|████████▊ | 15430/17525 [3:04:45<20:17,  1.72it/s]                                                       {'loss': 0.3917, 'grad_norm': 9.813472747802734, 'learning_rate': 7.051449740042704e-07, 'epoch': 22.01}
 88%|████████▊ | 15430/17525 [3:04:45<20:17,  1.72it/s] 88%|████████▊ | 15431/17525 [3:04:46<20:16,  1.72it/s] 88%|████████▊ | 15432/17525 [3:04:46<20:16,  1.72it/s] 88%|████████▊ | 15433/17525 [3:04:47<20:14,  1.72it/s] 88%|████████▊ | 15434/17525 [3:04:47<20:16,  1.72it/s] 88%|████████▊ | 15435/17525 [3:04:48<20:14,  1.72it/s] 88%|████████▊ | 15436/17525 [3:04:49<20:13,  1.72it/s] 88%|████████▊ | 15437/17525 [3:04:49<20:07,  1.73it/s] 88%|████████▊ | 15438/17525 [3:04:50<20:06,  1.73it/s] 88%|████████▊ | 15439/17525 [3:04:50<20:04,  1.73it/s] 88%|████████▊ | 15440/17525 [3:04:51<20:03,  1.73it/s]                                                       {'loss': 0.4246, 'grad_norm': 7.104280471801758, 'learning_rate': 6.985401028556437e-07, 'epoch': 22.03}
 88%|████████▊ | 15440/17525 [3:04:51<20:03,  1.73it/s] 88%|████████▊ | 15441/17525 [3:04:51<20:03,  1.73it/s] 88%|████████▊ | 15442/17525 [3:04:52<20:01,  1.73it/s] 88%|████████▊ | 15443/17525 [3:04:53<20:00,  1.73it/s] 88%|████████▊ | 15444/17525 [3:04:53<19:59,  1.73it/s] 88%|████████▊ | 15445/17525 [3:04:54<20:01,  1.73it/s] 88%|████████▊ | 15446/17525 [3:04:54<20:10,  1.72it/s] 88%|████████▊ | 15447/17525 [3:04:55<20:04,  1.73it/s] 88%|████████▊ | 15448/17525 [3:04:56<23:43,  1.46it/s] 88%|████████▊ | 15449/17525 [3:04:56<22:36,  1.53it/s] 88%|████████▊ | 15450/17525 [3:04:57<21:49,  1.58it/s]                                                       {'loss': 0.3053, 'grad_norm': 10.84337043762207, 'learning_rate': 6.919651906520819e-07, 'epoch': 22.04}
 88%|████████▊ | 15450/17525 [3:04:57<21:49,  1.58it/s][INFO|trainer.py:3203] 2024-06-25 05:08:18,890 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15450
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bfd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ca385f6b-32ea-4d8e-a97a-573004e309a0)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:08:28,949 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:08:28,952 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15450/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 88%|████████▊ | 15451/17525 [3:05:08<2:07:53,  3.70s/it] 88%|████████▊ | 15452/17525 [3:05:08<1:35:32,  2.77s/it] 88%|████████▊ | 15453/17525 [3:05:09<1:12:50,  2.11s/it] 88%|████████▊ | 15454/17525 [3:05:10<56:56,  1.65s/it]   88%|████████▊ | 15455/17525 [3:05:10<45:45,  1.33s/it] 88%|████████▊ | 15456/17525 [3:05:11<41:32,  1.20s/it] 88%|████████▊ | 15457/17525 [3:05:12<35:01,  1.02s/it] 88%|████████▊ | 15458/17525 [3:05:12<30:26,  1.13it/s] 88%|████████▊ | 15459/17525 [3:05:13<27:16,  1.26it/s] 88%|████████▊ | 15460/17525 [3:05:13<25:01,  1.38it/s]                                                       {'loss': 0.2433, 'grad_norm': 9.610271453857422, 'learning_rate': 6.854202585706249e-07, 'epoch': 22.05}
 88%|████████▊ | 15460/17525 [3:05:13<25:01,  1.38it/s] 88%|████████▊ | 15461/17525 [3:05:14<23:30,  1.46it/s] 88%|████████▊ | 15462/17525 [3:05:15<22:23,  1.54it/s] 88%|████████▊ | 15463/17525 [3:05:15<21:37,  1.59it/s] 88%|████████▊ | 15464/17525 [3:05:16<21:00,  1.63it/s] 88%|████████▊ | 15465/17525 [3:05:16<20:38,  1.66it/s] 88%|████████▊ | 15466/17525 [3:05:17<20:23,  1.68it/s] 88%|████████▊ | 15467/17525 [3:05:17<20:11,  1.70it/s] 88%|████████▊ | 15468/17525 [3:05:18<20:01,  1.71it/s] 88%|████████▊ | 15469/17525 [3:05:19<19:54,  1.72it/s] 88%|████████▊ | 15470/17525 [3:05:19<19:51,  1.73it/s]                                                       {'loss': 0.3208, 'grad_norm': 7.37874698638916, 'learning_rate': 6.78905327691759e-07, 'epoch': 22.07}
 88%|████████▊ | 15470/17525 [3:05:19<19:51,  1.73it/s] 88%|████████▊ | 15471/17525 [3:05:20<19:50,  1.73it/s] 88%|████████▊ | 15472/17525 [3:05:20<19:49,  1.73it/s] 88%|████████▊ | 15473/17525 [3:05:21<19:49,  1.72it/s] 88%|████████▊ | 15474/17525 [3:05:21<19:46,  1.73it/s] 88%|████████▊ | 15475/17525 [3:05:22<19:43,  1.73it/s] 88%|████████▊ | 15476/17525 [3:05:23<19:43,  1.73it/s] 88%|████████▊ | 15477/17525 [3:05:23<19:41,  1.73it/s] 88%|████████▊ | 15478/17525 [3:05:24<19:40,  1.73it/s] 88%|████████▊ | 15479/17525 [3:05:24<19:38,  1.74it/s] 88%|████████▊ | 15480/17525 [3:05:25<19:38,  1.74it/s]                                                       {'loss': 0.4021, 'grad_norm': 12.040348052978516, 'learning_rate': 6.724204189993334e-07, 'epoch': 22.08}
 88%|████████▊ | 15480/17525 [3:05:25<19:38,  1.74it/s] 88%|████████▊ | 15481/17525 [3:05:26<19:40,  1.73it/s] 88%|████████▊ | 15482/17525 [3:05:26<19:38,  1.73it/s] 88%|████████▊ | 15483/17525 [3:05:27<19:37,  1.73it/s] 88%|████████▊ | 15484/17525 [3:05:27<19:35,  1.74it/s] 88%|████████▊ | 15485/17525 [3:05:28<19:35,  1.74it/s] 88%|████████▊ | 15486/17525 [3:05:28<19:34,  1.74it/s] 88%|████████▊ | 15487/17525 [3:05:30<30:11,  1.12it/s] 88%|████████▊ | 15488/17525 [3:05:31<26:58,  1.26it/s] 88%|████████▊ | 15489/17525 [3:05:31<25:01,  1.36it/s] 88%|████████▊ | 15490/17525 [3:05:32<23:22,  1.45it/s]                                                       {'loss': 0.3174, 'grad_norm': 16.020648956298828, 'learning_rate': 6.659655533805031e-07, 'epoch': 22.1}
 88%|████████▊ | 15490/17525 [3:05:32<23:22,  1.45it/s] 88%|████████▊ | 15491/17525 [3:05:32<22:18,  1.52it/s] 88%|████████▊ | 15492/17525 [3:05:33<21:28,  1.58it/s] 88%|████████▊ | 15493/17525 [3:05:33<20:52,  1.62it/s] 88%|████████▊ | 15494/17525 [3:05:34<20:27,  1.65it/s] 88%|████████▊ | 15495/17525 [3:05:35<20:08,  1.68it/s] 88%|████████▊ | 15496/17525 [3:05:35<19:56,  1.70it/s] 88%|████████▊ | 15497/17525 [3:05:36<19:50,  1.70it/s] 88%|████████▊ | 15498/17525 [3:05:36<19:43,  1.71it/s] 88%|████████▊ | 15499/17525 [3:05:37<19:38,  1.72it/s] 88%|████████▊ | 15500/17525 [3:05:38<19:35,  1.72it/s]                                                       {'loss': 0.3588, 'grad_norm': 15.918221473693848, 'learning_rate': 6.595407516256569e-07, 'epoch': 22.11}
 88%|████████▊ | 15500/17525 [3:05:38<19:35,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:08:59,429 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:08:59,430 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:08:59,430 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.187567949295044, 'eval_runtime': 4.5917, 'eval_samples_per_second': 96.479, 'eval_steps_per_second': 4.138, 'epoch': 22.11}
 88%|████████▊ | 15500/17525 [3:05:42<19:35,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 88%|████████▊ | 15501/17525 [3:05:43<1:06:05,  1.96s/it] 88%|████████▊ | 15502/17525 [3:05:43<52:04,  1.54s/it]   88%|████████▊ | 15503/17525 [3:05:44<42:17,  1.26s/it] 88%|████████▊ | 15504/17525 [3:05:44<35:26,  1.05s/it] 88%|████████▊ | 15505/17525 [3:05:45<30:35,  1.10it/s] 88%|████████▊ | 15506/17525 [3:05:46<27:12,  1.24it/s] 88%|████████▊ | 15507/17525 [3:05:46<24:49,  1.35it/s] 88%|████████▊ | 15508/17525 [3:05:47<23:11,  1.45it/s] 88%|████████▊ | 15509/17525 [3:05:47<22:03,  1.52it/s] 89%|████████▊ | 15510/17525 [3:05:48<22:39,  1.48it/s]                                                       {'loss': 0.3782, 'grad_norm': 11.593449592590332, 'learning_rate': 6.531460344283513e-07, 'epoch': 22.13}
 89%|████████▊ | 15510/17525 [3:05:48<22:39,  1.48it/s] 89%|████████▊ | 15511/17525 [3:05:49<21:40,  1.55it/s] 89%|████████▊ | 15512/17525 [3:05:49<20:59,  1.60it/s] 89%|████████▊ | 15513/17525 [3:05:50<20:28,  1.64it/s] 89%|████████▊ | 15514/17525 [3:05:50<20:22,  1.65it/s] 89%|████████▊ | 15515/17525 [3:05:51<20:02,  1.67it/s] 89%|████████▊ | 15516/17525 [3:05:52<19:54,  1.68it/s] 89%|████████▊ | 15517/17525 [3:05:52<19:43,  1.70it/s] 89%|████████▊ | 15518/17525 [3:05:53<19:48,  1.69it/s] 89%|████████▊ | 15519/17525 [3:05:53<19:40,  1.70it/s] 89%|████████▊ | 15520/17525 [3:05:54<19:31,  1.71it/s]                                                       {'loss': 0.3393, 'grad_norm': 10.702516555786133, 'learning_rate': 6.46781422385242e-07, 'epoch': 22.14}
 89%|████████▊ | 15520/17525 [3:05:54<19:31,  1.71it/s] 89%|████████▊ | 15521/17525 [3:05:54<19:29,  1.71it/s] 89%|████████▊ | 15522/17525 [3:05:55<19:25,  1.72it/s] 89%|████████▊ | 15523/17525 [3:05:56<19:23,  1.72it/s] 89%|████████▊ | 15524/17525 [3:05:56<19:21,  1.72it/s] 89%|████████▊ | 15525/17525 [3:05:57<19:18,  1.73it/s] 89%|████████▊ | 15526/17525 [3:05:57<19:16,  1.73it/s] 89%|████████▊ | 15527/17525 [3:05:58<19:15,  1.73it/s] 89%|████████▊ | 15528/17525 [3:05:58<19:13,  1.73it/s] 89%|████████▊ | 15529/17525 [3:05:59<19:18,  1.72it/s] 89%|████████▊ | 15530/17525 [3:06:00<19:16,  1.72it/s]                                                       {'loss': 0.3613, 'grad_norm': 14.504679679870605, 'learning_rate': 6.404469359960208e-07, 'epoch': 22.15}
 89%|████████▊ | 15530/17525 [3:06:00<19:16,  1.72it/s] 89%|████████▊ | 15531/17525 [3:06:00<19:16,  1.72it/s] 89%|████████▊ | 15532/17525 [3:06:01<19:14,  1.73it/s] 89%|████████▊ | 15533/17525 [3:06:01<19:32,  1.70it/s] 89%|████████▊ | 15534/17525 [3:06:02<19:24,  1.71it/s] 89%|████████▊ | 15535/17525 [3:06:03<19:19,  1.72it/s] 89%|████████▊ | 15536/17525 [3:06:03<19:16,  1.72it/s] 89%|████████▊ | 15537/17525 [3:06:04<19:11,  1.73it/s] 89%|████████▊ | 15538/17525 [3:06:04<19:10,  1.73it/s] 89%|████████▊ | 15539/17525 [3:06:05<19:07,  1.73it/s] 89%|████████▊ | 15540/17525 [3:06:05<19:06,  1.73it/s]                                                       {'loss': 0.3621, 'grad_norm': 12.609495162963867, 'learning_rate': 6.341425956633518e-07, 'epoch': 22.17}
 89%|████████▊ | 15540/17525 [3:06:05<19:06,  1.73it/s] 89%|████████▊ | 15541/17525 [3:06:06<19:06,  1.73it/s] 89%|████████▊ | 15542/17525 [3:06:07<19:06,  1.73it/s] 89%|████████▊ | 15543/17525 [3:06:07<19:17,  1.71it/s] 89%|████████▊ | 15544/17525 [3:06:08<19:13,  1.72it/s] 89%|████████▊ | 15545/17525 [3:06:08<19:08,  1.72it/s] 89%|████████▊ | 15546/17525 [3:06:09<19:06,  1.73it/s] 89%|████████▊ | 15547/17525 [3:06:10<19:03,  1.73it/s] 89%|████████▊ | 15548/17525 [3:06:10<19:00,  1.73it/s] 89%|████████▊ | 15549/17525 [3:06:11<18:59,  1.73it/s] 89%|████████▊ | 15550/17525 [3:06:11<18:59,  1.73it/s]                                                       {'loss': 0.3676, 'grad_norm': 10.539939880371094, 'learning_rate': 6.278684216927921e-07, 'epoch': 22.18}
 89%|████████▊ | 15550/17525 [3:06:11<18:59,  1.73it/s] 89%|████████▊ | 15551/17525 [3:06:12<22:32,  1.46it/s] 89%|████████▊ | 15552/17525 [3:06:13<21:29,  1.53it/s] 89%|████████▊ | 15553/17525 [3:06:13<20:44,  1.58it/s] 89%|████████▉ | 15554/17525 [3:06:14<20:12,  1.63it/s] 89%|████████▉ | 15555/17525 [3:06:15<19:48,  1.66it/s] 89%|████████▉ | 15556/17525 [3:06:15<19:30,  1.68it/s] 89%|████████▉ | 15557/17525 [3:06:16<19:20,  1.70it/s] 89%|████████▉ | 15558/17525 [3:06:16<19:14,  1.70it/s] 89%|████████▉ | 15559/17525 [3:06:17<19:06,  1.72it/s] 89%|████████▉ | 15560/17525 [3:06:17<19:00,  1.72it/s]                                                       {'loss': 0.3542, 'grad_norm': 11.600728988647461, 'learning_rate': 6.216244342927502e-07, 'epoch': 22.2}
 89%|████████▉ | 15560/17525 [3:06:17<19:00,  1.72it/s] 89%|████████▉ | 15561/17525 [3:06:18<18:57,  1.73it/s] 89%|████████▉ | 15562/17525 [3:06:19<18:55,  1.73it/s] 89%|████████▉ | 15563/17525 [3:06:19<19:03,  1.72it/s] 89%|████████▉ | 15564/17525 [3:06:20<19:00,  1.72it/s] 89%|████████▉ | 15565/17525 [3:06:20<18:55,  1.73it/s] 89%|████████▉ | 15566/17525 [3:06:21<18:54,  1.73it/s] 89%|████████▉ | 15567/17525 [3:06:21<18:50,  1.73it/s] 89%|████████▉ | 15568/17525 [3:06:22<18:47,  1.74it/s] 89%|████████▉ | 15569/17525 [3:06:23<18:57,  1.72it/s] 89%|████████▉ | 15570/17525 [3:06:23<18:53,  1.73it/s]                                                       {'loss': 0.3641, 'grad_norm': 26.964319229125977, 'learning_rate': 6.154106535743931e-07, 'epoch': 22.21}
 89%|████████▉ | 15570/17525 [3:06:23<18:53,  1.73it/s] 89%|████████▉ | 15571/17525 [3:06:24<18:50,  1.73it/s] 89%|████████▉ | 15572/17525 [3:06:24<18:48,  1.73it/s] 89%|████████▉ | 15573/17525 [3:06:25<18:45,  1.74it/s] 89%|████████▉ | 15574/17525 [3:06:25<18:46,  1.73it/s] 89%|████████▉ | 15575/17525 [3:06:26<18:46,  1.73it/s] 89%|████████▉ | 15576/17525 [3:06:27<23:18,  1.39it/s] 89%|████████▉ | 15577/17525 [3:06:28<21:57,  1.48it/s] 89%|████████▉ | 15578/17525 [3:06:28<20:58,  1.55it/s] 89%|████████▉ | 15579/17525 [3:06:29<20:18,  1.60it/s] 89%|████████▉ | 15580/17525 [3:06:29<19:47,  1.64it/s]                                                       {'loss': 0.3975, 'grad_norm': 12.944009780883789, 'learning_rate': 6.092270995516092e-07, 'epoch': 22.23}
 89%|████████▉ | 15580/17525 [3:06:29<19:47,  1.64it/s] 89%|████████▉ | 15581/17525 [3:06:30<19:27,  1.66it/s] 89%|████████▉ | 15582/17525 [3:06:31<19:12,  1.69it/s] 89%|████████▉ | 15583/17525 [3:06:31<19:00,  1.70it/s] 89%|████████▉ | 15584/17525 [3:06:32<18:54,  1.71it/s] 89%|████████▉ | 15585/17525 [3:06:32<18:49,  1.72it/s] 89%|████████▉ | 15586/17525 [3:06:33<18:45,  1.72it/s] 89%|████████▉ | 15587/17525 [3:06:33<18:42,  1.73it/s] 89%|████████▉ | 15588/17525 [3:06:34<18:41,  1.73it/s] 89%|████████▉ | 15589/17525 [3:06:35<18:39,  1.73it/s] 89%|████████▉ | 15590/17525 [3:06:36<26:07,  1.23it/s]                                                       {'loss': 0.2712, 'grad_norm': 8.298182487487793, 'learning_rate': 6.030737921409169e-07, 'epoch': 22.24}
 89%|████████▉ | 15590/17525 [3:06:36<26:07,  1.23it/s] 89%|████████▉ | 15591/17525 [3:06:37<23:53,  1.35it/s] 89%|████████▉ | 15592/17525 [3:06:37<22:16,  1.45it/s] 89%|████████▉ | 15593/17525 [3:06:38<21:08,  1.52it/s] 89%|████████▉ | 15594/17525 [3:06:38<20:21,  1.58it/s] 89%|████████▉ | 15595/17525 [3:06:39<19:51,  1.62it/s] 89%|████████▉ | 15596/17525 [3:06:39<19:26,  1.65it/s] 89%|████████▉ | 15597/17525 [3:06:40<19:06,  1.68it/s] 89%|████████▉ | 15598/17525 [3:06:41<18:55,  1.70it/s] 89%|████████▉ | 15599/17525 [3:06:41<18:46,  1.71it/s] 89%|████████▉ | 15600/17525 [3:06:42<18:41,  1.72it/s]                                                       {'loss': 0.3291, 'grad_norm': 8.224946022033691, 'learning_rate': 5.969507511614225e-07, 'epoch': 22.25}
 89%|████████▉ | 15600/17525 [3:06:42<18:41,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:10:03,612 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:10:03,612 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:10:03,612 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.84it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1922188997268677, 'eval_runtime': 4.6002, 'eval_samples_per_second': 96.299, 'eval_steps_per_second': 4.13, 'epoch': 22.25}
 89%|████████▉ | 15600/17525 [3:06:46<18:41,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:10:08,216 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15600
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c55990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 1850bfa3-7c03-48fa-b3dc-747b9620ecea)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:10:18,274 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:10:18,276 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15600/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 89%|████████▉ | 15601/17525 [3:06:57<2:41:07,  5.02s/it] 89%|████████▉ | 15602/17525 [3:06:58<1:58:19,  3.69s/it] 89%|████████▉ | 15603/17525 [3:06:58<1:28:20,  2.76s/it] 89%|████████▉ | 15604/17525 [3:06:59<1:07:21,  2.10s/it] 89%|████████▉ | 15605/17525 [3:06:59<52:41,  1.65s/it]   89%|████████▉ | 15606/17525 [3:07:00<42:22,  1.32s/it] 89%|████████▉ | 15607/17525 [3:07:01<35:09,  1.10s/it] 89%|████████▉ | 15608/17525 [3:07:02<33:29,  1.05s/it] 89%|████████▉ | 15609/17525 [3:07:02<28:56,  1.10it/s] 89%|████████▉ | 15610/17525 [3:07:03<25:43,  1.24it/s]                                                       {'loss': 0.3153, 'grad_norm': 7.7450127601623535, 'learning_rate': 5.908579963347461e-07, 'epoch': 22.27}
 89%|████████▉ | 15610/17525 [3:07:03<25:43,  1.24it/s] 89%|████████▉ | 15611/17525 [3:07:03<23:40,  1.35it/s] 89%|████████▉ | 15612/17525 [3:07:04<22:03,  1.45it/s] 89%|████████▉ | 15613/17525 [3:07:04<20:57,  1.52it/s] 89%|████████▉ | 15614/17525 [3:07:05<24:20,  1.31it/s] 89%|████████▉ | 15615/17525 [3:07:06<25:49,  1.23it/s] 89%|████████▉ | 15616/17525 [3:07:08<30:51,  1.03it/s] 89%|████████▉ | 15617/17525 [3:07:08<27:07,  1.17it/s] 89%|████████▉ | 15618/17525 [3:07:09<24:28,  1.30it/s] 89%|████████▉ | 15619/17525 [3:07:09<22:37,  1.40it/s] 89%|████████▉ | 15620/17525 [3:07:10<21:22,  1.49it/s]                                                       {'loss': 0.3132, 'grad_norm': 8.933184623718262, 'learning_rate': 5.847955472849564e-07, 'epoch': 22.28}
 89%|████████▉ | 15620/17525 [3:07:10<21:22,  1.49it/s] 89%|████████▉ | 15621/17525 [3:07:11<20:29,  1.55it/s] 89%|████████▉ | 15622/17525 [3:07:11<21:08,  1.50it/s] 89%|████████▉ | 15623/17525 [3:07:12<20:19,  1.56it/s] 89%|████████▉ | 15624/17525 [3:07:12<19:40,  1.61it/s] 89%|████████▉ | 15625/17525 [3:07:13<19:15,  1.65it/s] 89%|████████▉ | 15626/17525 [3:07:14<18:54,  1.67it/s] 89%|████████▉ | 15627/17525 [3:07:14<18:49,  1.68it/s] 89%|████████▉ | 15628/17525 [3:07:15<18:39,  1.69it/s] 89%|████████▉ | 15629/17525 [3:07:15<18:30,  1.71it/s] 89%|████████▉ | 15630/17525 [3:07:16<18:27,  1.71it/s]                                                       {'loss': 0.3893, 'grad_norm': 7.239593029022217, 'learning_rate': 5.787634235385131e-07, 'epoch': 22.3}
 89%|████████▉ | 15630/17525 [3:07:16<18:27,  1.71it/s] 89%|████████▉ | 15631/17525 [3:07:16<18:25,  1.71it/s] 89%|████████▉ | 15632/17525 [3:07:17<18:24,  1.71it/s] 89%|████████▉ | 15633/17525 [3:07:18<18:21,  1.72it/s] 89%|████████▉ | 15634/17525 [3:07:18<18:18,  1.72it/s] 89%|████████▉ | 15635/17525 [3:07:19<18:27,  1.71it/s] 89%|████████▉ | 15636/17525 [3:07:19<18:22,  1.71it/s] 89%|████████▉ | 15637/17525 [3:07:20<18:18,  1.72it/s] 89%|████████▉ | 15638/17525 [3:07:21<18:17,  1.72it/s] 89%|████████▉ | 15639/17525 [3:07:21<18:14,  1.72it/s] 89%|████████▉ | 15640/17525 [3:07:22<18:14,  1.72it/s]                                                       {'loss': 0.3791, 'grad_norm': 15.235363960266113, 'learning_rate': 5.727616445242046e-07, 'epoch': 22.31}
 89%|████████▉ | 15640/17525 [3:07:22<18:14,  1.72it/s] 89%|████████▉ | 15641/17525 [3:07:22<18:16,  1.72it/s] 89%|████████▉ | 15642/17525 [3:07:23<21:24,  1.47it/s] 89%|████████▉ | 15643/17525 [3:07:24<20:24,  1.54it/s] 89%|████████▉ | 15644/17525 [3:07:24<19:44,  1.59it/s] 89%|████████▉ | 15645/17525 [3:07:25<19:15,  1.63it/s] 89%|████████▉ | 15646/17525 [3:07:26<18:56,  1.65it/s] 89%|████████▉ | 15647/17525 [3:07:26<18:38,  1.68it/s] 89%|████████▉ | 15648/17525 [3:07:27<18:25,  1.70it/s] 89%|████████▉ | 15649/17525 [3:07:27<18:20,  1.70it/s] 89%|████████▉ | 15650/17525 [3:07:28<18:14,  1.71it/s]                                                       {'loss': 0.303, 'grad_norm': 3.9045066833496094, 'learning_rate': 5.667902295730732e-07, 'epoch': 22.33}
 89%|████████▉ | 15650/17525 [3:07:28<18:14,  1.71it/s] 89%|████████▉ | 15651/17525 [3:07:28<18:12,  1.71it/s] 89%|████████▉ | 15652/17525 [3:07:29<18:24,  1.70it/s] 89%|████████▉ | 15653/17525 [3:07:30<18:17,  1.71it/s] 89%|████████▉ | 15654/17525 [3:07:30<18:20,  1.70it/s] 89%|████████▉ | 15655/17525 [3:07:31<18:18,  1.70it/s] 89%|████████▉ | 15656/17525 [3:07:31<18:10,  1.71it/s] 89%|████████▉ | 15657/17525 [3:07:32<18:06,  1.72it/s] 89%|████████▉ | 15658/17525 [3:07:33<18:05,  1.72it/s] 89%|████████▉ | 15659/17525 [3:07:33<18:03,  1.72it/s] 89%|████████▉ | 15660/17525 [3:07:34<18:00,  1.73it/s]                                                       {'loss': 0.3027, 'grad_norm': 3.990955114364624, 'learning_rate': 5.608491979183705e-07, 'epoch': 22.34}
 89%|████████▉ | 15660/17525 [3:07:34<18:00,  1.73it/s] 89%|████████▉ | 15661/17525 [3:07:34<18:02,  1.72it/s] 89%|████████▉ | 15662/17525 [3:07:35<18:00,  1.72it/s] 89%|████████▉ | 15663/17525 [3:07:35<17:59,  1.73it/s] 89%|████████▉ | 15664/17525 [3:07:36<17:56,  1.73it/s] 89%|████████▉ | 15665/17525 [3:07:37<17:54,  1.73it/s] 89%|████████▉ | 15666/17525 [3:07:37<17:50,  1.74it/s] 89%|████████▉ | 15667/17525 [3:07:38<17:51,  1.73it/s] 89%|████████▉ | 15668/17525 [3:07:38<17:52,  1.73it/s] 89%|████████▉ | 15669/17525 [3:07:39<17:49,  1.73it/s] 89%|████████▉ | 15670/17525 [3:07:39<17:52,  1.73it/s]                                                       {'loss': 0.2419, 'grad_norm': 7.112801551818848, 'learning_rate': 5.549385686954845e-07, 'epoch': 22.35}
 89%|████████▉ | 15670/17525 [3:07:39<17:52,  1.73it/s] 89%|████████▉ | 15671/17525 [3:07:40<17:53,  1.73it/s] 89%|████████▉ | 15672/17525 [3:07:41<17:52,  1.73it/s] 89%|████████▉ | 15673/17525 [3:07:41<17:54,  1.72it/s] 89%|████████▉ | 15674/17525 [3:07:42<17:52,  1.73it/s] 89%|████████▉ | 15675/17525 [3:07:42<17:54,  1.72it/s] 89%|████████▉ | 15676/17525 [3:07:43<17:51,  1.73it/s] 89%|████████▉ | 15677/17525 [3:07:44<17:50,  1.73it/s] 89%|████████▉ | 15678/17525 [3:07:44<17:47,  1.73it/s] 89%|████████▉ | 15679/17525 [3:07:45<17:44,  1.73it/s] 89%|████████▉ | 15680/17525 [3:07:45<17:43,  1.73it/s]                                                       {'loss': 0.3096, 'grad_norm': 8.394477844238281, 'learning_rate': 5.490583609418798e-07, 'epoch': 22.37}
 89%|████████▉ | 15680/17525 [3:07:45<17:43,  1.73it/s] 89%|████████▉ | 15681/17525 [3:07:47<25:04,  1.23it/s] 89%|████████▉ | 15682/17525 [3:07:47<22:49,  1.35it/s] 89%|████████▉ | 15683/17525 [3:07:48<21:34,  1.42it/s] 89%|████████▉ | 15684/17525 [3:07:48<20:34,  1.49it/s] 90%|████████▉ | 15685/17525 [3:07:49<19:38,  1.56it/s] 90%|████████▉ | 15686/17525 [3:07:50<19:02,  1.61it/s] 90%|████████▉ | 15687/17525 [3:07:50<19:00,  1.61it/s] 90%|████████▉ | 15688/17525 [3:07:51<18:34,  1.65it/s] 90%|████████▉ | 15689/17525 [3:07:51<18:17,  1.67it/s] 90%|████████▉ | 15690/17525 [3:07:52<18:03,  1.69it/s]                                                       {'loss': 0.3359, 'grad_norm': 8.997679710388184, 'learning_rate': 5.432085935970388e-07, 'epoch': 22.38}
 90%|████████▉ | 15690/17525 [3:07:52<18:03,  1.69it/s] 90%|████████▉ | 15691/17525 [3:07:52<17:57,  1.70it/s] 90%|████████▉ | 15692/17525 [3:07:53<17:49,  1.71it/s] 90%|████████▉ | 15693/17525 [3:07:54<17:42,  1.72it/s] 90%|████████▉ | 15694/17525 [3:07:54<17:40,  1.73it/s] 90%|████████▉ | 15695/17525 [3:07:55<17:36,  1.73it/s] 90%|████████▉ | 15696/17525 [3:07:55<17:35,  1.73it/s] 90%|████████▉ | 15697/17525 [3:07:56<19:13,  1.59it/s] 90%|████████▉ | 15698/17525 [3:07:57<18:44,  1.63it/s] 90%|████████▉ | 15699/17525 [3:07:57<18:21,  1.66it/s] 90%|████████▉ | 15700/17525 [3:07:58<18:03,  1.68it/s]                                                       {'loss': 0.3801, 'grad_norm': 12.938709259033203, 'learning_rate': 5.373892855023921e-07, 'epoch': 22.4}
 90%|████████▉ | 15700/17525 [3:07:58<18:03,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 05:11:19,722 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:11:19,722 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:11:19,722 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1918795108795166, 'eval_runtime': 4.5947, 'eval_samples_per_second': 96.416, 'eval_steps_per_second': 4.135, 'epoch': 22.4}
 90%|████████▉ | 15700/17525 [3:08:02<18:03,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 90%|████████▉ | 15701/17525 [3:08:03<59:54,  1.97s/it] 90%|████████▉ | 15702/17525 [3:08:04<47:09,  1.55s/it] 90%|████████▉ | 15703/17525 [3:08:04<38:13,  1.26s/it] 90%|████████▉ | 15704/17525 [3:08:05<31:58,  1.05s/it] 90%|████████▉ | 15705/17525 [3:08:05<27:41,  1.10it/s] 90%|████████▉ | 15706/17525 [3:08:06<30:06,  1.01it/s] 90%|████████▉ | 15707/17525 [3:08:07<26:19,  1.15it/s] 90%|████████▉ | 15708/17525 [3:08:08<23:37,  1.28it/s] 90%|████████▉ | 15709/17525 [3:08:08<21:45,  1.39it/s] 90%|████████▉ | 15710/17525 [3:08:09<20:26,  1.48it/s]                                                       {'loss': 0.334, 'grad_norm': 6.0450873374938965, 'learning_rate': 5.316004554012765e-07, 'epoch': 22.41}
 90%|████████▉ | 15710/17525 [3:08:09<20:26,  1.48it/s] 90%|████████▉ | 15711/17525 [3:08:09<19:33,  1.55it/s] 90%|████████▉ | 15712/17525 [3:08:10<18:53,  1.60it/s] 90%|████████▉ | 15713/17525 [3:08:11<18:25,  1.64it/s] 90%|████████▉ | 15714/17525 [3:08:11<18:05,  1.67it/s] 90%|████████▉ | 15715/17525 [3:08:12<17:51,  1.69it/s] 90%|████████▉ | 15716/17525 [3:08:12<17:42,  1.70it/s] 90%|████████▉ | 15717/17525 [3:08:13<17:39,  1.71it/s] 90%|████████▉ | 15718/17525 [3:08:13<17:39,  1.71it/s] 90%|████████▉ | 15719/17525 [3:08:14<17:34,  1.71it/s] 90%|████████▉ | 15720/17525 [3:08:15<17:29,  1.72it/s]                                                       {'loss': 0.3033, 'grad_norm': 10.463692665100098, 'learning_rate': 5.258421219388488e-07, 'epoch': 22.43}
 90%|████████▉ | 15720/17525 [3:08:15<17:29,  1.72it/s] 90%|████████▉ | 15721/17525 [3:08:15<17:27,  1.72it/s] 90%|████████▉ | 15722/17525 [3:08:16<17:23,  1.73it/s] 90%|████████▉ | 15723/17525 [3:08:16<17:19,  1.73it/s] 90%|████████▉ | 15724/17525 [3:08:17<17:19,  1.73it/s] 90%|████████▉ | 15725/17525 [3:08:17<17:19,  1.73it/s] 90%|████████▉ | 15726/17525 [3:08:18<17:18,  1.73it/s] 90%|████████▉ | 15727/17525 [3:08:19<17:15,  1.74it/s] 90%|████████▉ | 15728/17525 [3:08:19<17:16,  1.73it/s] 90%|████████▉ | 15729/17525 [3:08:20<17:16,  1.73it/s] 90%|████████▉ | 15730/17525 [3:08:20<17:15,  1.73it/s]                                                       {'loss': 0.3845, 'grad_norm': 13.091980934143066, 'learning_rate': 5.201143036620538e-07, 'epoch': 22.44}
 90%|████████▉ | 15730/17525 [3:08:20<17:15,  1.73it/s] 90%|████████▉ | 15731/17525 [3:08:21<17:18,  1.73it/s] 90%|████████▉ | 15732/17525 [3:08:22<17:16,  1.73it/s] 90%|████████▉ | 15733/17525 [3:08:22<17:14,  1.73it/s] 90%|████████▉ | 15734/17525 [3:08:23<17:14,  1.73it/s] 90%|████████▉ | 15735/17525 [3:08:23<17:11,  1.73it/s] 90%|████████▉ | 15736/17525 [3:08:24<17:14,  1.73it/s] 90%|████████▉ | 15737/17525 [3:08:24<17:26,  1.71it/s] 90%|████████▉ | 15738/17525 [3:08:25<18:42,  1.59it/s] 90%|████████▉ | 15739/17525 [3:08:26<18:15,  1.63it/s] 90%|████████▉ | 15740/17525 [3:08:26<17:55,  1.66it/s]                                                       {'loss': 0.2914, 'grad_norm': 3.7806742191314697, 'learning_rate': 5.144170190195363e-07, 'epoch': 22.45}
 90%|████████▉ | 15740/17525 [3:08:26<17:55,  1.66it/s] 90%|████████▉ | 15741/17525 [3:08:27<17:44,  1.68it/s] 90%|████████▉ | 15742/17525 [3:08:27<17:33,  1.69it/s] 90%|████████▉ | 15743/17525 [3:08:28<17:24,  1.71it/s] 90%|████████▉ | 15744/17525 [3:08:29<17:19,  1.71it/s] 90%|████████▉ | 15745/17525 [3:08:29<17:18,  1.71it/s] 90%|████████▉ | 15746/17525 [3:08:30<17:12,  1.72it/s] 90%|████████▉ | 15747/17525 [3:08:30<17:10,  1.73it/s] 90%|████████▉ | 15748/17525 [3:08:31<17:09,  1.73it/s] 90%|████████▉ | 15749/17525 [3:08:32<17:08,  1.73it/s] 90%|████████▉ | 15750/17525 [3:08:32<17:05,  1.73it/s]                                                       {'loss': 0.2901, 'grad_norm': 10.042386054992676, 'learning_rate': 5.087502863616067e-07, 'epoch': 22.47}
 90%|████████▉ | 15750/17525 [3:08:32<17:05,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 05:11:53,972 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15750
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c7d990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f9c5e5ac-a2e8-4aab-9bef-e4c86d488ef4)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:12:04,030 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:12:04,032 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15750/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 90%|████████▉ | 15751/17525 [3:08:43<1:47:39,  3.64s/it] 90%|████████▉ | 15752/17525 [3:08:43<1:20:26,  2.72s/it] 90%|████████▉ | 15753/17525 [3:08:44<1:01:24,  2.08s/it] 90%|████████▉ | 15754/17525 [3:08:45<51:41,  1.75s/it]   90%|████████▉ | 15755/17525 [3:08:46<41:15,  1.40s/it] 90%|████████▉ | 15756/17525 [3:08:46<33:56,  1.15s/it] 90%|████████▉ | 15757/17525 [3:08:47<28:51,  1.02it/s] 90%|████████▉ | 15758/17525 [3:08:47<25:18,  1.16it/s] 90%|████████▉ | 15759/17525 [3:08:48<22:48,  1.29it/s] 90%|████████▉ | 15760/17525 [3:08:48<21:01,  1.40it/s]                                                       {'loss': 0.3599, 'grad_norm': 10.644396781921387, 'learning_rate': 5.031141239401649e-07, 'epoch': 22.48}
 90%|████████▉ | 15760/17525 [3:08:48<21:01,  1.40it/s] 90%|████████▉ | 15761/17525 [3:08:49<19:48,  1.48it/s] 90%|████████▉ | 15762/17525 [3:08:50<20:31,  1.43it/s] 90%|████████▉ | 15763/17525 [3:08:51<21:04,  1.39it/s] 90%|████████▉ | 15764/17525 [3:08:51<19:49,  1.48it/s] 90%|████████▉ | 15765/17525 [3:08:52<18:55,  1.55it/s] 90%|████████▉ | 15766/17525 [3:08:52<18:18,  1.60it/s] 90%|████████▉ | 15767/17525 [3:08:53<17:52,  1.64it/s] 90%|████████▉ | 15768/17525 [3:08:53<17:33,  1.67it/s] 90%|████████▉ | 15769/17525 [3:08:54<17:20,  1.69it/s] 90%|████████▉ | 15770/17525 [3:08:55<17:12,  1.70it/s]                                                       {'loss': 0.384, 'grad_norm': 6.296751499176025, 'learning_rate': 4.975085499086507e-07, 'epoch': 22.5}
 90%|████████▉ | 15770/17525 [3:08:55<17:12,  1.70it/s] 90%|████████▉ | 15771/17525 [3:08:55<17:08,  1.71it/s] 90%|████████▉ | 15772/17525 [3:08:56<17:03,  1.71it/s] 90%|█████████ | 15773/17525 [3:08:56<17:01,  1.72it/s] 90%|█████████ | 15774/17525 [3:08:57<16:58,  1.72it/s] 90%|█████████ | 15775/17525 [3:08:57<16:56,  1.72it/s] 90%|█████████ | 15776/17525 [3:08:58<16:53,  1.73it/s] 90%|█████████ | 15777/17525 [3:08:59<16:51,  1.73it/s] 90%|█████████ | 15778/17525 [3:08:59<16:50,  1.73it/s] 90%|█████████ | 15779/17525 [3:09:00<16:49,  1.73it/s] 90%|█████████ | 15780/17525 [3:09:00<16:49,  1.73it/s]                                                       {'loss': 0.3437, 'grad_norm': 7.6117262840271, 'learning_rate': 4.919335823219817e-07, 'epoch': 22.51}
 90%|█████████ | 15780/17525 [3:09:00<16:49,  1.73it/s] 90%|█████████ | 15781/17525 [3:09:01<16:48,  1.73it/s] 90%|█████████ | 15782/17525 [3:09:02<16:45,  1.73it/s] 90%|█████████ | 15783/17525 [3:09:02<16:56,  1.71it/s] 90%|█████████ | 15784/17525 [3:09:03<16:52,  1.72it/s] 90%|█████████ | 15785/17525 [3:09:03<16:50,  1.72it/s] 90%|█████████ | 15786/17525 [3:09:04<16:47,  1.73it/s] 90%|█████████ | 15787/17525 [3:09:04<16:46,  1.73it/s] 90%|█████████ | 15788/17525 [3:09:05<16:45,  1.73it/s] 90%|█████████ | 15789/17525 [3:09:06<16:48,  1.72it/s] 90%|█████████ | 15790/17525 [3:09:06<16:44,  1.73it/s]                                                       {'loss': 0.2595, 'grad_norm': 6.481251239776611, 'learning_rate': 4.863892391364922e-07, 'epoch': 22.52}
 90%|█████████ | 15790/17525 [3:09:06<16:44,  1.73it/s] 90%|█████████ | 15791/17525 [3:09:07<16:47,  1.72it/s] 90%|█████████ | 15792/17525 [3:09:07<16:46,  1.72it/s] 90%|█████████ | 15793/17525 [3:09:08<16:47,  1.72it/s] 90%|█████████ | 15794/17525 [3:09:09<16:50,  1.71it/s] 90%|█████████ | 15795/17525 [3:09:09<16:49,  1.71it/s] 90%|█████████ | 15796/17525 [3:09:10<16:45,  1.72it/s] 90%|█████████ | 15797/17525 [3:09:10<16:42,  1.72it/s] 90%|█████████ | 15798/17525 [3:09:11<16:40,  1.73it/s] 90%|█████████ | 15799/17525 [3:09:11<16:39,  1.73it/s] 90%|█████████ | 15800/17525 [3:09:12<16:37,  1.73it/s]                                                       {'loss': 0.3765, 'grad_norm': 9.476154327392578, 'learning_rate': 4.808755382098828e-07, 'epoch': 22.54}
 90%|█████████ | 15800/17525 [3:09:12<16:37,  1.73it/s][INFO|trainer.py:3512] 2024-06-25 05:12:33,888 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:12:33,888 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:12:33,888 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.05it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1921800374984741, 'eval_runtime': 4.5901, 'eval_samples_per_second': 96.512, 'eval_steps_per_second': 4.139, 'epoch': 22.54}
 90%|█████████ | 15800/17525 [3:09:17<16:37,  1.73it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 90%|█████████ | 15801/17525 [3:09:17<56:16,  1.96s/it] 90%|█████████ | 15802/17525 [3:09:18<44:20,  1.54s/it] 90%|█████████ | 15803/17525 [3:09:19<38:44,  1.35s/it] 90%|█████████ | 15804/17525 [3:09:19<32:06,  1.12s/it] 90%|█████████ | 15805/17525 [3:09:20<27:26,  1.04it/s] 90%|█████████ | 15806/17525 [3:09:20<24:09,  1.19it/s] 90%|█████████ | 15807/17525 [3:09:21<21:52,  1.31it/s] 90%|█████████ | 15808/17525 [3:09:22<20:23,  1.40it/s] 90%|█████████ | 15809/17525 [3:09:22<19:14,  1.49it/s] 90%|█████████ | 15810/17525 [3:09:23<18:23,  1.55it/s]                                                       {'loss': 0.3755, 'grad_norm': 9.968999862670898, 'learning_rate': 4.75392497301157e-07, 'epoch': 22.55}
 90%|█████████ | 15810/17525 [3:09:23<18:23,  1.55it/s] 90%|█████████ | 15811/17525 [3:09:23<17:52,  1.60it/s] 90%|█████████ | 15812/17525 [3:09:24<17:27,  1.63it/s] 90%|█████████ | 15813/17525 [3:09:24<17:08,  1.66it/s] 90%|█████████ | 15814/17525 [3:09:25<16:57,  1.68it/s] 90%|█████████ | 15815/17525 [3:09:26<16:48,  1.70it/s] 90%|█████████ | 15816/17525 [3:09:26<16:42,  1.70it/s] 90%|█████████ | 15817/17525 [3:09:27<16:36,  1.71it/s] 90%|█████████ | 15818/17525 [3:09:27<16:32,  1.72it/s] 90%|█████████ | 15819/17525 [3:09:28<16:31,  1.72it/s] 90%|█████████ | 15820/17525 [3:09:29<19:34,  1.45it/s]                                                       {'loss': 0.3072, 'grad_norm': 8.154420852661133, 'learning_rate': 4.6994013407056784e-07, 'epoch': 22.57}
 90%|█████████ | 15820/17525 [3:09:29<19:34,  1.45it/s] 90%|█████████ | 15821/17525 [3:09:29<18:40,  1.52it/s] 90%|█████████ | 15822/17525 [3:09:30<18:00,  1.58it/s] 90%|█████████ | 15823/17525 [3:09:31<17:33,  1.62it/s] 90%|█████████ | 15824/17525 [3:09:31<17:10,  1.65it/s] 90%|█████████ | 15825/17525 [3:09:32<16:53,  1.68it/s] 90%|█████████ | 15826/17525 [3:09:32<16:41,  1.70it/s] 90%|█████████ | 15827/17525 [3:09:33<16:34,  1.71it/s] 90%|█████████ | 15828/17525 [3:09:33<16:28,  1.72it/s] 90%|█████████ | 15829/17525 [3:09:34<16:25,  1.72it/s] 90%|█████████ | 15830/17525 [3:09:35<16:21,  1.73it/s]                                                       {'loss': 0.3378, 'grad_norm': 19.307785034179688, 'learning_rate': 4.645184660795532e-07, 'epoch': 22.58}
 90%|█████████ | 15830/17525 [3:09:35<16:21,  1.73it/s] 90%|█████████ | 15831/17525 [3:09:35<16:20,  1.73it/s] 90%|█████████ | 15832/17525 [3:09:36<16:21,  1.73it/s] 90%|█████████ | 15833/17525 [3:09:36<16:24,  1.72it/s] 90%|█████████ | 15834/17525 [3:09:37<16:23,  1.72it/s] 90%|█████████ | 15835/17525 [3:09:38<16:20,  1.72it/s] 90%|█████████ | 15836/17525 [3:09:38<16:21,  1.72it/s] 90%|█████████ | 15837/17525 [3:09:39<16:21,  1.72it/s] 90%|█████████ | 15838/17525 [3:09:39<16:20,  1.72it/s] 90%|█████████ | 15839/17525 [3:09:40<16:19,  1.72it/s] 90%|█████████ | 15840/17525 [3:09:40<16:16,  1.73it/s]                                                       {'loss': 0.4141, 'grad_norm': 13.531181335449219, 'learning_rate': 4.591275107906956e-07, 'epoch': 22.6}
 90%|█████████ | 15840/17525 [3:09:40<16:16,  1.73it/s] 90%|█████████ | 15841/17525 [3:09:41<16:16,  1.72it/s] 90%|█████████ | 15842/17525 [3:09:42<16:23,  1.71it/s] 90%|█████████ | 15843/17525 [3:09:42<16:17,  1.72it/s] 90%|█████████ | 15844/17525 [3:09:43<16:18,  1.72it/s] 90%|█████████ | 15845/17525 [3:09:43<16:18,  1.72it/s] 90%|█████████ | 15846/17525 [3:09:44<16:14,  1.72it/s] 90%|█████████ | 15847/17525 [3:09:45<16:12,  1.73it/s] 90%|█████████ | 15848/17525 [3:09:45<16:15,  1.72it/s] 90%|█████████ | 15849/17525 [3:09:46<16:13,  1.72it/s] 90%|█████████ | 15850/17525 [3:09:46<16:10,  1.73it/s]                                                       {'loss': 0.3859, 'grad_norm': 10.211220741271973, 'learning_rate': 4.537672855676434e-07, 'epoch': 22.61}
 90%|█████████ | 15850/17525 [3:09:46<16:10,  1.73it/s] 90%|█████████ | 15851/17525 [3:09:47<16:08,  1.73it/s] 90%|█████████ | 15852/17525 [3:09:47<16:06,  1.73it/s] 90%|█████████ | 15853/17525 [3:09:48<16:04,  1.73it/s] 90%|█████████ | 15854/17525 [3:09:49<16:03,  1.73it/s] 90%|█████████ | 15855/17525 [3:09:49<16:03,  1.73it/s] 90%|█████████ | 15856/17525 [3:09:50<16:02,  1.73it/s] 90%|█████████ | 15857/17525 [3:09:50<16:01,  1.73it/s] 90%|█████████ | 15858/17525 [3:09:51<16:01,  1.73it/s] 90%|█████████ | 15859/17525 [3:09:51<16:00,  1.74it/s] 90%|█████████ | 15860/17525 [3:09:52<16:00,  1.73it/s]                                                       {'loss': 0.3704, 'grad_norm': 16.79706573486328, 'learning_rate': 4.4843780767507837e-07, 'epoch': 22.62}
 90%|█████████ | 15860/17525 [3:09:52<16:00,  1.73it/s] 91%|█████████ | 15861/17525 [3:09:53<16:02,  1.73it/s] 91%|█████████ | 15862/17525 [3:09:53<16:02,  1.73it/s] 91%|█████████ | 15863/17525 [3:09:54<16:02,  1.73it/s] 91%|█████████ | 15864/17525 [3:09:54<16:02,  1.73it/s] 91%|█████████ | 15865/17525 [3:09:55<19:03,  1.45it/s] 91%|█████████ | 15866/17525 [3:09:56<18:06,  1.53it/s] 91%|█████████ | 15867/17525 [3:09:56<17:26,  1.58it/s] 91%|█████████ | 15868/17525 [3:09:57<16:59,  1.63it/s] 91%|█████████ | 15869/17525 [3:09:58<16:38,  1.66it/s] 91%|█████████ | 15870/17525 [3:09:58<16:26,  1.68it/s]                                                       {'loss': 0.2712, 'grad_norm': 13.198626518249512, 'learning_rate': 4.4313909427863957e-07, 'epoch': 22.64}
 91%|█████████ | 15870/17525 [3:09:58<16:26,  1.68it/s] 91%|█████████ | 15871/17525 [3:09:59<16:19,  1.69it/s] 91%|█████████ | 15872/17525 [3:09:59<16:13,  1.70it/s] 91%|█████████ | 15873/17525 [3:10:00<16:10,  1.70it/s] 91%|█████████ | 15874/17525 [3:10:00<16:07,  1.71it/s] 91%|█████████ | 15875/17525 [3:10:01<16:03,  1.71it/s] 91%|█████████ | 15876/17525 [3:10:02<15:59,  1.72it/s] 91%|█████████ | 15877/17525 [3:10:02<15:57,  1.72it/s] 91%|█████████ | 15878/17525 [3:10:03<15:53,  1.73it/s] 91%|█████████ | 15879/17525 [3:10:03<15:50,  1.73it/s] 91%|█████████ | 15880/17525 [3:10:04<15:48,  1.73it/s]                                                       {'loss': 0.3292, 'grad_norm': 10.48470687866211, 'learning_rate': 4.3787116244488057e-07, 'epoch': 22.65}
 91%|█████████ | 15880/17525 [3:10:04<15:48,  1.73it/s] 91%|█████████ | 15881/17525 [3:10:05<15:49,  1.73it/s] 91%|█████████ | 15882/17525 [3:10:05<15:47,  1.73it/s] 91%|█████████ | 15883/17525 [3:10:06<15:46,  1.73it/s] 91%|█████████ | 15884/17525 [3:10:06<15:44,  1.74it/s] 91%|█████████ | 15885/17525 [3:10:07<15:45,  1.73it/s] 91%|█████████ | 15886/17525 [3:10:07<15:47,  1.73it/s] 91%|█████████ | 15887/17525 [3:10:08<15:47,  1.73it/s] 91%|█████████ | 15888/17525 [3:10:09<15:45,  1.73it/s] 91%|█████████ | 15889/17525 [3:10:09<17:23,  1.57it/s] 91%|█████████ | 15890/17525 [3:10:10<16:52,  1.61it/s]                                                       {'loss': 0.2846, 'grad_norm': 10.409564018249512, 'learning_rate': 4.3263402914121234e-07, 'epoch': 22.67}
 91%|█████████ | 15890/17525 [3:10:10<16:52,  1.61it/s] 91%|█████████ | 15891/17525 [3:10:11<16:32,  1.65it/s] 91%|█████████ | 15892/17525 [3:10:11<16:15,  1.67it/s] 91%|█████████ | 15893/17525 [3:10:12<16:05,  1.69it/s] 91%|█████████ | 15894/17525 [3:10:12<15:58,  1.70it/s] 91%|█████████ | 15895/17525 [3:10:13<15:52,  1.71it/s] 91%|█████████ | 15896/17525 [3:10:13<15:48,  1.72it/s] 91%|█████████ | 15897/17525 [3:10:14<15:44,  1.72it/s] 91%|█████████ | 15898/17525 [3:10:15<15:42,  1.73it/s] 91%|█████████ | 15899/17525 [3:10:15<15:39,  1.73it/s] 91%|█████████ | 15900/17525 [3:10:16<15:36,  1.74it/s]                                                       {'loss': 0.3452, 'grad_norm': 7.5732927322387695, 'learning_rate': 4.274277112358438e-07, 'epoch': 22.68}
 91%|█████████ | 15900/17525 [3:10:16<15:36,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:13:37,591 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:13:37,591 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:13:37,591 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.86it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.201995849609375, 'eval_runtime': 4.5974, 'eval_samples_per_second': 96.359, 'eval_steps_per_second': 4.133, 'epoch': 22.68}
 91%|█████████ | 15900/17525 [3:10:20<15:36,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:13:42,192 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15900
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bccad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 872c7857-21c9-48e7-a86c-dbe2e2753112)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:13:52,251 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15900/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:13:52,254 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-15900/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 91%|█████████ | 15901/17525 [3:10:31<2:15:53,  5.02s/it] 91%|█████████ | 15902/17525 [3:10:32<1:39:44,  3.69s/it] 91%|█████████ | 15903/17525 [3:10:32<1:14:27,  2.75s/it] 91%|█████████ | 15904/17525 [3:10:33<56:45,  2.10s/it]   91%|█████████ | 15905/17525 [3:10:33<44:22,  1.64s/it] 91%|█████████ | 15906/17525 [3:10:34<35:44,  1.32s/it] 91%|█████████ | 15907/17525 [3:10:35<35:59,  1.33s/it] 91%|█████████ | 15908/17525 [3:10:36<29:53,  1.11s/it] 91%|█████████ | 15909/17525 [3:10:36<25:33,  1.05it/s] 91%|█████████ | 15910/17525 [3:10:37<22:32,  1.19it/s]                                                       {'loss': 0.3373, 'grad_norm': 3.561194658279419, 'learning_rate': 4.222522254977368e-07, 'epoch': 22.7}
 91%|█████████ | 15910/17525 [3:10:37<22:32,  1.19it/s] 91%|█████████ | 15911/17525 [3:10:38<24:15,  1.11it/s] 91%|█████████ | 15912/17525 [3:10:39<21:37,  1.24it/s] 91%|█████████ | 15913/17525 [3:10:39<19:45,  1.36it/s] 91%|█████████ | 15914/17525 [3:10:40<18:28,  1.45it/s] 91%|█████████ | 15915/17525 [3:10:40<17:35,  1.53it/s] 91%|█████████ | 15916/17525 [3:10:41<16:57,  1.58it/s] 91%|█████████ | 15917/17525 [3:10:42<16:28,  1.63it/s] 91%|█████████ | 15918/17525 [3:10:42<16:10,  1.66it/s] 91%|█████████ | 15919/17525 [3:10:43<17:07,  1.56it/s] 91%|█████████ | 15920/17525 [3:10:43<16:37,  1.61it/s]                                                       {'loss': 0.3467, 'grad_norm': 6.935973167419434, 'learning_rate': 4.171075885965392e-07, 'epoch': 22.71}
 91%|█████████ | 15920/17525 [3:10:43<16:37,  1.61it/s] 91%|█████████ | 15921/17525 [3:10:44<19:38,  1.36it/s] 91%|█████████ | 15922/17525 [3:10:45<18:21,  1.46it/s] 91%|█████████ | 15923/17525 [3:10:46<17:27,  1.53it/s] 91%|█████████ | 15924/17525 [3:10:46<16:51,  1.58it/s] 91%|█████████ | 15925/17525 [3:10:47<16:32,  1.61it/s] 91%|█████████ | 15926/17525 [3:10:47<16:14,  1.64it/s] 91%|█████████ | 15927/17525 [3:10:48<15:59,  1.66it/s] 91%|█████████ | 15928/17525 [3:10:49<15:52,  1.68it/s] 91%|█████████ | 15929/17525 [3:10:49<15:55,  1.67it/s] 91%|█████████ | 15930/17525 [3:10:50<15:44,  1.69it/s]                                                       {'loss': 0.3648, 'grad_norm': 18.567127227783203, 'learning_rate': 4.119938171025428e-07, 'epoch': 22.72}
 91%|█████████ | 15930/17525 [3:10:50<15:44,  1.69it/s] 91%|█████████ | 15931/17525 [3:10:50<15:38,  1.70it/s] 91%|█████████ | 15932/17525 [3:10:51<15:34,  1.71it/s] 91%|█████████ | 15933/17525 [3:10:51<15:28,  1.71it/s] 91%|█████████ | 15934/17525 [3:10:52<15:26,  1.72it/s] 91%|█████████ | 15935/17525 [3:10:53<18:45,  1.41it/s] 91%|█████████ | 15936/17525 [3:10:54<17:43,  1.49it/s] 91%|█████████ | 15937/17525 [3:10:55<19:46,  1.34it/s] 91%|█████████ | 15938/17525 [3:10:55<18:25,  1.44it/s] 91%|█████████ | 15939/17525 [3:10:56<17:47,  1.49it/s] 91%|█████████ | 15940/17525 [3:10:56<17:02,  1.55it/s]                                                       {'loss': 0.3826, 'grad_norm': 8.917522430419922, 'learning_rate': 4.069109274866245e-07, 'epoch': 22.74}
 91%|█████████ | 15940/17525 [3:10:56<17:02,  1.55it/s] 91%|█████████ | 15941/17525 [3:10:57<18:04,  1.46it/s] 91%|█████████ | 15942/17525 [3:10:58<17:13,  1.53it/s] 91%|█████████ | 15943/17525 [3:10:58<16:37,  1.59it/s] 91%|█████████ | 15944/17525 [3:10:59<16:12,  1.63it/s] 91%|█████████ | 15945/17525 [3:10:59<15:54,  1.65it/s] 91%|█████████ | 15946/17525 [3:11:00<15:41,  1.68it/s] 91%|█████████ | 15947/17525 [3:11:01<15:31,  1.69it/s] 91%|█████████ | 15948/17525 [3:11:01<15:25,  1.70it/s] 91%|█████████ | 15949/17525 [3:11:02<15:20,  1.71it/s] 91%|█████████ | 15950/17525 [3:11:02<15:16,  1.72it/s]                                                       {'loss': 0.3593, 'grad_norm': 8.109623908996582, 'learning_rate': 4.01858936120193e-07, 'epoch': 22.75}
 91%|█████████ | 15950/17525 [3:11:02<15:16,  1.72it/s] 91%|█████████ | 15951/17525 [3:11:03<15:13,  1.72it/s] 91%|█████████ | 15952/17525 [3:11:03<15:11,  1.73it/s] 91%|█████████ | 15953/17525 [3:11:04<15:10,  1.73it/s] 91%|█████████ | 15954/17525 [3:11:05<15:08,  1.73it/s] 91%|█████████ | 15955/17525 [3:11:05<15:09,  1.73it/s] 91%|█████████ | 15956/17525 [3:11:06<15:09,  1.73it/s] 91%|█████████ | 15957/17525 [3:11:06<15:07,  1.73it/s] 91%|█████████ | 15958/17525 [3:11:07<15:05,  1.73it/s] 91%|█████████ | 15959/17525 [3:11:08<15:04,  1.73it/s] 91%|█████████ | 15960/17525 [3:11:08<15:03,  1.73it/s]                                                       {'loss': 0.3101, 'grad_norm': 16.897502899169922, 'learning_rate': 3.968378592751399e-07, 'epoch': 22.77}
 91%|█████████ | 15960/17525 [3:11:08<15:03,  1.73it/s] 91%|█████████ | 15961/17525 [3:11:09<15:10,  1.72it/s] 91%|█████████ | 15962/17525 [3:11:09<15:05,  1.73it/s] 91%|█████████ | 15963/17525 [3:11:10<15:12,  1.71it/s] 91%|█████████ | 15964/17525 [3:11:11<17:50,  1.46it/s] 91%|█████████ | 15965/17525 [3:11:11<17:11,  1.51it/s] 91%|█████████ | 15966/17525 [3:11:12<16:32,  1.57it/s] 91%|█████████ | 15967/17525 [3:11:13<16:03,  1.62it/s] 91%|█████████ | 15968/17525 [3:11:13<15:44,  1.65it/s] 91%|█████████ | 15969/17525 [3:11:14<15:31,  1.67it/s] 91%|█████████ | 15970/17525 [3:11:14<15:21,  1.69it/s]                                                       {'loss': 0.4013, 'grad_norm': 6.336503982543945, 'learning_rate': 3.918477131237841e-07, 'epoch': 22.78}
 91%|█████████ | 15970/17525 [3:11:14<15:21,  1.69it/s] 91%|█████████ | 15971/17525 [3:11:15<15:17,  1.69it/s] 91%|█████████ | 15972/17525 [3:11:15<15:10,  1.70it/s] 91%|█████████ | 15973/17525 [3:11:16<15:09,  1.71it/s] 91%|█████████ | 15974/17525 [3:11:17<15:05,  1.71it/s] 91%|█████████ | 15975/17525 [3:11:17<15:01,  1.72it/s] 91%|█████████ | 15976/17525 [3:11:18<16:04,  1.61it/s] 91%|█████████ | 15977/17525 [3:11:19<18:30,  1.39it/s] 91%|█████████ | 15978/17525 [3:11:19<17:22,  1.48it/s] 91%|█████████ | 15979/17525 [3:11:20<16:39,  1.55it/s] 91%|█████████ | 15980/17525 [3:11:21<18:37,  1.38it/s]                                                       {'loss': 0.2552, 'grad_norm': 11.699814796447754, 'learning_rate': 3.8688851373881453e-07, 'epoch': 22.8}
 91%|█████████ | 15980/17525 [3:11:21<18:37,  1.38it/s] 91%|█████████ | 15981/17525 [3:11:21<17:30,  1.47it/s] 91%|█████████ | 15982/17525 [3:11:22<16:40,  1.54it/s] 91%|█████████ | 15983/17525 [3:11:23<16:07,  1.59it/s] 91%|█████████ | 15984/17525 [3:11:23<15:42,  1.63it/s] 91%|█████████ | 15985/17525 [3:11:24<15:26,  1.66it/s] 91%|█████████ | 15986/17525 [3:11:24<15:12,  1.69it/s] 91%|█████████ | 15987/17525 [3:11:25<15:15,  1.68it/s] 91%|█████████ | 15988/17525 [3:11:26<15:05,  1.70it/s] 91%|█████████ | 15989/17525 [3:11:26<14:58,  1.71it/s] 91%|█████████ | 15990/17525 [3:11:27<14:53,  1.72it/s]                                                       {'loss': 0.4131, 'grad_norm': 8.260903358459473, 'learning_rate': 3.819602770932529e-07, 'epoch': 22.81}
 91%|█████████ | 15990/17525 [3:11:27<14:53,  1.72it/s] 91%|█████████ | 15991/17525 [3:11:27<14:49,  1.72it/s] 91%|█████████▏| 15992/17525 [3:11:28<14:46,  1.73it/s] 91%|█████████▏| 15993/17525 [3:11:28<14:46,  1.73it/s] 91%|█████████▏| 15994/17525 [3:11:30<22:35,  1.13it/s] 91%|█████████▏| 15995/17525 [3:11:31<20:12,  1.26it/s] 91%|█████████▏| 15996/17525 [3:11:31<18:32,  1.37it/s] 91%|█████████▏| 15997/17525 [3:11:32<17:22,  1.47it/s] 91%|█████████▏| 15998/17525 [3:11:32<16:32,  1.54it/s] 91%|█████████▏| 15999/17525 [3:11:33<15:56,  1.60it/s] 91%|█████████▏| 16000/17525 [3:11:33<15:31,  1.64it/s]                                                       {'loss': 0.4171, 'grad_norm': 16.13286781311035, 'learning_rate': 3.770630190603874e-07, 'epoch': 22.82}
 91%|█████████▏| 16000/17525 [3:11:33<15:31,  1.64it/s][INFO|trainer.py:3512] 2024-06-25 05:14:55,336 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:14:55,336 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:14:55,336 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.81it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1987392902374268, 'eval_runtime': 4.5969, 'eval_samples_per_second': 96.369, 'eval_steps_per_second': 4.133, 'epoch': 22.82}
 91%|█████████▏| 16000/17525 [3:11:38<15:31,  1.64it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 91%|█████████▏| 16001/17525 [3:11:39<50:18,  1.98s/it] 91%|█████████▏| 16002/17525 [3:11:39<39:34,  1.56s/it] 91%|█████████▏| 16003/17525 [3:11:40<34:51,  1.37s/it] 91%|█████████▏| 16004/17525 [3:11:41<28:44,  1.13s/it] 91%|█████████▏| 16005/17525 [3:11:41<24:29,  1.03it/s] 91%|█████████▏| 16006/17525 [3:11:42<21:28,  1.18it/s] 91%|█████████▏| 16007/17525 [3:11:42<19:31,  1.30it/s] 91%|█████████▏| 16008/17525 [3:11:43<18:00,  1.40it/s] 91%|█████████▏| 16009/17525 [3:11:44<16:57,  1.49it/s] 91%|█████████▏| 16010/17525 [3:11:44<16:12,  1.56it/s]                                                       {'loss': 0.4376, 'grad_norm': 5.558046817779541, 'learning_rate': 3.721967554137307e-07, 'epoch': 22.84}
 91%|█████████▏| 16010/17525 [3:11:44<16:12,  1.56it/s] 91%|█████████▏| 16011/17525 [3:11:45<15:42,  1.61it/s] 91%|█████████▏| 16012/17525 [3:11:45<15:20,  1.64it/s] 91%|█████████▏| 16013/17525 [3:11:46<15:04,  1.67it/s] 91%|█████████▏| 16014/17525 [3:11:46<14:53,  1.69it/s] 91%|█████████▏| 16015/17525 [3:11:47<14:45,  1.71it/s] 91%|█████████▏| 16016/17525 [3:11:48<14:39,  1.72it/s] 91%|█████████▏| 16017/17525 [3:11:48<14:35,  1.72it/s] 91%|█████████▏| 16018/17525 [3:11:49<14:31,  1.73it/s] 91%|█████████▏| 16019/17525 [3:11:49<14:31,  1.73it/s] 91%|█████████▏| 16020/17525 [3:11:50<14:28,  1.73it/s]                                                       {'loss': 0.3333, 'grad_norm': 6.078148365020752, 'learning_rate': 3.6736150182696385e-07, 'epoch': 22.85}
 91%|█████████▏| 16020/17525 [3:11:50<14:28,  1.73it/s] 91%|█████████▏| 16021/17525 [3:11:51<14:28,  1.73it/s] 91%|█████████▏| 16022/17525 [3:11:51<14:27,  1.73it/s] 91%|█████████▏| 16023/17525 [3:11:52<14:26,  1.73it/s] 91%|█████████▏| 16024/17525 [3:11:52<14:26,  1.73it/s] 91%|█████████▏| 16025/17525 [3:11:53<14:26,  1.73it/s] 91%|█████████▏| 16026/17525 [3:11:53<14:24,  1.73it/s] 91%|█████████▏| 16027/17525 [3:11:54<14:23,  1.74it/s] 91%|█████████▏| 16028/17525 [3:11:55<14:22,  1.74it/s] 91%|█████████▏| 16029/17525 [3:11:55<14:21,  1.74it/s] 91%|█████████▏| 16030/17525 [3:11:56<14:20,  1.74it/s]                                                       {'loss': 0.3929, 'grad_norm': 6.584996700286865, 'learning_rate': 3.6255727387388807e-07, 'epoch': 22.87}
 91%|█████████▏| 16030/17525 [3:11:56<14:20,  1.74it/s] 91%|█████████▏| 16031/17525 [3:11:56<14:20,  1.74it/s] 91%|█████████▏| 16032/17525 [3:11:57<14:17,  1.74it/s] 91%|█████████▏| 16033/17525 [3:11:57<14:15,  1.74it/s] 91%|█████████▏| 16034/17525 [3:11:58<14:16,  1.74it/s] 91%|█████████▏| 16035/17525 [3:11:59<14:15,  1.74it/s] 92%|█████████▏| 16036/17525 [3:11:59<15:21,  1.62it/s] 92%|█████████▏| 16037/17525 [3:12:00<15:01,  1.65it/s] 92%|█████████▏| 16038/17525 [3:12:00<14:47,  1.68it/s] 92%|█████████▏| 16039/17525 [3:12:01<14:37,  1.69it/s] 92%|█████████▏| 16040/17525 [3:12:02<14:28,  1.71it/s]                                                       {'loss': 0.3068, 'grad_norm': 12.18802547454834, 'learning_rate': 3.5778408702837885e-07, 'epoch': 22.88}
 92%|█████████▏| 16040/17525 [3:12:02<14:28,  1.71it/s] 92%|█████████▏| 16041/17525 [3:12:02<14:33,  1.70it/s] 92%|█████████▏| 16042/17525 [3:12:03<14:26,  1.71it/s] 92%|█████████▏| 16043/17525 [3:12:03<14:19,  1.72it/s] 92%|█████████▏| 16044/17525 [3:12:04<14:16,  1.73it/s] 92%|█████████▏| 16045/17525 [3:12:04<14:13,  1.73it/s] 92%|█████████▏| 16046/17525 [3:12:05<14:12,  1.73it/s] 92%|█████████▏| 16047/17525 [3:12:06<14:10,  1.74it/s] 92%|█████████▏| 16048/17525 [3:12:07<18:42,  1.32it/s] 92%|█████████▏| 16049/17525 [3:12:07<17:20,  1.42it/s] 92%|█████████▏| 16050/17525 [3:12:08<16:24,  1.50it/s]                                                       {'loss': 0.3474, 'grad_norm': 27.119848251342773, 'learning_rate': 3.5304195666432396e-07, 'epoch': 22.9}
 92%|█████████▏| 16050/17525 [3:12:08<16:24,  1.50it/s][INFO|trainer.py:3203] 2024-06-25 05:15:29,862 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16050
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bccad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 87a40bcf-3b71-44eb-9c12-e457a1917fc1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:15:39,920 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16050/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:15:39,922 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16050/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 92%|█████████▏| 16051/17525 [3:12:19<1:30:57,  3.70s/it] 92%|█████████▏| 16052/17525 [3:12:19<1:07:51,  2.76s/it] 92%|█████████▏| 16053/17525 [3:12:20<51:42,  2.11s/it]   92%|█████████▏| 16054/17525 [3:12:20<40:25,  1.65s/it] 92%|█████████▏| 16055/17525 [3:12:21<32:32,  1.33s/it] 92%|█████████▏| 16056/17525 [3:12:22<27:00,  1.10s/it] 92%|█████████▏| 16057/17525 [3:12:22<23:10,  1.06it/s] 92%|█████████▏| 16058/17525 [3:12:23<20:26,  1.20it/s] 92%|█████████▏| 16059/17525 [3:12:23<18:32,  1.32it/s] 92%|█████████▏| 16060/17525 [3:12:24<17:09,  1.42it/s]                                                       {'loss': 0.3594, 'grad_norm': 15.562786102294922, 'learning_rate': 3.4833089805559106e-07, 'epoch': 22.91}
 92%|█████████▏| 16060/17525 [3:12:24<17:09,  1.42it/s] 92%|█████████▏| 16061/17525 [3:12:25<16:13,  1.50it/s] 92%|█████████▏| 16062/17525 [3:12:25<15:32,  1.57it/s] 92%|█████████▏| 16063/17525 [3:12:26<15:05,  1.61it/s] 92%|█████████▏| 16064/17525 [3:12:26<14:47,  1.65it/s] 92%|█████████▏| 16065/17525 [3:12:27<14:31,  1.67it/s] 92%|█████████▏| 16066/17525 [3:12:27<14:35,  1.67it/s] 92%|█████████▏| 16067/17525 [3:12:28<14:24,  1.69it/s] 92%|█████████▏| 16068/17525 [3:12:29<14:24,  1.68it/s] 92%|█████████▏| 16069/17525 [3:12:29<14:15,  1.70it/s] 92%|█████████▏| 16070/17525 [3:12:30<14:10,  1.71it/s]                                                       {'loss': 0.3858, 'grad_norm': 12.47906494140625, 'learning_rate': 3.436509263759613e-07, 'epoch': 22.92}
 92%|█████████▏| 16070/17525 [3:12:30<14:10,  1.71it/s] 92%|█████████▏| 16071/17525 [3:12:30<14:06,  1.72it/s] 92%|█████████▏| 16072/17525 [3:12:31<14:03,  1.72it/s] 92%|█████████▏| 16073/17525 [3:12:31<14:00,  1.73it/s] 92%|█████████▏| 16074/17525 [3:12:32<13:59,  1.73it/s] 92%|█████████▏| 16075/17525 [3:12:33<13:57,  1.73it/s] 92%|█████████▏| 16076/17525 [3:12:33<13:55,  1.73it/s] 92%|█████████▏| 16077/17525 [3:12:34<13:54,  1.74it/s] 92%|█████████▏| 16078/17525 [3:12:34<13:52,  1.74it/s] 92%|█████████▏| 16079/17525 [3:12:35<13:50,  1.74it/s] 92%|█████████▏| 16080/17525 [3:12:36<13:50,  1.74it/s]                                                       {'loss': 0.3613, 'grad_norm': 7.798850059509277, 'learning_rate': 3.390020566990915e-07, 'epoch': 22.94}
 92%|█████████▏| 16080/17525 [3:12:36<13:50,  1.74it/s] 92%|█████████▏| 16081/17525 [3:12:36<13:49,  1.74it/s] 92%|█████████▏| 16082/17525 [3:12:37<13:49,  1.74it/s] 92%|█████████▏| 16083/17525 [3:12:37<13:49,  1.74it/s] 92%|█████████▏| 16084/17525 [3:12:38<13:50,  1.73it/s] 92%|█████████▏| 16085/17525 [3:12:39<15:10,  1.58it/s] 92%|█████████▏| 16086/17525 [3:12:39<14:45,  1.63it/s] 92%|█████████▏| 16087/17525 [3:12:40<14:27,  1.66it/s] 92%|█████████▏| 16088/17525 [3:12:40<14:14,  1.68it/s] 92%|█████████▏| 16089/17525 [3:12:41<14:04,  1.70it/s] 92%|█████████▏| 16090/17525 [3:12:41<13:58,  1.71it/s]                                                       {'loss': 0.3638, 'grad_norm': 11.984889030456543, 'learning_rate': 3.34384303998464e-07, 'epoch': 22.95}
 92%|█████████▏| 16090/17525 [3:12:41<13:58,  1.71it/s] 92%|█████████▏| 16091/17525 [3:12:42<13:54,  1.72it/s] 92%|█████████▏| 16092/17525 [3:12:43<13:50,  1.73it/s] 92%|█████████▏| 16093/17525 [3:12:43<13:48,  1.73it/s] 92%|█████████▏| 16094/17525 [3:12:44<13:46,  1.73it/s] 92%|█████████▏| 16095/17525 [3:12:44<13:43,  1.74it/s] 92%|█████████▏| 16096/17525 [3:12:45<13:41,  1.74it/s] 92%|█████████▏| 16097/17525 [3:12:45<13:39,  1.74it/s] 92%|█████████▏| 16098/17525 [3:12:46<13:39,  1.74it/s] 92%|█████████▏| 16099/17525 [3:12:47<13:39,  1.74it/s] 92%|█████████▏| 16100/17525 [3:12:47<13:39,  1.74it/s]                                                       {'loss': 0.3418, 'grad_norm': 11.923872947692871, 'learning_rate': 3.297976831473337e-07, 'epoch': 22.97}
 92%|█████████▏| 16100/17525 [3:12:47<13:39,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:16:09,092 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:16:09,092 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:16:09,092 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:03,  5.64it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.79it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1930080652236938, 'eval_runtime': 4.6221, 'eval_samples_per_second': 95.843, 'eval_steps_per_second': 4.111, 'epoch': 22.97}
 92%|█████████▏| 16100/17525 [3:12:52<13:39,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 92%|█████████▏| 16101/17525 [3:12:52<46:51,  1.97s/it] 92%|█████████▏| 16102/17525 [3:12:53<36:52,  1.55s/it] 92%|█████████▏| 16103/17525 [3:12:54<29:52,  1.26s/it] 92%|█████████▏| 16104/17525 [3:12:54<25:02,  1.06s/it] 92%|█████████▏| 16105/17525 [3:12:55<21:36,  1.10it/s] 92%|█████████▏| 16106/17525 [3:12:55<19:11,  1.23it/s] 92%|█████████▏| 16107/17525 [3:12:56<17:30,  1.35it/s] 92%|█████████▏| 16108/17525 [3:12:56<16:19,  1.45it/s] 92%|█████████▏| 16109/17525 [3:12:57<15:27,  1.53it/s] 92%|█████████▏| 16110/17525 [3:12:58<14:53,  1.58it/s]                                                       {'loss': 0.2834, 'grad_norm': 10.129079818725586, 'learning_rate': 3.2524220891868683e-07, 'epoch': 22.98}
 92%|█████████▏| 16110/17525 [3:12:58<14:53,  1.58it/s] 92%|█████████▏| 16111/17525 [3:12:58<14:30,  1.62it/s] 92%|█████████▏| 16112/17525 [3:12:59<14:12,  1.66it/s] 92%|█████████▏| 16113/17525 [3:12:59<14:00,  1.68it/s] 92%|█████████▏| 16114/17525 [3:13:00<13:51,  1.70it/s] 92%|█████████▏| 16115/17525 [3:13:00<13:45,  1.71it/s] 92%|█████████▏| 16116/17525 [3:13:01<13:40,  1.72it/s] 92%|█████████▏| 16117/17525 [3:13:02<13:37,  1.72it/s] 92%|█████████▏| 16118/17525 [3:13:02<14:35,  1.61it/s] 92%|█████████▏| 16119/17525 [3:13:03<14:15,  1.64it/s] 92%|█████████▏| 16120/17525 [3:13:04<14:02,  1.67it/s]                                                       {'loss': 0.3111, 'grad_norm': 9.605165481567383, 'learning_rate': 3.2071789598518753e-07, 'epoch': 23.0}
 92%|█████████▏| 16120/17525 [3:13:04<14:02,  1.67it/s] 92%|█████████▏| 16121/17525 [3:13:04<13:51,  1.69it/s] 92%|█████████▏| 16122/17525 [3:13:05<13:43,  1.70it/s] 92%|█████████▏| 16123/17525 [3:13:05<13:37,  1.72it/s] 92%|█████████▏| 16124/17525 [3:13:06<13:33,  1.72it/s] 92%|█████████▏| 16125/17525 [3:13:06<13:30,  1.73it/s] 92%|█████████▏| 16126/17525 [3:13:07<13:29,  1.73it/s] 92%|█████████▏| 16127/17525 [3:13:08<13:27,  1.73it/s] 92%|█████████▏| 16128/17525 [3:13:08<13:46,  1.69it/s] 92%|█████████▏| 16129/17525 [3:13:09<13:38,  1.71it/s] 92%|█████████▏| 16130/17525 [3:13:09<13:32,  1.72it/s]                                                       {'loss': 0.2887, 'grad_norm': 8.849125862121582, 'learning_rate': 3.162247589191325e-07, 'epoch': 23.01}
 92%|█████████▏| 16130/17525 [3:13:09<13:32,  1.72it/s] 92%|█████████▏| 16131/17525 [3:13:10<13:29,  1.72it/s] 92%|█████████▏| 16132/17525 [3:13:10<13:25,  1.73it/s] 92%|█████████▏| 16133/17525 [3:13:11<13:24,  1.73it/s] 92%|█████████▏| 16134/17525 [3:13:12<13:22,  1.73it/s] 92%|█████████▏| 16135/17525 [3:13:12<13:20,  1.74it/s] 92%|█████████▏| 16136/17525 [3:13:13<16:19,  1.42it/s] 92%|█████████▏| 16137/17525 [3:13:14<15:25,  1.50it/s] 92%|█████████▏| 16138/17525 [3:13:14<14:48,  1.56it/s] 92%|█████████▏| 16139/17525 [3:13:15<14:19,  1.61it/s] 92%|█████████▏| 16140/17525 [3:13:16<13:58,  1.65it/s]                                                       {'loss': 0.295, 'grad_norm': 6.033238887786865, 'learning_rate': 3.1176281219240657e-07, 'epoch': 23.02}
 92%|█████████▏| 16140/17525 [3:13:16<13:58,  1.65it/s] 92%|█████████▏| 16141/17525 [3:13:16<13:48,  1.67it/s] 92%|█████████▏| 16142/17525 [3:13:17<13:38,  1.69it/s] 92%|█████████▏| 16143/17525 [3:13:17<13:30,  1.70it/s] 92%|█████████▏| 16144/17525 [3:13:18<13:24,  1.72it/s] 92%|█████████▏| 16145/17525 [3:13:18<13:26,  1.71it/s] 92%|█████████▏| 16146/17525 [3:13:19<13:22,  1.72it/s] 92%|█████████▏| 16147/17525 [3:13:20<13:18,  1.73it/s] 92%|█████████▏| 16148/17525 [3:13:20<13:15,  1.73it/s] 92%|█████████▏| 16149/17525 [3:13:21<13:15,  1.73it/s] 92%|█████████▏| 16150/17525 [3:13:21<13:14,  1.73it/s]                                                       {'loss': 0.3096, 'grad_norm': 6.584863185882568, 'learning_rate': 3.0733207017643265e-07, 'epoch': 23.04}
 92%|█████████▏| 16150/17525 [3:13:21<13:14,  1.73it/s] 92%|█████████▏| 16151/17525 [3:13:22<13:16,  1.72it/s] 92%|█████████▏| 16152/17525 [3:13:22<13:20,  1.71it/s] 92%|█████████▏| 16153/17525 [3:13:23<13:16,  1.72it/s] 92%|█████████▏| 16154/17525 [3:13:24<13:12,  1.73it/s] 92%|█████████▏| 16155/17525 [3:13:24<13:21,  1.71it/s] 92%|█████████▏| 16156/17525 [3:13:25<13:20,  1.71it/s] 92%|█████████▏| 16157/17525 [3:13:25<13:16,  1.72it/s] 92%|█████████▏| 16158/17525 [3:13:26<13:12,  1.72it/s] 92%|█████████▏| 16159/17525 [3:13:27<13:10,  1.73it/s] 92%|█████████▏| 16160/17525 [3:13:27<13:09,  1.73it/s]                                                       {'loss': 0.3447, 'grad_norm': 9.460627555847168, 'learning_rate': 3.0293254714212514e-07, 'epoch': 23.05}
 92%|█████████▏| 16160/17525 [3:13:27<13:09,  1.73it/s] 92%|█████████▏| 16161/17525 [3:13:28<13:09,  1.73it/s] 92%|█████████▏| 16162/17525 [3:13:28<13:08,  1.73it/s] 92%|█████████▏| 16163/17525 [3:13:29<13:09,  1.72it/s] 92%|█████████▏| 16164/17525 [3:13:29<13:07,  1.73it/s] 92%|█████████▏| 16165/17525 [3:13:30<13:06,  1.73it/s] 92%|█████████▏| 16166/17525 [3:13:31<13:05,  1.73it/s] 92%|█████████▏| 16167/17525 [3:13:31<13:03,  1.73it/s] 92%|█████████▏| 16168/17525 [3:13:32<14:19,  1.58it/s] 92%|█████████▏| 16169/17525 [3:13:32<13:55,  1.62it/s] 92%|█████████▏| 16170/17525 [3:13:33<13:38,  1.66it/s]                                                       {'loss': 0.3178, 'grad_norm': 7.838024616241455, 'learning_rate': 2.985642572598524e-07, 'epoch': 23.07}
 92%|█████████▏| 16170/17525 [3:13:33<13:38,  1.66it/s] 92%|█████████▏| 16171/17525 [3:13:34<13:26,  1.68it/s] 92%|█████████▏| 16172/17525 [3:13:34<13:17,  1.70it/s] 92%|█████████▏| 16173/17525 [3:13:35<13:11,  1.71it/s] 92%|█████████▏| 16174/17525 [3:13:35<13:05,  1.72it/s] 92%|█████████▏| 16175/17525 [3:13:36<13:01,  1.73it/s] 92%|█████████▏| 16176/17525 [3:13:36<12:59,  1.73it/s] 92%|█████████▏| 16177/17525 [3:13:37<14:17,  1.57it/s] 92%|█████████▏| 16178/17525 [3:13:38<13:51,  1.62it/s] 92%|█████████▏| 16179/17525 [3:13:38<13:34,  1.65it/s] 92%|█████████▏| 16180/17525 [3:13:39<13:27,  1.66it/s]                                                       {'loss': 0.3757, 'grad_norm': 10.306118965148926, 'learning_rate': 2.942272145993741e-07, 'epoch': 23.08}
 92%|█████████▏| 16180/17525 [3:13:39<13:27,  1.66it/s] 92%|█████████▏| 16181/17525 [3:13:40<13:18,  1.68it/s] 92%|█████████▏| 16182/17525 [3:13:40<13:09,  1.70it/s] 92%|█████████▏| 16183/17525 [3:13:41<13:03,  1.71it/s] 92%|█████████▏| 16184/17525 [3:13:41<13:00,  1.72it/s] 92%|█████████▏| 16185/17525 [3:13:42<13:07,  1.70it/s] 92%|█████████▏| 16186/17525 [3:13:42<13:03,  1.71it/s] 92%|█████████▏| 16187/17525 [3:13:43<13:00,  1.72it/s] 92%|█████████▏| 16188/17525 [3:13:44<12:55,  1.72it/s] 92%|█████████▏| 16189/17525 [3:13:44<12:57,  1.72it/s] 92%|█████████▏| 16190/17525 [3:13:45<12:54,  1.72it/s]                                                       {'loss': 0.2612, 'grad_norm': 10.233077049255371, 'learning_rate': 2.899214331298172e-07, 'epoch': 23.1}
 92%|█████████▏| 16190/17525 [3:13:45<12:54,  1.72it/s] 92%|█████████▏| 16191/17525 [3:13:45<12:54,  1.72it/s] 92%|█████████▏| 16192/17525 [3:13:46<12:51,  1.73it/s] 92%|█████████▏| 16193/17525 [3:13:47<12:50,  1.73it/s] 92%|█████████▏| 16194/17525 [3:13:47<12:47,  1.73it/s] 92%|█████████▏| 16195/17525 [3:13:48<14:04,  1.58it/s] 92%|█████████▏| 16196/17525 [3:13:49<14:07,  1.57it/s] 92%|█████████▏| 16197/17525 [3:13:49<13:42,  1.61it/s] 92%|█████████▏| 16198/17525 [3:13:50<15:49,  1.40it/s] 92%|█████████▏| 16199/17525 [3:13:51<14:54,  1.48it/s] 92%|█████████▏| 16200/17525 [3:13:51<14:14,  1.55it/s]                                                       {'loss': 0.2699, 'grad_norm': 18.123577117919922, 'learning_rate': 2.8564692671960937e-07, 'epoch': 23.11}
 92%|█████████▏| 16200/17525 [3:13:51<14:14,  1.55it/s][INFO|trainer.py:3512] 2024-06-25 05:17:13,095 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:17:13,096 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:17:13,096 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.79it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.60it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1956442594528198, 'eval_runtime': 4.5934, 'eval_samples_per_second': 96.442, 'eval_steps_per_second': 4.136, 'epoch': 23.11}
 92%|█████████▏| 16200/17525 [3:13:56<14:14,  1.55it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:17:17,692 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16200
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bfd990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 9ecde6f0-99e8-4af7-b72e-96642a6ce471)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:17:27,749 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:17:27,751 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16200/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 92%|█████████▏| 16201/17525 [3:14:07<1:51:53,  5.07s/it] 92%|█████████▏| 16202/17525 [3:14:07<1:22:04,  3.72s/it] 92%|█████████▏| 16203/17525 [3:14:08<1:01:12,  2.78s/it] 92%|█████████▏| 16204/17525 [3:14:08<46:37,  2.12s/it]   92%|█████████▏| 16205/17525 [3:14:09<36:24,  1.65s/it] 92%|█████████▏| 16206/17525 [3:14:09<29:15,  1.33s/it] 92%|█████████▏| 16207/17525 [3:14:10<24:15,  1.10s/it] 92%|█████████▏| 16208/17525 [3:14:11<23:56,  1.09s/it] 92%|█████████▏| 16209/17525 [3:14:12<20:32,  1.07it/s] 92%|█████████▏| 16210/17525 [3:14:12<18:15,  1.20it/s]                                                       {'loss': 0.3436, 'grad_norm': 7.0321879386901855, 'learning_rate': 2.81403709136453e-07, 'epoch': 23.12}
 92%|█████████▏| 16210/17525 [3:14:12<18:15,  1.20it/s] 93%|█████████▎| 16211/17525 [3:14:13<16:34,  1.32it/s] 93%|█████████▎| 16212/17525 [3:14:13<15:24,  1.42it/s] 93%|█████████▎| 16213/17525 [3:14:14<14:39,  1.49it/s] 93%|█████████▎| 16214/17525 [3:14:15<14:02,  1.56it/s] 93%|█████████▎| 16215/17525 [3:14:15<13:41,  1.60it/s] 93%|█████████▎| 16216/17525 [3:14:16<13:20,  1.64it/s] 93%|█████████▎| 16217/17525 [3:14:16<13:05,  1.66it/s] 93%|█████████▎| 16218/17525 [3:14:17<12:55,  1.68it/s] 93%|█████████▎| 16219/17525 [3:14:18<12:48,  1.70it/s] 93%|█████████▎| 16220/17525 [3:14:18<12:42,  1.71it/s]                                                       {'loss': 0.3442, 'grad_norm': 9.263792037963867, 'learning_rate': 2.7719179404726794e-07, 'epoch': 23.14}
 93%|█████████▎| 16220/17525 [3:14:18<12:42,  1.71it/s] 93%|█████████▎| 16221/17525 [3:14:19<12:41,  1.71it/s] 93%|█████████▎| 16222/17525 [3:14:19<12:39,  1.72it/s] 93%|█████████▎| 16223/17525 [3:14:20<12:36,  1.72it/s] 93%|█████████▎| 16224/17525 [3:14:20<12:35,  1.72it/s] 93%|█████████▎| 16225/17525 [3:14:21<12:35,  1.72it/s] 93%|█████████▎| 16226/17525 [3:14:22<12:33,  1.72it/s] 93%|█████████▎| 16227/17525 [3:14:22<12:31,  1.73it/s] 93%|█████████▎| 16228/17525 [3:14:23<12:33,  1.72it/s] 93%|█████████▎| 16229/17525 [3:14:23<12:32,  1.72it/s] 93%|█████████▎| 16230/17525 [3:14:24<12:34,  1.72it/s]                                                       {'loss': 0.3184, 'grad_norm': 7.011515140533447, 'learning_rate': 2.7301119501815464e-07, 'epoch': 23.15}
 93%|█████████▎| 16230/17525 [3:14:24<12:34,  1.72it/s] 93%|█████████▎| 16231/17525 [3:14:24<12:31,  1.72it/s] 93%|█████████▎| 16232/17525 [3:14:25<12:27,  1.73it/s] 93%|█████████▎| 16233/17525 [3:14:26<12:24,  1.73it/s] 93%|█████████▎| 16234/17525 [3:14:26<12:23,  1.74it/s] 93%|█████████▎| 16235/17525 [3:14:27<12:23,  1.74it/s] 93%|█████████▎| 16236/17525 [3:14:27<12:23,  1.73it/s] 93%|█████████▎| 16237/17525 [3:14:28<12:24,  1.73it/s] 93%|█████████▎| 16238/17525 [3:14:28<12:24,  1.73it/s] 93%|█████████▎| 16239/17525 [3:14:29<14:30,  1.48it/s] 93%|█████████▎| 16240/17525 [3:14:30<13:52,  1.54it/s]                                                       {'loss': 0.3691, 'grad_norm': 6.151900291442871, 'learning_rate': 2.6886192551434766e-07, 'epoch': 23.17}
 93%|█████████▎| 16240/17525 [3:14:30<13:52,  1.54it/s] 93%|█████████▎| 16241/17525 [3:14:31<13:28,  1.59it/s] 93%|█████████▎| 16242/17525 [3:14:31<13:08,  1.63it/s] 93%|█████████▎| 16243/17525 [3:14:32<12:57,  1.65it/s] 93%|█████████▎| 16244/17525 [3:14:32<12:46,  1.67it/s] 93%|█████████▎| 16245/17525 [3:14:33<12:36,  1.69it/s] 93%|█████████▎| 16246/17525 [3:14:33<12:30,  1.70it/s] 93%|█████████▎| 16247/17525 [3:14:34<12:29,  1.71it/s] 93%|█████████▎| 16248/17525 [3:14:35<12:24,  1.71it/s] 93%|█████████▎| 16249/17525 [3:14:35<12:20,  1.72it/s] 93%|█████████▎| 16250/17525 [3:14:36<12:19,  1.72it/s]                                                       {'loss': 0.3961, 'grad_norm': 16.939218521118164, 'learning_rate': 2.647439989001732e-07, 'epoch': 23.18}
 93%|█████████▎| 16250/17525 [3:14:36<12:19,  1.72it/s] 93%|█████████▎| 16251/17525 [3:14:36<12:19,  1.72it/s] 93%|█████████▎| 16252/17525 [3:14:37<14:16,  1.49it/s] 93%|█████████▎| 16253/17525 [3:14:38<13:40,  1.55it/s] 93%|█████████▎| 16254/17525 [3:14:39<15:31,  1.36it/s] 93%|█████████▎| 16255/17525 [3:14:40<21:11,  1.00s/it] 93%|█████████▎| 16256/17525 [3:14:41<18:28,  1.15it/s] 93%|█████████▎| 16257/17525 [3:14:42<16:33,  1.28it/s] 93%|█████████▎| 16258/17525 [3:14:42<15:13,  1.39it/s] 93%|█████████▎| 16259/17525 [3:14:43<14:20,  1.47it/s] 93%|█████████▎| 16260/17525 [3:14:43<13:41,  1.54it/s]                                                       {'loss': 0.2986, 'grad_norm': 6.936781406402588, 'learning_rate': 2.606574284390029e-07, 'epoch': 23.2}
 93%|█████████▎| 16260/17525 [3:14:43<13:41,  1.54it/s] 93%|█████████▎| 16261/17525 [3:14:44<13:14,  1.59it/s] 93%|█████████▎| 16262/17525 [3:14:44<12:54,  1.63it/s] 93%|█████████▎| 16263/17525 [3:14:45<12:42,  1.66it/s] 93%|█████████▎| 16264/17525 [3:14:46<12:31,  1.68it/s] 93%|█████████▎| 16265/17525 [3:14:46<12:22,  1.70it/s] 93%|█████████▎| 16266/17525 [3:14:47<12:15,  1.71it/s] 93%|█████████▎| 16267/17525 [3:14:47<12:11,  1.72it/s] 93%|█████████▎| 16268/17525 [3:14:48<12:09,  1.72it/s] 93%|█████████▎| 16269/17525 [3:14:48<12:07,  1.73it/s] 93%|█████████▎| 16270/17525 [3:14:49<12:08,  1.72it/s]                                                       {'loss': 0.3541, 'grad_norm': 8.320143699645996, 'learning_rate': 2.566022272932167e-07, 'epoch': 23.21}
 93%|█████████▎| 16270/17525 [3:14:49<12:08,  1.72it/s] 93%|█████████▎| 16271/17525 [3:14:50<12:06,  1.73it/s] 93%|█████████▎| 16272/17525 [3:14:50<12:05,  1.73it/s] 93%|█████████▎| 16273/17525 [3:14:51<12:04,  1.73it/s] 93%|█████████▎| 16274/17525 [3:14:51<12:04,  1.73it/s] 93%|█████████▎| 16275/17525 [3:14:52<12:02,  1.73it/s] 93%|█████████▎| 16276/17525 [3:14:53<12:17,  1.69it/s] 93%|█████████▎| 16277/17525 [3:14:53<12:14,  1.70it/s] 93%|█████████▎| 16278/17525 [3:14:54<12:08,  1.71it/s] 93%|█████████▎| 16279/17525 [3:14:54<12:05,  1.72it/s] 93%|█████████▎| 16280/17525 [3:14:55<12:01,  1.72it/s]                                                       {'loss': 0.3303, 'grad_norm': 12.669050216674805, 'learning_rate': 2.525784085241567e-07, 'epoch': 23.22}
 93%|█████████▎| 16280/17525 [3:14:55<12:01,  1.72it/s] 93%|█████████▎| 16281/17525 [3:14:55<12:02,  1.72it/s] 93%|█████████▎| 16282/17525 [3:14:56<11:59,  1.73it/s] 93%|█████████▎| 16283/17525 [3:14:57<11:58,  1.73it/s] 93%|█████████▎| 16284/17525 [3:14:57<11:57,  1.73it/s] 93%|█████████▎| 16285/17525 [3:14:58<11:56,  1.73it/s] 93%|█████████▎| 16286/17525 [3:14:58<11:55,  1.73it/s] 93%|█████████▎| 16287/17525 [3:14:59<11:53,  1.73it/s] 93%|█████████▎| 16288/17525 [3:14:59<11:53,  1.73it/s] 93%|█████████▎| 16289/17525 [3:15:00<11:52,  1.74it/s] 93%|█████████▎| 16290/17525 [3:15:01<11:50,  1.74it/s]                                                       {'loss': 0.3555, 'grad_norm': 11.01351261138916, 'learning_rate': 2.4858598509208463e-07, 'epoch': 23.24}
 93%|█████████▎| 16290/17525 [3:15:01<11:50,  1.74it/s] 93%|█████████▎| 16291/17525 [3:15:01<11:49,  1.74it/s] 93%|█████████▎| 16292/17525 [3:15:02<11:48,  1.74it/s] 93%|█████████▎| 16293/17525 [3:15:02<11:48,  1.74it/s] 93%|█████████▎| 16294/17525 [3:15:03<11:48,  1.74it/s] 93%|█████████▎| 16295/17525 [3:15:04<11:48,  1.74it/s] 93%|█████████▎| 16296/17525 [3:15:04<13:56,  1.47it/s] 93%|█████████▎| 16297/17525 [3:15:05<13:16,  1.54it/s] 93%|█████████▎| 16298/17525 [3:15:06<12:49,  1.59it/s] 93%|█████████▎| 16299/17525 [3:15:06<12:31,  1.63it/s] 93%|█████████▎| 16300/17525 [3:15:07<12:17,  1.66it/s]                                                       {'loss': 0.3605, 'grad_norm': 8.001150131225586, 'learning_rate': 2.446249698561454e-07, 'epoch': 23.25}
 93%|█████████▎| 16300/17525 [3:15:07<12:17,  1.66it/s][INFO|trainer.py:3512] 2024-06-25 05:18:28,710 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:18:28,710 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:18:28,710 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.03it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1983795166015625, 'eval_runtime': 4.5928, 'eval_samples_per_second': 96.456, 'eval_steps_per_second': 4.137, 'epoch': 23.25}
 93%|█████████▎| 16300/17525 [3:15:11<12:17,  1.66it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 93%|█████████▎| 16301/17525 [3:15:12<40:41,  2.00s/it] 93%|█████████▎| 16302/17525 [3:15:13<32:00,  1.57s/it] 93%|█████████▎| 16303/17525 [3:15:13<25:53,  1.27s/it] 93%|█████████▎| 16304/17525 [3:15:14<21:38,  1.06s/it] 93%|█████████▎| 16305/17525 [3:15:14<18:40,  1.09it/s] 93%|█████████▎| 16306/17525 [3:15:15<16:34,  1.23it/s] 93%|█████████▎| 16307/17525 [3:15:15<15:05,  1.35it/s] 93%|█████████▎| 16308/17525 [3:15:16<14:03,  1.44it/s] 93%|█████████▎| 16309/17525 [3:15:17<13:28,  1.50it/s] 93%|█████████▎| 16310/17525 [3:15:17<13:07,  1.54it/s]                                                       {'loss': 0.4937, 'grad_norm': 9.25204849243164, 'learning_rate': 2.406953755743147e-07, 'epoch': 23.27}
 93%|█████████▎| 16310/17525 [3:15:17<13:07,  1.54it/s] 93%|█████████▎| 16311/17525 [3:15:18<13:37,  1.49it/s] 93%|█████████▎| 16312/17525 [3:15:19<13:17,  1.52it/s] 93%|█████████▎| 16313/17525 [3:15:19<12:50,  1.57it/s] 93%|█████████▎| 16314/17525 [3:15:20<12:27,  1.62it/s] 93%|█████████▎| 16315/17525 [3:15:20<12:12,  1.65it/s] 93%|█████████▎| 16316/17525 [3:15:21<12:02,  1.67it/s] 93%|█████████▎| 16317/17525 [3:15:21<11:54,  1.69it/s] 93%|█████████▎| 16318/17525 [3:15:22<11:47,  1.71it/s] 93%|█████████▎| 16319/17525 [3:15:23<11:43,  1.72it/s] 93%|█████████▎| 16320/17525 [3:15:23<11:40,  1.72it/s]                                                       {'loss': 0.3348, 'grad_norm': 13.43014144897461, 'learning_rate': 2.3679721490337258e-07, 'epoch': 23.28}
 93%|█████████▎| 16320/17525 [3:15:23<11:40,  1.72it/s] 93%|█████████▎| 16321/17525 [3:15:24<11:38,  1.72it/s] 93%|█████████▎| 16322/17525 [3:15:24<11:35,  1.73it/s] 93%|█████████▎| 16323/17525 [3:15:25<11:34,  1.73it/s] 93%|█████████▎| 16324/17525 [3:15:26<11:33,  1.73it/s] 93%|█████████▎| 16325/17525 [3:15:26<11:32,  1.73it/s] 93%|█████████▎| 16326/17525 [3:15:27<11:32,  1.73it/s] 93%|█████████▎| 16327/17525 [3:15:27<11:31,  1.73it/s] 93%|█████████▎| 16328/17525 [3:15:28<11:30,  1.73it/s] 93%|█████████▎| 16329/17525 [3:15:28<11:30,  1.73it/s] 93%|█████████▎| 16330/17525 [3:15:29<11:30,  1.73it/s]                                                       {'loss': 0.345, 'grad_norm': 9.511295318603516, 'learning_rate': 2.3293050039884912e-07, 'epoch': 23.3}
 93%|█████████▎| 16330/17525 [3:15:29<11:30,  1.73it/s] 93%|█████████▎| 16331/17525 [3:15:30<11:29,  1.73it/s] 93%|█████████▎| 16332/17525 [3:15:30<11:27,  1.73it/s] 93%|█████████▎| 16333/17525 [3:15:31<11:28,  1.73it/s] 93%|█████████▎| 16334/17525 [3:15:31<11:27,  1.73it/s] 93%|█████████▎| 16335/17525 [3:15:32<11:27,  1.73it/s] 93%|█████████▎| 16336/17525 [3:15:32<11:26,  1.73it/s] 93%|█████████▎| 16337/17525 [3:15:33<11:24,  1.73it/s] 93%|█████████▎| 16338/17525 [3:15:34<11:33,  1.71it/s] 93%|█████████▎| 16339/17525 [3:15:34<11:29,  1.72it/s] 93%|█████████▎| 16340/17525 [3:15:35<11:26,  1.73it/s]                                                       {'loss': 0.366, 'grad_norm': 11.16701889038086, 'learning_rate': 2.2909524451499409e-07, 'epoch': 23.31}
 93%|█████████▎| 16340/17525 [3:15:35<11:26,  1.73it/s] 93%|█████████▎| 16341/17525 [3:15:35<11:34,  1.70it/s] 93%|█████████▎| 16342/17525 [3:15:36<11:31,  1.71it/s] 93%|█████████▎| 16343/17525 [3:15:37<11:28,  1.72it/s] 93%|█████████▎| 16344/17525 [3:15:37<11:24,  1.72it/s] 93%|█████████▎| 16345/17525 [3:15:38<11:22,  1.73it/s] 93%|█████████▎| 16346/17525 [3:15:38<11:20,  1.73it/s] 93%|█████████▎| 16347/17525 [3:15:39<11:19,  1.73it/s] 93%|█████████▎| 16348/17525 [3:15:39<11:17,  1.74it/s] 93%|█████████▎| 16349/17525 [3:15:40<11:24,  1.72it/s] 93%|█████████▎| 16350/17525 [3:15:41<11:20,  1.73it/s]                                                       {'loss': 0.3517, 'grad_norm': 10.653655052185059, 'learning_rate': 2.2529145960473065e-07, 'epoch': 23.32}
 93%|█████████▎| 16350/17525 [3:15:41<11:20,  1.73it/s][INFO|trainer.py:3203] 2024-06-25 05:19:02,468 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16350
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7bccad0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 008c127b-db00-4765-b3dc-57390ebbc0f1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:19:12,838 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:19:12,840 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16350/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 93%|█████████▎| 16351/17525 [3:15:52<1:13:06,  3.74s/it] 93%|█████████▎| 16352/17525 [3:15:52<54:30,  2.79s/it]   93%|█████████▎| 16353/17525 [3:15:53<41:29,  2.12s/it] 93%|█████████▎| 16354/17525 [3:15:53<32:23,  1.66s/it] 93%|█████████▎| 16355/17525 [3:15:54<26:00,  1.33s/it] 93%|█████████▎| 16356/17525 [3:15:55<22:24,  1.15s/it] 93%|█████████▎| 16357/17525 [3:15:55<19:00,  1.02it/s] 93%|█████████▎| 16358/17525 [3:15:56<16:39,  1.17it/s] 93%|█████████▎| 16359/17525 [3:15:56<15:01,  1.29it/s] 93%|█████████▎| 16360/17525 [3:15:57<13:51,  1.40it/s]                                                       {'loss': 0.4099, 'grad_norm': 10.861233711242676, 'learning_rate': 2.215191579196152e-07, 'epoch': 23.34}
 93%|█████████▎| 16360/17525 [3:15:57<13:51,  1.40it/s] 93%|█████████▎| 16361/17525 [3:15:58<13:21,  1.45it/s] 93%|█████████▎| 16362/17525 [3:15:58<12:42,  1.53it/s] 93%|█████████▎| 16363/17525 [3:15:59<12:13,  1.58it/s] 93%|█████████▎| 16364/17525 [3:15:59<11:54,  1.63it/s] 93%|█████████▎| 16365/17525 [3:16:00<11:40,  1.66it/s] 93%|█████████▎| 16366/17525 [3:16:01<11:29,  1.68it/s] 93%|█████████▎| 16367/17525 [3:16:01<11:23,  1.69it/s] 93%|█████████▎| 16368/17525 [3:16:02<11:19,  1.70it/s] 93%|█████████▎| 16369/17525 [3:16:02<12:15,  1.57it/s] 93%|█████████▎| 16370/17525 [3:16:03<11:54,  1.62it/s]                                                       {'loss': 0.2806, 'grad_norm': 14.216874122619629, 'learning_rate': 2.177783516098053e-07, 'epoch': 23.35}
 93%|█████████▎| 16370/17525 [3:16:03<11:54,  1.62it/s] 93%|█████████▎| 16371/17525 [3:16:04<11:39,  1.65it/s] 93%|█████████▎| 16372/17525 [3:16:04<11:27,  1.68it/s] 93%|█████████▎| 16373/17525 [3:16:05<11:19,  1.70it/s] 93%|█████████▎| 16374/17525 [3:16:05<11:13,  1.71it/s] 93%|█████████▎| 16375/17525 [3:16:06<11:10,  1.72it/s] 93%|█████████▎| 16376/17525 [3:16:06<11:07,  1.72it/s] 93%|█████████▎| 16377/17525 [3:16:07<11:03,  1.73it/s] 93%|█████████▎| 16378/17525 [3:16:08<11:02,  1.73it/s] 93%|█████████▎| 16379/17525 [3:16:08<11:00,  1.73it/s] 93%|█████████▎| 16380/17525 [3:16:09<11:00,  1.73it/s]                                                       {'loss': 0.2998, 'grad_norm': 5.513502597808838, 'learning_rate': 2.140690527240119e-07, 'epoch': 23.37}
 93%|█████████▎| 16380/17525 [3:16:09<11:00,  1.73it/s] 93%|█████████▎| 16381/17525 [3:16:09<11:01,  1.73it/s] 93%|█████████▎| 16382/17525 [3:16:10<10:59,  1.73it/s] 93%|█████████▎| 16383/17525 [3:16:10<10:59,  1.73it/s] 93%|█████████▎| 16384/17525 [3:16:11<10:57,  1.73it/s] 93%|█████████▎| 16385/17525 [3:16:12<10:57,  1.74it/s] 94%|█████████▎| 16386/17525 [3:16:12<10:56,  1.73it/s] 94%|█████████▎| 16387/17525 [3:16:13<10:56,  1.73it/s] 94%|█████████▎| 16388/17525 [3:16:13<10:55,  1.73it/s] 94%|█████████▎| 16389/17525 [3:16:14<10:54,  1.74it/s] 94%|█████████▎| 16390/17525 [3:16:15<10:53,  1.74it/s]                                                       {'loss': 0.3749, 'grad_norm': 11.2593994140625, 'learning_rate': 2.1039127320946596e-07, 'epoch': 23.38}
 94%|█████████▎| 16390/17525 [3:16:15<10:53,  1.74it/s] 94%|█████████▎| 16391/17525 [3:16:15<10:53,  1.73it/s] 94%|█████████▎| 16392/17525 [3:16:16<10:53,  1.73it/s] 94%|█████████▎| 16393/17525 [3:16:16<10:53,  1.73it/s] 94%|█████████▎| 16394/17525 [3:16:17<10:52,  1.73it/s] 94%|█████████▎| 16395/17525 [3:16:17<10:50,  1.74it/s] 94%|█████████▎| 16396/17525 [3:16:18<10:49,  1.74it/s] 94%|█████████▎| 16397/17525 [3:16:19<10:50,  1.73it/s] 94%|█████████▎| 16398/17525 [3:16:19<10:48,  1.74it/s] 94%|█████████▎| 16399/17525 [3:16:20<10:47,  1.74it/s] 94%|█████████▎| 16400/17525 [3:16:20<10:47,  1.74it/s]                                                       {'loss': 0.3824, 'grad_norm': 8.621814727783203, 'learning_rate': 2.067450249118752e-07, 'epoch': 23.4}
 94%|█████████▎| 16400/17525 [3:16:20<10:47,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:19:42,171 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:19:42,171 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:19:42,171 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.195449709892273, 'eval_runtime': 4.5968, 'eval_samples_per_second': 96.371, 'eval_steps_per_second': 4.133, 'epoch': 23.4}
 94%|█████████▎| 16400/17525 [3:16:25<10:47,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 94%|█████████▎| 16401/17525 [3:16:26<39:04,  2.09s/it] 94%|█████████▎| 16402/17525 [3:16:26<30:35,  1.63s/it] 94%|█████████▎| 16403/17525 [3:16:27<24:38,  1.32s/it] 94%|█████████▎| 16404/17525 [3:16:28<20:27,  1.10s/it] 94%|█████████▎| 16405/17525 [3:16:28<17:32,  1.06it/s] 94%|█████████▎| 16406/17525 [3:16:29<15:31,  1.20it/s] 94%|█████████▎| 16407/17525 [3:16:29<14:03,  1.33it/s] 94%|█████████▎| 16408/17525 [3:16:30<13:03,  1.43it/s] 94%|█████████▎| 16409/17525 [3:16:31<12:19,  1.51it/s] 94%|█████████▎| 16410/17525 [3:16:31<11:49,  1.57it/s]                                                       {'loss': 0.3006, 'grad_norm': 15.44880485534668, 'learning_rate': 2.0313031957539198e-07, 'epoch': 23.41}
 94%|█████████▎| 16410/17525 [3:16:31<11:49,  1.57it/s] 94%|█████████▎| 16411/17525 [3:16:32<11:29,  1.62it/s] 94%|█████████▎| 16412/17525 [3:16:32<11:13,  1.65it/s] 94%|█████████▎| 16413/17525 [3:16:33<11:10,  1.66it/s] 94%|█████████▎| 16414/17525 [3:16:33<11:00,  1.68it/s] 94%|█████████▎| 16415/17525 [3:16:34<10:54,  1.70it/s] 94%|█████████▎| 16416/17525 [3:16:35<10:48,  1.71it/s] 94%|█████████▎| 16417/17525 [3:16:35<10:44,  1.72it/s] 94%|█████████▎| 16418/17525 [3:16:36<10:40,  1.73it/s] 94%|█████████▎| 16419/17525 [3:16:36<10:39,  1.73it/s] 94%|█████████▎| 16420/17525 [3:16:37<10:38,  1.73it/s]                                                       {'loss': 0.3485, 'grad_norm': 5.8685102462768555, 'learning_rate': 1.9954716884257208e-07, 'epoch': 23.42}
 94%|█████████▎| 16420/17525 [3:16:37<10:38,  1.73it/s] 94%|█████████▎| 16421/17525 [3:16:37<10:38,  1.73it/s] 94%|█████████▎| 16422/17525 [3:16:38<10:37,  1.73it/s] 94%|█████████▎| 16423/17525 [3:16:39<10:36,  1.73it/s] 94%|█████████▎| 16424/17525 [3:16:39<10:35,  1.73it/s] 94%|█████████▎| 16425/17525 [3:16:40<10:34,  1.73it/s] 94%|█████████▎| 16426/17525 [3:16:40<10:33,  1.74it/s] 94%|█████████▎| 16427/17525 [3:16:41<10:32,  1.74it/s] 94%|█████████▎| 16428/17525 [3:16:41<10:31,  1.74it/s] 94%|█████████▎| 16429/17525 [3:16:42<10:31,  1.74it/s] 94%|█████████▍| 16430/17525 [3:16:43<10:30,  1.74it/s]                                                       {'loss': 0.3704, 'grad_norm': 9.779800415039062, 'learning_rate': 1.9599558425433597e-07, 'epoch': 23.44}
 94%|█████████▍| 16430/17525 [3:16:43<10:30,  1.74it/s] 94%|█████████▍| 16431/17525 [3:16:43<10:30,  1.73it/s] 94%|█████████▍| 16432/17525 [3:16:44<10:30,  1.73it/s] 94%|█████████▍| 16433/17525 [3:16:44<10:31,  1.73it/s] 94%|█████████▍| 16434/17525 [3:16:45<10:30,  1.73it/s] 94%|█████████▍| 16435/17525 [3:16:46<10:27,  1.74it/s] 94%|█████████▍| 16436/17525 [3:16:46<10:27,  1.74it/s] 94%|█████████▍| 16437/17525 [3:16:47<10:26,  1.74it/s] 94%|█████████▍| 16438/17525 [3:16:47<10:24,  1.74it/s] 94%|█████████▍| 16439/17525 [3:16:48<10:23,  1.74it/s] 94%|█████████▍| 16440/17525 [3:16:48<10:23,  1.74it/s]                                                       {'loss': 0.4055, 'grad_norm': 8.576982498168945, 'learning_rate': 1.9247557724993426e-07, 'epoch': 23.45}
 94%|█████████▍| 16440/17525 [3:16:48<10:23,  1.74it/s] 94%|█████████▍| 16441/17525 [3:16:49<10:25,  1.73it/s] 94%|█████████▍| 16442/17525 [3:16:50<10:24,  1.73it/s] 94%|█████████▍| 16443/17525 [3:16:50<10:24,  1.73it/s] 94%|█████████▍| 16444/17525 [3:16:51<10:35,  1.70it/s] 94%|█████████▍| 16445/17525 [3:16:51<10:31,  1.71it/s] 94%|█████████▍| 16446/17525 [3:16:52<10:26,  1.72it/s] 94%|█████████▍| 16447/17525 [3:16:52<10:25,  1.72it/s] 94%|█████████▍| 16448/17525 [3:16:53<10:23,  1.73it/s] 94%|█████████▍| 16449/17525 [3:16:54<10:22,  1.73it/s] 94%|█████████▍| 16450/17525 [3:16:54<10:19,  1.74it/s]                                                       {'loss': 0.306, 'grad_norm': 8.922402381896973, 'learning_rate': 1.8898715916690902e-07, 'epoch': 23.47}
 94%|█████████▍| 16450/17525 [3:16:54<10:19,  1.74it/s] 94%|█████████▍| 16451/17525 [3:16:55<10:21,  1.73it/s] 94%|█████████▍| 16452/17525 [3:16:56<14:31,  1.23it/s] 94%|█████████▍| 16453/17525 [3:16:57<13:14,  1.35it/s] 94%|█████████▍| 16454/17525 [3:16:57<12:20,  1.45it/s] 94%|█████████▍| 16455/17525 [3:16:58<11:42,  1.52it/s] 94%|█████████▍| 16456/17525 [3:16:58<11:16,  1.58it/s] 94%|█████████▍| 16457/17525 [3:16:59<10:57,  1.62it/s] 94%|█████████▍| 16458/17525 [3:17:00<10:44,  1.65it/s] 94%|█████████▍| 16459/17525 [3:17:00<10:34,  1.68it/s] 94%|█████████▍| 16460/17525 [3:17:01<10:27,  1.70it/s]                                                       {'loss': 0.3042, 'grad_norm': 14.052421569824219, 'learning_rate': 1.8553034124105807e-07, 'epoch': 23.48}
 94%|█████████▍| 16460/17525 [3:17:01<10:27,  1.70it/s] 94%|█████████▍| 16461/17525 [3:17:01<10:22,  1.71it/s] 94%|█████████▍| 16462/17525 [3:17:02<10:19,  1.72it/s] 94%|█████████▍| 16463/17525 [3:17:02<10:15,  1.73it/s] 94%|█████████▍| 16464/17525 [3:17:03<10:12,  1.73it/s] 94%|█████████▍| 16465/17525 [3:17:04<11:07,  1.59it/s] 94%|█████████▍| 16466/17525 [3:17:04<10:49,  1.63it/s] 94%|█████████▍| 16467/17525 [3:17:05<10:36,  1.66it/s] 94%|█████████▍| 16468/17525 [3:17:05<10:28,  1.68it/s] 94%|█████████▍| 16469/17525 [3:17:06<10:21,  1.70it/s] 94%|█████████▍| 16470/17525 [3:17:07<10:16,  1.71it/s]                                                       {'loss': 0.3783, 'grad_norm': 6.141567707061768, 'learning_rate': 1.8210513460640067e-07, 'epoch': 23.5}
 94%|█████████▍| 16470/17525 [3:17:07<10:16,  1.71it/s] 94%|█████████▍| 16471/17525 [3:17:08<14:23,  1.22it/s] 94%|█████████▍| 16472/17525 [3:17:09<13:06,  1.34it/s] 94%|█████████▍| 16473/17525 [3:17:09<12:10,  1.44it/s] 94%|█████████▍| 16474/17525 [3:17:10<11:32,  1.52it/s] 94%|█████████▍| 16475/17525 [3:17:10<11:05,  1.58it/s] 94%|█████████▍| 16476/17525 [3:17:11<10:46,  1.62it/s] 94%|█████████▍| 16477/17525 [3:17:11<10:32,  1.66it/s] 94%|█████████▍| 16478/17525 [3:17:12<10:22,  1.68it/s] 94%|█████████▍| 16479/17525 [3:17:13<10:16,  1.70it/s] 94%|█████████▍| 16480/17525 [3:17:13<10:11,  1.71it/s]                                                       {'loss': 0.324, 'grad_norm': 10.49398422241211, 'learning_rate': 1.7871155029513643e-07, 'epoch': 23.51}
 94%|█████████▍| 16480/17525 [3:17:13<10:11,  1.71it/s] 94%|█████████▍| 16481/17525 [3:17:14<10:08,  1.72it/s] 94%|█████████▍| 16482/17525 [3:17:14<10:05,  1.72it/s] 94%|█████████▍| 16483/17525 [3:17:15<10:02,  1.73it/s] 94%|█████████▍| 16484/17525 [3:17:16<11:55,  1.45it/s] 94%|█████████▍| 16485/17525 [3:17:16<11:20,  1.53it/s] 94%|█████████▍| 16486/17525 [3:17:17<10:54,  1.59it/s] 94%|█████████▍| 16487/17525 [3:17:18<10:37,  1.63it/s] 94%|█████████▍| 16488/17525 [3:17:18<10:24,  1.66it/s] 94%|█████████▍| 16489/17525 [3:17:19<10:15,  1.68it/s] 94%|█████████▍| 16490/17525 [3:17:19<10:08,  1.70it/s]                                                       {'loss': 0.4216, 'grad_norm': 8.134044647216797, 'learning_rate': 1.753495992376153e-07, 'epoch': 23.52}
 94%|█████████▍| 16490/17525 [3:17:19<10:08,  1.70it/s] 94%|█████████▍| 16491/17525 [3:17:20<10:03,  1.71it/s] 94%|█████████▍| 16492/17525 [3:17:20<09:59,  1.72it/s] 94%|█████████▍| 16493/17525 [3:17:21<09:57,  1.73it/s] 94%|█████████▍| 16494/17525 [3:17:22<09:55,  1.73it/s] 94%|█████████▍| 16495/17525 [3:17:23<11:40,  1.47it/s] 94%|█████████▍| 16496/17525 [3:17:23<11:54,  1.44it/s] 94%|█████████▍| 16497/17525 [3:17:24<11:17,  1.52it/s] 94%|█████████▍| 16498/17525 [3:17:24<10:51,  1.58it/s] 94%|█████████▍| 16499/17525 [3:17:25<10:33,  1.62it/s] 94%|█████████▍| 16500/17525 [3:17:26<10:20,  1.65it/s]                                                       {'loss': 0.2888, 'grad_norm': 18.840980529785156, 'learning_rate': 1.7201929226229873e-07, 'epoch': 23.54}
 94%|█████████▍| 16500/17525 [3:17:26<10:20,  1.65it/s][INFO|trainer.py:3512] 2024-06-25 05:20:47,459 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:20:47,459 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:20:47,459 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1944506168365479, 'eval_runtime': 4.6117, 'eval_samples_per_second': 96.061, 'eval_steps_per_second': 4.12, 'epoch': 23.54}
 94%|█████████▍| 16500/17525 [3:17:30<10:20,  1.65it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:20:52,075 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16500
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7fc37113-0314-4031-a988-b3da75e8a749)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:21:02,388 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:21:02,391 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16500/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 94%|█████████▍| 16501/17525 [3:17:41<1:27:26,  5.12s/it] 94%|█████████▍| 16502/17525 [3:17:42<1:04:04,  3.76s/it] 94%|█████████▍| 16503/17525 [3:17:42<47:46,  2.80s/it]   94%|█████████▍| 16504/17525 [3:17:43<36:21,  2.14s/it] 94%|█████████▍| 16505/17525 [3:17:44<28:21,  1.67s/it] 94%|█████████▍| 16506/17525 [3:17:44<22:45,  1.34s/it] 94%|█████████▍| 16507/17525 [3:17:45<18:50,  1.11s/it] 94%|█████████▍| 16508/17525 [3:17:45<16:05,  1.05it/s] 94%|█████████▍| 16509/17525 [3:17:46<14:09,  1.20it/s] 94%|█████████▍| 16510/17525 [3:17:46<12:51,  1.32it/s]                                                       {'loss': 0.2955, 'grad_norm': 6.78842306137085, 'learning_rate': 1.6872064009572863e-07, 'epoch': 23.55}
 94%|█████████▍| 16510/17525 [3:17:46<12:51,  1.32it/s] 94%|█████████▍| 16511/17525 [3:17:47<11:55,  1.42it/s] 94%|█████████▍| 16512/17525 [3:17:48<11:15,  1.50it/s] 94%|█████████▍| 16513/17525 [3:17:48<10:46,  1.57it/s] 94%|█████████▍| 16514/17525 [3:17:49<10:26,  1.61it/s] 94%|█████████▍| 16515/17525 [3:17:49<10:11,  1.65it/s] 94%|█████████▍| 16516/17525 [3:17:50<10:00,  1.68it/s] 94%|█████████▍| 16517/17525 [3:17:50<09:54,  1.70it/s] 94%|█████████▍| 16518/17525 [3:17:51<09:48,  1.71it/s] 94%|█████████▍| 16519/17525 [3:17:52<09:45,  1.72it/s] 94%|█████████▍| 16520/17525 [3:17:52<09:43,  1.72it/s]                                                       {'loss': 0.3372, 'grad_norm': 8.259293556213379, 'learning_rate': 1.654536533624873e-07, 'epoch': 23.57}
 94%|█████████▍| 16520/17525 [3:17:52<09:43,  1.72it/s] 94%|█████████▍| 16521/17525 [3:17:53<09:42,  1.72it/s] 94%|█████████▍| 16522/17525 [3:17:53<09:47,  1.71it/s] 94%|█████████▍| 16523/17525 [3:17:54<09:44,  1.72it/s] 94%|█████████▍| 16524/17525 [3:17:55<10:24,  1.60it/s] 94%|█████████▍| 16525/17525 [3:17:55<10:09,  1.64it/s] 94%|█████████▍| 16526/17525 [3:17:56<09:58,  1.67it/s] 94%|█████████▍| 16527/17525 [3:17:56<09:51,  1.69it/s] 94%|█████████▍| 16528/17525 [3:17:57<09:46,  1.70it/s] 94%|█████████▍| 16529/17525 [3:17:58<09:42,  1.71it/s] 94%|█████████▍| 16530/17525 [3:17:58<09:38,  1.72it/s]                                                       {'loss': 0.4048, 'grad_norm': 8.190001487731934, 'learning_rate': 1.6221834258516755e-07, 'epoch': 23.58}
 94%|█████████▍| 16530/17525 [3:17:58<09:38,  1.72it/s] 94%|█████████▍| 16531/17525 [3:17:59<09:36,  1.72it/s] 94%|█████████▍| 16532/17525 [3:17:59<09:34,  1.73it/s] 94%|█████████▍| 16533/17525 [3:18:00<09:32,  1.73it/s] 94%|█████████▍| 16534/17525 [3:18:00<09:31,  1.73it/s] 94%|█████████▍| 16535/17525 [3:18:01<09:29,  1.74it/s] 94%|█████████▍| 16536/17525 [3:18:02<09:38,  1.71it/s] 94%|█████████▍| 16537/17525 [3:18:02<09:34,  1.72it/s] 94%|█████████▍| 16538/17525 [3:18:03<09:31,  1.73it/s] 94%|█████████▍| 16539/17525 [3:18:03<09:29,  1.73it/s] 94%|█████████▍| 16540/17525 [3:18:04<09:29,  1.73it/s]                                                       {'loss': 0.3561, 'grad_norm': 11.11359977722168, 'learning_rate': 1.5901471818433823e-07, 'epoch': 23.59}
 94%|█████████▍| 16540/17525 [3:18:04<09:29,  1.73it/s] 94%|█████████▍| 16541/17525 [3:18:04<09:28,  1.73it/s] 94%|█████████▍| 16542/17525 [3:18:05<09:33,  1.71it/s] 94%|█████████▍| 16543/17525 [3:18:06<09:31,  1.72it/s] 94%|█████████▍| 16544/17525 [3:18:06<09:29,  1.72it/s] 94%|█████████▍| 16545/17525 [3:18:07<09:26,  1.73it/s] 94%|█████████▍| 16546/17525 [3:18:07<09:25,  1.73it/s] 94%|█████████▍| 16547/17525 [3:18:08<09:23,  1.74it/s] 94%|█████████▍| 16548/17525 [3:18:09<12:22,  1.32it/s] 94%|█████████▍| 16549/17525 [3:18:10<11:27,  1.42it/s] 94%|█████████▍| 16550/17525 [3:18:10<10:49,  1.50it/s]                                                       {'loss': 0.3254, 'grad_norm': 7.4165215492248535, 'learning_rate': 1.558427904785098e-07, 'epoch': 23.61}
 94%|█████████▍| 16550/17525 [3:18:10<10:49,  1.50it/s] 94%|█████████▍| 16551/17525 [3:18:11<10:22,  1.56it/s] 94%|█████████▍| 16552/17525 [3:18:11<10:02,  1.61it/s] 94%|█████████▍| 16553/17525 [3:18:12<09:48,  1.65it/s] 94%|█████████▍| 16554/17525 [3:18:13<09:40,  1.67it/s] 94%|█████████▍| 16555/17525 [3:18:13<09:35,  1.69it/s] 94%|█████████▍| 16556/17525 [3:18:14<09:28,  1.70it/s] 94%|█████████▍| 16557/17525 [3:18:14<09:24,  1.71it/s] 94%|█████████▍| 16558/17525 [3:18:15<09:21,  1.72it/s] 94%|█████████▍| 16559/17525 [3:18:15<09:18,  1.73it/s] 94%|█████████▍| 16560/17525 [3:18:16<09:16,  1.74it/s]                                                       {'loss': 0.3821, 'grad_norm': 3.4589197635650635, 'learning_rate': 1.5270256968410003e-07, 'epoch': 23.62}
 94%|█████████▍| 16560/17525 [3:18:16<09:16,  1.74it/s] 94%|█████████▍| 16561/17525 [3:18:17<09:14,  1.74it/s] 95%|█████████▍| 16562/17525 [3:18:17<09:14,  1.74it/s] 95%|█████████▍| 16563/17525 [3:18:18<09:18,  1.72it/s] 95%|█████████▍| 16564/17525 [3:18:18<09:15,  1.73it/s] 95%|█████████▍| 16565/17525 [3:18:19<09:13,  1.73it/s] 95%|█████████▍| 16566/17525 [3:18:19<09:12,  1.74it/s] 95%|█████████▍| 16567/17525 [3:18:20<09:11,  1.74it/s] 95%|█████████▍| 16568/17525 [3:18:21<09:11,  1.74it/s] 95%|█████████▍| 16569/17525 [3:18:21<09:10,  1.74it/s] 95%|█████████▍| 16570/17525 [3:18:22<09:10,  1.74it/s]                                                       {'loss': 0.3726, 'grad_norm': 10.822630882263184, 'learning_rate': 1.495940659154027e-07, 'epoch': 23.64}
 95%|█████████▍| 16570/17525 [3:18:22<09:10,  1.74it/s] 95%|█████████▍| 16571/17525 [3:18:22<09:11,  1.73it/s] 95%|█████████▍| 16572/17525 [3:18:23<09:09,  1.73it/s] 95%|█████████▍| 16573/17525 [3:18:24<09:08,  1.74it/s] 95%|█████████▍| 16574/17525 [3:18:24<09:06,  1.74it/s] 95%|█████████▍| 16575/17525 [3:18:25<09:05,  1.74it/s] 95%|█████████▍| 16576/17525 [3:18:25<09:05,  1.74it/s] 95%|█████████▍| 16577/17525 [3:18:26<09:05,  1.74it/s] 95%|█████████▍| 16578/17525 [3:18:26<09:04,  1.74it/s] 95%|█████████▍| 16579/17525 [3:18:27<09:04,  1.74it/s] 95%|█████████▍| 16580/17525 [3:18:28<09:04,  1.73it/s]                                                       {'loss': 0.4058, 'grad_norm': 7.25944709777832, 'learning_rate': 1.4651728918455676e-07, 'epoch': 23.65}
 95%|█████████▍| 16580/17525 [3:18:28<09:04,  1.73it/s] 95%|█████████▍| 16581/17525 [3:18:28<09:05,  1.73it/s] 95%|█████████▍| 16582/17525 [3:18:29<09:04,  1.73it/s] 95%|█████████▍| 16583/17525 [3:18:29<09:04,  1.73it/s] 95%|█████████▍| 16584/17525 [3:18:30<09:03,  1.73it/s] 95%|█████████▍| 16585/17525 [3:18:30<09:01,  1.74it/s] 95%|█████████▍| 16586/17525 [3:18:31<09:00,  1.74it/s] 95%|█████████▍| 16587/17525 [3:18:32<09:00,  1.74it/s] 95%|█████████▍| 16588/17525 [3:18:32<08:59,  1.74it/s] 95%|█████████▍| 16589/17525 [3:18:33<08:57,  1.74it/s] 95%|█████████▍| 16590/17525 [3:18:33<09:00,  1.73it/s]                                                       {'loss': 0.333, 'grad_norm': 11.183126449584961, 'learning_rate': 1.434722494015084e-07, 'epoch': 23.67}
 95%|█████████▍| 16590/17525 [3:18:33<09:00,  1.73it/s] 95%|█████████▍| 16591/17525 [3:18:34<08:59,  1.73it/s] 95%|█████████▍| 16592/17525 [3:18:34<08:58,  1.73it/s] 95%|█████████▍| 16593/17525 [3:18:35<08:56,  1.74it/s] 95%|█████████▍| 16594/17525 [3:18:36<08:57,  1.73it/s] 95%|█████████▍| 16595/17525 [3:18:36<08:56,  1.73it/s] 95%|█████████▍| 16596/17525 [3:18:37<08:55,  1.74it/s] 95%|█████████▍| 16597/17525 [3:18:37<08:53,  1.74it/s] 95%|█████████▍| 16598/17525 [3:18:38<09:03,  1.71it/s] 95%|█████████▍| 16599/17525 [3:18:39<09:00,  1.71it/s] 95%|█████████▍| 16600/17525 [3:18:39<08:57,  1.72it/s]                                                       {'loss': 0.283, 'grad_norm': 5.6075215339660645, 'learning_rate': 1.4045895637398665e-07, 'epoch': 23.68}
 95%|█████████▍| 16600/17525 [3:18:39<08:57,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:22:00,997 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:22:00,997 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:22:00,997 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1962213516235352, 'eval_runtime': 4.5965, 'eval_samples_per_second': 96.377, 'eval_steps_per_second': 4.134, 'epoch': 23.68}
 95%|█████████▍| 16600/17525 [3:18:44<08:57,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A 95%|█████████▍| 16601/17525 [3:18:44<30:12,  1.96s/it] 95%|█████████▍| 16602/17525 [3:18:45<23:46,  1.55s/it] 95%|█████████▍| 16603/17525 [3:18:45<19:16,  1.25s/it] 95%|█████████▍| 16604/17525 [3:18:46<17:46,  1.16s/it] 95%|█████████▍| 16605/17525 [3:18:47<15:04,  1.02it/s] 95%|█████████▍| 16606/17525 [3:18:48<13:11,  1.16it/s] 95%|█████████▍| 16607/17525 [3:18:48<11:52,  1.29it/s] 95%|█████████▍| 16608/17525 [3:18:49<10:56,  1.40it/s] 95%|█████████▍| 16609/17525 [3:18:50<11:56,  1.28it/s] 95%|█████████▍| 16610/17525 [3:18:50<10:59,  1.39it/s]                                                       {'loss': 0.3013, 'grad_norm': 5.794300556182861, 'learning_rate': 1.3747741980746464e-07, 'epoch': 23.69}
 95%|█████████▍| 16610/17525 [3:18:50<10:59,  1.39it/s] 95%|█████████▍| 16611/17525 [3:18:51<10:19,  1.48it/s] 95%|█████████▍| 16612/17525 [3:18:51<09:50,  1.55it/s] 95%|█████████▍| 16613/17525 [3:18:52<09:32,  1.59it/s] 95%|█████████▍| 16614/17525 [3:18:52<09:17,  1.63it/s] 95%|█████████▍| 16615/17525 [3:18:53<09:06,  1.66it/s] 95%|█████████▍| 16616/17525 [3:18:54<08:59,  1.69it/s] 95%|█████████▍| 16617/17525 [3:18:54<08:53,  1.70it/s] 95%|█████████▍| 16618/17525 [3:18:55<08:49,  1.71it/s] 95%|█████████▍| 16619/17525 [3:18:55<08:46,  1.72it/s] 95%|█████████▍| 16620/17525 [3:18:56<08:44,  1.73it/s]                                                       {'loss': 0.3525, 'grad_norm': 6.870838165283203, 'learning_rate': 1.3452764930513284e-07, 'epoch': 23.71}
 95%|█████████▍| 16620/17525 [3:18:56<08:44,  1.73it/s] 95%|█████████▍| 16621/17525 [3:18:57<08:43,  1.73it/s] 95%|█████████▍| 16622/17525 [3:18:57<08:41,  1.73it/s] 95%|█████████▍| 16623/17525 [3:18:58<08:40,  1.73it/s] 95%|█████████▍| 16624/17525 [3:18:58<09:33,  1.57it/s] 95%|█████████▍| 16625/17525 [3:18:59<09:16,  1.62it/s] 95%|█████████▍| 16626/17525 [3:19:00<09:03,  1.65it/s] 95%|█████████▍| 16627/17525 [3:19:00<08:53,  1.68it/s] 95%|█████████▍| 16628/17525 [3:19:01<08:47,  1.70it/s] 95%|█████████▍| 16629/17525 [3:19:01<08:42,  1.71it/s] 95%|█████████▍| 16630/17525 [3:19:02<08:40,  1.72it/s]                                                       {'loss': 0.3268, 'grad_norm': 15.138082504272461, 'learning_rate': 1.3160965436786687e-07, 'epoch': 23.72}
 95%|█████████▍| 16630/17525 [3:19:02<08:40,  1.72it/s] 95%|█████████▍| 16631/17525 [3:19:02<08:37,  1.73it/s] 95%|█████████▍| 16632/17525 [3:19:03<10:26,  1.43it/s] 95%|█████████▍| 16633/17525 [3:19:04<09:51,  1.51it/s] 95%|█████████▍| 16634/17525 [3:19:05<09:26,  1.57it/s] 95%|█████████▍| 16635/17525 [3:19:05<09:10,  1.62it/s] 95%|█████████▍| 16636/17525 [3:19:06<08:57,  1.65it/s] 95%|█████████▍| 16637/17525 [3:19:06<08:48,  1.68it/s] 95%|█████████▍| 16638/17525 [3:19:07<08:43,  1.69it/s] 95%|█████████▍| 16639/17525 [3:19:07<08:39,  1.71it/s] 95%|█████████▍| 16640/17525 [3:19:08<08:36,  1.71it/s]                                                       {'loss': 0.3468, 'grad_norm': 9.45128059387207, 'learning_rate': 1.287234443941976e-07, 'epoch': 23.74}
 95%|█████████▍| 16640/17525 [3:19:08<08:36,  1.71it/s] 95%|█████████▍| 16641/17525 [3:19:09<08:33,  1.72it/s] 95%|█████████▍| 16642/17525 [3:19:09<08:31,  1.73it/s] 95%|█████████▍| 16643/17525 [3:19:10<08:30,  1.73it/s] 95%|█████████▍| 16644/17525 [3:19:11<10:01,  1.46it/s] 95%|█████████▍| 16645/17525 [3:19:11<09:32,  1.54it/s] 95%|█████████▍| 16646/17525 [3:19:12<09:12,  1.59it/s] 95%|█████████▍| 16647/17525 [3:19:12<08:57,  1.63it/s] 95%|█████████▍| 16648/17525 [3:19:13<08:52,  1.65it/s] 95%|█████████▌| 16649/17525 [3:19:14<08:53,  1.64it/s] 95%|█████████▌| 16650/17525 [3:19:14<08:44,  1.67it/s]                                                       {'loss': 0.3544, 'grad_norm': 30.624767303466797, 'learning_rate': 1.2586902868027773e-07, 'epoch': 23.75}
 95%|█████████▌| 16650/17525 [3:19:14<08:44,  1.67it/s][INFO|trainer.py:3203] 2024-06-25 05:22:36,114 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16650
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7cbc4d0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: c19c1791-7482-435f-b61c-f5478e44c0ef)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:22:46,170 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:22:46,173 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16650/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 95%|█████████▌| 16651/17525 [3:19:25<53:14,  3.65s/it] 95%|█████████▌| 16652/17525 [3:19:26<39:44,  2.73s/it] 95%|█████████▌| 16653/17525 [3:19:26<30:18,  2.09s/it] 95%|█████████▌| 16654/17525 [3:19:27<23:42,  1.63s/it] 95%|█████████▌| 16655/17525 [3:19:27<19:05,  1.32s/it] 95%|█████████▌| 16656/17525 [3:19:28<15:51,  1.09s/it] 95%|█████████▌| 16657/17525 [3:19:28<13:35,  1.06it/s] 95%|█████████▌| 16658/17525 [3:19:29<13:30,  1.07it/s] 95%|█████████▌| 16659/17525 [3:19:30<11:56,  1.21it/s] 95%|█████████▌| 16660/17525 [3:19:31<10:50,  1.33it/s]                                                       {'loss': 0.3387, 'grad_norm': 9.024470329284668, 'learning_rate': 1.2304641641985526e-07, 'epoch': 23.77}
 95%|█████████▌| 16660/17525 [3:19:31<10:50,  1.33it/s] 95%|█████████▌| 16661/17525 [3:19:31<10:04,  1.43it/s] 95%|█████████▌| 16662/17525 [3:19:32<12:10,  1.18it/s] 95%|█████████▌| 16663/17525 [3:19:33<10:59,  1.31it/s] 95%|█████████▌| 16664/17525 [3:19:33<10:09,  1.41it/s] 95%|█████████▌| 16665/17525 [3:19:34<09:34,  1.50it/s] 95%|█████████▌| 16666/17525 [3:19:35<09:47,  1.46it/s] 95%|█████████▌| 16667/17525 [3:19:35<09:19,  1.53it/s] 95%|█████████▌| 16668/17525 [3:19:36<08:58,  1.59it/s] 95%|█████████▌| 16669/17525 [3:19:36<08:44,  1.63it/s] 95%|█████████▌| 16670/17525 [3:19:37<08:34,  1.66it/s]                                                       {'loss': 0.3091, 'grad_norm': 10.078418731689453, 'learning_rate': 1.202556167042468e-07, 'epoch': 23.78}
 95%|█████████▌| 16670/17525 [3:19:37<08:34,  1.66it/s] 95%|█████████▌| 16671/17525 [3:19:38<08:27,  1.68it/s] 95%|█████████▌| 16672/17525 [3:19:38<08:22,  1.70it/s] 95%|█████████▌| 16673/17525 [3:19:39<08:18,  1.71it/s] 95%|█████████▌| 16674/17525 [3:19:39<08:16,  1.71it/s] 95%|█████████▌| 16675/17525 [3:19:40<08:13,  1.72it/s] 95%|█████████▌| 16676/17525 [3:19:41<08:12,  1.73it/s] 95%|█████████▌| 16677/17525 [3:19:41<08:11,  1.72it/s] 95%|█████████▌| 16678/17525 [3:19:42<08:10,  1.73it/s] 95%|█████████▌| 16679/17525 [3:19:42<08:09,  1.73it/s] 95%|█████████▌| 16680/17525 [3:19:43<08:08,  1.73it/s]                                                       {'loss': 0.3664, 'grad_norm': 11.82384967803955, 'learning_rate': 1.1749663852229864e-07, 'epoch': 23.79}
 95%|█████████▌| 16680/17525 [3:19:43<08:08,  1.73it/s] 95%|█████████▌| 16681/17525 [3:19:43<08:07,  1.73it/s] 95%|█████████▌| 16682/17525 [3:19:44<08:06,  1.73it/s] 95%|█████████▌| 16683/17525 [3:19:45<09:36,  1.46it/s] 95%|█████████▌| 16684/17525 [3:19:45<09:08,  1.53it/s] 95%|█████████▌| 16685/17525 [3:19:46<08:47,  1.59it/s] 95%|█████████▌| 16686/17525 [3:19:47<08:34,  1.63it/s] 95%|█████████▌| 16687/17525 [3:19:47<08:23,  1.66it/s] 95%|█████████▌| 16688/17525 [3:19:48<08:17,  1.68it/s] 95%|█████████▌| 16689/17525 [3:19:48<08:12,  1.70it/s] 95%|█████████▌| 16690/17525 [3:19:49<08:08,  1.71it/s]                                                       {'loss': 0.3868, 'grad_norm': 8.515548706054688, 'learning_rate': 1.147694907603647e-07, 'epoch': 23.81}
 95%|█████████▌| 16690/17525 [3:19:49<08:08,  1.71it/s] 95%|█████████▌| 16691/17525 [3:19:50<08:05,  1.72it/s] 95%|█████████▌| 16692/17525 [3:19:51<09:46,  1.42it/s] 95%|█████████▌| 16693/17525 [3:19:51<09:13,  1.50it/s] 95%|█████████▌| 16694/17525 [3:19:52<08:51,  1.56it/s] 95%|█████████▌| 16695/17525 [3:19:53<12:55,  1.07it/s] 95%|█████████▌| 16696/17525 [3:19:54<11:25,  1.21it/s] 95%|█████████▌| 16697/17525 [3:19:54<10:21,  1.33it/s] 95%|█████████▌| 16698/17525 [3:19:55<09:37,  1.43it/s] 95%|█████████▌| 16699/17525 [3:19:56<09:06,  1.51it/s] 95%|█████████▌| 16700/17525 [3:19:56<08:44,  1.57it/s]                                                       {'loss': 0.3559, 'grad_norm': 7.237719535827637, 'learning_rate': 1.1207418220228084e-07, 'epoch': 23.82}
 95%|█████████▌| 16700/17525 [3:19:56<08:44,  1.57it/s][INFO|trainer.py:3512] 2024-06-25 05:23:18,063 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:23:18,064 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:23:18,064 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1988600492477417, 'eval_runtime': 4.5916, 'eval_samples_per_second': 96.481, 'eval_steps_per_second': 4.138, 'epoch': 23.82}
 95%|█████████▌| 16700/17525 [3:20:01<08:44,  1.57it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 95%|█████████▌| 16701/17525 [3:20:01<27:32,  2.00s/it] 95%|█████████▌| 16702/17525 [3:20:02<21:37,  1.58s/it] 95%|█████████▌| 16703/17525 [3:20:03<17:28,  1.28s/it] 95%|█████████▌| 16704/17525 [3:20:03<14:34,  1.07s/it] 95%|█████████▌| 16705/17525 [3:20:04<14:32,  1.06s/it] 95%|█████████▌| 16706/17525 [3:20:05<12:31,  1.09it/s] 95%|█████████▌| 16707/17525 [3:20:05<11:11,  1.22it/s] 95%|█████████▌| 16708/17525 [3:20:06<10:11,  1.34it/s] 95%|█████████▌| 16709/17525 [3:20:06<09:28,  1.44it/s] 95%|█████████▌| 16710/17525 [3:20:07<08:58,  1.51it/s]                                                       {'loss': 0.3384, 'grad_norm': 16.414106369018555, 'learning_rate': 1.0941072152932719e-07, 'epoch': 23.84}
 95%|█████████▌| 16710/17525 [3:20:07<08:58,  1.51it/s] 95%|█████████▌| 16711/17525 [3:20:08<08:37,  1.57it/s] 95%|█████████▌| 16712/17525 [3:20:08<08:22,  1.62it/s] 95%|█████████▌| 16713/17525 [3:20:09<09:40,  1.40it/s] 95%|█████████▌| 16714/17525 [3:20:10<09:06,  1.48it/s] 95%|█████████▌| 16715/17525 [3:20:10<08:41,  1.55it/s] 95%|█████████▌| 16716/17525 [3:20:11<08:23,  1.61it/s] 95%|█████████▌| 16717/17525 [3:20:11<08:16,  1.63it/s] 95%|█████████▌| 16718/17525 [3:20:12<08:05,  1.66it/s] 95%|█████████▌| 16719/17525 [3:20:13<07:58,  1.68it/s] 95%|█████████▌| 16720/17525 [3:20:13<07:53,  1.70it/s]                                                       {'loss': 0.3508, 'grad_norm': 7.835052013397217, 'learning_rate': 1.0677911732020929e-07, 'epoch': 23.85}
 95%|█████████▌| 16720/17525 [3:20:13<07:53,  1.70it/s] 95%|█████████▌| 16721/17525 [3:20:15<11:01,  1.22it/s] 95%|█████████▌| 16722/17525 [3:20:15<10:00,  1.34it/s] 95%|█████████▌| 16723/17525 [3:20:16<09:18,  1.44it/s] 95%|█████████▌| 16724/17525 [3:20:16<08:48,  1.51it/s] 95%|█████████▌| 16725/17525 [3:20:17<08:29,  1.57it/s] 95%|█████████▌| 16726/17525 [3:20:17<08:14,  1.62it/s] 95%|█████████▌| 16727/17525 [3:20:18<08:03,  1.65it/s] 95%|█████████▌| 16728/17525 [3:20:19<07:55,  1.67it/s] 95%|█████████▌| 16729/17525 [3:20:19<07:49,  1.69it/s] 95%|█████████▌| 16730/17525 [3:20:20<07:45,  1.71it/s]                                                       {'loss': 0.3199, 'grad_norm': 9.599568367004395, 'learning_rate': 1.0417937805102474e-07, 'epoch': 23.87}
 95%|█████████▌| 16730/17525 [3:20:20<07:45,  1.71it/s] 95%|█████████▌| 16731/17525 [3:20:20<07:43,  1.71it/s] 95%|█████████▌| 16732/17525 [3:20:21<07:41,  1.72it/s] 95%|█████████▌| 16733/17525 [3:20:21<07:38,  1.73it/s] 95%|█████████▌| 16734/17525 [3:20:22<07:37,  1.73it/s] 95%|█████████▌| 16735/17525 [3:20:23<07:36,  1.73it/s] 95%|█████████▌| 16736/17525 [3:20:23<08:20,  1.58it/s] 96%|█████████▌| 16737/17525 [3:20:24<08:07,  1.62it/s] 96%|█████████▌| 16738/17525 [3:20:25<07:57,  1.65it/s] 96%|█████████▌| 16739/17525 [3:20:25<07:49,  1.67it/s] 96%|█████████▌| 16740/17525 [3:20:26<07:44,  1.69it/s]                                                       {'loss': 0.33, 'grad_norm': 6.656881332397461, 'learning_rate': 1.0161151209523878e-07, 'epoch': 23.88}
 96%|█████████▌| 16740/17525 [3:20:26<07:44,  1.69it/s] 96%|█████████▌| 16741/17525 [3:20:26<07:40,  1.70it/s] 96%|█████████▌| 16742/17525 [3:20:27<07:37,  1.71it/s] 96%|█████████▌| 16743/17525 [3:20:28<08:08,  1.60it/s] 96%|█████████▌| 16744/17525 [3:20:28<07:56,  1.64it/s] 96%|█████████▌| 16745/17525 [3:20:29<07:47,  1.67it/s] 96%|█████████▌| 16746/17525 [3:20:29<07:42,  1.68it/s] 96%|█████████▌| 16747/17525 [3:20:30<07:37,  1.70it/s] 96%|█████████▌| 16748/17525 [3:20:30<07:38,  1.70it/s] 96%|█████████▌| 16749/17525 [3:20:31<07:33,  1.71it/s] 96%|█████████▌| 16750/17525 [3:20:32<07:30,  1.72it/s]                                                       {'loss': 0.4067, 'grad_norm': 12.908409118652344, 'learning_rate': 9.907552772365436e-08, 'epoch': 23.89}
 96%|█████████▌| 16750/17525 [3:20:32<07:30,  1.72it/s] 96%|█████████▌| 16751/17525 [3:20:32<07:28,  1.72it/s] 96%|█████████▌| 16752/17525 [3:20:33<07:27,  1.73it/s] 96%|█████████▌| 16753/17525 [3:20:33<07:25,  1.73it/s] 96%|█████████▌| 16754/17525 [3:20:34<07:23,  1.74it/s] 96%|█████████▌| 16755/17525 [3:20:35<07:23,  1.74it/s] 96%|█████████▌| 16756/17525 [3:20:35<07:23,  1.74it/s] 96%|█████████▌| 16757/17525 [3:20:36<07:21,  1.74it/s] 96%|█████████▌| 16758/17525 [3:20:36<07:21,  1.74it/s] 96%|█████████▌| 16759/17525 [3:20:37<07:21,  1.74it/s] 96%|█████████▌| 16760/17525 [3:20:37<07:20,  1.74it/s]                                                       {'loss': 0.328, 'grad_norm': 15.968781471252441, 'learning_rate': 9.657143310438877e-08, 'epoch': 23.91}
 96%|█████████▌| 16760/17525 [3:20:37<07:20,  1.74it/s] 96%|█████████▌| 16761/17525 [3:20:38<07:20,  1.73it/s] 96%|█████████▌| 16762/17525 [3:20:39<07:20,  1.73it/s] 96%|█████████▌| 16763/17525 [3:20:39<07:40,  1.66it/s] 96%|█████████▌| 16764/17525 [3:20:40<07:47,  1.63it/s] 96%|█████████▌| 16765/17525 [3:20:40<07:51,  1.61it/s] 96%|█████████▌| 16766/17525 [3:20:41<07:49,  1.61it/s] 96%|█████████▌| 16767/17525 [3:20:42<07:45,  1.63it/s] 96%|█████████▌| 16768/17525 [3:20:42<08:09,  1.55it/s] 96%|█████████▌| 16769/17525 [3:20:43<08:03,  1.56it/s] 96%|█████████▌| 16770/17525 [3:20:44<09:09,  1.37it/s]                                                       {'loss': 0.3105, 'grad_norm': 8.886999130249023, 'learning_rate': 9.409923630284812e-08, 'epoch': 23.92}
 96%|█████████▌| 16770/17525 [3:20:44<09:09,  1.37it/s] 96%|█████████▌| 16771/17525 [3:20:45<08:41,  1.45it/s] 96%|█████████▌| 16772/17525 [3:20:45<08:20,  1.51it/s] 96%|█████████▌| 16773/17525 [3:20:46<07:59,  1.57it/s] 96%|█████████▌| 16774/17525 [3:20:46<07:44,  1.62it/s] 96%|█████████▌| 16775/17525 [3:20:47<07:35,  1.65it/s] 96%|█████████▌| 16776/17525 [3:20:48<07:32,  1.65it/s] 96%|█████████▌| 16777/17525 [3:20:48<07:29,  1.66it/s] 96%|█████████▌| 16778/17525 [3:20:49<07:23,  1.68it/s] 96%|█████████▌| 16779/17525 [3:20:49<07:18,  1.70it/s] 96%|█████████▌| 16780/17525 [3:20:50<07:14,  1.71it/s]                                                       {'loss': 0.3595, 'grad_norm': 10.599400520324707, 'learning_rate': 9.165894528169628e-08, 'epoch': 23.94}
 96%|█████████▌| 16780/17525 [3:20:50<07:14,  1.71it/s] 96%|█████████▌| 16781/17525 [3:20:50<07:20,  1.69it/s] 96%|█████████▌| 16782/17525 [3:20:51<07:21,  1.68it/s] 96%|█████████▌| 16783/17525 [3:20:52<07:18,  1.69it/s] 96%|█████████▌| 16784/17525 [3:20:52<07:15,  1.70it/s] 96%|█████████▌| 16785/17525 [3:20:53<07:12,  1.71it/s] 96%|█████████▌| 16786/17525 [3:20:53<07:12,  1.71it/s] 96%|█████████▌| 16787/17525 [3:20:54<07:09,  1.72it/s] 96%|█████████▌| 16788/17525 [3:20:55<07:07,  1.72it/s] 96%|█████████▌| 16789/17525 [3:20:55<07:09,  1.71it/s] 96%|█████████▌| 16790/17525 [3:20:56<07:07,  1.72it/s]                                                       {'loss': 0.2261, 'grad_norm': 15.57278823852539, 'learning_rate': 8.925056790083264e-08, 'epoch': 23.95}
 96%|█████████▌| 16790/17525 [3:20:56<07:07,  1.72it/s] 96%|█████████▌| 16791/17525 [3:20:56<07:06,  1.72it/s] 96%|█████████▌| 16792/17525 [3:20:57<07:04,  1.73it/s] 96%|█████████▌| 16793/17525 [3:20:57<07:04,  1.73it/s] 96%|█████████▌| 16794/17525 [3:20:58<07:09,  1.70it/s] 96%|█████████▌| 16795/17525 [3:20:59<07:07,  1.71it/s] 96%|█████████▌| 16796/17525 [3:20:59<07:47,  1.56it/s] 96%|█████████▌| 16797/17525 [3:21:00<07:34,  1.60it/s] 96%|█████████▌| 16798/17525 [3:21:01<07:23,  1.64it/s] 96%|█████████▌| 16799/17525 [3:21:01<07:15,  1.67it/s] 96%|█████████▌| 16800/17525 [3:21:02<07:13,  1.67it/s]                                                       {'loss': 0.3571, 'grad_norm': 5.480131149291992, 'learning_rate': 8.687411191736884e-08, 'epoch': 23.97}
 96%|█████████▌| 16800/17525 [3:21:02<07:13,  1.67it/s][INFO|trainer.py:3512] 2024-06-25 05:24:23,616 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:24:23,617 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:24:23,617 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.61it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.33it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.57it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.68it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.72it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.80it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.87it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.10it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.57it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  3.99it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A                                                       
                                               [A{'eval_loss': 1.1984906196594238, 'eval_runtime': 4.6265, 'eval_samples_per_second': 95.752, 'eval_steps_per_second': 4.107, 'epoch': 23.97}
 96%|█████████▌| 16800/17525 [3:21:06<07:13,  1.67it/s]
100%|██████████| 19/19 [00:04<00:00,  3.74it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:24:28,246 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16800
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c55990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 68b42705-1253-43b6-9a13-51af2eb4b067)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:24:38,307 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16800/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:24:38,310 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16800/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 96%|█████████▌| 16801/17525 [3:21:17<1:01:08,  5.07s/it] 96%|█████████▌| 16802/17525 [3:21:18<45:04,  3.74s/it]   96%|█████████▌| 16803/17525 [3:21:19<34:09,  2.84s/it] 96%|█████████▌| 16804/17525 [3:21:19<26:06,  2.17s/it] 96%|█████████▌| 16805/17525 [3:21:20<20:23,  1.70s/it] 96%|█████████▌| 16806/17525 [3:21:20<16:22,  1.37s/it] 96%|█████████▌| 16807/17525 [3:21:21<13:34,  1.13s/it] 96%|█████████▌| 16808/17525 [3:21:22<11:34,  1.03it/s] 96%|█████████▌| 16809/17525 [3:21:22<10:14,  1.16it/s] 96%|█████████▌| 16810/17525 [3:21:23<09:13,  1.29it/s]                                                       {'loss': 0.3554, 'grad_norm': 8.002782821655273, 'learning_rate': 8.452958498559649e-08, 'epoch': 23.98}
 96%|█████████▌| 16810/17525 [3:21:23<09:13,  1.29it/s] 96%|█████████▌| 16811/17525 [3:21:23<08:30,  1.40it/s] 96%|█████████▌| 16812/17525 [3:21:24<08:02,  1.48it/s] 96%|█████████▌| 16813/17525 [3:21:25<07:43,  1.53it/s] 96%|█████████▌| 16814/17525 [3:21:25<07:27,  1.59it/s] 96%|█████████▌| 16815/17525 [3:21:26<07:22,  1.60it/s] 96%|█████████▌| 16816/17525 [3:21:26<07:11,  1.64it/s] 96%|█████████▌| 16817/17525 [3:21:27<07:12,  1.64it/s] 96%|█████████▌| 16818/17525 [3:21:27<07:05,  1.66it/s] 96%|█████████▌| 16819/17525 [3:21:29<09:41,  1.21it/s] 96%|█████████▌| 16820/17525 [3:21:29<08:48,  1.33it/s]                                                       {'loss': 0.3479, 'grad_norm': 13.079583168029785, 'learning_rate': 8.221699465697285e-08, 'epoch': 23.99}
 96%|█████████▌| 16820/17525 [3:21:29<08:48,  1.33it/s] 96%|█████████▌| 16821/17525 [3:21:30<08:12,  1.43it/s] 96%|█████████▌| 16822/17525 [3:21:31<07:45,  1.51it/s] 96%|█████████▌| 16823/17525 [3:21:31<07:33,  1.55it/s] 96%|█████████▌| 16824/17525 [3:21:32<07:18,  1.60it/s] 96%|█████████▌| 16825/17525 [3:21:32<07:08,  1.63it/s] 96%|█████████▌| 16826/17525 [3:21:33<07:00,  1.66it/s] 96%|█████████▌| 16827/17525 [3:21:34<07:04,  1.65it/s] 96%|█████████▌| 16828/17525 [3:21:34<06:57,  1.67it/s] 96%|█████████▌| 16829/17525 [3:21:35<06:53,  1.68it/s] 96%|█████████▌| 16830/17525 [3:21:35<06:48,  1.70it/s]                                                       {'loss': 0.3517, 'grad_norm': 8.21761417388916, 'learning_rate': 7.993634838008745e-08, 'epoch': 24.01}
 96%|█████████▌| 16830/17525 [3:21:35<06:48,  1.70it/s] 96%|█████████▌| 16831/17525 [3:21:36<06:46,  1.71it/s] 96%|█████████▌| 16832/17525 [3:21:36<06:43,  1.72it/s] 96%|█████████▌| 16833/17525 [3:21:37<06:41,  1.72it/s] 96%|█████████▌| 16834/17525 [3:21:38<06:50,  1.68it/s] 96%|█████████▌| 16835/17525 [3:21:38<06:47,  1.69it/s] 96%|█████████▌| 16836/17525 [3:21:39<06:44,  1.71it/s] 96%|█████████▌| 16837/17525 [3:21:39<06:45,  1.70it/s] 96%|█████████▌| 16838/17525 [3:21:40<06:42,  1.71it/s] 96%|█████████▌| 16839/17525 [3:21:41<06:39,  1.72it/s] 96%|█████████▌| 16840/17525 [3:21:41<06:41,  1.71it/s]                                                       {'loss': 0.3659, 'grad_norm': 9.884528160095215, 'learning_rate': 7.768765350064322e-08, 'epoch': 24.02}
 96%|█████████▌| 16840/17525 [3:21:41<06:41,  1.71it/s] 96%|█████████▌| 16841/17525 [3:21:42<07:07,  1.60it/s] 96%|█████████▌| 16842/17525 [3:21:42<07:03,  1.61it/s] 96%|█████████▌| 16843/17525 [3:21:43<06:53,  1.65it/s] 96%|█████████▌| 16844/17525 [3:21:44<06:49,  1.66it/s] 96%|█████████▌| 16845/17525 [3:21:44<06:46,  1.67it/s] 96%|█████████▌| 16846/17525 [3:21:45<06:42,  1.69it/s] 96%|█████████▌| 16847/17525 [3:21:45<06:39,  1.70it/s] 96%|█████████▌| 16848/17525 [3:21:46<06:36,  1.71it/s] 96%|█████████▌| 16849/17525 [3:21:46<06:34,  1.72it/s] 96%|█████████▌| 16850/17525 [3:21:47<06:37,  1.70it/s]                                                       {'loss': 0.2827, 'grad_norm': 9.83476448059082, 'learning_rate': 7.547091726143097e-08, 'epoch': 24.04}
 96%|█████████▌| 16850/17525 [3:21:47<06:37,  1.70it/s] 96%|█████████▌| 16851/17525 [3:21:48<06:39,  1.69it/s] 96%|█████████▌| 16852/17525 [3:21:48<06:41,  1.67it/s] 96%|█████████▌| 16853/17525 [3:21:49<06:39,  1.68it/s] 96%|█████████▌| 16854/17525 [3:21:49<06:37,  1.69it/s] 96%|█████████▌| 16855/17525 [3:21:50<06:37,  1.68it/s] 96%|█████████▌| 16856/17525 [3:21:51<06:33,  1.70it/s] 96%|█████████▌| 16857/17525 [3:21:51<06:39,  1.67it/s] 96%|█████████▌| 16858/17525 [3:21:52<06:37,  1.68it/s] 96%|█████████▌| 16859/17525 [3:21:52<06:32,  1.70it/s] 96%|█████████▌| 16860/17525 [3:21:53<06:30,  1.70it/s]                                                       {'loss': 0.3442, 'grad_norm': 8.139857292175293, 'learning_rate': 7.328614680230495e-08, 'epoch': 24.05}
 96%|█████████▌| 16860/17525 [3:21:53<06:30,  1.70it/s] 96%|█████████▌| 16861/17525 [3:21:54<06:29,  1.70it/s] 96%|█████████▌| 16862/17525 [3:21:54<06:30,  1.70it/s] 96%|█████████▌| 16863/17525 [3:21:55<06:27,  1.71it/s] 96%|█████████▌| 16864/17525 [3:21:55<06:31,  1.69it/s] 96%|█████████▌| 16865/17525 [3:21:56<06:30,  1.69it/s] 96%|█████████▌| 16866/17525 [3:21:57<06:26,  1.70it/s] 96%|█████████▌| 16867/17525 [3:21:57<06:23,  1.71it/s] 96%|█████████▋| 16868/17525 [3:21:58<06:23,  1.71it/s] 96%|█████████▋| 16869/17525 [3:21:58<06:26,  1.70it/s] 96%|█████████▋| 16870/17525 [3:21:59<06:22,  1.71it/s]                                                       {'loss': 0.3909, 'grad_norm': 8.581937789916992, 'learning_rate': 7.1133349160164e-08, 'epoch': 24.07}
 96%|█████████▋| 16870/17525 [3:21:59<06:22,  1.71it/s] 96%|█████████▋| 16871/17525 [3:22:00<06:32,  1.67it/s] 96%|█████████▋| 16872/17525 [3:22:00<06:26,  1.69it/s] 96%|█████████▋| 16873/17525 [3:22:01<06:22,  1.70it/s] 96%|█████████▋| 16874/17525 [3:22:01<06:24,  1.69it/s] 96%|█████████▋| 16875/17525 [3:22:02<06:24,  1.69it/s] 96%|█████████▋| 16876/17525 [3:22:02<06:22,  1.70it/s] 96%|█████████▋| 16877/17525 [3:22:03<06:19,  1.71it/s] 96%|█████████▋| 16878/17525 [3:22:04<07:31,  1.43it/s] 96%|█████████▋| 16879/17525 [3:22:05<07:06,  1.51it/s] 96%|█████████▋| 16880/17525 [3:22:05<07:26,  1.44it/s]                                                       {'loss': 0.3154, 'grad_norm': 6.678131580352783, 'learning_rate': 6.901253126892271e-08, 'epoch': 24.08}
 96%|█████████▋| 16880/17525 [3:22:05<07:26,  1.44it/s] 96%|█████████▋| 16881/17525 [3:22:06<07:29,  1.43it/s] 96%|█████████▋| 16882/17525 [3:22:07<07:11,  1.49it/s] 96%|█████████▋| 16883/17525 [3:22:07<06:55,  1.54it/s] 96%|█████████▋| 16884/17525 [3:22:08<06:40,  1.60it/s] 96%|█████████▋| 16885/17525 [3:22:08<06:34,  1.62it/s] 96%|█████████▋| 16886/17525 [3:22:09<06:30,  1.64it/s] 96%|█████████▋| 16887/17525 [3:22:10<06:23,  1.67it/s] 96%|█████████▋| 16888/17525 [3:22:10<06:52,  1.54it/s] 96%|█████████▋| 16889/17525 [3:22:11<06:38,  1.60it/s] 96%|█████████▋| 16890/17525 [3:22:11<06:28,  1.64it/s]                                                       {'loss': 0.3462, 'grad_norm': 10.349714279174805, 'learning_rate': 6.692369995949577e-08, 'epoch': 24.09}
 96%|█████████▋| 16890/17525 [3:22:11<06:28,  1.64it/s] 96%|█████████▋| 16891/17525 [3:22:12<06:24,  1.65it/s] 96%|█████████▋| 16892/17525 [3:22:13<06:21,  1.66it/s] 96%|█████████▋| 16893/17525 [3:22:13<06:19,  1.67it/s] 96%|█████████▋| 16894/17525 [3:22:14<06:14,  1.69it/s] 96%|█████████▋| 16895/17525 [3:22:15<06:47,  1.55it/s] 96%|█████████▋| 16896/17525 [3:22:15<06:33,  1.60it/s] 96%|█████████▋| 16897/17525 [3:22:16<06:23,  1.64it/s] 96%|█████████▋| 16898/17525 [3:22:16<06:16,  1.67it/s] 96%|█████████▋| 16899/17525 [3:22:17<06:10,  1.69it/s] 96%|█████████▋| 16900/17525 [3:22:18<06:11,  1.68it/s]                                                       {'loss': 0.3632, 'grad_norm': 6.239135265350342, 'learning_rate': 6.486686195977144e-08, 'epoch': 24.11}
 96%|█████████▋| 16900/17525 [3:22:18<06:11,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 05:25:39,419 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:25:39,419 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:25:39,419 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  3.86it/s][A
 32%|███▏      | 6/19 [00:01<00:03,  4.08it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.28it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.00it/s][A
 47%|████▋     | 9/19 [00:02<00:02,  4.32it/s][A
 53%|█████▎    | 10/19 [00:02<00:02,  4.24it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.34it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.52it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.61it/s][A
 74%|███████▎  | 14/19 [00:03<00:01,  4.81it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  4.98it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.04it/s][A
 89%|████████▉ | 17/19 [00:04<00:00,  3.56it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.97it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A                                                       
                                               [A{'eval_loss': 1.1976284980773926, 'eval_runtime': 4.8091, 'eval_samples_per_second': 92.117, 'eval_steps_per_second': 3.951, 'epoch': 24.11}
 96%|█████████▋| 16900/17525 [3:22:22<06:11,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.73it/s][A
                                               [A 96%|█████████▋| 16901/17525 [3:22:23<21:11,  2.04s/it] 96%|█████████▋| 16902/17525 [3:22:24<16:37,  1.60s/it] 96%|█████████▋| 16903/17525 [3:22:24<14:31,  1.40s/it] 96%|█████████▋| 16904/17525 [3:22:25<11:59,  1.16s/it] 96%|█████████▋| 16905/17525 [3:22:26<10:12,  1.01it/s] 96%|█████████▋| 16906/17525 [3:22:26<08:58,  1.15it/s] 96%|█████████▋| 16907/17525 [3:22:27<08:04,  1.28it/s] 96%|█████████▋| 16908/17525 [3:22:27<07:28,  1.38it/s] 96%|█████████▋| 16909/17525 [3:22:28<07:00,  1.46it/s] 96%|█████████▋| 16910/17525 [3:22:29<07:42,  1.33it/s]                                                       {'loss': 0.3708, 'grad_norm': 9.621559143066406, 'learning_rate': 6.284202389459148e-08, 'epoch': 24.12}
 96%|█████████▋| 16910/17525 [3:22:29<07:42,  1.33it/s] 96%|█████████▋| 16911/17525 [3:22:30<07:16,  1.41it/s] 97%|█████████▋| 16912/17525 [3:22:30<06:52,  1.49it/s] 97%|█████████▋| 16913/17525 [3:22:31<06:40,  1.53it/s] 97%|█████████▋| 16914/17525 [3:22:31<06:26,  1.58it/s] 97%|█████████▋| 16915/17525 [3:22:32<06:16,  1.62it/s] 97%|█████████▋| 16916/17525 [3:22:32<06:15,  1.62it/s] 97%|█████████▋| 16917/17525 [3:22:33<06:16,  1.62it/s] 97%|█████████▋| 16918/17525 [3:22:34<06:08,  1.65it/s] 97%|█████████▋| 16919/17525 [3:22:34<06:02,  1.67it/s] 97%|█████████▋| 16920/17525 [3:22:35<05:57,  1.69it/s]                                                       {'loss': 0.2969, 'grad_norm': 4.841909885406494, 'learning_rate': 6.084919228572794e-08, 'epoch': 24.14}
 97%|█████████▋| 16920/17525 [3:22:35<05:57,  1.69it/s] 97%|█████████▋| 16921/17525 [3:22:35<05:55,  1.70it/s] 97%|█████████▋| 16922/17525 [3:22:36<05:52,  1.71it/s] 97%|█████████▋| 16923/17525 [3:22:37<05:49,  1.72it/s] 97%|█████████▋| 16924/17525 [3:22:37<05:50,  1.72it/s] 97%|█████████▋| 16925/17525 [3:22:38<05:47,  1.73it/s] 97%|█████████▋| 16926/17525 [3:22:38<05:49,  1.71it/s] 97%|█████████▋| 16927/17525 [3:22:39<05:48,  1.72it/s] 97%|█████████▋| 16928/17525 [3:22:39<05:49,  1.71it/s] 97%|█████████▋| 16929/17525 [3:22:40<05:49,  1.71it/s] 97%|█████████▋| 16930/17525 [3:22:41<05:48,  1.71it/s]                                                       {'loss': 0.2842, 'grad_norm': 6.722659587860107, 'learning_rate': 5.888837355186527e-08, 'epoch': 24.15}
 97%|█████████▋| 16930/17525 [3:22:41<05:48,  1.71it/s] 97%|█████████▋| 16931/17525 [3:22:41<05:49,  1.70it/s] 97%|█████████▋| 16932/17525 [3:22:42<05:49,  1.70it/s] 97%|█████████▋| 16933/17525 [3:22:42<05:50,  1.69it/s] 97%|█████████▋| 16934/17525 [3:22:43<05:46,  1.70it/s] 97%|█████████▋| 16935/17525 [3:22:44<05:47,  1.70it/s] 97%|█████████▋| 16936/17525 [3:22:44<05:45,  1.71it/s] 97%|█████████▋| 16937/17525 [3:22:45<05:47,  1.69it/s] 97%|█████████▋| 16938/17525 [3:22:45<05:50,  1.68it/s] 97%|█████████▋| 16939/17525 [3:22:46<06:21,  1.54it/s] 97%|█████████▋| 16940/17525 [3:22:47<06:07,  1.59it/s]                                                       {'loss': 0.3166, 'grad_norm': 6.001133918762207, 'learning_rate': 5.695957400857821e-08, 'epoch': 24.17}
 97%|█████████▋| 16940/17525 [3:22:47<06:07,  1.59it/s] 97%|█████████▋| 16941/17525 [3:22:47<05:59,  1.63it/s] 97%|█████████▋| 16942/17525 [3:22:48<05:56,  1.63it/s] 97%|█████████▋| 16943/17525 [3:22:49<05:50,  1.66it/s] 97%|█████████▋| 16944/17525 [3:22:49<05:45,  1.68it/s] 97%|█████████▋| 16945/17525 [3:22:50<05:42,  1.69it/s] 97%|█████████▋| 16946/17525 [3:22:50<05:39,  1.71it/s] 97%|█████████▋| 16947/17525 [3:22:51<06:04,  1.59it/s] 97%|█████████▋| 16948/17525 [3:22:52<07:10,  1.34it/s] 97%|█████████▋| 16949/17525 [3:22:53<06:40,  1.44it/s] 97%|█████████▋| 16950/17525 [3:22:54<09:23,  1.02it/s]                                                       {'loss': 0.309, 'grad_norm': 12.626761436462402, 'learning_rate': 5.506279986831065e-08, 'epoch': 24.18}
 97%|█████████▋| 16950/17525 [3:22:54<09:23,  1.02it/s][INFO|trainer.py:3203] 2024-06-25 05:26:16,129 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16950
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: c0fb9a42-554f-47b1-9ba0-c720cf6e8fea)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:26:26,186 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16950/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:26:26,189 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-16950/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 97%|█████████▋| 16951/17525 [3:23:05<37:42,  3.94s/it] 97%|█████████▋| 16952/17525 [3:23:06<28:01,  2.93s/it] 97%|█████████▋| 16953/17525 [3:23:06<21:16,  2.23s/it] 97%|█████████▋| 16954/17525 [3:23:07<16:35,  1.74s/it] 97%|█████████▋| 16955/17525 [3:23:08<14:20,  1.51s/it] 97%|█████████▋| 16956/17525 [3:23:08<11:39,  1.23s/it] 97%|█████████▋| 16957/17525 [3:23:09<09:47,  1.03s/it] 97%|█████████▋| 16958/17525 [3:23:10<08:31,  1.11it/s] 97%|█████████▋| 16959/17525 [3:23:10<07:38,  1.24it/s] 97%|█████████▋| 16960/17525 [3:23:11<06:57,  1.35it/s]                                                       {'loss': 0.341, 'grad_norm': 10.224223136901855, 'learning_rate': 5.319805724035676e-08, 'epoch': 24.19}
 97%|█████████▋| 16960/17525 [3:23:11<06:57,  1.35it/s] 97%|█████████▋| 16961/17525 [3:23:11<06:30,  1.44it/s] 97%|█████████▋| 16962/17525 [3:23:12<06:10,  1.52it/s] 97%|█████████▋| 16963/17525 [3:23:12<05:56,  1.58it/s] 97%|█████████▋| 16964/17525 [3:23:13<05:46,  1.62it/s] 97%|█████████▋| 16965/17525 [3:23:14<05:39,  1.65it/s] 97%|█████████▋| 16966/17525 [3:23:14<05:34,  1.67it/s] 97%|█████████▋| 16967/17525 [3:23:15<05:30,  1.69it/s] 97%|█████████▋| 16968/17525 [3:23:15<05:30,  1.68it/s] 97%|█████████▋| 16969/17525 [3:23:16<05:27,  1.70it/s] 97%|█████████▋| 16970/17525 [3:23:17<05:24,  1.71it/s]                                                       {'loss': 0.3537, 'grad_norm': 9.834003448486328, 'learning_rate': 5.136535213083993e-08, 'epoch': 24.21}
 97%|█████████▋| 16970/17525 [3:23:17<05:24,  1.71it/s] 97%|█████████▋| 16971/17525 [3:23:17<05:22,  1.72it/s] 97%|█████████▋| 16972/17525 [3:23:18<05:27,  1.69it/s] 97%|█████████▋| 16973/17525 [3:23:18<05:29,  1.67it/s] 97%|█████████▋| 16974/17525 [3:23:19<05:29,  1.67it/s] 97%|█████████▋| 16975/17525 [3:23:20<05:24,  1.70it/s] 97%|█████████▋| 16976/17525 [3:23:20<05:23,  1.70it/s] 97%|█████████▋| 16977/17525 [3:23:21<05:20,  1.71it/s] 97%|█████████▋| 16978/17525 [3:23:21<05:18,  1.72it/s] 97%|█████████▋| 16979/17525 [3:23:22<05:17,  1.72it/s] 97%|█████████▋| 16980/17525 [3:23:22<05:15,  1.73it/s]                                                       {'loss': 0.3814, 'grad_norm': 9.113436698913574, 'learning_rate': 4.956469044269496e-08, 'epoch': 24.22}
 97%|█████████▋| 16980/17525 [3:23:22<05:15,  1.73it/s] 97%|█████████▋| 16981/17525 [3:23:23<06:13,  1.46it/s] 97%|█████████▋| 16982/17525 [3:23:24<05:55,  1.53it/s] 97%|█████████▋| 16983/17525 [3:23:25<06:36,  1.37it/s] 97%|█████████▋| 16984/17525 [3:23:25<06:11,  1.46it/s] 97%|█████████▋| 16985/17525 [3:23:26<05:53,  1.53it/s] 97%|█████████▋| 16986/17525 [3:23:27<06:10,  1.45it/s] 97%|█████████▋| 16987/17525 [3:23:27<05:52,  1.53it/s] 97%|█████████▋| 16988/17525 [3:23:28<05:40,  1.58it/s] 97%|█████████▋| 16989/17525 [3:23:29<05:29,  1.63it/s] 97%|█████████▋| 16990/17525 [3:23:30<07:03,  1.26it/s]                                                       {'loss': 0.3049, 'grad_norm': 8.244590759277344, 'learning_rate': 4.7796077975649224e-08, 'epoch': 24.24}
 97%|█████████▋| 16990/17525 [3:23:30<07:03,  1.26it/s] 97%|█████████▋| 16991/17525 [3:23:30<06:31,  1.36it/s] 97%|█████████▋| 16992/17525 [3:23:31<06:05,  1.46it/s] 97%|█████████▋| 16993/17525 [3:23:31<05:47,  1.53it/s] 97%|█████████▋| 16994/17525 [3:23:32<05:34,  1.59it/s] 97%|█████████▋| 16995/17525 [3:23:33<05:26,  1.62it/s] 97%|█████████▋| 16996/17525 [3:23:33<05:19,  1.65it/s] 97%|█████████▋| 16997/17525 [3:23:34<05:16,  1.67it/s] 97%|█████████▋| 16998/17525 [3:23:34<05:11,  1.69it/s] 97%|█████████▋| 16999/17525 [3:23:35<05:09,  1.70it/s] 97%|█████████▋| 17000/17525 [3:23:36<05:11,  1.68it/s]                                                       {'loss': 0.2755, 'grad_norm': 18.13241195678711, 'learning_rate': 4.6059520426202656e-08, 'epoch': 24.25}
 97%|█████████▋| 17000/17525 [3:23:36<05:11,  1.68it/s][INFO|trainer.py:3512] 2024-06-25 05:26:57,436 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:26:57,436 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:26:57,436 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.81it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.197979211807251, 'eval_runtime': 4.5916, 'eval_samples_per_second': 96.48, 'eval_steps_per_second': 4.138, 'epoch': 24.25}
 97%|█████████▋| 17000/17525 [3:23:40<05:11,  1.68it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 97%|█████████▋| 17001/17525 [3:23:41<17:15,  1.98s/it] 97%|█████████▋| 17002/17525 [3:23:41<13:33,  1.56s/it] 97%|█████████▋| 17003/17525 [3:23:42<10:58,  1.26s/it] 97%|█████████▋| 17004/17525 [3:23:42<09:11,  1.06s/it] 97%|█████████▋| 17005/17525 [3:23:43<07:55,  1.09it/s] 97%|█████████▋| 17006/17525 [3:23:44<07:01,  1.23it/s] 97%|█████████▋| 17007/17525 [3:23:44<06:24,  1.35it/s] 97%|█████████▋| 17008/17525 [3:23:45<05:59,  1.44it/s] 97%|█████████▋| 17009/17525 [3:23:45<05:44,  1.50it/s] 97%|█████████▋| 17010/17525 [3:23:46<05:29,  1.56it/s]                                                       {'loss': 0.3407, 'grad_norm': 12.406707763671875, 'learning_rate': 4.435502338760889e-08, 'epoch': 24.27}
 97%|█████████▋| 17010/17525 [3:23:46<05:29,  1.56it/s] 97%|█████████▋| 17011/17525 [3:23:47<05:22,  1.59it/s] 97%|█████████▋| 17012/17525 [3:23:47<05:14,  1.63it/s] 97%|█████████▋| 17013/17525 [3:23:48<05:07,  1.66it/s] 97%|█████████▋| 17014/17525 [3:23:48<05:02,  1.69it/s] 97%|█████████▋| 17015/17525 [3:23:49<04:59,  1.70it/s] 97%|█████████▋| 17016/17525 [3:23:49<04:58,  1.71it/s] 97%|█████████▋| 17017/17525 [3:23:50<04:59,  1.70it/s] 97%|█████████▋| 17018/17525 [3:23:51<05:02,  1.67it/s] 97%|█████████▋| 17019/17525 [3:23:51<04:58,  1.69it/s] 97%|█████████▋| 17020/17525 [3:23:52<04:55,  1.71it/s]                                                       {'loss': 0.3275, 'grad_norm': 5.997659206390381, 'learning_rate': 4.268259234985861e-08, 'epoch': 24.28}
 97%|█████████▋| 17020/17525 [3:23:52<04:55,  1.71it/s] 97%|█████████▋| 17021/17525 [3:23:52<04:54,  1.71it/s] 97%|█████████▋| 17022/17525 [3:23:53<05:46,  1.45it/s] 97%|█████████▋| 17023/17525 [3:23:54<05:29,  1.53it/s] 97%|█████████▋| 17024/17525 [3:23:54<05:16,  1.58it/s] 97%|█████████▋| 17025/17525 [3:23:55<05:07,  1.63it/s] 97%|█████████▋| 17026/17525 [3:23:56<05:00,  1.66it/s] 97%|█████████▋| 17027/17525 [3:23:56<05:00,  1.66it/s] 97%|█████████▋| 17028/17525 [3:23:57<04:55,  1.68it/s] 97%|█████████▋| 17029/17525 [3:23:57<04:52,  1.70it/s] 97%|█████████▋| 17030/17525 [3:23:58<04:51,  1.70it/s]                                                       {'loss': 0.2854, 'grad_norm': 7.047318458557129, 'learning_rate': 4.104223269966401e-08, 'epoch': 24.29}
 97%|█████████▋| 17030/17525 [3:23:58<04:51,  1.70it/s] 97%|█████████▋| 17031/17525 [3:23:59<04:49,  1.71it/s] 97%|█████████▋| 17032/17525 [3:24:00<05:58,  1.37it/s] 97%|█████████▋| 17033/17525 [3:24:00<05:35,  1.47it/s] 97%|█████████▋| 17034/17525 [3:24:01<05:21,  1.53it/s] 97%|█████████▋| 17035/17525 [3:24:01<05:09,  1.58it/s] 97%|█████████▋| 17036/17525 [3:24:02<05:04,  1.61it/s] 97%|█████████▋| 17037/17525 [3:24:03<04:58,  1.63it/s] 97%|█████████▋| 17038/17525 [3:24:03<04:52,  1.66it/s] 97%|█████████▋| 17039/17525 [3:24:04<04:49,  1.68it/s] 97%|█████████▋| 17040/17525 [3:24:04<04:46,  1.69it/s]                                                       {'loss': 0.3139, 'grad_norm': 7.407310485839844, 'learning_rate': 3.9433949720435464e-08, 'epoch': 24.31}
 97%|█████████▋| 17040/17525 [3:24:04<04:46,  1.69it/s] 97%|█████████▋| 17041/17525 [3:24:05<04:43,  1.71it/s] 97%|█████████▋| 17042/17525 [3:24:05<04:43,  1.70it/s] 97%|█████████▋| 17043/17525 [3:24:06<04:40,  1.72it/s] 97%|█████████▋| 17044/17525 [3:24:07<04:38,  1.72it/s] 97%|█████████▋| 17045/17525 [3:24:07<04:38,  1.73it/s] 97%|█████████▋| 17046/17525 [3:24:08<04:38,  1.72it/s] 97%|█████████▋| 17047/17525 [3:24:08<04:37,  1.72it/s] 97%|█████████▋| 17048/17525 [3:24:09<04:36,  1.73it/s] 97%|█████████▋| 17049/17525 [3:24:10<04:38,  1.71it/s] 97%|█████████▋| 17050/17525 [3:24:10<04:36,  1.72it/s]                                                       {'loss': 0.3248, 'grad_norm': 8.604022979736328, 'learning_rate': 3.785774859226932e-08, 'epoch': 24.32}
 97%|█████████▋| 17050/17525 [3:24:10<04:36,  1.72it/s] 97%|█████████▋| 17051/17525 [3:24:11<04:35,  1.72it/s] 97%|█████████▋| 17052/17525 [3:24:12<05:43,  1.38it/s] 97%|█████████▋| 17053/17525 [3:24:12<05:21,  1.47it/s] 97%|█████████▋| 17054/17525 [3:24:13<05:06,  1.54it/s] 97%|█████████▋| 17055/17525 [3:24:13<04:55,  1.59it/s] 97%|█████████▋| 17056/17525 [3:24:14<04:48,  1.62it/s] 97%|█████████▋| 17057/17525 [3:24:15<04:42,  1.66it/s] 97%|█████████▋| 17058/17525 [3:24:15<04:38,  1.68it/s] 97%|█████████▋| 17059/17525 [3:24:16<04:34,  1.70it/s] 97%|█████████▋| 17060/17525 [3:24:16<04:32,  1.71it/s]                                                       {'loss': 0.3289, 'grad_norm': 9.04815673828125, 'learning_rate': 3.631363439193236e-08, 'epoch': 24.34}
 97%|█████████▋| 17060/17525 [3:24:16<04:32,  1.71it/s] 97%|█████████▋| 17061/17525 [3:24:17<04:30,  1.71it/s] 97%|█████████▋| 17062/17525 [3:24:18<04:29,  1.72it/s] 97%|█████████▋| 17063/17525 [3:24:18<04:27,  1.73it/s] 97%|█████████▋| 17064/17525 [3:24:19<04:27,  1.73it/s] 97%|█████████▋| 17065/17525 [3:24:19<04:26,  1.73it/s] 97%|█████████▋| 17066/17525 [3:24:20<04:25,  1.73it/s] 97%|█████████▋| 17067/17525 [3:24:20<04:24,  1.73it/s] 97%|█████████▋| 17068/17525 [3:24:21<04:42,  1.62it/s] 97%|█████████▋| 17069/17525 [3:24:22<04:36,  1.65it/s] 97%|█████████▋| 17070/17525 [3:24:22<04:32,  1.67it/s]                                                       {'loss': 0.3675, 'grad_norm': 15.502671241760254, 'learning_rate': 3.48016120928385e-08, 'epoch': 24.35}
 97%|█████████▋| 17070/17525 [3:24:22<04:32,  1.67it/s] 97%|█████████▋| 17071/17525 [3:24:23<04:29,  1.69it/s] 97%|█████████▋| 17072/17525 [3:24:23<04:26,  1.70it/s] 97%|█████████▋| 17073/17525 [3:24:24<04:27,  1.69it/s] 97%|█████████▋| 17074/17525 [3:24:25<04:24,  1.70it/s] 97%|█████████▋| 17075/17525 [3:24:25<04:22,  1.71it/s] 97%|█████████▋| 17076/17525 [3:24:26<04:20,  1.72it/s] 97%|█████████▋| 17077/17525 [3:24:26<04:19,  1.73it/s] 97%|█████████▋| 17078/17525 [3:24:27<04:18,  1.73it/s] 97%|█████████▋| 17079/17525 [3:24:27<04:18,  1.73it/s] 97%|█████████▋| 17080/17525 [3:24:28<04:17,  1.73it/s]                                                       {'loss': 0.3694, 'grad_norm': 14.55251693725586, 'learning_rate': 3.332168656504209e-08, 'epoch': 24.37}
 97%|█████████▋| 17080/17525 [3:24:28<04:17,  1.73it/s] 97%|█████████▋| 17081/17525 [3:24:29<04:16,  1.73it/s] 97%|█████████▋| 17082/17525 [3:24:29<04:16,  1.73it/s] 97%|█████████▋| 17083/17525 [3:24:30<04:25,  1.67it/s] 97%|█████████▋| 17084/17525 [3:24:31<05:10,  1.42it/s] 97%|█████████▋| 17085/17525 [3:24:31<04:55,  1.49it/s] 97%|█████████▋| 17086/17525 [3:24:32<04:44,  1.55it/s] 98%|█████████▊| 17087/17525 [3:24:33<04:39,  1.57it/s] 98%|█████████▊| 17088/17525 [3:24:33<04:32,  1.60it/s] 98%|█████████▊| 17089/17525 [3:24:34<04:25,  1.64it/s] 98%|█████████▊| 17090/17525 [3:24:34<04:21,  1.66it/s]                                                       {'loss': 0.3701, 'grad_norm': 11.033646583557129, 'learning_rate': 3.187386257521241e-08, 'epoch': 24.38}
 98%|█████████▊| 17090/17525 [3:24:34<04:21,  1.66it/s] 98%|█████████▊| 17091/17525 [3:24:35<04:22,  1.65it/s] 98%|█████████▊| 17092/17525 [3:24:36<04:19,  1.67it/s] 98%|█████████▊| 17093/17525 [3:24:36<04:17,  1.68it/s] 98%|█████████▊| 17094/17525 [3:24:37<04:19,  1.66it/s] 98%|█████████▊| 17095/17525 [3:24:37<04:15,  1.69it/s] 98%|█████████▊| 17096/17525 [3:24:38<04:12,  1.70it/s] 98%|█████████▊| 17097/17525 [3:24:38<04:12,  1.70it/s] 98%|█████████▊| 17098/17525 [3:24:39<04:11,  1.70it/s] 98%|█████████▊| 17099/17525 [3:24:40<04:09,  1.71it/s] 98%|█████████▊| 17100/17525 [3:24:40<04:07,  1.72it/s]                                                       {'loss': 0.3957, 'grad_norm': 28.299543380737305, 'learning_rate': 3.0458144786628116e-08, 'epoch': 24.39}
 98%|█████████▊| 17100/17525 [3:24:40<04:07,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:28:02,131 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:28:02,131 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:28:02,131 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.03it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.37it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.61it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.85it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.27it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.54it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.66it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.72it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.69it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.78it/s][A
 74%|███████▎  | 14/19 [00:02<00:01,  4.96it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.07it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.04it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.54it/s][A
 95%|█████████▍| 18/19 [00:04<00:00,  3.96it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.72it/s][A                                                       
                                               [A{'eval_loss': 1.1985559463500977, 'eval_runtime': 4.6529, 'eval_samples_per_second': 95.21, 'eval_steps_per_second': 4.083, 'epoch': 24.39}
 98%|█████████▊| 17100/17525 [3:24:45<04:07,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.72it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:28:06,788 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17100
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7a95990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 34843bd9-27da-45a9-a278-2a98ad988b5d)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:28:16,846 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:28:16,848 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17100/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 98%|█████████▊| 17101/17525 [3:24:56<35:39,  5.05s/it] 98%|█████████▊| 17102/17525 [3:24:56<26:30,  3.76s/it] 98%|█████████▊| 17103/17525 [3:24:57<19:45,  2.81s/it] 98%|█████████▊| 17104/17525 [3:24:58<15:03,  2.15s/it] 98%|█████████▊| 17105/17525 [3:24:58<11:47,  1.68s/it] 98%|█████████▊| 17106/17525 [3:24:59<09:30,  1.36s/it] 98%|█████████▊| 17107/17525 [3:24:59<07:51,  1.13s/it] 98%|█████████▊| 17108/17525 [3:25:00<06:40,  1.04it/s] 98%|█████████▊| 17109/17525 [3:25:01<05:55,  1.17it/s] 98%|█████████▊| 17110/17525 [3:25:01<05:20,  1.29it/s]                                                       {'loss': 0.3262, 'grad_norm': 5.554653644561768, 'learning_rate': 2.907453775915503e-08, 'epoch': 24.41}
 98%|█████████▊| 17110/17525 [3:25:01<05:20,  1.29it/s] 98%|█████████▊| 17111/17525 [3:25:02<04:55,  1.40it/s] 98%|█████████▊| 17112/17525 [3:25:02<04:37,  1.49it/s] 98%|█████████▊| 17113/17525 [3:25:03<04:26,  1.54it/s] 98%|█████████▊| 17114/17525 [3:25:04<04:19,  1.58it/s] 98%|█████████▊| 17115/17525 [3:25:04<04:52,  1.40it/s] 98%|█████████▊| 17116/17525 [3:25:05<04:34,  1.49it/s] 98%|█████████▊| 17117/17525 [3:25:06<04:25,  1.54it/s] 98%|█████████▊| 17118/17525 [3:25:06<04:15,  1.60it/s] 98%|█████████▊| 17119/17525 [3:25:07<04:11,  1.61it/s] 98%|█████████▊| 17120/17525 [3:25:08<04:23,  1.54it/s]                                                       {'loss': 0.3775, 'grad_norm': 10.84881591796875, 'learning_rate': 2.7723045949232807e-08, 'epoch': 24.42}
 98%|█████████▊| 17120/17525 [3:25:08<04:23,  1.54it/s] 98%|█████████▊| 17121/17525 [3:25:08<04:14,  1.59it/s] 98%|█████████▊| 17122/17525 [3:25:09<04:12,  1.59it/s] 98%|█████████▊| 17123/17525 [3:25:09<04:06,  1.63it/s] 98%|█████████▊| 17124/17525 [3:25:10<04:01,  1.66it/s] 98%|█████████▊| 17125/17525 [3:25:10<03:57,  1.68it/s] 98%|█████████▊| 17126/17525 [3:25:11<03:54,  1.70it/s] 98%|█████████▊| 17127/17525 [3:25:12<03:52,  1.71it/s] 98%|█████████▊| 17128/17525 [3:25:12<03:51,  1.72it/s] 98%|█████████▊| 17129/17525 [3:25:13<03:50,  1.72it/s] 98%|█████████▊| 17130/17525 [3:25:13<03:50,  1.72it/s]                                                       {'loss': 0.3003, 'grad_norm': 10.519539833068848, 'learning_rate': 2.6403673709863854e-08, 'epoch': 24.44}
 98%|█████████▊| 17130/17525 [3:25:13<03:50,  1.72it/s] 98%|█████████▊| 17131/17525 [3:25:14<03:49,  1.72it/s] 98%|█████████▊| 17132/17525 [3:25:14<03:47,  1.73it/s] 98%|█████████▊| 17133/17525 [3:25:15<03:46,  1.73it/s] 98%|█████████▊| 17134/17525 [3:25:16<03:47,  1.72it/s] 98%|█████████▊| 17135/17525 [3:25:16<03:48,  1.71it/s] 98%|█████████▊| 17136/17525 [3:25:17<03:46,  1.72it/s] 98%|█████████▊| 17137/17525 [3:25:17<03:46,  1.71it/s] 98%|█████████▊| 17138/17525 [3:25:18<03:45,  1.72it/s] 98%|█████████▊| 17139/17525 [3:25:19<04:25,  1.46it/s] 98%|█████████▊| 17140/17525 [3:25:20<04:11,  1.53it/s]                                                       {'loss': 0.3469, 'grad_norm': 11.72506332397461, 'learning_rate': 2.5116425290595548e-08, 'epoch': 24.45}
 98%|█████████▊| 17140/17525 [3:25:20<04:11,  1.53it/s] 98%|█████████▊| 17141/17525 [3:25:20<04:02,  1.59it/s] 98%|█████████▊| 17142/17525 [3:25:21<03:55,  1.63it/s] 98%|█████████▊| 17143/17525 [3:25:21<03:50,  1.66it/s] 98%|█████████▊| 17144/17525 [3:25:22<03:46,  1.68it/s] 98%|█████████▊| 17145/17525 [3:25:22<03:44,  1.70it/s] 98%|█████████▊| 17146/17525 [3:25:23<03:41,  1.71it/s] 98%|█████████▊| 17147/17525 [3:25:24<03:40,  1.72it/s] 98%|█████████▊| 17148/17525 [3:25:25<05:38,  1.11it/s] 98%|█████████▊| 17149/17525 [3:25:26<05:03,  1.24it/s] 98%|█████████▊| 17150/17525 [3:25:26<04:37,  1.35it/s]                                                       {'loss': 0.329, 'grad_norm': 13.105684280395508, 'learning_rate': 2.3861304837509146e-08, 'epoch': 24.47}
 98%|█████████▊| 17150/17525 [3:25:26<04:37,  1.35it/s] 98%|█████████▊| 17151/17525 [3:25:27<04:19,  1.44it/s] 98%|█████████▊| 17152/17525 [3:25:28<04:05,  1.52it/s] 98%|█████████▊| 17153/17525 [3:25:28<03:55,  1.58it/s] 98%|█████████▊| 17154/17525 [3:25:29<03:48,  1.62it/s] 98%|█████████▊| 17155/17525 [3:25:29<03:43,  1.66it/s] 98%|█████████▊| 17156/17525 [3:25:30<03:39,  1.68it/s] 98%|█████████▊| 17157/17525 [3:25:30<03:39,  1.68it/s] 98%|█████████▊| 17158/17525 [3:25:31<03:36,  1.69it/s] 98%|█████████▊| 17159/17525 [3:25:32<03:35,  1.70it/s] 98%|█████████▊| 17160/17525 [3:25:32<03:34,  1.70it/s]                                                       {'loss': 0.3026, 'grad_norm': 9.950326919555664, 'learning_rate': 2.263831639320646e-08, 'epoch': 24.48}
 98%|█████████▊| 17160/17525 [3:25:32<03:34,  1.70it/s] 98%|█████████▊| 17161/17525 [3:25:33<03:33,  1.71it/s] 98%|█████████▊| 17162/17525 [3:25:33<03:31,  1.72it/s] 98%|█████████▊| 17163/17525 [3:25:34<03:30,  1.72it/s] 98%|█████████▊| 17164/17525 [3:25:34<03:29,  1.72it/s] 98%|█████████▊| 17165/17525 [3:25:35<03:28,  1.73it/s] 98%|█████████▊| 17166/17525 [3:25:36<03:27,  1.73it/s] 98%|█████████▊| 17167/17525 [3:25:36<03:26,  1.73it/s] 98%|█████████▊| 17168/17525 [3:25:37<03:25,  1.73it/s] 98%|█████████▊| 17169/17525 [3:25:37<03:26,  1.72it/s] 98%|█████████▊| 17170/17525 [3:25:38<03:25,  1.73it/s]                                                       {'loss': 0.325, 'grad_norm': 14.14775276184082, 'learning_rate': 2.1447463896790977e-08, 'epoch': 24.49}
 98%|█████████▊| 17170/17525 [3:25:38<03:25,  1.73it/s] 98%|█████████▊| 17171/17525 [3:25:39<03:25,  1.72it/s] 98%|█████████▊| 17172/17525 [3:25:39<03:25,  1.71it/s] 98%|█████████▊| 17173/17525 [3:25:40<03:24,  1.72it/s] 98%|█████████▊| 17174/17525 [3:25:40<03:25,  1.71it/s] 98%|█████████▊| 17175/17525 [3:25:41<03:23,  1.72it/s] 98%|█████████▊| 17176/17525 [3:25:41<03:22,  1.72it/s] 98%|█████████▊| 17177/17525 [3:25:42<03:21,  1.73it/s] 98%|█████████▊| 17178/17525 [3:25:43<03:22,  1.72it/s] 98%|█████████▊| 17179/17525 [3:25:43<03:20,  1.72it/s] 98%|█████████▊| 17180/17525 [3:25:44<03:21,  1.72it/s]                                                       {'loss': 0.3209, 'grad_norm': 8.025217056274414, 'learning_rate': 2.028875118386675e-08, 'epoch': 24.51}
 98%|█████████▊| 17180/17525 [3:25:44<03:21,  1.72it/s] 98%|█████████▊| 17181/17525 [3:25:44<03:20,  1.72it/s] 98%|█████████▊| 17182/17525 [3:25:45<03:18,  1.72it/s] 98%|█████████▊| 17183/17525 [3:25:45<03:18,  1.73it/s] 98%|█████████▊| 17184/17525 [3:25:46<03:17,  1.73it/s] 98%|█████████▊| 17185/17525 [3:25:47<03:15,  1.74it/s] 98%|█████████▊| 17186/17525 [3:25:47<03:15,  1.74it/s] 98%|█████████▊| 17187/17525 [3:25:48<03:51,  1.46it/s] 98%|█████████▊| 17188/17525 [3:25:49<03:39,  1.53it/s] 98%|█████████▊| 17189/17525 [3:25:49<03:32,  1.58it/s] 98%|█████████▊| 17190/17525 [3:25:50<03:26,  1.63it/s]                                                       {'loss': 0.2999, 'grad_norm': 6.056881904602051, 'learning_rate': 1.9162181986512875e-08, 'epoch': 24.52}
 98%|█████████▊| 17190/17525 [3:25:50<03:26,  1.63it/s] 98%|█████████▊| 17191/17525 [3:25:50<03:21,  1.65it/s] 98%|█████████▊| 17192/17525 [3:25:51<03:18,  1.68it/s] 98%|█████████▊| 17193/17525 [3:25:52<03:15,  1.70it/s] 98%|█████████▊| 17194/17525 [3:25:52<03:13,  1.71it/s] 98%|█████████▊| 17195/17525 [3:25:53<03:13,  1.71it/s] 98%|█████████▊| 17196/17525 [3:25:53<03:11,  1.72it/s] 98%|█████████▊| 17197/17525 [3:25:54<03:14,  1.68it/s] 98%|█████████▊| 17198/17525 [3:25:55<03:12,  1.70it/s] 98%|█████████▊| 17199/17525 [3:25:55<03:11,  1.70it/s] 98%|█████████▊| 17200/17525 [3:25:56<03:09,  1.71it/s]                                                       {'loss': 0.3337, 'grad_norm': 10.343420028686523, 'learning_rate': 1.8067759933282358e-08, 'epoch': 24.54}
 98%|█████████▊| 17200/17525 [3:25:56<03:09,  1.71it/s][INFO|trainer.py:3512] 2024-06-25 05:29:17,621 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:29:17,621 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:29:17,621 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.1987203359603882, 'eval_runtime': 4.5975, 'eval_samples_per_second': 96.357, 'eval_steps_per_second': 4.133, 'epoch': 24.54}
 98%|█████████▊| 17200/17525 [3:26:00<03:09,  1.71it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 98%|█████████▊| 17201/17525 [3:26:01<10:36,  1.96s/it] 98%|█████████▊| 17202/17525 [3:26:01<08:21,  1.55s/it] 98%|█████████▊| 17203/17525 [3:26:02<06:45,  1.26s/it] 98%|█████████▊| 17204/17525 [3:26:03<05:38,  1.06s/it] 98%|█████████▊| 17205/17525 [3:26:03<04:52,  1.10it/s] 98%|█████████▊| 17206/17525 [3:26:04<04:19,  1.23it/s] 98%|█████████▊| 17207/17525 [3:26:04<03:56,  1.34it/s] 98%|█████████▊| 17208/17525 [3:26:05<03:43,  1.42it/s] 98%|█████████▊| 17209/17525 [3:26:06<03:30,  1.50it/s] 98%|█████████▊| 17210/17525 [3:26:06<03:21,  1.56it/s]                                                       {'loss': 0.3543, 'grad_norm': 9.908059120178223, 'learning_rate': 1.700548854918327e-08, 'epoch': 24.55}
 98%|█████████▊| 17210/17525 [3:26:06<03:21,  1.56it/s] 98%|█████████▊| 17211/17525 [3:26:07<03:15,  1.61it/s] 98%|█████████▊| 17212/17525 [3:26:07<03:10,  1.64it/s] 98%|█████████▊| 17213/17525 [3:26:08<03:06,  1.67it/s] 98%|█████████▊| 17214/17525 [3:26:08<03:03,  1.69it/s] 98%|█████████▊| 17215/17525 [3:26:09<03:02,  1.70it/s] 98%|█████████▊| 17216/17525 [3:26:10<03:00,  1.71it/s] 98%|█████████▊| 17217/17525 [3:26:10<02:59,  1.72it/s] 98%|█████████▊| 17218/17525 [3:26:11<02:58,  1.72it/s] 98%|█████████▊| 17219/17525 [3:26:11<02:57,  1.73it/s] 98%|█████████▊| 17220/17525 [3:26:12<02:56,  1.73it/s]                                                       {'loss': 0.3665, 'grad_norm': 15.428021430969238, 'learning_rate': 1.5975371255672056e-08, 'epoch': 24.56}
 98%|█████████▊| 17220/17525 [3:26:12<02:56,  1.73it/s] 98%|█████████▊| 17221/17525 [3:26:13<02:55,  1.73it/s] 98%|█████████▊| 17222/17525 [3:26:13<02:55,  1.73it/s] 98%|█████████▊| 17223/17525 [3:26:14<02:54,  1.73it/s] 98%|█████████▊| 17224/17525 [3:26:14<02:53,  1.73it/s] 98%|█████████▊| 17225/17525 [3:26:15<02:53,  1.73it/s] 98%|█████████▊| 17226/17525 [3:26:15<02:54,  1.72it/s] 98%|█████████▊| 17227/17525 [3:26:16<02:54,  1.71it/s] 98%|█████████▊| 17228/17525 [3:26:17<02:53,  1.72it/s] 98%|█████████▊| 17229/17525 [3:26:17<02:51,  1.72it/s] 98%|█████████▊| 17230/17525 [3:26:18<02:50,  1.73it/s]                                                       {'loss': 0.3312, 'grad_norm': 15.730279922485352, 'learning_rate': 1.4977411370638018e-08, 'epoch': 24.58}
 98%|█████████▊| 17230/17525 [3:26:18<02:50,  1.73it/s] 98%|█████████▊| 17231/17525 [3:26:18<02:50,  1.73it/s] 98%|█████████▊| 17232/17525 [3:26:19<02:49,  1.73it/s] 98%|█████████▊| 17233/17525 [3:26:20<03:26,  1.41it/s] 98%|█████████▊| 17234/17525 [3:26:20<03:14,  1.50it/s] 98%|█████████▊| 17235/17525 [3:26:21<03:05,  1.56it/s] 98%|█████████▊| 17236/17525 [3:26:22<02:59,  1.61it/s] 98%|█████████▊| 17237/17525 [3:26:22<02:54,  1.65it/s] 98%|█████████▊| 17238/17525 [3:26:23<02:51,  1.67it/s] 98%|█████████▊| 17239/17525 [3:26:23<02:48,  1.69it/s] 98%|█████████▊| 17240/17525 [3:26:24<02:46,  1.71it/s]                                                       {'loss': 0.3257, 'grad_norm': 11.1537446975708, 'learning_rate': 1.4011612108398853e-08, 'epoch': 24.59}
 98%|█████████▊| 17240/17525 [3:26:24<02:46,  1.71it/s] 98%|█████████▊| 17241/17525 [3:26:25<03:51,  1.22it/s] 98%|█████████▊| 17242/17525 [3:26:26<03:30,  1.34it/s] 98%|█████████▊| 17243/17525 [3:26:26<03:15,  1.44it/s] 98%|█████████▊| 17244/17525 [3:26:27<03:05,  1.52it/s] 98%|█████████▊| 17245/17525 [3:26:28<02:57,  1.57it/s] 98%|█████████▊| 17246/17525 [3:26:28<02:53,  1.61it/s] 98%|█████████▊| 17247/17525 [3:26:29<02:48,  1.65it/s] 98%|█████████▊| 17248/17525 [3:26:29<02:45,  1.68it/s] 98%|█████████▊| 17249/17525 [3:26:30<02:42,  1.70it/s] 98%|█████████▊| 17250/17525 [3:26:30<02:41,  1.71it/s]                                                       {'loss': 0.2991, 'grad_norm': 12.125682830810547, 'learning_rate': 1.3077976579680684e-08, 'epoch': 24.61}
 98%|█████████▊| 17250/17525 [3:26:30<02:41,  1.71it/s][INFO|trainer.py:3203] 2024-06-25 05:29:52,369 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17250
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7c65990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5c52a878-d154-4531-8e91-ad7abc7a8c86)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:30:02,427 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17250/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:30:02,430 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17250/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 98%|█████████▊| 17251/17525 [3:26:41<16:40,  3.65s/it] 98%|█████████▊| 17252/17525 [3:26:42<12:25,  2.73s/it] 98%|█████████▊| 17253/17525 [3:26:42<09:27,  2.09s/it] 98%|█████████▊| 17254/17525 [3:26:43<07:22,  1.63s/it] 98%|█████████▊| 17255/17525 [3:26:44<05:55,  1.32s/it] 98%|█████████▊| 17256/17525 [3:26:44<04:54,  1.10s/it] 98%|█████████▊| 17257/17525 [3:26:45<04:12,  1.06it/s] 98%|█████████▊| 17258/17525 [3:26:45<03:42,  1.20it/s] 98%|█████████▊| 17259/17525 [3:26:46<03:20,  1.33it/s] 98%|█████████▊| 17260/17525 [3:26:46<03:05,  1.43it/s]                                                       {'loss': 0.3378, 'grad_norm': 12.235055923461914, 'learning_rate': 1.2176507791621384e-08, 'epoch': 24.62}
 98%|█████████▊| 17260/17525 [3:26:46<03:05,  1.43it/s] 98%|█████████▊| 17261/17525 [3:26:47<02:55,  1.50it/s] 98%|█████████▊| 17262/17525 [3:26:48<02:47,  1.57it/s] 99%|█████████▊| 17263/17525 [3:26:48<02:42,  1.62it/s] 99%|█████████▊| 17264/17525 [3:26:49<02:38,  1.65it/s] 99%|█████████▊| 17265/17525 [3:26:49<02:35,  1.68it/s] 99%|█████████▊| 17266/17525 [3:26:50<02:32,  1.69it/s] 99%|█████████▊| 17267/17525 [3:26:51<02:31,  1.70it/s] 99%|█████████▊| 17268/17525 [3:26:51<02:29,  1.72it/s] 99%|█████████▊| 17269/17525 [3:26:52<02:29,  1.71it/s] 99%|█████████▊| 17270/17525 [3:26:52<02:28,  1.72it/s]                                                       {'loss': 0.373, 'grad_norm': 14.127571105957031, 'learning_rate': 1.1307208647746149e-08, 'epoch': 24.64}
 99%|█████████▊| 17270/17525 [3:26:52<02:28,  1.72it/s] 99%|█████████▊| 17271/17525 [3:26:53<02:27,  1.72it/s] 99%|█████████▊| 17272/17525 [3:26:53<02:26,  1.73it/s] 99%|█████████▊| 17273/17525 [3:26:54<02:25,  1.73it/s] 99%|█████████▊| 17274/17525 [3:26:55<02:24,  1.73it/s] 99%|█████████▊| 17275/17525 [3:26:55<02:23,  1.74it/s] 99%|█████████▊| 17276/17525 [3:26:56<02:23,  1.74it/s] 99%|█████████▊| 17277/17525 [3:26:56<02:23,  1.73it/s] 99%|█████████▊| 17278/17525 [3:26:57<02:48,  1.47it/s] 99%|█████████▊| 17279/17525 [3:26:58<02:39,  1.54it/s] 99%|█████████▊| 17280/17525 [3:26:58<02:33,  1.60it/s]                                                       {'loss': 0.3118, 'grad_norm': 8.522421836853027, 'learning_rate': 1.0470081947970834e-08, 'epoch': 24.65}
 99%|█████████▊| 17280/17525 [3:26:58<02:33,  1.60it/s] 99%|█████████▊| 17281/17525 [3:26:59<02:29,  1.64it/s] 99%|█████████▊| 17282/17525 [3:27:00<02:26,  1.66it/s] 99%|█████████▊| 17283/17525 [3:27:01<03:20,  1.21it/s] 99%|█████████▊| 17284/17525 [3:27:01<03:01,  1.33it/s] 99%|█████████▊| 17285/17525 [3:27:02<02:47,  1.43it/s] 99%|█████████▊| 17286/17525 [3:27:03<02:38,  1.51it/s] 99%|█████████▊| 17287/17525 [3:27:03<02:34,  1.54it/s] 99%|█████████▊| 17288/17525 [3:27:04<02:28,  1.60it/s] 99%|█████████▊| 17289/17525 [3:27:04<02:24,  1.64it/s] 99%|█████████▊| 17290/17525 [3:27:05<02:21,  1.66it/s]                                                       {'loss': 0.4308, 'grad_norm': 10.63631820678711, 'learning_rate': 9.665130388584187e-09, 'epoch': 24.66}
 99%|█████████▊| 17290/17525 [3:27:05<02:21,  1.66it/s] 99%|█████████▊| 17291/17525 [3:27:06<02:19,  1.68it/s] 99%|█████████▊| 17292/17525 [3:27:06<02:19,  1.67it/s] 99%|█████████▊| 17293/17525 [3:27:07<02:18,  1.68it/s] 99%|█████████▊| 17294/17525 [3:27:07<02:16,  1.70it/s] 99%|█████████▊| 17295/17525 [3:27:08<02:14,  1.71it/s] 99%|█████████▊| 17296/17525 [3:27:08<02:13,  1.71it/s] 99%|█████████▊| 17297/17525 [3:27:09<02:12,  1.72it/s] 99%|█████████▊| 17298/17525 [3:27:10<02:11,  1.72it/s] 99%|█████████▊| 17299/17525 [3:27:10<02:10,  1.73it/s] 99%|█████████▊| 17300/17525 [3:27:11<02:09,  1.74it/s]                                                       {'loss': 0.4771, 'grad_norm': nan, 'learning_rate': 8.968185875141144e-09, 'epoch': 24.68}
 99%|█████████▊| 17300/17525 [3:27:11<02:09,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:30:32,646 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:30:32,646 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:30:32,646 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.80it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.06it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.41it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.65it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.89it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.60it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.75it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.15it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.198425054550171, 'eval_runtime': 4.5912, 'eval_samples_per_second': 96.489, 'eval_steps_per_second': 4.138, 'epoch': 24.68}
 99%|█████████▊| 17300/17525 [3:27:15<02:09,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A 99%|█████████▊| 17301/17525 [3:27:16<07:17,  1.96s/it] 99%|█████████▊| 17302/17525 [3:27:17<05:44,  1.54s/it] 99%|█████████▊| 17303/17525 [3:27:17<04:38,  1.25s/it] 99%|█████████▊| 17304/17525 [3:27:18<03:51,  1.05s/it] 99%|█████████▊| 17305/17525 [3:27:18<03:19,  1.10it/s] 99%|█████████▉| 17306/17525 [3:27:19<02:56,  1.24it/s] 99%|█████████▉| 17307/17525 [3:27:19<02:40,  1.35it/s] 99%|█████████▉| 17308/17525 [3:27:20<02:29,  1.45it/s] 99%|█████████▉| 17309/17525 [3:27:21<02:21,  1.53it/s] 99%|█████████▉| 17310/17525 [3:27:21<02:15,  1.58it/s]                                                       {'loss': 0.3458, 'grad_norm': 5.166443347930908, 'learning_rate': 8.224374139605973e-09, 'epoch': 24.69}
 99%|█████████▉| 17310/17525 [3:27:21<02:15,  1.58it/s] 99%|█████████▉| 17311/17525 [3:27:22<02:11,  1.63it/s] 99%|█████████▉| 17312/17525 [3:27:22<02:08,  1.66it/s] 99%|█████████▉| 17313/17525 [3:27:23<02:06,  1.68it/s] 99%|█████████▉| 17314/17525 [3:27:23<02:06,  1.67it/s] 99%|█████████▉| 17315/17525 [3:27:24<02:04,  1.69it/s] 99%|█████████▉| 17316/17525 [3:27:25<02:02,  1.71it/s] 99%|█████████▉| 17317/17525 [3:27:25<02:01,  1.71it/s] 99%|█████████▉| 17318/17525 [3:27:26<02:00,  1.72it/s] 99%|█████████▉| 17319/17525 [3:27:26<01:59,  1.72it/s] 99%|█████████▉| 17320/17525 [3:27:27<01:58,  1.73it/s]                                                       {'loss': 0.3789, 'grad_norm': 10.5675687789917, 'learning_rate': 7.512744777630198e-09, 'epoch': 24.71}
 99%|█████████▉| 17320/17525 [3:27:27<01:58,  1.73it/s] 99%|█████████▉| 17321/17525 [3:27:27<01:58,  1.73it/s] 99%|█████████▉| 17322/17525 [3:27:28<01:57,  1.73it/s] 99%|█████████▉| 17323/17525 [3:27:29<01:56,  1.73it/s] 99%|█████████▉| 17324/17525 [3:27:29<01:55,  1.73it/s] 99%|█████████▉| 17325/17525 [3:27:30<01:55,  1.73it/s] 99%|█████████▉| 17326/17525 [3:27:30<01:54,  1.74it/s] 99%|█████████▉| 17327/17525 [3:27:31<01:54,  1.73it/s] 99%|█████████▉| 17328/17525 [3:27:32<01:53,  1.74it/s] 99%|█████████▉| 17329/17525 [3:27:33<02:29,  1.31it/s] 99%|█████████▉| 17330/17525 [3:27:33<02:17,  1.42it/s]                                                       {'loss': 0.2489, 'grad_norm': 4.979775428771973, 'learning_rate': 6.83330008128924e-09, 'epoch': 24.72}
 99%|█████████▉| 17330/17525 [3:27:33<02:17,  1.42it/s] 99%|█████████▉| 17331/17525 [3:27:34<02:09,  1.50it/s] 99%|█████████▉| 17332/17525 [3:27:34<02:03,  1.56it/s] 99%|█████████▉| 17333/17525 [3:27:35<01:59,  1.61it/s] 99%|█████████▉| 17334/17525 [3:27:36<01:55,  1.65it/s] 99%|█████████▉| 17335/17525 [3:27:36<01:53,  1.67it/s] 99%|█████████▉| 17336/17525 [3:27:37<01:52,  1.69it/s] 99%|█████████▉| 17337/17525 [3:27:37<01:50,  1.70it/s] 99%|█████████▉| 17338/17525 [3:27:38<01:49,  1.71it/s] 99%|█████████▉| 17339/17525 [3:27:38<01:48,  1.72it/s] 99%|█████████▉| 17340/17525 [3:27:39<01:47,  1.72it/s]                                                       {'loss': 0.3812, 'grad_norm': 12.457465171813965, 'learning_rate': 6.186042238999213e-09, 'epoch': 24.74}
 99%|█████████▉| 17340/17525 [3:27:39<01:47,  1.72it/s] 99%|█████████▉| 17341/17525 [3:27:40<01:46,  1.73it/s] 99%|█████████▉| 17342/17525 [3:27:40<01:45,  1.73it/s] 99%|█████████▉| 17343/17525 [3:27:41<01:44,  1.73it/s] 99%|█████████▉| 17344/17525 [3:27:41<01:44,  1.73it/s] 99%|█████████▉| 17345/17525 [3:27:42<01:43,  1.73it/s] 99%|█████████▉| 17346/17525 [3:27:43<01:43,  1.73it/s] 99%|█████████▉| 17347/17525 [3:27:43<01:42,  1.73it/s] 99%|█████████▉| 17348/17525 [3:27:44<01:42,  1.73it/s] 99%|█████████▉| 17349/17525 [3:27:44<01:41,  1.73it/s] 99%|█████████▉| 17350/17525 [3:27:45<01:41,  1.73it/s]                                                       {'loss': 0.3171, 'grad_norm': 11.126042366027832, 'learning_rate': 5.570973335503604e-09, 'epoch': 24.75}
 99%|█████████▉| 17350/17525 [3:27:45<01:41,  1.73it/s] 99%|█████████▉| 17351/17525 [3:27:45<01:40,  1.73it/s] 99%|█████████▉| 17352/17525 [3:27:46<01:39,  1.73it/s] 99%|█████████▉| 17353/17525 [3:27:47<01:39,  1.73it/s] 99%|█████████▉| 17354/17525 [3:27:47<01:38,  1.73it/s] 99%|█████████▉| 17355/17525 [3:27:48<01:38,  1.73it/s] 99%|█████████▉| 17356/17525 [3:27:48<01:37,  1.73it/s] 99%|█████████▉| 17357/17525 [3:27:49<01:36,  1.74it/s] 99%|█████████▉| 17358/17525 [3:27:49<01:36,  1.74it/s] 99%|█████████▉| 17359/17525 [3:27:50<01:35,  1.74it/s] 99%|█████████▉| 17360/17525 [3:27:51<01:36,  1.71it/s]                                                       {'loss': 0.2891, 'grad_norm': 10.647660255432129, 'learning_rate': 4.988095351867728e-09, 'epoch': 24.76}
 99%|█████████▉| 17360/17525 [3:27:51<01:36,  1.71it/s] 99%|█████████▉| 17361/17525 [3:27:51<01:35,  1.72it/s] 99%|█████████▉| 17362/17525 [3:27:52<01:34,  1.72it/s] 99%|█████████▉| 17363/17525 [3:27:52<01:33,  1.72it/s] 99%|█████████▉| 17364/17525 [3:27:53<01:33,  1.73it/s] 99%|█████████▉| 17365/17525 [3:27:53<01:32,  1.73it/s] 99%|█████████▉| 17366/17525 [3:27:54<01:31,  1.73it/s] 99%|█████████▉| 17367/17525 [3:27:55<01:31,  1.73it/s] 99%|█████████▉| 17368/17525 [3:27:55<01:30,  1.74it/s] 99%|█████████▉| 17369/17525 [3:27:56<01:29,  1.74it/s] 99%|█████████▉| 17370/17525 [3:27:56<01:30,  1.72it/s]                                                       {'loss': 0.3573, 'grad_norm': 12.558786392211914, 'learning_rate': 4.437410165477607e-09, 'epoch': 24.78}
 99%|█████████▉| 17370/17525 [3:27:56<01:30,  1.72it/s] 99%|█████████▉| 17371/17525 [3:27:57<01:30,  1.71it/s] 99%|█████████▉| 17372/17525 [3:27:58<01:34,  1.61it/s] 99%|█████████▉| 17373/17525 [3:27:58<01:32,  1.65it/s] 99%|█████████▉| 17374/17525 [3:27:59<01:30,  1.67it/s] 99%|█████████▉| 17375/17525 [3:27:59<01:28,  1.69it/s] 99%|█████████▉| 17376/17525 [3:28:00<01:27,  1.70it/s] 99%|█████████▉| 17377/17525 [3:28:01<01:26,  1.71it/s] 99%|█████████▉| 17378/17525 [3:28:01<01:25,  1.72it/s] 99%|█████████▉| 17379/17525 [3:28:02<01:24,  1.72it/s] 99%|█████████▉| 17380/17525 [3:28:02<01:23,  1.73it/s]                                                       {'loss': 0.4183, 'grad_norm': 9.936393737792969, 'learning_rate': 3.918919550026656e-09, 'epoch': 24.79}
 99%|█████████▉| 17380/17525 [3:28:02<01:23,  1.73it/s] 99%|█████████▉| 17381/17525 [3:28:03<01:23,  1.73it/s] 99%|█████████▉| 17382/17525 [3:28:03<01:22,  1.73it/s] 99%|█████████▉| 17383/17525 [3:28:04<01:22,  1.73it/s] 99%|█████████▉| 17384/17525 [3:28:05<01:21,  1.73it/s] 99%|█████████▉| 17385/17525 [3:28:05<01:20,  1.73it/s] 99%|█████████▉| 17386/17525 [3:28:06<01:20,  1.74it/s] 99%|█████████▉| 17387/17525 [3:28:06<01:19,  1.74it/s] 99%|█████████▉| 17388/17525 [3:28:07<01:18,  1.74it/s] 99%|█████████▉| 17389/17525 [3:28:08<01:35,  1.42it/s] 99%|█████████▉| 17390/17525 [3:28:08<01:29,  1.50it/s]                                                       {'loss': 0.3898, 'grad_norm': 7.071048259735107, 'learning_rate': 3.43262517551346e-09, 'epoch': 24.81}
 99%|█████████▉| 17390/17525 [3:28:08<01:29,  1.50it/s] 99%|█████████▉| 17391/17525 [3:28:09<01:25,  1.57it/s] 99%|█████████▉| 17392/17525 [3:28:10<01:22,  1.61it/s] 99%|█████████▉| 17393/17525 [3:28:10<01:20,  1.65it/s] 99%|█████████▉| 17394/17525 [3:28:11<01:18,  1.68it/s] 99%|█████████▉| 17395/17525 [3:28:11<01:16,  1.69it/s] 99%|█████████▉| 17396/17525 [3:28:12<01:15,  1.71it/s] 99%|█████████▉| 17397/17525 [3:28:13<01:14,  1.71it/s] 99%|█████████▉| 17398/17525 [3:28:13<01:13,  1.72it/s] 99%|█████████▉| 17399/17525 [3:28:14<01:13,  1.73it/s] 99%|█████████▉| 17400/17525 [3:28:14<01:12,  1.72it/s]                                                       {'loss': 0.4304, 'grad_norm': 10.59312629699707, 'learning_rate': 2.97852860823844e-09, 'epoch': 24.82}
 99%|█████████▉| 17400/17525 [3:28:14<01:12,  1.72it/s][INFO|trainer.py:3512] 2024-06-25 05:31:36,156 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:31:36,157 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:31:36,157 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.78it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.05it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.63it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.69it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.04it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.20it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.02it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A                                                       
                                               [A{'eval_loss': 1.198254942893982, 'eval_runtime': 4.5964, 'eval_samples_per_second': 96.379, 'eval_steps_per_second': 4.134, 'epoch': 24.82}
 99%|█████████▉| 17400/17525 [3:28:19<01:12,  1.72it/s]
100%|██████████| 19/19 [00:04<00:00,  3.76it/s][A
                                               [A[INFO|trainer.py:3203] 2024-06-25 05:31:40,757 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17400
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7d15990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d99c3c2d-903e-49c8-9c79-40c8891240f1)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:31:50,816 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:31:50,818 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/checkpoint-17400/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
 99%|█████████▉| 17401/17525 [3:28:30<10:27,  5.06s/it] 99%|█████████▉| 17402/17525 [3:28:30<07:36,  3.71s/it] 99%|█████████▉| 17403/17525 [3:28:31<05:38,  2.77s/it] 99%|█████████▉| 17404/17525 [3:28:32<04:31,  2.24s/it] 99%|█████████▉| 17405/17525 [3:28:32<03:28,  1.74s/it] 99%|█████████▉| 17406/17525 [3:28:33<02:45,  1.39s/it] 99%|█████████▉| 17407/17525 [3:28:34<02:15,  1.15s/it] 99%|█████████▉| 17408/17525 [3:28:34<01:54,  1.03it/s] 99%|█████████▉| 17409/17525 [3:28:35<01:39,  1.17it/s] 99%|█████████▉| 17410/17525 [3:28:36<01:33,  1.22it/s]                                                       {'loss': 0.3326, 'grad_norm': 6.2291998863220215, 'learning_rate': 2.5566313107938667e-09, 'epoch': 24.84}
 99%|█████████▉| 17410/17525 [3:28:36<01:33,  1.22it/s] 99%|█████████▉| 17411/17525 [3:28:36<01:25,  1.34it/s] 99%|█████████▉| 17412/17525 [3:28:37<01:18,  1.44it/s] 99%|█████████▉| 17413/17525 [3:28:37<01:14,  1.51it/s] 99%|█████████▉| 17414/17525 [3:28:38<01:16,  1.46it/s] 99%|█████████▉| 17415/17525 [3:28:39<01:12,  1.51it/s] 99%|█████████▉| 17416/17525 [3:28:40<01:20,  1.35it/s] 99%|█████████▉| 17417/17525 [3:28:40<01:14,  1.45it/s] 99%|█████████▉| 17418/17525 [3:28:41<01:10,  1.51it/s] 99%|█████████▉| 17419/17525 [3:28:41<01:07,  1.56it/s] 99%|█████████▉| 17420/17525 [3:28:42<01:05,  1.61it/s]                                                       {'loss': 0.339, 'grad_norm': 12.325597763061523, 'learning_rate': 2.166934642063856e-09, 'epoch': 24.85}
 99%|█████████▉| 17420/17525 [3:28:42<01:05,  1.61it/s] 99%|█████████▉| 17421/17525 [3:28:42<01:03,  1.64it/s] 99%|█████████▉| 17422/17525 [3:28:43<01:01,  1.67it/s] 99%|█████████▉| 17423/17525 [3:28:44<01:00,  1.69it/s] 99%|█████████▉| 17424/17525 [3:28:44<00:59,  1.70it/s] 99%|█████████▉| 17425/17525 [3:28:45<00:58,  1.71it/s] 99%|█████████▉| 17426/17525 [3:28:45<00:57,  1.72it/s] 99%|█████████▉| 17427/17525 [3:28:46<00:56,  1.72it/s] 99%|█████████▉| 17428/17525 [3:28:47<01:18,  1.23it/s] 99%|█████████▉| 17429/17525 [3:28:48<01:11,  1.35it/s] 99%|█████████▉| 17430/17525 [3:28:48<01:05,  1.44it/s]                                                       {'loss': 0.3626, 'grad_norm': 7.662369251251221, 'learning_rate': 1.8094398572154891e-09, 'epoch': 24.86}
 99%|█████████▉| 17430/17525 [3:28:48<01:05,  1.44it/s] 99%|█████████▉| 17431/17525 [3:28:49<01:01,  1.52it/s] 99%|█████████▉| 17432/17525 [3:28:50<00:59,  1.58it/s] 99%|█████████▉| 17433/17525 [3:28:50<00:56,  1.62it/s] 99%|█████████▉| 17434/17525 [3:28:51<00:55,  1.65it/s] 99%|█████████▉| 17435/17525 [3:28:51<00:53,  1.67it/s] 99%|█████████▉| 17436/17525 [3:28:52<00:52,  1.69it/s] 99%|█████████▉| 17437/17525 [3:28:52<00:51,  1.70it/s]100%|█████████▉| 17438/17525 [3:28:53<00:50,  1.71it/s]100%|█████████▉| 17439/17525 [3:28:54<00:50,  1.71it/s]100%|█████████▉| 17440/17525 [3:28:54<00:49,  1.71it/s]                                                       {'loss': 0.4226, 'grad_norm': 16.01782989501953, 'learning_rate': 1.4841481077010334e-09, 'epoch': 24.88}
100%|█████████▉| 17440/17525 [3:28:54<00:49,  1.71it/s]100%|█████████▉| 17441/17525 [3:28:55<00:48,  1.72it/s]100%|█████████▉| 17442/17525 [3:28:55<00:48,  1.72it/s]100%|█████████▉| 17443/17525 [3:28:56<00:47,  1.72it/s]100%|█████████▉| 17444/17525 [3:28:57<00:46,  1.72it/s]100%|█████████▉| 17445/17525 [3:28:57<00:46,  1.73it/s]100%|█████████▉| 17446/17525 [3:28:58<00:45,  1.73it/s]100%|█████████▉| 17447/17525 [3:28:58<00:45,  1.73it/s]100%|█████████▉| 17448/17525 [3:28:59<00:44,  1.73it/s]100%|█████████▉| 17449/17525 [3:28:59<00:43,  1.73it/s]100%|█████████▉| 17450/17525 [3:29:00<00:43,  1.73it/s]                                                       {'loss': 0.3408, 'grad_norm': 10.367748260498047, 'learning_rate': 1.1910604412468384e-09, 'epoch': 24.89}
100%|█████████▉| 17450/17525 [3:29:00<00:43,  1.73it/s]100%|█████████▉| 17451/17525 [3:29:01<00:42,  1.73it/s]100%|█████████▉| 17452/17525 [3:29:01<00:42,  1.71it/s]100%|█████████▉| 17453/17525 [3:29:02<00:42,  1.71it/s]100%|█████████▉| 17454/17525 [3:29:02<00:41,  1.72it/s]100%|█████████▉| 17455/17525 [3:29:03<00:40,  1.72it/s]100%|█████████▉| 17456/17525 [3:29:04<00:47,  1.45it/s]100%|█████████▉| 17457/17525 [3:29:04<00:44,  1.53it/s]100%|█████████▉| 17458/17525 [3:29:05<00:42,  1.58it/s]100%|█████████▉| 17459/17525 [3:29:06<00:40,  1.62it/s]100%|█████████▉| 17460/17525 [3:29:06<00:39,  1.65it/s]                                                       {'loss': 0.3383, 'grad_norm': 4.947216987609863, 'learning_rate': 9.301778018555585e-10, 'epoch': 24.91}
100%|█████████▉| 17460/17525 [3:29:06<00:39,  1.65it/s]100%|█████████▉| 17461/17525 [3:29:07<00:38,  1.68it/s]100%|█████████▉| 17462/17525 [3:29:07<00:37,  1.69it/s]100%|█████████▉| 17463/17525 [3:29:08<00:36,  1.70it/s]100%|█████████▉| 17464/17525 [3:29:08<00:35,  1.71it/s]100%|█████████▉| 17465/17525 [3:29:09<00:34,  1.72it/s]100%|█████████▉| 17466/17525 [3:29:10<00:34,  1.72it/s]100%|█████████▉| 17467/17525 [3:29:10<00:33,  1.73it/s]100%|█████████▉| 17468/17525 [3:29:11<00:32,  1.73it/s]100%|█████████▉| 17469/17525 [3:29:11<00:32,  1.73it/s]100%|█████████▉| 17470/17525 [3:29:12<00:31,  1.73it/s]                                                       {'loss': 0.3312, 'grad_norm': 8.78575611114502, 'learning_rate': 7.015010297994895e-10, 'epoch': 24.92}
100%|█████████▉| 17470/17525 [3:29:12<00:31,  1.73it/s]100%|█████████▉| 17471/17525 [3:29:13<00:31,  1.73it/s]100%|█████████▉| 17472/17525 [3:29:13<00:30,  1.73it/s]100%|█████████▉| 17473/17525 [3:29:14<00:30,  1.73it/s]100%|█████████▉| 17474/17525 [3:29:14<00:29,  1.73it/s]100%|█████████▉| 17475/17525 [3:29:15<00:28,  1.73it/s]100%|█████████▉| 17476/17525 [3:29:15<00:28,  1.71it/s]100%|█████████▉| 17477/17525 [3:29:16<00:27,  1.72it/s]100%|█████████▉| 17478/17525 [3:29:17<00:38,  1.23it/s]100%|█████████▉| 17479/17525 [3:29:18<00:34,  1.34it/s]100%|█████████▉| 17480/17525 [3:29:19<00:31,  1.44it/s]                                                       {'loss': 0.2759, 'grad_norm': 8.840595245361328, 'learning_rate': 5.050308616216803e-10, 'epoch': 24.94}
100%|█████████▉| 17480/17525 [3:29:19<00:31,  1.44it/s]100%|█████████▉| 17481/17525 [3:29:19<00:29,  1.52it/s]100%|█████████▉| 17482/17525 [3:29:20<00:27,  1.58it/s]100%|█████████▉| 17483/17525 [3:29:20<00:25,  1.62it/s]100%|█████████▉| 17484/17525 [3:29:21<00:24,  1.65it/s]100%|█████████▉| 17485/17525 [3:29:21<00:23,  1.68it/s]100%|█████████▉| 17486/17525 [3:29:22<00:23,  1.69it/s]100%|█████████▉| 17487/17525 [3:29:23<00:22,  1.71it/s]100%|█████████▉| 17488/17525 [3:29:23<00:21,  1.71it/s]100%|█████████▉| 17489/17525 [3:29:24<00:20,  1.72it/s]100%|█████████▉| 17490/17525 [3:29:24<00:20,  1.73it/s]                                                       {'loss': 0.361, 'grad_norm': 19.15407371520996, 'learning_rate': 3.4076793013038123e-10, 'epoch': 24.95}
100%|█████████▉| 17490/17525 [3:29:24<00:20,  1.73it/s]100%|█████████▉| 17491/17525 [3:29:25<00:19,  1.73it/s]100%|█████████▉| 17492/17525 [3:29:25<00:19,  1.73it/s]100%|█████████▉| 17493/17525 [3:29:26<00:18,  1.73it/s]100%|█████████▉| 17494/17525 [3:29:27<00:17,  1.73it/s]100%|█████████▉| 17495/17525 [3:29:27<00:17,  1.73it/s]100%|█████████▉| 17496/17525 [3:29:28<00:16,  1.73it/s]100%|█████████▉| 17497/17525 [3:29:28<00:16,  1.74it/s]100%|█████████▉| 17498/17525 [3:29:29<00:15,  1.74it/s]100%|█████████▉| 17499/17525 [3:29:29<00:14,  1.74it/s]100%|█████████▉| 17500/17525 [3:29:30<00:14,  1.74it/s]                                                       {'loss': 0.3648, 'grad_norm': 12.575352668762207, 'learning_rate': 2.0871276439682342e-10, 'epoch': 24.96}
100%|█████████▉| 17500/17525 [3:29:30<00:14,  1.74it/s][INFO|trainer.py:3512] 2024-06-25 05:32:51,935 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:32:51,935 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:32:51,935 >>   Batch size = 4

  0%|          | 0/19 [00:00<?, ?it/s][A
 11%|█         | 2/19 [00:00<00:02,  5.77it/s][A
 16%|█▌        | 3/19 [00:00<00:03,  4.85it/s][A
 21%|██        | 4/19 [00:00<00:03,  4.04it/s][A
 26%|██▋       | 5/19 [00:01<00:03,  4.39it/s][A
 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s][A
 37%|███▋      | 7/19 [00:01<00:02,  4.87it/s][A
 42%|████▏     | 8/19 [00:01<00:02,  4.34it/s][A
 47%|████▋     | 9/19 [00:01<00:02,  4.59it/s][A
 53%|█████▎    | 10/19 [00:02<00:01,  4.70it/s][A
 58%|█████▊    | 11/19 [00:02<00:01,  4.74it/s][A
 63%|██████▎   | 12/19 [00:02<00:01,  4.82it/s][A
 68%|██████▊   | 13/19 [00:02<00:01,  4.88it/s][A
 74%|███████▎  | 14/19 [00:02<00:00,  5.03it/s][A
 79%|███████▉  | 15/19 [00:03<00:00,  5.14it/s][A
 84%|████████▍ | 16/19 [00:03<00:00,  5.19it/s][A
 89%|████████▉ | 17/19 [00:03<00:00,  3.61it/s][A
 95%|█████████▍| 18/19 [00:03<00:00,  4.01it/s][A
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A                                                       
                                               [A{'eval_loss': 1.1984163522720337, 'eval_runtime': 4.6006, 'eval_samples_per_second': 96.292, 'eval_steps_per_second': 4.13, 'epoch': 24.96}
100%|█████████▉| 17500/17525 [3:29:35<00:14,  1.74it/s]
100%|██████████| 19/19 [00:04<00:00,  3.75it/s][A
                                               [A100%|█████████▉| 17501/17525 [3:29:35<00:46,  1.96s/it]100%|█████████▉| 17502/17525 [3:29:36<00:35,  1.55s/it]100%|█████████▉| 17503/17525 [3:29:36<00:27,  1.26s/it]100%|█████████▉| 17504/17525 [3:29:37<00:22,  1.05s/it]100%|█████████▉| 17505/17525 [3:29:38<00:18,  1.10it/s]100%|█████████▉| 17506/17525 [3:29:38<00:15,  1.24it/s]100%|█████████▉| 17507/17525 [3:29:39<00:13,  1.35it/s]100%|█████████▉| 17508/17525 [3:29:39<00:11,  1.45it/s]100%|█████████▉| 17509/17525 [3:29:40<00:10,  1.53it/s]100%|█████████▉| 17510/17525 [3:29:40<00:09,  1.58it/s]                                                       {'loss': 0.3842, 'grad_norm': 8.010016441345215, 'learning_rate': 1.0886578975632944e-10, 'epoch': 24.98}
100%|█████████▉| 17510/17525 [3:29:40<00:09,  1.58it/s]100%|█████████▉| 17511/17525 [3:29:41<00:08,  1.63it/s]100%|█████████▉| 17512/17525 [3:29:42<00:07,  1.65it/s]100%|█████████▉| 17513/17525 [3:29:42<00:07,  1.67it/s]100%|█████████▉| 17514/17525 [3:29:43<00:06,  1.68it/s]100%|█████████▉| 17515/17525 [3:29:43<00:05,  1.70it/s]100%|█████████▉| 17516/17525 [3:29:44<00:05,  1.71it/s]100%|█████████▉| 17517/17525 [3:29:44<00:04,  1.72it/s]100%|█████████▉| 17518/17525 [3:29:45<00:04,  1.72it/s]100%|█████████▉| 17519/17525 [3:29:46<00:03,  1.72it/s]100%|█████████▉| 17520/17525 [3:29:46<00:02,  1.73it/s]                                                       {'loss': 0.345, 'grad_norm': 7.451024055480957, 'learning_rate': 4.122732780387217e-11, 'epoch': 24.99}
100%|█████████▉| 17520/17525 [3:29:46<00:02,  1.73it/s]100%|█████████▉| 17521/17525 [3:29:47<00:02,  1.73it/s]100%|█████████▉| 17522/17525 [3:29:47<00:01,  1.73it/s]100%|█████████▉| 17523/17525 [3:29:48<00:01,  1.73it/s]100%|█████████▉| 17524/17525 [3:29:49<00:00,  1.73it/s]100%|██████████| 17525/17525 [3:29:49<00:00,  1.74it/s][INFO|trainer.py:2231] 2024-06-25 05:33:10,977 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                       {'train_runtime': 12589.6578, 'train_samples_per_second': 16.696, 'train_steps_per_second': 1.392, 'train_loss': 0.5035748872199174, 'epoch': 25.0}
100%|██████████| 17525/17525 [3:29:49<00:00,  1.74it/s]100%|██████████| 17525/17525 [3:29:49<00:00,  1.39it/s]
[INFO|trainer.py:3203] 2024-06-25 05:33:11,006 >> Saving model checkpoint to LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /Yi-9B-post-pt/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x2b28a7ca5990>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: a18f33d3-0992-4ba9-b8cc-8b468d259a7e)') - silently ignoring the lookup for the file config.json in Yi-9B-post-pt.
  warnings.warn(
/HOME/scz4074/.conda/envs/fine-tuning-LLM/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in Yi-9B-post-pt - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2502] 2024-06-25 05:33:21,120 >> tokenizer config file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/tokenizer_config.json
[INFO|tokenization_utils_base.py:2511] 2024-06-25 05:33:21,123 >> Special tokens file saved in LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/special_tokens_map.json
The OrderedVocab you are attempting to save contains holes for indices [3, 4, 5, 9, 10, 11, 12, 13], your vocabulary could be corrupted !
***** train metrics *****
  epoch                    =       25.0
  train_loss               =     0.5036
  train_runtime            = 3:29:49.65
  train_samples_per_second =     16.696
  train_steps_per_second   =      1.392
Figure saved at: LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/training_loss.png
Figure saved at: LLaMA-Factory/LLaMA-Factory-main/saves/Yi-9B/sft/training_eval_loss.png
[INFO|trainer.py:3512] 2024-06-25 05:33:25,863 >> ***** Running Evaluation *****
[INFO|trainer.py:3514] 2024-06-25 05:33:25,863 >>   Num examples = 443
[INFO|trainer.py:3517] 2024-06-25 05:33:25,863 >>   Batch size = 4
  0%|          | 0/19 [00:00<?, ?it/s] 11%|█         | 2/19 [00:00<00:02,  5.78it/s] 16%|█▌        | 3/19 [00:00<00:03,  4.86it/s] 21%|██        | 4/19 [00:00<00:03,  4.06it/s] 26%|██▋       | 5/19 [00:01<00:03,  4.40it/s] 32%|███▏      | 6/19 [00:01<00:02,  4.64it/s] 37%|███▋      | 7/19 [00:01<00:02,  4.88it/s] 42%|████▏     | 8/19 [00:01<00:02,  4.35it/s] 47%|████▋     | 9/19 [00:01<00:02,  4.61it/s] 53%|█████▎    | 10/19 [00:02<00:01,  4.71it/s] 58%|█████▊    | 11/19 [00:02<00:01,  4.76it/s] 63%|██████▎   | 12/19 [00:02<00:01,  4.83it/s] 68%|██████▊   | 13/19 [00:02<00:01,  4.89it/s] 74%|███████▎  | 14/19 [00:02<00:00,  5.06it/s] 79%|███████▉  | 15/19 [00:03<00:00,  5.16it/s] 84%|████████▍ | 16/19 [00:03<00:00,  5.21it/s] 89%|████████▉ | 17/19 [00:03<00:00,  3.62it/s] 95%|█████████▍| 18/19 [00:03<00:00,  4.03it/s]100%|██████████| 19/19 [00:04<00:00,  3.77it/s]100%|██████████| 19/19 [00:04<00:00,  4.45it/s]
***** eval metrics *****
  epoch                   =       25.0
  eval_loss               =     1.1985
  eval_runtime            = 0:00:04.60
  eval_samples_per_second =       96.1
  eval_steps_per_second   =      4.122
[INFO|modelcard.py:450] 2024-06-25 05:33:30,482 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
